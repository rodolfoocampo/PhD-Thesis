@ARTICLE{Essel2024-qc,
  title     = "{ChatGPT} effects on cognitive skills of undergraduate students:
               Receiving instant responses from {AI}-based conversational large
               language models ({LLMs})",
  author    = "Essel, Harry Barton and Vlachopoulos, Dimitrios and Essuman,
               Albert Benjamin and Amankwa, John Opuni",
  journal   = "Computers and Education: Artificial Intelligence",
  publisher = "Elsevier BV",
  volume    =  6,
  number    =  100198,
  pages     =  100198,
  month     =  jun,
  year      =  2024,
  language  = "en"
}

@ARTICLE{Lubart2005-zi,
  title    = "How can computers be partners in the creative process:
              {Classification} and commentary on the {Special} {Issue}",
  author   = "Lubart, Todd",
  journal  = "Int. J. Hum. Comput. Stud.",
  volume   =  63,
  number   =  4,
  pages    = "365--369",
  abstract = "The different ways that computers can be involved in creative work
              are examined. A classification based on four categories of
              human–computer interaction to promote creativity is proposed:
              computers may facilitate (a) the management of creative work, (b)
              communication between individuals collaborating on creative
              projects, (c) the use of creativity enhancement techniques, (d)
              the creative act through integrated human–computer cooperation
              during idea production. The papers in the Special Issue are
              discussed according to this classification. Issues to be
              considered in future work on human–computer interactions for
              promoting creativity are discussed.",
  series   = "Computer support for creativity",
  month    =  oct,
  year     =  2005,
  keywords = "Creativity, Human–computer interaction",
  language = "en"
}

@ARTICLE{Allen1999-sr,
  title   = "Mixed-initiative interaction",
  author  = "Allen, J E and Guinn, C I and Horvtz, E",
  journal = "IEEE Intelligent Systems and their Applications",
  volume  =  14,
  number  =  5,
  pages   = "14--23",
  year    =  1999
}

@INPROCEEDINGS{Kantosalo2021-mp,
  title       = "Role-based perceptions of computer participants in
                 human-computer co-creativity",
  author      = "Kantosalo, Anna and Jordanous, Anna",
  institution = "AISB",
  year        =  2021
}

@ARTICLE{Guzik2023-cl,
  title     = "The originality of machines: {AI} takes the Torrance Test",
  author    = "Guzik, Erik E and Byrge, Christian and Gilde, Christian",
  journal   = "Journal of Creativity",
  publisher = "Elsevier BV",
  volume    =  33,
  number    =  3,
  pages     =  100065,
  abstract  = "This exploratory research investigated the creative abilities of
               OpenAI's large language model, ChatGPT, based on the GPT-4
               architecture, as assessed …",
  month     =  dec,
  year      =  2023,
  language  = "en"
}

@INPROCEEDINGS{Chakrabarty2024-ov,
  title     = "Creativity support in the age of large language models: An
               empirical study involving professional writers",
  author    = "Chakrabarty, Tuhin and Padmakumar, Vishakh and Brahman, Faeze and
               Muresan, Smaranda",
  booktitle = "Creativity and Cognition",
  publisher = "ACM",
  address   = "New York, NY, USA",
  month     =  jun,
  year      =  2024,
  language  = "en"
}

@INPROCEEDINGS{Li2024-yh,
  title     = "User experience design professionals’ perceptions of generative
               artificial intelligence",
  author    = "Li, Jie and Cao, Hancheng and Lin, Laura and Hou, Youyang and
               Zhu, Ruihao and El Ali, Abdallah",
  booktitle = "Proceedings of the CHI Conference on Human Factors in Computing
               Systems",
  publisher = "ACM",
  address   = "New York, NY, USA",
  volume    =  2,
  pages     = "1--18",
  month     =  may,
  year      =  2024,
  language  = "en"
}

@INPROCEEDINGS{Han2024-cq,
  title     = "When teams embrace {AI}: Human collaboration strategies in
               generative prompting in a creative design task",
  author    = "Han, Yuanning and Qiu, Ziyi and Cheng, Jiale and Lc, Ray",
  booktitle = "Proceedings of the CHI Conference on Human Factors in Computing
               Systems",
  publisher = "ACM",
  address   = "New York, NY, USA",
  volume    =  23,
  pages     = "1--14",
  month     =  may,
  year      =  2024,
  language  = "en"
}

@ARTICLE{McGuire2024-im,
  title     = "Establishing the importance of co-creation and self-efficacy in
               creative collaboration with artificial intelligence",
  author    = "McGuire, Jack and De Cremer, David and Van de Cruys, Tim",
  journal   = "Sci. Rep.",
  publisher = "Springer Science and Business Media LLC",
  volume    =  14,
  number    =  1,
  pages     =  18525,
  abstract  = "The emergence of generative AI technologies has led to an
               increasing number of people collaborating with AI to produce
               creative works. Across two experimental studies, in which we
               carefully designed and programmed state-of-the-art human-AI
               interfaces, we examine how the design of generative AI systems
               influences human creativity (poetry writing). First, we find that
               people were most creative when writing a poem on their own,
               compared to first receiving a poem generated by an AI system and
               using sophisticated tools to edit it (Study 1). Following this,
               we demonstrate that this creativity deficit dissipates when
               people co-create with-not edit-AI and establish creative
               self-efficacy as an important mechanism in this process (Study
               2). Thus, our findings indicate that people must occupy the role
               of a co-creator, not an editor, to reap the benefits of
               generative AI in the production of creative works.",
  month     =  aug,
  year      =  2024,
  keywords  = "Artificial intelligence; Co-creation; Creativity; Self-efficacy",
  language  = "en"
}

@INCOLLECTION{Moura2024-zb,
  title     = "Rethinking creativity frameworks for artificial intelligence",
  author    = "Moura, Francisco Tigre",
  booktitle = "Artificial Intelligence, Co-Creation and Creativity",
  publisher = "Routledge",
  address   = "London",
  edition   = "1st Edition",
  pages     = "32--44",
  abstract  = "The rapid development and adoption of artificial intelligence
               (AI) into creative processes has brought about a transformative
               era, challenging established notions of creativity. Traditional
               creativity frameworks, such as the 4Ps, 5As, 7Cs, and 8Ps,
               grounded in human-centric assumptions, fail to address the
               impersonal and autonomous nature of intelligent systems. Also,
               AI’s efficiency in problem-solving across domains challenges the
               domain specificity often associated with human creativity. AI
               exhibits unprecedented capabilities in tasks like composing
               music, writing poetry, and designing art, often rivalling human
               creativity. However, this shift raises fundamental questions
               about the nature of creativity, including attributing
               intentionality to AI-generated outputs. This chapter reviews
               recent frameworks, such as the 5C model, specifically designed
               for human–computer co-creativity, to propose adaptations to
               existing creativity frameworks, such as the 8P model. Exploring
               missing elements in traditional frameworks, the chapter addresses
               gaps related to propulsion, problem, and purpose. As AI adoption
               accelerates, distinguishing between human- and AI-generated
               creative outputs becomes increasingly challenging, necessitating
               an inclusive framework that embraces this evolving reality. Thus,
               the chapter concludes by advocating for a paradigm shift in
               creativity understanding, acknowledging smart systems as vital
               creative agents, and suggesting future research directions that
               emphasize the dynamic nature of human–AI collaboration.",
  month     =  jun,
  year      =  2024,
  language  = "en"
}

@ARTICLE{Uitdenbogerd2023-no,
  title     = "Raging with the machine in the uncanny valley: {Human–AI}
               cocreativity in the eurovision-themed {AI} Song Contest",
  author    = "Uitdenbogerd, Alexandra L and Bown, Oliver and Hill, Charlton and
               Pegram, Caroline and Shave, Justin and Wright, Brendan",
  journal   = "Comput. Music J.",
  publisher = "MIT Press",
  volume    =  47,
  number    =  1,
  pages     = "44--63",
  abstract  = "Abstract We report here the processes involved in creating our
               entry in the 2020 AI Song Contest, “Beautiful the World”; the
               technical innovations from the project; and the decision-making
               that divided tasks between human and machine in a way that
               ensured that the final creation was AI-inspired but
               human-created, starting from generated melodies, lyrics, and
               timbres. Key innovations include the use of lyric stress patterns
               as queries to a stress-based melody index to a database of
               generated melodies, and the creation of a novel instrument timbre
               with differential digital signal processing, trained on
               Australian animal calls. We reflect on how human–AI cocreativity
               occurred during the process and how it may develop in the future.",
  month     =  jun,
  year      =  2023,
  language  = "en"
}

@INPROCEEDINGS{Zhou2024-vp,
  title     = "Understanding nonlinear collaboration between human and {AI}
               agents: A co-design framework for creative design",
  author    = "Zhou, Jiayi and Li, Renzhong and Tang, Junxiu and Tang, Tan and
               Li, Haotian and Cui, Weiwei and Wu, Yingcai",
  booktitle = "Proceedings of the CHI Conference on Human Factors in Computing
               Systems",
  publisher = "ACM",
  address   = "New York, NY, USA",
  pages     = "1--16",
  month     =  may,
  year      =  2024,
  language  = "en"
}

@ARTICLE{Ding2023-wp,
  title         = "Mapping the design space of interactions in human-{AI} text
                   co-creation tasks",
  author        = "Ding, Zijian and Chan, Joel",
  journal       = "arXiv [cs.AI]",
  abstract      = "Large Language Models (LLMs) have demonstrated impressive
                   text generation capabilities, prompting us to reconsider the
                   future of human-AI co-creation and how humans interact with
                   LLMs. In this paper, we present a spectrum of content
                   generation tasks and their corresponding human-AI interaction
                   patterns. These tasks include: 1) fixed-scope content
                   curation tasks with minimal human-AI interactions, 2)
                   independent creative tasks with precise human-AI
                   interactions, and 3) complex and interdependent creative
                   tasks with iterative human-AI interactions. We encourage the
                   generative AI and HCI research communities to focus on the
                   more complex and interdependent tasks, which require greater
                   levels of human involvement.",
  month         =  mar,
  year          =  2023,
  archivePrefix = "arXiv",
  primaryClass  = "cs.AI"
}

@ARTICLE{Wadinambiarachchi2024-jn,
  title         = "The effects of generative {AI} on design fixation and
                   divergent thinking",
  author        = "Wadinambiarachchi, Samangi and Kelly, Ryan M and Pareek,
                   Saumya and Zhou, Qiushi and Velloso, Eduardo",
  journal       = "arXiv [cs.HC]",
  abstract      = "Generative AI systems have been heralded as tools for
                   augmenting human creativity and inspiring divergent thinking,
                   though with little empirical evidence for these claims. This
                   paper explores the effects of exposure to AI-generated images
                   on measures of design fixation and divergent thinking in a
                   visual ideation task. Through a between-participants
                   experiment (N=60), we found that support from an AI image
                   generator during ideation leads to higher fixation on an
                   initial example. Participants who used AI produced fewer
                   ideas, with less variety and lower originality compared to a
                   baseline. Our qualitative analysis suggests that the
                   effectiveness of co-ideation with AI rests on participants'
                   chosen approach to prompt creation and on the strategies used
                   by participants to generate ideas in response to the AI's
                   suggestions. We discuss opportunities for designing
                   generative AI systems for ideation support and incorporating
                   these AI tools into ideation workflows.",
  month         =  mar,
  year          =  2024,
  archivePrefix = "arXiv",
  primaryClass  = "cs.HC"
}

@ARTICLE{Koch2020-gx,
  title     = "{ImageSense}: An intelligent collaborative ideation tool to
               support diverse human-computer partnerships",
  author    = "Koch, Janin and Taffin, Nicolas and Beaudouin-Lafon, Michel and
               Laine, Markku and Lucero, Andrés and Mackay, Wendy E",
  journal   = "Proc. ACM Hum. Comput. Interact.",
  publisher = "Association for Computing Machinery (ACM)",
  volume    =  4,
  number    = "CSCW1",
  pages     = "1--27",
  abstract  = "Professional designers create mood boards to explore, visualize,
               and communicate hard-to-express ideas. We present ImageCascade,
               an intelligent, collaborative ideation tool that combines
               individual and shared work spaces, as well as collaboration with
               multiple forms of intelligent agents. In the collection phase,
               ImageCascade offers fluid transitions between serendipitous
               discovery of curated images via ImageCascade, combined text- and
               image-based Semantic search, and intelligent AI suggestions for
               finding new images. For later composition and reflection,
               ImageCascade provides semantic labels, generated color palettes,
               and multiple tag clouds to help communicate the intent of the
               mood board. A study of nine professional designers revealed
               nuances in designers' preferences for designer-led, system-led,
               and mixed-initiative approaches that evolve throughout the design
               process. We discuss the challenges in creating effective
               human-computer partnerships for creative activities, and suggest
               directions for future research.",
  month     =  may,
  year      =  2020,
  language  = "en"
}

@ARTICLE{McCormack2024-gv,
  title         = "Mimetic Poet",
  author        = "McCormack, Jon and Wilson, Elliott and Rajcic, Nina and
                   Llano, Maria Teresa",
  journal       = "arXiv [cs.HC]",
  abstract      = "This paper presents the design and initial assessment of a
                   novel device that uses generative AI to facilitate creative
                   ideation, inspiration, and reflective thought. Inspired by
                   magnetic poetry, which was originally designed to help
                   overcome writer's block, the device allows participants to
                   compose short poetic texts from a limited vocabulary by
                   physically placing words on the device's surface. Upon
                   composing the text, the system employs a large language model
                   (LLM) to generate a response, displayed on an e-ink screen.
                   We explored various strategies for internally sequencing
                   prompts to foster creative thinking, including analogy,
                   allegorical interpretations, and ideation. We installed the
                   device in our research laboratory for two weeks and held a
                   focus group at the conclusion to evaluate the design. The
                   design choice to limit interactions with the LLM to poetic
                   text, coupled with the tactile experience of assembling the
                   poem, fostered a deeper and more enjoyable engagement with
                   the LLM compared to traditional chatbot or screen-based
                   interactions. This approach gives users the opportunity to
                   reflect on the AI-generated responses in a manner conducive
                   to creative thought.",
  month         =  jun,
  year          =  2024,
  archivePrefix = "arXiv",
  primaryClass  = "cs.HC"
}

@ARTICLE{Nguyen2024-pc,
  title     = "Human-{AI} collaboration patterns in {AI}-assisted academic
               writing",
  author    = "Nguyen, Andy and Hong, Yvonne and Dang, Belle and Huang, Xiaoshan",
  journal   = "Stud. High. Educ.",
  publisher = "Informa UK Limited",
  volume    =  49,
  number    =  5,
  pages     = "847--864",
  month     =  may,
  year      =  2024,
  language  = "en"
}

@INPROCEEDINGS{Lee2024-hd,
  title     = "A Design Space for Intelligent and Interactive Writing Assistants",
  author    = "Lee, Mina and Gero, Katy Ilonka and Chung, John Joon Young and
               Shum, Simon Buckingham and Raheja, Vipul and Shen, Hua and
               Venugopalan, Subhashini and Wambsganss, Thiemo and Zhou, David
               and Alghamdi, Emad A and August, Tal and Bhat, Avinash and
               Choksi, Madiha Zahrah and Dutta, Senjuti and Guo, Jin L C and
               Hoque, Md Naimul and Kim, Yewon and Knight, Simon and Neshaei,
               Seyed Parsa and Shibani, Antonette and Shrivastava, Disha and
               Shroff, Lila and Sergeyuk, Agnia and Stark, Jessi and Sterman,
               Sarah and Wang, Sitong and Bosselut, Antoine and Buschek, Daniel
               and Chang, Joseph Chee and Chen, Sherol and Kreminski, Max and
               Park, Joonsuk and Pea, Roy and Rho, Eugenia Ha Rim and Shen,
               Zejiang and Siangliulue, Pao",
  booktitle = "Proceedings of the CHI Conference on Human Factors in Computing
               Systems",
  publisher = "ACM",
  address   = "New York, NY, USA",
  volume    =  7,
  pages     = "1--35",
  month     =  may,
  year      =  2024,
  language  = "en"
}

@INPROCEEDINGS{Masson2024-nt,
  title     = "{DirectGPT}: A direct manipulation interface to interact with
               large language models",
  author    = "Masson, Damien and Malacria, Sylvain and Casiez, Géry and Vogel,
               Daniel",
  booktitle = "Proceedings of the CHI Conference on Human Factors in Computing
               Systems",
  publisher = "ACM",
  address   = "New York, NY, USA",
  pages     = "1--16",
  month     =  may,
  year      =  2024,
  language  = "en"
}

@INPROCEEDINGS{Peng2024-tr,
  title     = "{DesignPrompt}: Using multimodal interaction for design
               exploration with generative {AI}",
  author    = "Peng, Xiaohan and Koch, Janin and Mackay, Wendy E",
  booktitle = "Designing Interactive Systems Conference",
  publisher = "ACM",
  address   = "New York, NY, USA",
  month     =  jul,
  year      =  2024
}

@INPROCEEDINGS{Park2024-gw,
  title     = "``we are visual thinkers, not verbal thinkers!'': A thematic
               analysis of how professional designers use generative {AI} image
               generation tools",
  author    = "Park, Hyerim and Eirich, Joscha and Luckow, Andre and Sedlmair,
               Michael",
  booktitle = "Nordic Conference on Human-Computer Interaction",
  publisher = "ACM",
  address   = "New York, NY, USA",
  pages     = "1--14",
  month     =  oct,
  year      =  2024,
  language  = "en"
}

@ARTICLE{Wingstrom_undated-ca,
  title     = "Redefining Creativity in the Era of {AI}? Perspectives of
               Computer Scientists and New Media Artists",
  author    = "Wingström, Roosa and Hautala, Johanna and Lundman, Riina",
  journal   = "Creat. Res. J.",
  publisher = "Routledge",
  pages     = "1--17",
  abstract  = "Artificial intelligence (AI) has breached creativity research.
               The advancements of creative AI systems dispute the common
               definitions of creativity that have traditionally focused on five
               elements: actor, process, outcome, domain, and space. Moreover,
               creative workers, such as scientists and artists, increasingly
               use AI in their creative processes, and the concept of
               co-creativity has emerged to describe blended human?AI
               creativity. These issues evoke the question of whether creativity
               requires redefinition in the era of AI. Currently, co-creativity
               is mostly studied within the framework of computer science in
               pre-organized laboratory settings. This study contributes from a
               human scientific perspective with 52 interviews of Finland-based
               computer scientists and new media artists who use AI in their
               work. The results suggest scientists and artists use similar
               elements to define creativity. However, the role of AI differs
               between the scientific and artistic creative processes.
               Scientists need AI to produce accurate and trustworthy outcomes,
               whereas artists use AI to explore and play. Unlike the
               scientists, some artists also considered their work with AI
               co-creative. We suggest that co-creativity can explain the
               contemporary creative processes in the era of AI and should be
               the focal point of future creativity research."
}

@INPROCEEDINGS{Bray2016-ff,
  title     = "Applying core interaction design principles to computational
               creativity",
  author    = "Bray, Liam and Bown, Oliver",
  booktitle = "Proceedings of the seventh international conference on
               computational creativity",
  pages     = "93--97",
  year      =  2016
}

@ARTICLE{Zhu2018-yc,
  title    = "Generative {Visual} {Manipulation} on the {Natural} {Image}
              {Manifold}",
  author   = "Zhu, Jun-Yan and Krähenbühl, Philipp and Shechtman, Eli and Efros,
              Alexei A",
  journal  = "arXiv:1609. 03552 [cs]",
  abstract = "Realistic image manipulation is challenging because it requires
              modifying the image appearance in a user-controlled way, while
              preserving the realism of the result. Unless the user has
              considerable artistic skill, it is easy to ``fall off'' the
              manifold of natural images while editing. In this paper, we
              propose to learn the natural image manifold directly from data
              using a generative adversarial neural network. We then define a
              class of image editing operations, and constrain their output to
              lie on that learned manifold at all times. The model automatically
              adjusts the output keeping all edits as realistic as possible. All
              our manipulations are expressed in terms of constrained
              optimization and are applied in near-real time. We evaluate our
              algorithm on the task of realistic photo manipulation of shape and
              color. The presented method can further be used for changing one
              image to look like the other, as well as generating novel imagery
              from scratch based on user's scribbles.",
  month    =  dec,
  year     =  2018,
  keywords = "Computer Science - Computer Vision and Pattern Recognition"
}

@ARTICLE{Heer2019-ev,
  title    = "Agency plus automation: {Designing} artificial intelligence into
              interactive systems",
  author   = "Heer, Jeffrey",
  journal  = "Proceedings of the National Academy of Sciences",
  volume   =  116,
  number   =  6,
  pages    = "1844--1850",
  abstract = "Much contemporary rhetoric regards the prospects and pitfalls of
              using artificial intelligence techniques to automate an increasing
              range of tasks, especially those once considered the purview of
              people alone. These accounts are often wildly optimistic,
              understating outstanding challenges while turning a blind eye to
              the human labor that undergirds and sustains ostensibly
              “automated” services. This long-standing focus on purely automated
              methods unnecessarily cedes a promising design space: one in which
              computational assistance augments and enriches, rather than
              replaces, people’s intellectual work. This tension between human
              agency and machine automation poses vital challenges for design
              and engineering. In this work, we consider the design of systems
              that enable rich, adaptive interaction between people and
              algorithms. We seek to balance the often-complementary strengths
              and weaknesses of each, while promoting human control and skillful
              action. We share case studies of interactive systems we have
              developed in three arenas—data wrangling, exploratory analysis,
              and natural language translation—that integrate proactive
              computational support into interactive systems. To improve
              outcomes and support learning by both people and machines, we
              describe the use of shared representations of tasks augmented with
              predictive models of human capabilities and actions. We conclude
              with a discussion of future prospects and scientific frontiers for
              intelligence augmentation research.",
  month    =  feb,
  year     =  2019,
  keywords = "artificial intelligence, automation, data science, human–computer
              interaction, visualization",
  language = "en"
}

@ARTICLE{Karimi2019-qb,
  title    = "Deep {Learning} in a {Computational} {Model} for {Conceptual}
              {Shifts} in a {Co}-{Creative} {Design} {System}",
  author   = "Karimi, Pegah and Maher, Mary Lou and Davis, Nicholas and Grace,
              Kazjon",
  journal  = "arXiv:1906. 10188 [cs, stat]",
  abstract = "This paper presents a computational model for conceptual shifts,
              based on a novelty metric applied to a vector representation
              generated through deep learning. This model is integrated into a
              co-creative design system, which enables a partnership between an
              AI agent and a human designer interacting through a sketching
              canvas. The AI agent responds to the human designer's sketch with
              a new sketch that is a conceptual shift: intentionally varying the
              visual and conceptual similarity with increasingly more novelty.
              The paper presents the results of a user study showing that
              increasing novelty in the AI contribution is associated with
              higher creative outcomes, whereas low novelty leads to less
              creative outcomes.",
  month    =  jun,
  year     =  2019,
  keywords = "Computer Science - Human-Computer Interaction, Computer Science -
              Machine Learning, Statistics - Machine Learning"
}

@ARTICLE{Goodfellow2014-jz,
  title    = "Generative {Adversarial} {Networks}",
  author   = "Goodfellow, Ian J and Pouget-Abadie, Jean and Mirza, Mehdi and Xu,
              Bing and Warde-Farley, David and Ozair, Sherjil and Courville,
              Aaron and Bengio, Yoshua",
  journal  = "arXiv:1406. 2661 [cs, stat]",
  abstract = "We propose a new framework for estimating generative models via an
              adversarial process, in which we simultaneously train two models:
              a generative model G that captures the data distribution, and a
              discriminative model D that estimates the probability that a
              sample came from the training data rather than G. The training
              procedure for G is to maximize the probability of D making a
              mistake. This framework corresponds to a minimax two-player game.
              In the space of arbitrary functions G and D, a unique solution
              exists, with G recovering the training data distribution and D
              equal to 1/2 everywhere. In the case where G and D are defined by
              multilayer perceptrons, the entire system can be trained with
              backpropagation. There is no need for any Markov chains or
              unrolled approximate inference networks during either training or
              generation of samples. Experiments demonstrate the potential of
              the framework through qualitative and quantitative evaluation of
              the generated samples.",
  month    =  jun,
  year     =  2014,
  keywords = "Computer Science - Machine Learning, Statistics - Machine Learning"
}

@ARTICLE{Guzdial2019-gr,
  title    = "An {Interaction} {Framework} for {Studying} {Co}-{Creative} {AI}",
  author   = "Guzdial, Matthew and Riedl, Mark",
  journal  = "arXiv:1903. 09709 [cs]",
  abstract = "Machine learning has been applied to a number of creative,
              design-oriented tasks. However, it remains unclear how to best
              empower human users with these machine learning approaches,
              particularly those users without technical expertise. In this
              paper we propose a general framework for turn-based interaction
              between human users and AI agents designed to support human
              creativity, called \{co-creative systems\}. The framework can be
              used to better understand the space of possible designs of
              co-creative systems and reveal future research directions. We
              demonstrate how to apply this framework in conjunction with a pair
              of recent human subject studies, comparing between the four
              human-AI systems employed in these studies and generating
              hypotheses towards future studies.",
  month    =  mar,
  year     =  2019,
  keywords = "Computer Science - Human-Computer Interaction, Computer Science -
              Artificial Intelligence"
}

@ARTICLE{Karras2019-bv,
  title    = "A {Style}-{Based} {Generator} {Architecture} for {Generative}
              {Adversarial} {Networks}",
  author   = "Karras, Tero and Laine, Samuli and Aila, Timo",
  journal  = "arXiv:1812. 04948 [cs, stat]",
  abstract = "We propose an alternative generator architecture for generative
              adversarial networks, borrowing from style transfer literature.
              The new architecture leads to an automatically learned,
              unsupervised separation of high-level attributes (e.g., pose and
              identity when trained on human faces) and stochastic variation in
              the generated images (e.g., freckles, hair), and it enables
              intuitive, scale-specific control of the synthesis. The new
              generator improves the state-of-the-art in terms of traditional
              distribution quality metrics, leads to demonstrably better
              interpolation properties, and also better disentangles the latent
              factors of variation. To quantify interpolation quality and
              disentanglement, we propose two new, automated methods that are
              applicable to any generator architecture. Finally, we introduce a
              new, highly varied and high-quality dataset of human faces.",
  month    =  mar,
  year     =  2019,
  keywords = "Computer Science - Machine Learning, Statistics - Machine
              Learning, Computer Science - Neural and Evolutionary Computing"
}

@ARTICLE{Dhariwal2020-au,
  title    = "Jukebox: {A} {Generative} {Model} for {Music}",
  author   = "Dhariwal, Prafulla and Jun, Heewoo and Payne, Christine and Kim,
              Jong Wook and Radford, Alec and Sutskever, Ilya",
  journal  = "arXiv:2005. 00341 [cs, eess, stat]",
  abstract = "We introduce Jukebox, a model that generates music with singing in
              the raw audio domain. We tackle the long context of raw audio
              using a multi-scale VQ-VAE to compress it to discrete codes, and
              modeling those using autoregressive Transformers. We show that the
              combined model at scale can generate high-fidelity and diverse
              songs with coherence up to multiple minutes. We can condition on
              artist and genre to steer the musical and vocal style, and on
              unaligned lyrics to make the singing more controllable. We are
              releasing thousands of non cherry-picked samples at
              https://jukebox.openai.com, along with model weights and code at
              https://github.com/openai/jukebox",
  month    =  apr,
  year     =  2020,
  keywords = "Computer Science - Machine Learning, Statistics - Machine
              Learning, Computer Science - Sound, Electrical Engineering and
              Systems Science - Audio and Speech Processing"
}

@ARTICLE{Brown2020-js,
  title    = "Language {Models} are {Few}-{Shot} {Learners}",
  author   = "Brown, Tom B and Mann, Benjamin and Ryder, Nick and Subbiah,
              Melanie and Kaplan, Jared and Dhariwal, Prafulla and Neelakantan,
              Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and
              Agarwal, Sandhini and Herbert-Voss, Ariel and Krueger, Gretchen
              and Henighan, Tom and Child, Rewon and Ramesh, Aditya and Ziegler,
              Daniel M and Wu, Jeffrey and Winter, Clemens and Hesse,
              Christopher and Chen, Mark and Sigler, Eric and Litwin, Mateusz
              and Gray, Scott and Chess, Benjamin and Clark, Jack and Berner,
              Christopher and McCandlish, Sam and Radford, Alec and Sutskever,
              Ilya and Amodei, Dario",
  journal  = "arXiv:2005. 14165 [cs]",
  abstract = "Recent work has demonstrated substantial gains on many NLP tasks
              and benchmarks by pre-training on a large corpus of text followed
              by fine-tuning on a specific task. While typically task-agnostic
              in architecture, this method still requires task-specific
              fine-tuning datasets of thousands or tens of thousands of
              examples. By contrast, humans can generally perform a new language
              task from only a few examples or from simple instructions -
              something which current NLP systems still largely struggle to do.
              Here we show that scaling up language models greatly improves
              task-agnostic, few-shot performance, sometimes even reaching
              competitiveness with prior state-of-the-art fine-tuning
              approaches. Specifically, we train GPT-3, an autoregressive
              language model with 175 billion parameters, 10x more than any
              previous non-sparse language model, and test its performance in
              the few-shot setting. For all tasks, GPT-3 is applied without any
              gradient updates or fine-tuning, with tasks and few-shot
              demonstrations specified purely via text interaction with the
              model. GPT-3 achieves strong performance on many NLP datasets,
              including translation, question-answering, and cloze tasks, as
              well as several tasks that require on-the-fly reasoning or domain
              adaptation, such as unscrambling words, using a novel word in a
              sentence, or performing 3-digit arithmetic. At the same time, we
              also identify some datasets where GPT-3's few-shot learning still
              struggles, as well as some datasets where GPT-3 faces
              methodological issues related to training on large web corpora.
              Finally, we find that GPT-3 can generate samples of news articles
              which human evaluators have difficulty distinguishing from
              articles written by humans. We discuss broader societal impacts of
              this finding and of GPT-3 in general.",
  month    =  jul,
  year     =  2020,
  keywords = "Computer Science - Computation and Language"
}

@ARTICLE{Engel2017-ig,
  title    = "Neural {Audio} {Synthesis} of {Musical} {Notes} with {WaveNet}
              {Autoencoders}",
  author   = "Engel, Jesse and Resnick, Cinjon and Roberts, Adam and Dieleman,
              Sander and Eck, Douglas and Simonyan, Karen and Norouzi, Mohammad",
  journal  = "arXiv:1704. 01279 [cs]",
  abstract = "Generative models in vision have seen rapid progress due to
              algorithmic improvements and the availability of high-quality
              image datasets. In this paper, we offer contributions in both
              these areas to enable similar progress in audio modeling. First,
              we detail a powerful new WaveNet-style autoencoder model that
              conditions an autoregressive decoder on temporal codes learned
              from the raw audio waveform. Second, we introduce NSynth, a
              large-scale and high-quality dataset of musical notes that is an
              order of magnitude larger than comparable public datasets. Using
              NSynth, we demonstrate improved qualitative and quantitative
              performance of the WaveNet autoencoder over a well-tuned spectral
              autoencoder baseline. Finally, we show that the model learns a
              manifold of embeddings that allows for morphing between
              instruments, meaningfully interpolating in timbre to create new
              types of sounds that are realistic and expressive.",
  month    =  apr,
  year     =  2017,
  keywords = "Computer Science - Machine Learning, Computer Science - Artificial
              Intelligence, Computer Science - Sound"
}

@ARTICLE{Roberts2019-ym,
  title    = "A {Hierarchical} {Latent} {Vector} {Model} for {Learning}
              {Long}-{Term} {Structure} in {Music}",
  author   = "Roberts, Adam and Engel, Jesse and Raffel, Colin and Hawthorne,
              Curtis and Eck, Douglas",
  journal  = "arXiv:1803. 05428 [cs, eess, stat]",
  abstract = "The Variational Autoencoder (VAE) has proven to be an effective
              model for producing semantically meaningful latent representations
              for natural data. However, it has thus far seen limited
              application to sequential data, and, as we demonstrate, existing
              recurrent VAE models have difficulty modeling sequences with
              long-term structure. To address this issue, we propose the use of
              a hierarchical decoder, which first outputs embeddings for
              subsequences of the input and then uses these embeddings to
              generate each subsequence independently. This structure encourages
              the model to utilize its latent code, thereby avoiding the
              ``posterior collapse'' problem, which remains an issue for
              recurrent VAEs. We apply this architecture to modeling sequences
              of musical notes and find that it exhibits dramatically better
              sampling, interpolation, and reconstruction performance than a
              ``flat'' baseline model. An implementation of our ``MusicVAE'' is
              available online at http://g.co/magenta/musicvae-code.",
  month    =  nov,
  year     =  2019,
  keywords = "Computer Science - Machine Learning, Statistics - Machine
              Learning, Computer Science - Sound, Electrical Engineering and
              Systems Science - Audio and Speech Processing"
}

@ARTICLE{Smith2017-kw,
  title    = "The {Machine} as {Artist}: {An} {Introduction}",
  author   = "Smith, Glenn W and Leymarie, Frederic Fol",
  journal  = "Arts Health",
  volume   =  6,
  number   =  2,
  pages    =  5,
  abstract = "With the understanding that art and technology are continuing to
              experience an historic and rapidly intensifying rapprochement—but
              with the understanding as well that accounts thereof have tended
              to be constrained by scientific/engineering rigor on the one hand,
              or have tended to swing to the opposite extreme—it is the goal of
              this special issue of Arts to provide an opportunity for artists,
              humanists, scientists, and engineers to consider this development
              from the broader perspective which it deserves, while at the same
              time retaining a focus on what must surely be the emerging core of
              our subject: the state of the art in mechatronics and computation
              is such that we can now begin to speak comfortably of the machine
              as artist—and we can begin to hope, as well, that an aesthetic
              sensitivity on the part of the machine might help lead to a
              friendlier and more sensitive machine intelligence in general.",
  month    =  jun,
  year     =  2017,
  keywords = "artificial intelligence, aesthetics, art, embodiment, empathy,
              science, technology",
  language = "en"
}

@MISC{Taylor2019-ih,
  title    = "Creative skills are critical to protect workers from being
              replaced by robots, expert says",
  author   = "Taylor, Chloe",
  journal  = "CNBC",
  abstract = "Experts say creative skills are vital for workers looking to
              protect themselves from being replaced by new technologies.",
  month    =  aug,
  year     =  2019,
  language = "en"
}

@ARTICLE{Tierney2002-xp,
  title    = "Creative {Self}-{Efficacy}: {Its} {Potential} {Antecedents} and
              {Relationship} to {Creative} {Performance}",
  author   = "Tierney, Pamela and Farmer, Steven M",
  journal  = "Acad. Manage. J.",
  volume   =  45,
  number   =  6,
  pages    = "1137--1148",
  abstract = "Using data from two different firms, this study tested a new
              construct, creative self-efficacy, tapping employees' belief) that
              they can be creative in their work roles. Results support the
              discriminant validity of the construct and indicate that job
              tenure, job self-efficacy, supervisor behavior, and job complexity
              contribute to creative efficacy beliefs. Creative self-efficacy
              also predicted creative performance beyond the predictive effects
              of job self-efficacy. Differences in results between white-collar
              and blue-collar samples suggest considerations for both theory and
              practice.",
  month    =  dec,
  year     =  2002
}

@ARTICLE{Karimi2018-wi,
  title    = "Evaluating {Creativity} in {Computational} {Co}-{Creative}
              {Systems}",
  author   = "Karimi, Pegah and Grace, Kazjon and Maher, Mary Lou and Davis,
              Nicholas",
  journal  = "arXiv:1807. 09886 [cs]",
  abstract = "This paper provides a framework for evaluating creativity in
              co-creative systems: those that involve computer programs
              collaborating with human users on creative tasks. We situate
              co-creative systems within a broader context of computational
              creativity and explain the unique qualities of these systems. We
              present four main questions that can guide evaluation in
              co-creative systems: Who is evaluating the creativity, what is
              being evaluated, when does evaluation occur and how the evaluation
              is performed. These questions provide a framework for comparing
              how existing co-creative systems evaluate creativity, and we apply
              them to examples of co-creative systems in art, humor, games and
              robotics. We conclude that existing co-creative systems tend to
              focus on evaluating the user experience. Adopting evaluation
              methods from autonomous creative systems may lead to co-creative
              systems that are self-aware and intentional.",
  month    =  jul,
  year     =  2018,
  keywords = "Computer Science - Human-Computer Interaction, Computer Science -
              Artificial Intelligence"
}

@INPROCEEDINGS{Hwang2022-hp,
  title     = "Too late to be creative? {AI}-empowered tools in creative
               processes",
  author    = "Hwang, Angel Hsing-Chi",
  booktitle = "CHI Conference on Human Factors in Computing Systems Extended
               Abstracts",
  publisher = "ACM",
  address   = "New York, NY, USA",
  abstract  = "The present case study examines the product landscape of current
               AI-empowered co-creative tools. Specifically, I review literature
               in both creativity and HCI research and investigate how these
               tools support different stages in humans’ creative processes and
               how common challenges in human-AI interaction (HAII) are
               addressed. I find these AI-driven tools mostly support the
               generation and execution of ideas and are less involved in the
               early stages of co-creation. Moreover, HAII challenges identified
               in other fields receive little attention in the creative domain.
               Based on a synthetic analysis, I elaborate on how future tools
               can leverage the ”non-human” quality of AI to achieve innovation
               through a more human-centered, collaborative journey.",
  month     =  apr,
  year      =  2022,
  language  = "en"
}

@INPROCEEDINGS{Lehmann2022-kr,
  title     = "Suggestion lists vs. Continuous generation: Interaction design
               for writing with generative models on mobile devices affect text
               length, wording and perceived authorship",
  author    = "Lehmann, Florian and Markert, Niklas and Dang, Hai and Buschek,
               Daniel",
  booktitle = "Mensch und Computer 2022",
  publisher = "ACM",
  address   = "New York, NY, USA",
  abstract  = "Two user interfaces for writing with AI on mobile devices, which
               manipulate levels of initiative and control are designed and
               compared, which add new empirical evidence on the impact of UI
               design decisions on user experience and output with co-creative
               systems. Neural language models have the potential to support
               human writing. However, questions remain on their integration and
               influence on writing and output. To address this, we designed and
               compared two user interfaces for writing with AI on mobile
               devices, which manipulate levels of initiative and control: 1)
               Writing with continuously generated text, the AI adds text
               word-by-word and user steers. 2) Writing with suggestions, the AI
               suggests phrases and user selects from a list. In a supervised
               online study (N=18), participants used these prototypes and a
               baseline without AI. We collected touch interactions, ratings on
               inspiration and authorship, and interview data. With AI
               suggestions, people wrote less actively, yet felt they were the
               author. Continuously generated text reduced this perceived
               authorship, yet increased editing behavior. In both designs, AI
               increased text length and was perceived to influence wording. Our
               findings add new empirical evidence on the impact of UI design
               decisions on user experience and output with co-creative systems.",
  month     =  sep,
  year      =  2022,
  language  = "en"
}

@ARTICLE{Lin2023-jd,
  title         = "Beyond prompts: Exploring the design space of
                   mixed-initiative co-creativity systems",
  author        = "Lin, Zhiyu and Ehsan, Upol and Agarwal, Rohan and Dani,
                   Samihan and Vashishth, Vidushi and Riedl, Mark",
  journal       = "arXiv [cs.AI]",
  abstract      = "Generative Artificial Intelligence systems have been
                   developed for image, code, story, and game generation with
                   the goal of facilitating human creativity. Recent work on
                   neural generative systems has emphasized one particular means
                   of interacting with AI systems: the user provides a
                   specification, usually in the form of prompts, and the AI
                   system generates the content. However, there are other
                   configurations of human and AI coordination, such as
                   co-creativity (CC) in which both human and AI systems can
                   contribute to content creation, and mixed-initiative (MI) in
                   which both human and AI systems can initiate content changes.
                   In this paper, we define a hypothetical human-AI
                   configuration design space consisting of different means for
                   humans and AI systems to communicate creative intent to each
                   other. We conduct a human participant study with 185
                   participants to understand how users want to interact with
                   differently configured MI-CC systems. We find out that MI-CC
                   systems with more extensive coverage of the design space are
                   rated higher or on par on a variety of creative and
                   goal-completion metrics, demonstrating that wider coverage of
                   the design space can improve user experience and achievement
                   when using the system; Preference varies greatly between
                   expertise groups, suggesting the development of adaptive,
                   personalized MI-CC systems; Participants identified new
                   design space dimensions including scrutability -- the ability
                   to poke and prod at models -- and explainability.",
  month         =  may,
  year          =  2023,
  archivePrefix = "arXiv",
  primaryClass  = "cs.AI"
}

@ARTICLE{Jia2024-vp,
  title     = "When and how artificial intelligence augments employee creativity",
  author    = "Jia, Nan and Luo, Xueming and Fang, Zheng and Liao, Chengcheng",
  journal   = "Acad. Manage. J.",
  publisher = "Academy of Management",
  volume    =  67,
  number    =  1,
  pages     = "5--32",
  abstract  = "Can artificial intelligence (AI) assist human employees in
               increasing employee creativity? Drawing on research on AI–human
               collaboration, job design, and employee creativity, we examine AI
               assistance in the form of a sequential division of labor within
               organizations: in a task, AI handles the initial portion, which
               is well-codified and repetitive, and employees focus on the
               subsequent portion, involving higher-level problem-solving.
               First, we provide causal evidence from a field experiment
               conducted at a telemarketing company. We find that AI assistance
               in generating sales leads, on average, increases employees’
               creativity in answering customers’ questions during subsequent
               sales persuasion. Enhanced creativity leads to increased sales.
               However, this effect is much more pronounced for higher-skilled
               employees. Next, we conducted a qualitative study using
               semi-structured interviews with the employees. We found that AI
               assistance changes job design by intensifying employees’
               interactions with more serious customers. This change enables
               higher-skilled employees to generate innovative scripts and
               develop positive emotions at work, which are conducive to
               creativity. By contrast, with AI assistance, lower-skilled
               employees make limited improvements to scripts and experience
               negative emotions at work. We conclude that employees can achieve
               AI-augmented creativity, but this desirable outcome is
               skill-biased by favoring experts with greater job skills.",
  month     =  feb,
  year      =  2024,
  language  = "en"
}

@INPROCEEDINGS{Suh2021-cj,
  title     = "{AI} as social glue: Uncovering the roles of deep generative {AI}
               during social music composition",
  author    = "Suh, Minhyang (mia) and Youngblom, Emily and Terry, Michael and
               Cai, Carrie J",
  booktitle = "Proceedings of the 2021 CHI Conference on Human Factors in
               Computing Systems",
  publisher = "ACM",
  address   = "New York, NY, USA",
  month     =  may,
  year      =  2021,
  language  = "en"
}

@INPROCEEDINGS{Palani2024-on,
  title     = "Evolving roles and workflows of creative practitioners in the age
               of generative {AI}",
  author    = "Palani, Srishti and Ramos, Gonzalo",
  booktitle = "Creativity and Cognition",
  publisher = "ACM",
  address   = "New York, NY, USA",
  month     =  jun,
  year      =  2024
}

@INPROCEEDINGS{Chung2021-kc,
  title     = "The intersection of users, roles, interactions, and technologies
               in creativity support tools",
  author    = "Chung, John Joon Young and He, Shiqing and Adar, Eytan",
  booktitle = "Designing Interactive Systems Conference 2021",
  publisher = "ACM",
  address   = "New York, NY, USA",
  month     =  jun,
  year      =  2021
}

@INPROCEEDINGS{Grigis2024-pf,
  title     = "Playwriting with large language models: Perceived features,
               interaction strategies and outcomes",
  author    = "Grigis, Paolo and De Angeli, Antonella",
  booktitle = "Proceedings of the 2024 International Conference on Advanced
               Visual Interfaces",
  publisher = "ACM",
  address   = "New York, NY, USA",
  month     =  jun,
  year      =  2024,
  language  = "en"
}

@MISC{Salvaggio2024-fl,
  title        = "Sounds Like Music: Toward a Multi-Modal Media Theory of
                  Gaussian Pop",
  author       = "Salvaggio, Eryk",
  booktitle    = "Cybernetic Forests.",
  abstract     = "AI generated music is a sonification of data about music. In
                  this essay, Eryk Salvaggio explores how this might inform a
                  ``multi-modal media theory'' for generated media.",
  month        =  oct,
  year         =  2024,
  howpublished = "\url{https://www.cyberneticforests.com/news/toward-a-multi-modal-media-theory}",
  note         = "Accessed: 2024-11-13",
  language     = "en"
}

@INPROCEEDINGS{Shakeri2021-dx,
  title     = "{SAGA}: Collaborative storytelling with {GPT}-3",
  author    = "Shakeri, Hanieh and Neustaedter, Carman and DiPaola, Steve",
  booktitle = "Companion Publication of the 2021 Conference on Computer
               Supported Cooperative Work and Social Computing",
  publisher = "ACM",
  address   = "New York, NY, USA",
  month     =  oct,
  year      =  2021,
  language  = "en"
}

@MISC{noauthor_undated-pm,
  title        = "x.com",
  booktitle    = "X (formerly Twitter)",
  howpublished = "\url{https://x.com/karinanguyen\_/status/1818122907203330266}",
  note         = "Accessed: 2024-8-2"
}

@MISC{Design_Theory2022-rw,
  title     = "Will Artificial Intelligence End Human Creativity?",
  author    = "{Design Theory}",
  publisher = "Youtube",
  abstract  = "You and your business can try Onshape for free at
               https://Onshape.pro/DesignTheory . With recent advancements in
               Artificial Intelligence design tools, we are...",
  month     =  jun,
  year      =  2022
}

@MISC{UnknownUnknown-nx,
  title        = "Oasis",
  abstract     = "Generating Worlds in Realtime",
  howpublished = "\url{https://oasis-model.github.io/}",
  note         = "Accessed: 2024-11-1",
  language     = "en"
}

@ARTICLE{Hoffman2019-ag,
  title    = "Evaluating Fluency in {Human–Robot} Collaboration",
  author   = "Hoffman, Guy",
  journal  = "IEEE Transactions on Human-Machine Systems",
  volume   =  49,
  number   =  3,
  pages    = "209--218",
  abstract = "Collaborative fluency is the coordinated meshing of joint
              activities between members of a well-synchronized team. In recent
              years, researchers in human-robot collaboration have been
              developing robots to work alongside humans aiming not only at task
              efficiency, but also at human-robot fluency. As part of this
              effort, we have developed a number of metrics to evaluate the
              level of fluency in human-robot shared-location teamwork. While
              these metrics are being used in existing research, there has been
              no systematic discussion on how to measure fluency and how the
              commonly used metrics perform and compare. In this paper, we
              codify subjective and objective human-robot fluency metrics,
              provide an analytical model for four objective metrics, and assess
              their dynamics in a turn-taking framework. We also report on a
              user study linking objective and subjective fluency metrics and
              survey recent use of these metrics in the literature.",
  month    =  jun,
  year     =  2019,
  keywords = "Measurement;Robot kinematics;Robot sensing systems;Task
              analysis;Teamwork;Artificial intelligence;computational and
              artificial intelligence;cooperative systems;human-robot
              interaction;intelligent robots;intelligent systems;man-machine
              systems;systems;man;cybernetics;user interfaces"
}

@MISC{Cursor2024-ow,
  title        = "Cursor",
  author       = "{Cursor}",
  booktitle    = "cursor.com",
  abstract     = "The AI Code Editor",
  year         =  2024,
  howpublished = "\url{https://www.cursor.com/}",
  note         = "Accessed: 2024-9-11",
  language     = "en"
}

@INPROCEEDINGS{Saleh2010-km,
  title     = "Towards generalized performance metrics for human-robot
               interaction",
  author    = "Saleh, Jamil Abou and Karray, Fakhreddine",
  booktitle = "2010 International Conference on Autonomous and Intelligent
               Systems, AIS 2010",
  pages     = "1--6",
  abstract  = "In order for cognitive robots to act adequately and safely in
               real world, they must be able to perceive and have abilities of
               reasoning up to a certain level. Toward this end, performance
               evaluation metrics are used as important measures to achieve
               these goals. This paper intends to be a further step towards
               identifying common metrics for task-oriented human-robot
               interaction. We believe that within the context of human-robot
               interaction systems, both human and robot independent actions and
               joint interactions can significantly affect the quality of the
               accomplished task, thus proposing a generic performance metric to
               assess the performance of the human-robot team. Toward the
               efficient modelling of such metric, we also propose a fuzzy
               temporal model to evaluate the human trust in automation while
               interacting with robots and machines to complete some tasks.
               Trust modelling is critical as it directly influences the
               interaction time that should be directly and indirectly dedicated
               toward interacting with the robot. Another fuzzy temporal-based
               model is also presented to evaluate the human reliability during
               interaction time, as many research studies state that a large
               percentage of system failures are due almost equally to humans
               and machines, and therefore, assessing this important factor in
               human-robot interaction systems is also crucial. The proposed
               framework is based on the most recent work in the area of
               cognitive human-machine interaction and performance evaluation.",
  month     =  jun,
  year      =  2010,
  keywords  = "Humans;Robots;Measurement;Reliability;Automation;Mathematical
               model;Productivity;performance metrics;fuzzy logic;finite
               automata"
}

@INPROCEEDINGS{Reicherts2020-up,
  title     = "Do make me think!: How {CUIs} can support cognitive processes",
  author    = "Reicherts, Leon and Rogers, Yvonne",
  booktitle = "Proceedings of the 2nd Conference on Conversational User
               Interfaces",
  publisher = "ACM",
  address   = "New York, NY, USA",
  volume    =  34,
  pages     = "1--4",
  month     =  jul,
  year      =  2020
}

@MISC{noauthor_undated-td,
  title        = "{AI} Photo Generator",
  booktitle    = "Photo AI",
  abstract     = "Generate photorealistic images of people with AI. Save money
                  and use AI to do a photo shoot from your laptop or phone
                  instead of hiring an expensive photographer ✏️ Upload your
                  selfies and create your own AI character 📸 Take 100\% AI
                  photos in any pose, place or action 🎞️ Create 100\% AI videos
                  from any AI photo you take ❤️ Run photo packs like AI Yearbook
                  and Old Money ✍️ Create AI-generated fashion designs with
                  Sketch2Image™",
  howpublished = "\url{https://photoai.com/}",
  note         = "Accessed: 2024-3-5",
  language     = "en"
}

@MISC{noauthor_undated-cc,
  title        = "Tau-induced memory loss in Alzheimer’s mice is reversible",
  abstract     = "Max Planck study raises hopes for the development of effective
                  therapies to help reverse memory loss in the early stages of
                  Alzheimer disease.",
  howpublished = "\url{https://www.mpg.de/1161288/alzheimer-reversible-memory-loss}",
  note         = "Accessed: 2022-12-7",
  language     = "en"
}

@MISC{noauthor_undated-jm,
  title        = "{SerendipityLM}",
  abstract     = "Interactive evolutionary exploration of generative design
                  spaces with large language models",
  howpublished = "\url{https://samim.io/studio/work/serendipityLM/}",
  note         = "Accessed: 2024-8-5",
  language     = "en"
}

@MISC{noauthor_undated-dj,
  title        = "[No title]",
  howpublished = "\url{https://elicit.org/}",
  note         = "Accessed: 2022-7-8",
  language     = "en"
}

@MISC{noauthor_2022-yb,
  title        = "Elicit",
  year         =  2022,
  howpublished = "\url{https://elicit.org/}",
  note         = "Accessed: 2022-7-8",
  language     = "en"
}

@ARTICLE{Runco2023-qi,
  title     = "{AI} can only produce artificial creativity",
  author    = "Runco, Mark A",
  journal   = "Journal of Creativity",
  publisher = "Elsevier BV",
  volume    =  33,
  number    =  100063,
  pages     =  100063,
  month     =  aug,
  year      =  2023,
  language  = "en"
}

@MISC{Anthropic2024-dl,
  title        = "What are Artifacts and how do {I} use them?",
  author       = "{Anthropic}",
  booktitle    = "anthropic.com",
  year         =  2024,
  howpublished = "\url{https://support.anthropic.com/en/articles/9487310-what-are-artifacts-and-how-do-i-use-them}",
  note         = "Accessed: 2024-9-11",
  language     = "en"
}

@ARTICLE{Rhodes1961-od,
  title     = "An Analysis of Creativity",
  author    = "Rhodes, Mel",
  journal   = "The Phi Delta Kappan",
  publisher = "Phi Delta Kappa International",
  volume    =  42,
  number    =  7,
  pages     = "305--310",
  year      =  1961
}

@MISC{noauthor_2024-xb,
  title        = "Why you need a Nobot",
  booktitle    = "The Thesis Whisperer",
  abstract     = "I've been working with Claude, an AI assistant from Anthropic,
                  for about a year. We've become... close. People laugh when I
                  call Claude my 'work husband'. I'm not really joking. Like a
                  good work spouse, Claude is always there to help and never
                  gets tired of my stories. Claude cheerfully does the tasks I
                  hate,…",
  month        =  oct,
  year         =  2024,
  howpublished = "\url{https://thesiswhisperer.com/2024/10/31/why-you-need-a-nobot/}",
  note         = "Accessed: 2024-11-26",
  language     = "en"
}

@INPROCEEDINGS{Zhang2023-fy,
  title     = "Towards human-centred {AI}-co-creation: A three-level framework
               for effective collaboration between human and {AI}",
  author    = "Zhang, Mingyuan and Cheng, Zhaolin and Shiu, Sheung Ting Ramona
               and Liang, Jiacheng and Fang, Cong and Ma, Zhengtao and Fang, Le
               and Wang, Stephen Jia",
  booktitle = "Computer Supported Cooperative Work and Social Computing",
  publisher = "ACM",
  address   = "New York, NY, USA",
  month     =  oct,
  year      =  2023,
  language  = "en"
}

@MISC{UnknownUnknown-dc,
  title     = "The Dor Brothers",
  publisher = "Youtube",
  abstract  = "The Dor Brothers is an AI Video Production company founded by the
               Dor brothers in Berlin, Germany. https://www.thedorbrothers.com/",
  language  = "en"
}

@MISC{UnknownUnknown-kc,
  title        = "The Dor Brothers",
  booktitle    = "The Dor Brothers",
  abstract     = "The Dor Brothers is an AI Visuals studio that creates AI Music
                  Videos, AI Commercials, and AI Films. Using advanced AI
                  technology, they produce next level creative content,
                  transforming the way stories are told and experienced.",
  howpublished = "\url{https://www.thedorbrothers.com/}",
  note         = "Accessed: 2024-12-5",
  language     = "en"
}

@MISC{Purohit2024-nx,
  title        = "Why {I} Avoided {AI—And} How {I} Finally Embraced It",
  author       = "Purohit, Rhea",
  abstract     = "Using a new technology can be hard. Here's what you can do
                  about it.",
  month        =  aug,
  year         =  2024,
  howpublished = "\url{https://every.to/learning-curve/why-i-avoided-ai-and-how-i-finally-embraced-it?utm\_source=www.theneurondaily.com\&utm\_medium=newsletter\&utm\_campaign=world-s-first-ai-mayor\&\_bhlid=a2b8f3444d7a70e5559413899dcf404d8e2b5e5a}",
  note         = "Accessed: 2024-8-23"
}

@ARTICLE{Meehan1976-xh,
  title     = "The metanovel: writing stories by computer",
  author    = "Meehan, J R",
  publisher = "Yale University",
  year      =  1976
}

@ARTICLE{Mordvintsev2015-yo,
  title    = "Inceptionism: Going deeper into neural networks",
  author   = "Mordvintsev, A and Olah, C and Tyka, Mike",
  journal  = "Google research blog",
  volume   =  20,
  number   =  14,
  pages    =  5,
  year     =  2015,
  language = "en"
}

@ARTICLE{Us-Epa2015-xb,
  title    = "Greenhouse Gas Equivalencies Calculator",
  author   = "Us Epa, Oar",
  abstract = "A calculator that allows users to translate abstract greenhouse
              gas amounts into concrete terms that are easy to understand.",
  month    =  aug,
  year     =  2015,
  language = "en"
}

@ARTICLE{Grimes2016-er,
  title     = "Harold Cohen, a Pioneer of Computer-Generated Art, Dies at 87",
  author    = "Grimes, William",
  journal   = "The New York Times",
  publisher = "The New York Times",
  abstract  = "Mr. Cohen, an abstract painter, developed Aaron, a software
               program that learned to create art in a manner similar to
               freehand drawing.",
  month     =  may,
  year      =  2016
}

@BOOK{Latour2007-ep,
  title     = "Reassembling the Social: An Introduction to Actor-Network-Theory",
  author    = "Latour, Bruno",
  publisher = "OUP Oxford",
  abstract  = "Reassembling the Social is a fundamental challenge from one of
               the world's leading social theorists to how we understand society
               and the 'social'. Bruno Latour's contention is that the word
               'social', as used by Social Scientists, has become laden with
               assumptions to the point where it has become misnomer. When the
               adjective is applied to a phenomenon, it is used to indicate a
               stablilized state of affairs, a bundle of ties that in due course
               may be used to account for another phenomenon. But Latour also
               finds the word used as if it described a type of material, in a
               comparable way to an adjective such as 'wooden' or 'steely'.
               Rather than simply indicating what is already assembled together,
               it is now used in a way that makes assumptions about the nature
               of what is assembled. It has become a word that designates two
               distinct things: a process of assembling; and a type of material,
               distinct from others. Latour shows why 'the social' cannot be
               thought of as a kind of material or domain, and disputes attempts
               to provide a 'social explanations' of other states of affairs.
               While these attempts have been productive (and probably
               necessary) in the past, the very success of the social sciences
               mean that they are largely no longer so. At the present stage it
               is no longer possible to inspect the precise constituents
               entering the social domain. Latour returns to the original
               meaning of 'the social' to redefine the notion, and allow it to
               trace connections again. It will then be possible to resume the
               traditional goal of the social sciences, but using more refined
               tools. Drawing on his extensive work examining the 'assemblages'
               of nature, Latour finds it necessary to scrutinize thoroughly the
               exact content of what is assembled under the umbrella of Society.
               This approach, a 'sociology of associations', has become known as
               Actor-Network-Theory, and this book is an essential introduction
               both for those seeking to understand Actor-Network Theory, or the
               ideas of one of its most influential proponents.",
  month     =  sep,
  year      =  2007,
  language  = "en"
}


@MISC{noauthor_undated-pc,
  title        = "Fast, accurate climate modeling with {NeuralGCM}",
  howpublished = "\url{https://research.google/blog/fast-accurate-climate-modeling-with-neuralgcm/}",
  note         = "Accessed: 2024-7-24",
  language     = "en"
}


@MISC{OpenAI2021-wf,
  title        = "{GPT}-3 Powers the Next Generation of Apps",
  author       = "{OpenAI}",
  abstract     = "Over 300 applications are delivering GPT-3–powered search,
                  conversation, text completion, and other advanced AI features
                  through our API.",
  month        =  mar,
  year         =  2021,
  howpublished = "\url{https://openai.com/blog/gpt-3-apps/}",
  note         = "Accessed: 2022-7-8"
}

@ARTICLE{Brooks2022-vo,
  title         = "{InstructPix2Pix}: Learning to Follow Image Editing
                   Instructions",
  author        = "Brooks, Tim and Holynski, Aleksander and Efros, Alexei A",
  journal       = "arXiv [cs.CV]",
  abstract      = "We propose a method for editing images from human
                   instructions: given an input image and a written instruction
                   that tells the model what to do, our model follows these
                   instructions to edit the image. To obtain training data for
                   this problem, we combine the knowledge of two large
                   pretrained models -- a language model (GPT-3) and a
                   text-to-image model (Stable Diffusion) -- to generate a large
                   dataset of image editing examples. Our conditional diffusion
                   model, InstructPix2Pix, is trained on our generated data, and
                   generalizes to real images and user-written instructions at
                   inference time. Since it performs edits in the forward pass
                   and does not require per example fine-tuning or inversion,
                   our model edits images quickly, in a matter of seconds. We
                   show compelling editing results for a diverse collection of
                   input images and written instructions.",
  month         =  nov,
  year          =  2022,
  archivePrefix = "arXiv",
  primaryClass  = "cs.CV"
}

@MISC{noauthor_undated-ih,
  title        = "Practice-as-research-context-method-knowledge-by-estelle-barrett-barbara-bolt-z-lib.Org-.Pdf",
  booktitle    = "Are.na",
  abstract     = "Are.na is a platform for connecting ideas and building
                  knowledge",
  howpublished = "\url{https://www.are.na/block/9736221}",
  note         = "Accessed: 2024-2-14",
  language     = "en"
}

@MISC{noauthor_2022-bf,
  title        = "Wordtune",
  abstract     = "Wordtune is the ultimate AI writing tool that rewrites,
                  rephrases, and rewords your writing! Trusted by over 1,000,000
                  users, Wordtune strengthens articles, academic papers, essays,
                  emails and any other online content.",
  year         =  2022,
  howpublished = "\url{https://www.wordtune.com/}",
  note         = "Accessed: 2022-7-8",
  language     = "en"
}

@MISC{Live2023-xc,
  title     = "{OpenAI} {CEO} Sam Altman on the Future of {AI}",
  author    = "Live, Bloomberg",
  publisher = "Youtube",
  abstract  = "Sam Altman, CEO \& Co-Founder, OpenAI discusses the explosive
               rise of OpenAI and its products and what an AI-laced future can
               look like with Bloomberg’s Emily...",
  month     =  jun,
  year      =  2023,
  keywords  = "bloomberg; bloomberg live"
}

@MISC{Hagey2024-ti,
  title        = "Sam Altman Seeks Trillions of Dollars to Reshape Business of
                  Chips and {AI}",
  author       = "Hagey, Keach and Fitch, Asa",
  booktitle    = "WSJ Online",
  abstract     = "The OpenAI chief executive is pursuing investors including the
                  U.A.E. for a project possibly requiring as much as \$7
                  trillion.",
  month        =  feb,
  year         =  2024,
  howpublished = "\url{https://www.wsj.com/tech/ai/sam-altman-seeks-trillions-of-dollars-to-reshape-business-of-chips-and-ai-89ab3db0}",
  note         = "Accessed: 2024-3-21"
}

@MISC{Commerce2022-ew,
  title        = "How High Quality Menu Images Can Boost Your Sales By 30\%",
  author       = "Commerce, Smooth",
  booktitle    = "Smooth Commerce",
  abstract     = "Think about the last time you ordered food, either digitally
                  or in-person. What factors played a role in your product
                  selection? There’s a good chance that your decision was based
                  on the product images, especially if you were visiting a place
                  for the first time. Here are some of the benefits of adding
                  photos to […]",
  month        =  jan,
  year         =  2022,
  howpublished = "\url{https://smooth.tech/marketing/menu-images-boost-sales/}",
  note         = "Accessed: 2024-5-7",
  language     = "en"
}

@ARTICLE{Youn2011-ew,
  title     = "The Effect of Menu Quality and Brand Image on Customer
               Satisfaction and Repurchase Intention in Family Restaurants",
  author    = "Youn, Ko Jae and {이승익}",
  journal   = "Culinary Science \& Hospitality Research",
  publisher = "Culinary Science \& Hospitality Research",
  volume    =  17,
  number    =  2,
  pages     = "153--167",
  abstract  = "Download Citation | On Apr 1, 2011, Ko Jae Youn and others
               published The Effect of Menu Quality and Brand Image on Customer
               Satisfaction and Repurchase Intention in Family Restaurants |
               Find, read and cite all the research you need on ResearchGate",
  month     =  apr,
  year      =  2011
}

@MISC{Ai2025-wi,
  title        = "Devin",
  author       = "Ai, Devin",
  booktitle    = "Devin.ai",
  abstract     = "Devin is a collaborative AI teammate built to help ambitious
                  engineering teams achieve more.",
  year         =  2025,
  howpublished = "\url{https://devin.ai/}",
  note         = "Accessed: 2025-3-8",
  language     = "en"
}

@BOOK{Toromanoff2018-hc,
  title     = "Impossible Photography: Surreal Pictures that Challenge our
               Perception",
  author    = "Toromanoff, Agata",
  publisher = "Eken Press",
  year      =  2018
}

@ARTICLE{Unknown2023-hi,
  title     = "How Generative {AI} Can Augment Human Creativity",
  journal   = "Harvard Business Review",
  publisher = "Harvard Business Review",
  abstract  = "There is tremendous apprehension about the potential of
               generative AI—technologies that can create new content such as
               text, images, and video—to replace people in many jobs. But one
               of the biggest opportunities generative AI offers is to augment
               human creativity and overcome the challenges of democratizing
               innovation. In the past two decades, companies have used
               crowdsourcing and idea competitions to involve outsiders in the
               innovation process. But many businesses have struggled to
               capitalize on these contributions. They’ve lacked an efficient
               way to evaluate the ideas, for instance, or to synthesize
               different ideas. Generative AI can help over­come those
               challenges, the authors say. It can supplement the creativity of
               employees and customers and help them produce and identify novel
               ideas—and improve the quality of raw ideas. Specifically,
               companies can use generative AI to promote divergent thinking,
               challenge expertise bias, assist in idea evaluation, support idea
               refinement, and facilitate collaboration among users.",
  month     =  jul,
  year      =  2023,
  language  = "en"
}

@INCOLLECTION{McCormack2008-rs,
  title     = "Facing the future: Evolutionary possibilities for human-machine
               creativity",
  author    = "McCormack, Jon Paul",
  booktitle = "The Art of Artificial Evolution: A Handbook on Evolutionary Art
               and Music",
  publisher = "Springer",
  pages     = "417--451",
  year      =  2008,
  language  = "en"
}

@BOOK{Freire1970-pa,
  title     = "Pedagogy of the Oppressed",
  author    = "Freire, Paulo",
  publisher = "Seabury Press",
  abstract  = "First published in Portuguese in 1968, Pedagogy of the Oppressed
               was translated and published in English in 1970. The methodology
               of the late Paulo Freire has helped to empower countless
               impoverished and illiterate people throughout the world. Freire's
               work has taken on especial urgency in the United States and
               Western Europe, where the creation of a permanent underclass
               among the underprivileged and minorities in cities and urban
               centers is increasingly accepted as the norm. With a substantive
               new introduction on Freire's life and the remarkable impact of
               this book by writer and Freire confidant and authority Donaldo
               Macedo, this anniversary edition of Pedagogy of the Oppressed
               will inspire a new generation of educators, students, and general
               readers for years to come.--amazon.com (30th anniversary ed.).",
  year      =  1970,
  language  = "en"
}

@MISC{MidJourney2022-sb,
  title        = "Early Model Versions",
  author       = "{MidJourney}",
  booktitle    = "Midjourney",
  year         =  2022,
  howpublished = "\url{https://docs.midjourney.com/docs/early-models}",
  note         = "Accessed: 2024-12-19",
  language     = "en"
}

@MISC{OpenAI2021-te,
  title        = "{DALL·E}: Creating images from text",
  author       = "{OpenAI}",
  booktitle    = "OpenAI",
  abstract     = "We’ve trained a neural network called DALL·E that creates
                  images from text captions for a wide range of concepts
                  expressible in natural language.",
  month        =  jan,
  year         =  2021,
  howpublished = "\url{https://openai.com/index/dall-e/}",
  note         = "Accessed: 2024-12-19",
  language     = "en"
}

@MISC{Computer-Vision-and-Learning-Research-Group-at-Ludwig-Maximilian-University-of-Munich2022-ne,
  title       = "stable-diffusion: A latent text-to-image diffusion model",
  author      = "{Computer Vision and Learning Research Group at Ludwig
                 Maximilian University of Munich}",
  institution = "Github",
  abstract    = "A latent text-to-image diffusion model. Contribute to
                 CompVis/stable-diffusion development by creating an account on
                 GitHub.",
  year        =  2022,
  language    = "en",
  version     = "v1"
}

@MISC{TensorflowUnknown-eb,
  title        = "Convolutional Variational Autoencoder",
  author       = "{Tensorflow}",
  booktitle    = "Tensorflow.org",
  howpublished = "\url{https://www.tensorflow.org/tutorials/generative/cvae}",
  note         = "Accessed: 2024-12-19",
  language     = "en"
}

@ARTICLE{noauthor_undated-uk,
  title = "{ISEA2022}-{BCN}-Proceedings.pdf"
}

@ARTICLE{Roberts2018-nr,
  title  = "Magenta.Js: A {JavaScript} {API} for augmenting creativity with deep
            learning",
  author = "Roberts, Adam and Hawthorne, Curtis and Simon, Ian",
  year   =  2018
}

@MISC{Offerman2024-lf,
  title        = "Creative pros see generative {AI} as part of their future",
  author       = "Offerman, Stefan",
  year         =  2024,
  howpublished = "\url{https://blog.adobe.com/en/publish/2023/03/21/research-creative-pros-see-generative-ai-as-part-of-their-future}",
  note         = "Accessed: 2024-3-13"
}

@MISC{noauthor_undated-kv,
  title        = "{ERIK} {JOHANSSON}",
  booktitle    = "ERIK JOHANSSON",
  abstract     = "Website of Swedish surreal photographer Erik Johansson.",
  howpublished = "\url{https://www.erikjo.com/}",
  note         = "Accessed: 2024-3-4",
  language     = "en"
}

@MISC{noauthor_2024-tm,
  title        = "stephen mcmennamy (@combophoto) • Instagram photos and videos",
  booktitle    = "Instagram",
  year         =  2024,
  howpublished = "\url{https://www.instagram.com/combophoto/}",
  note         = "Accessed: 2024-3-4",
  language     = "en"
}

@MISC{noauthor_undated-bz,
  title        = "Stelfie",
  booktitle    = "My Site",
  abstract     = "I'm Stelfie. the Time Traveller. In a parody of life and
                  history powered by AI, I time travel and I take stelfies.",
  howpublished = "\url{https://www.stelfiett.com/}",
  note         = "Accessed: 2024-3-4",
  language     = "en"
}

@ARTICLE{Rafner2023-jr,
  title    = "Creativity in the age of generative {AI}",
  author   = "Rafner, Janet and Beaty, Roger E and Kaufman, James C and Lubart,
              Todd and Sherson, Jacob",
  journal  = "Nat Hum Behav",
  volume   =  7,
  number   =  11,
  pages    = "1836--1838",
  month    =  nov,
  year     =  2023,
  language = "en"
}

@MISC{UnknownUnknown-hc,
  title        = "memory-profiler",
  booktitle    = "PyPI",
  abstract     = "A module for monitoring memory usage of a python program",
  howpublished = "\url{https://pypi.org/project/memory-profiler/}",
  note         = "Accessed: 2024-9-17",
  language     = "en"
}


@MISC{Anthropic2024-ne,
  title        = "Claude’s Character",
  author       = "{Anthropic}",
  abstract     = "Anthropic is an AI safety and research company that's working
                  to build reliable, interpretable, and steerable AI systems.",
  year         =  2024,
  howpublished = "\url{https://www.anthropic.com/research/claude-character}",
  note         = "Accessed: 2025-3-8",
  language     = "en"
}

@MISC{Sacasas2024-fj,
  title        = "Re-sourcing the mind",
  author       = "Sacasas, L M",
  booktitle    = "The Convivial Society",
  abstract     = "The Convivial Society: Vol. 5, No.",
  month        =  aug,
  year         =  2024,
  howpublished = "\url{https://theconvivialsociety.substack.com/p/re-sourcing-the-mind?utm\_campaign=email-half-post\&r=1aer3\&utm\_source=substack\&utm\_medium=email}",
  note         = "Accessed: 2024-8-1",
  language     = "en"
}

@ARTICLE{noauthor_2009-ue,
  title     = "Ratio of tau forms in the {CSF} identifies patients with
               progressive supranuclear palsy",
  journal   = "Nat. Clin. Pract. Neurol.",
  publisher = "Nature Publishing Group",
  volume    =  5,
  number    =  2,
  pages     = "62--63",
  month     =  feb,
  year      =  2009,
  language  = "en"
}

@MISC{Reybrouck2017-do,
  title   = "Music Knowledge Construction",
  author  = "Reybrouck, Mark",
  journal = "The Routledge Companion to Embodied Music Interaction",
  pages   = "58--65",
  year    =  2017
}

@MISC{Venkatesan_undated-so,
  title        = "Why we crave healthier computing",
  author       = "Venkatesan, Arun",
  abstract     = "How throughout history, increasing computing capability has
                  lead to increasing burden on users.",
  howpublished = "\url{https://arun.is/blog/healthy-computing/?utm\_source=substack\&utm\_medium=email}",
  note         = "Accessed: 2024-4-8"
}

@MISC{noauthor_undated-zr,
  title        = "About Us",
  howpublished = "\url{https://www.adept.ai/about-us}",
  note         = "Accessed: 2022-4-30"
}

@INCOLLECTION{Candy2019-vg,
  title     = "Reflective creative practice",
  author    = "Candy, Linda",
  booktitle = "The Creative Reflective Practitioner",
  publisher = "Routledge",
  pages     = "44--101",
  month     =  nov,
  year      =  2019
}

@MISC{noauthor_undated-oy,
  title = "{3f5ee243547dee91fbd053c1c4a845aa}-Paper.pdf"
}

@ARTICLE{Heersmink2024-mk,
  title     = "Use of large language models might affect our cognitive skills",
  author    = "Heersmink, Richard",
  journal   = "Nat. Hum. Behav.",
  publisher = "Springer Science and Business Media LLC",
  pages     = "1--2",
  abstract  = "Large language models can generate sophisticated text or code
               with little input from a user, which has the potential to
               impoverish our own writing and thinking skills. We need to
               understand the effect of this technology on our cognition and to
               decide whether this is what we want.",
  month     =  mar,
  year      =  2024,
  language  = "en"
}

@ARTICLE{Goldstein2024-fu,
  title     = "Alignment of brain embeddings and artificial contextual
               embeddings in natural language points to common geometric
               patterns",
  author    = "Goldstein, Ariel and Grinstein-Dabush, Avigail and Schain,
               Mariano and Wang, Haocheng and Hong, Zhuoqiao and Aubrey, Bobbi
               and Schain, Mariano and Nastase, Samuel A and Zada, Zaid and Ham,
               Eric and Feder, Amir and Gazula, Harshvardhan and Buchnik, Eliav
               and Doyle, Werner and Devore, Sasha and Dugan, Patricia and
               Reichart, Roi and Friedman, Daniel and Brenner, Michael and
               Hassidim, Avinatan and Devinsky, Orrin and Flinker, Adeen and
               Hasson, Uri",
  journal   = "Nat. Commun.",
  publisher = "Springer Science and Business Media LLC",
  volume    =  15,
  number    =  1,
  pages     = "1--12",
  abstract  = "AbstractContextual embeddings, derived from deep language models
               (DLMs), provide a continuous vectorial representation of
               language. This embedding space differs fundamentally from the
               symbolic representations posited by traditional
               psycholinguistics. We hypothesize that language areas in the
               human brain, similar to DLMs, rely on a continuous embedding
               space to represent language. To test this hypothesis, we densely
               record the neural activity patterns in the inferior frontal gyrus
               (IFG) of three participants using dense intracranial arrays while
               they listened to a 30-minute podcast. From these fine-grained
               spatiotemporal neural recordings, we derive a continuous
               vectorial representation for each word (i.e., a brain embedding)
               in each patient. Using stringent zero-shot mapping we demonstrate
               that brain embeddings in the IFG and the DLM contextual embedding
               space have common geometric patterns. The common geometric
               patterns allow us to predict the brain embedding in IFG of a
               given left-out word based solely on its geometrical relationship
               to other non-overlapping words in the podcast. Furthermore, we
               show that contextual embeddings capture the geometry of IFG
               embeddings better than static word embeddings. The continuous
               brain embedding space exposes a vector-based neural code for
               natural language processing in the human brain.",
  month     =  mar,
  year      =  2024,
  language  = "en"
}

@ARTICLE{Ben-Tal2021-hf,
  title     = "How music {AI} is useful: Engagements with composers, performers
               and audiences",
  author    = "Ben-Tal, Oded and Harris, Matthew Tobias and Sturm, Bob L T",
  journal   = "Leonardo",
  publisher = "MIT Press - Journals",
  volume    =  54,
  number    =  5,
  pages     = "510--516",
  abstract  = "Abstract Critical but often overlooked research questions in
               artificial intelligence applied to music involve the impact of
               the results for music. How and to what extent does such research
               contribute to the domain of music? How are the resulting models
               useful for music practitioners? This article describes work
               arising from research engaging with composers, musicians and
               audiences to address such questions: two websites that make their
               AI models accessible to a wide audience and a professionally
               recorded album released to expert reviewers to gauge the
               plausibility of AI-generated material. The authors describe the
               use of their models as tools for cocreation. Evaluating AI
               research and music models in such ways illuminates their impact
               on music-making.",
  month     =  oct,
  year      =  2021,
  language  = "en"
}

@MISC{noauthor_undated-bh,
  title        = "{MusicVAE} Documentation",
  howpublished = "\url{https://magenta.github.io/magenta-js/music/classes/\_music\_vae\_model\_.musicvae.html}",
  note         = "Accessed: 2021-12-7"
}

@ARTICLE{Roddy_undated-ck,
  title    = "Signal to Noise Loops: A Cybernetic Approach to Musical
              Performance with Smart City Data and Generative Music Techniques",
  author   = "Roddy, Stephen",
  abstract = "This article introduces the Signal to Noise Loops project which
              consisted of a series of performances and installations that took
              place worldwide between 2017 and 2021. The project utilised open
              data from a network of Internet of Things sensors placed around
              Dublin City in the context of experimental music performance and
              composition. This was underpinned by a theoretical framework from
              the field of Cybernetics which united and integrated methods and
              approaches from the wide-ranging fields of Data-Driven Music,
              Generative Music, Rhythmanalysis and Smart Cities Research."
}

@ARTICLE{Carter2017-xj,
  title     = "Using artificial intelligence to augment human intelligence",
  author    = "Carter, Shan and Nielsen, Michael",
  journal   = "Distill",
  publisher = "Distill Working Group",
  volume    =  2,
  number    =  12,
  month     =  dec,
  year      =  2017
}

@MISC{Hoc2000-iy,
  title   = "From human – machine interaction to human – machine cooperation",
  author  = "Hoc, Jean-Michel",
  journal = "Ergonomics",
  volume  =  43,
  number  =  7,
  pages   = "833--843",
  year    =  2000
}

@ARTICLE{Marjieh2024-yz,
  title     = "Timbral effects on consonance disentangle psychoacoustic
               mechanisms and suggest perceptual origins for musical scales",
  author    = "Marjieh, Raja and Harrison, Peter M C and Lee, Harin and
               Deligiannaki, Fotini and Jacoby, Nori",
  journal   = "Nat. Commun.",
  publisher = "Springer Science and Business Media LLC",
  volume    =  15,
  number    =  1,
  pages     = "1--22",
  abstract  = "AbstractThe phenomenon of musical consonance is an essential
               feature in diverse musical styles. The traditional belief,
               supported by centuries of Western music theory and psychological
               studies, is that consonance derives from simple (harmonic)
               frequency ratios between tones and is insensitive to timbre. Here
               we show through five large-scale behavioral studies, comprising
               235,440 human judgments from US and South Korean populations,
               that harmonic consonance preferences can be reshaped by timbral
               manipulations, even as far as to induce preferences for
               inharmonic intervals. We show how such effects may suggest
               perceptual origins for diverse scale systems ranging from the
               gamelan’s slendro scale to the tuning of Western mean-tone and
               equal-tempered scales. Through computational modeling we show
               that these timbral manipulations dissociate competing
               psychoacoustic mechanisms underlying consonance, and we derive an
               updated computational model combining liking of harmonicity,
               disliking of fast beats (roughness), and liking of slow beats.
               Altogether, this work showcases how large-scale behavioral
               experiments can inform classical questions in auditory
               perception.",
  month     =  feb,
  year      =  2024,
  language  = "en"
}

@ARTICLE{Aceves2024-yp,
  title     = "Human languages with greater information density have higher
               communication speed but lower conversation breadth",
  author    = "Aceves, Pedro and Evans, James A",
  journal   = "Nat. Hum. Behav.",
  publisher = "Springer Science and Business Media LLC",
  pages     = "1--13",
  abstract  = "Human languages vary widely in how they encode information within
               circumscribed semantic domains (for example, time, space, colour,
               human body parts and activities), but little is known about the
               global structure of semantic information and nothing about its
               relation to human communication. We first show that across a
               sample of ~1,000 languages, there is broad variation in how
               densely languages encode information into words. Second, we show
               that this language information density is associated with a
               denser configuration of semantic information. Finally, we trace
               the relationship between language information density and
               patterns of communication, showing that informationally denser
               languages tend towards faster communication but conceptually
               narrower conversations or expositions within which topics are
               discussed at greater depth. These results highlight an important
               source of variation across the human communicative channel,
               revealing that the structure of language shapes the nature and
               texture of human engagement, with consequences for human
               behaviour across levels of society. The authors document wide
               variation in information density and speed of communication
               across the world’s languages. They find that higher-density
               languages communicate information more quickly but with more
               sustained focus than lower-density languages.",
  month     =  feb,
  year      =  2024,
  language  = "en"
}

@MISC{Nebelong2023-rb,
  title        = "For generative {AI} to become an interesting art tool, we need
                  much more control over the output. The slot-machine-like
                  nature of pure text-to-image leaves too much to chance.Using
                  the ``Real-time Latent Consistency Model'' that {I}'m using in
                  the example here, is the first time I…
                  pic.twitter.com/{YH90MCHVNd}",
  author       = "Nebelong, Martin",
  booktitle    = "Twitter",
  month        =  nov,
  year         =  2023,
  howpublished = "\url{https://twitter.com/MartinNebelong/status/1724191921411608808}",
  note         = "Accessed: 2024-2-29",
  language     = "en"
}

@ARTICLE{Perez-y-Perez2007-xt,
  title     = "Employing emotions to drive plot generation in a computer-based
               storyteller",
  author    = "Pérez y Pérez, Rafael",
  journal   = "Cogn. Syst. Res.",
  publisher = "Elsevier BV",
  volume    =  8,
  number    =  2,
  pages     = "89--109",
  abstract  = "Emotions are an integral part of the creative process; however,
               it is hard to find computer models of creativity where emotions
               play a fundamental role. This paper describes a computer model
               for plot generation based on emotions and tensions between
               characters. In particular, the document illustrates how emotions
               are employed to progress a story in a coherent way and generate
               novel situations, and how the dramatic tension of the story in
               progress can be employed to evaluate its interestingness. The
               model is implemented in a computer program named MEXICA [Pérez y
               Pérez, R., \& Sharples, M. (2001). MEXICA: a computer model of a
               cognitive account of creative writing. Journal of Experimental
               and Theoretical Artificial Intelligence, 13(2), 119–139]; this
               work concentrates on the role of emotions in plot generation. The
               main claim is that a story can be represented as a cluster or
               group of emotional links and tensions between characters that
               progresses over story-time; story-actions work as operators that
               modify such clusters. I present results showing how story
               generation is affected by various model parameters. This approach
               means the program is flexible, as it avoids using predefined
               story-structures or characters’ goals to drive story generation.
               Furthermore, evaluation of computer generated stories showed that
               MEXICA’s stories were most often selected as the best story. This
               suggests that the story-generation mechanisms within MEXICA are
               sufficiently rich to generate interesting and novel stories.",
  month     =  jun,
  year      =  2007,
  language  = "en"
}

@ARTICLE{PErez2001-vz,
  title     = "{MEXICA}: A computer model of a cognitive account of creative
               writing",
  author    = "PÉrez, Rafael Pérez Ý and Sharples, Mike",
  journal   = "J. Exp. Theor. Artif. Intell.",
  publisher = "Informa UK Limited",
  volume    =  13,
  number    =  2,
  pages     = "119--139",
  abstract  = "MEXICA is a computer model that produces frameworks for short
               stories based on the engagement-reflection cognitive account of
               writing. During engagement MEXICA generates material guided by
               content and rhetorical constraints, avoiding the use of explicit
               goals or story-structure information. During reflection the
               system breaks impasses, evaluates the novelty and interestingness
               of the story in progress and verifies that coherence requirements
               are satisfied. In this way, MEXICA complements and extends those
               models of computerised story-telling based on traditional
               problem-solving techniques where explicit goals drive the
               generation of stories. This paper describes the
               engagement-reflection account of writing, the general
               characteristics of MEXICA and reports an evaluation of the
               program.",
  month     =  apr,
  year      =  2001,
  language  = "en"
}

@MISC{noauthor_undated-pq,
  title        = "What are these sounds?",
  abstract     = "Explore the fundamentals of music via Ableton's interactive
                  website. Experiment with beats, melody, harmony, basslines,
                  and song structure in your web browser.",
  howpublished = "\url{https://learningmusic.ableton.com/make-beats/what-are-these-sounds.html}",
  note         = "Accessed: 2022-3-1"
}

@MISC{noauthor_undated-gh,
  title        = "Interfaces as a Scarce Resource - {LessWrong}",
  abstract     = "Outline: • * The first three sections (Don Norman’s Fridge,
                  Interface Design, and When And Why Is It Hard?) cover what we
                  mean by “interface”, what it looks like for interfaces to be
                  scarce, and the…",
  howpublished = "\url{https://www.lesswrong.com/posts/hyShz2ABiKX56j5tJ/interfaces-as-a-scarce-resource}",
  note         = "Accessed: 2022-2-22"
}

@MISC{Gonsalves_undated-bo,
  title       = "{AI\_Tunes\_GPT\_3\_Training}.ipynb at main ·
                 robgon-art/ai-tunes",
  author      = "Gonsalves, Robert A",
  institution = "Github",
  abstract    = "Contribute to robgon-art/ai-tunes development by creating an
                 account on GitHub.",
  language    = "en"
}

@BOOK{Bowker2000-ts,
  title     = "Sorting Things Out: Classification and Its Consequences",
  author    = "Bowker, Geoffrey C and Star, Susan Leigh",
  publisher = "MIT Press",
  abstract  = "A revealing and surprising look at how classification systems can
               shape both worldviews and social interactions.What do a
               seventeenth-century mortality table (whose causes of death
               include ``fainted in a bath,'' ``frighted,'' and ``itch''); the
               identification of South Africans during apartheid as European,
               Asian, colored, or black; and the separation of machine- from
               hand-washables have in common? All are examples of
               classification—the scaffolding of information infrastructures.In
               Sorting Things Out, Geoffrey C. Bowker and Susan Leigh Star
               explore the role of categories and standards in shaping the
               modern world. In a clear and lively style, they investigate a
               variety of classification systems, including the International
               Classification of Diseases, the Nursing Interventions
               Classification, race classification under apartheid in South
               Africa, and the classification of viruses and of tuberculosis.The
               authors emphasize the role of invisibility in the process by
               which classification orders human interaction. They examine how
               categories are made and kept invisible, and how people can change
               this invisibility when necessary. They also explore systems of
               classification as part of the built information environment. Much
               as an urban historian would review highway permits and zoning
               decisions to tell a city's story, the authors review archives of
               classification design to understand how decisions have been made.
               Sorting Things Out has a moral agenda, for each standard and
               category valorizes some point of view and silences another.
               Standards and classifications produce advantage or suffering.
               Jobs are made and lost; some regions benefit at the expense of
               others. How these choices are made and how we think about that
               process are at the moral and political core of this work. The
               book is an important empirical source for understanding the
               building of information infrastructures.",
  month     =  aug,
  year      =  2000,
  language  = "en"
}

@ARTICLE{Kellas2005-lc,
  title     = "Rating interactional sense-making in the process of joint
               storytelling",
  author    = "Kellas, Jody Koenig and Trees, April R",
  journal   = "The sourcebook of nonverbal measures: Going beyond words",
  publisher = "books.google.com",
  volume    =  281,
  abstract  = "Telling stories helps people make sense of their experiences and
               develop a sense of control and understanding (Bochner, Ellis, \&
               Tillmann-Healy, 1997; Harvey, 1996). Research portrays
               storytelling as integral to human understanding (eg, Bruner,
               1990; Fisher, 1989), personal relationships (eg, Duck, 1994),
               individual and family identity (eg, Linde, 1993; Stone, 1988),
               and ways ofinteracting (eg, Mandelbaum, 1987, 1989; Miller,
               Mintz, Hoogstra, Fung, \& Pottset, 1992). Al though stories may
               be thought of as told individually, it is with, and …",
  year      =  2005
}

@MISC{UnknownUnknown-vi,
  title        = "Aviation emissions",
  abstract     = "Carbon Independent - Aviation emissions",
  howpublished = "\url{https://www.carbonindependent.org/22.html}",
  note         = "Accessed: 2024-9-17"
}

@MISC{Fein2022-fk,
  title        = "The Language Interface",
  author       = "Fein, Daniel",
  booktitle    = "Medium",
  abstract     = "He ultimately came up with “language interface,” at least for
                  now. This is more than just a one-off thought by Altman,
                  though. In recent weeks, we have seen many of the most
                  respected people in the…",
  month        =  apr,
  year         =  2022,
  howpublished = "\url{https://medium.com/@drfein/the-language-interface-c8096393383f}",
  note         = "Accessed: 2022-4-29",
  language     = "en"
}

@MISC{noauthor_undated-ea,
  title        = "Dialogflow",
  booktitle    = "Google Cloud",
  abstract     = "Virtual agents for bots, applications, services, and devices.",
  howpublished = "\url{https://cloud.google.com/dialogflow/docs}",
  note         = "Accessed: 2022-4-30",
  language     = "en"
}

@ARTICLE{Huang2018-pc,
  title   = "Music Transformer: Generating Music with Long-Term Structure",
  author  = "Huang, Cheng-Zhi Anna and Vaswani, Ashish and Uszkoreit, Jakob and
             Shazeer, Noam and Hawthorne, Curtis and Dai, Andrew M and Hoffman,
             Matthew D and Eck, Douglas",
  journal = "arXiv preprint arXiv:1809. 04281",
  year    =  2018
}

@ARTICLE{Shneiderman2020-je,
  title     = "Bridging the Gap Between Ethics and Practice: Guidelines for
               Reliable, Safe, and Trustworthy Human-centered {AI} Systems",
  author    = "Shneiderman, Ben",
  journal   = "ACM Trans. Interact. Intell. Syst.",
  publisher = "Association for Computing Machinery",
  address   = "New York, NY, USA",
  volume    =  10,
  number    =  4,
  pages     = "1--31",
  abstract  = "This article attempts to bridge the gap between widely discussed
               ethical principles of Human-centered AI (HCAI) and practical
               steps for effective governance. Since HCAI systems are developed
               and implemented in multiple organizational structures, I propose
               15 recommendations at three levels of governance: team,
               organization, and industry. The recommendations are intended to
               increase the reliability, safety, and trustworthiness of HCAI
               systems: (1) reliable systems based on sound software engineering
               practices, (2) safety culture through business management
               strategies, and (3) trustworthy certification by independent
               oversight. Software engineering practices within teams include
               audit trails to enable analysis of failures, software engineering
               workflows, verification and validation testing, bias testing to
               enhance fairness, and explainable user interfaces. The safety
               culture within organizations comes from management strategies
               that include leadership commitment to safety, hiring and training
               oriented to safety, extensive reporting of failures and near
               misses, internal review boards for problems and future plans, and
               alignment with industry standard practices. The trustworthiness
               certification comes from industry-wide efforts that include
               government interventions and regulation, accounting firms
               conducting external audits, insurance companies compensating for
               failures, non-governmental and civil society organizations
               advancing design principles, and professional organizations and
               research institutes developing standards, policies, and novel
               ideas. The larger goal of effective governance is to limit the
               dangers and increase the benefits of HCAI to individuals,
               organizations, and society.",
  month     =  oct,
  year      =  2020,
  keywords  = "Human-Computer Interaction, trustworthy, independent oversight,
               safe, design, Artificial Intelligence, software engineering
               practices, reliable, management strategies, Human-centered AI"
}

@ARTICLE{Gruetzemacher2022-ki,
  title    = "The Power of Natural Language Processing",
  author   = "Gruetzemacher, Ross",
  journal  = "Harvard Business Review",
  abstract = "The conventional wisdom around AI has been that while computers
              have the edge over humans when it comes to data-driven decision
              making, it can’t compete on qualitative tasks. That, however, is
              changing. Natural language processing (NLP) tools have advanced
              rapidly and can help with writing, coding, and discipline-specific
              reasoning. Companies that want to make use of this new tech should
              focus on the following: 1) Identify text data assets and determine
              how the latest techniques can be leveraged to add value for your
              firm, 2) understand how you might leverage AI-based language
              technologies to make better decisions or reorganize your skilled
              labor, 3) begin incorporating new language-based AI tools for a
              variety of tasks to better understand their capabilities, and 4)
              don’t underestimate the transformative potential of AI.",
  month    =  apr,
  year     =  2022
}

@ARTICLE{Carter2017-br,
  title    = "Using {Artificial} {Intelligence} to {Augment} {Human}
              {Intelligence}",
  author   = "Carter, Shan and Nielsen, Michael",
  journal  = "Distill",
  volume   =  2,
  number   =  12,
  pages    = "e9",
  abstract = "By creating user interfaces which let us work with the
              representations inside machine learning models, we can give people
              new tools for reasoning.",
  month    =  dec,
  year     =  2017,
  language = "en"
}

@INPROCEEDINGS{Horvitz1999-wh,
  title     = "Principles of mixed-initiative user interfaces",
  author    = "Horvitz, Eric",
  booktitle = "Proceedings of the {SIGCHI} conference on {Human} {Factors} in
               {Computing} {Systems}",
  publisher = "Association for Computing Machinery",
  address   = "New York, NY, USA",
  pages     = "159--166",
  abstract  = "Recent debate has centered on the relative promise of focusing
               user-interface research on developing new metaphors and tools
               that enhance users abilities to directly manipulate objects
               versus directing effort toward developing interface agents that
               provide automation. In this paper, we review principles that show
               promise for allowing engineers to enhance human-computer
               interaction through an elegant coupling of automated services
               with direct manipulation. Key ideas will be highlighted in terms
               of the Lookout system for scheduling and meeting management.",
  series    = "CHI '99",
  month     =  may,
  year      =  1999,
  keywords  = "decision theory, direct manipulaton, intelligent agents,
               probability, UI design, user modeling"
}

@INPROCEEDINGS{Terry2004-pg,
  title     = "Variation in element and action: supporting simultaneous
               development of alternative solutions",
  author    = "Terry, Michael and Mynatt, Elizabeth D and Nakakoji, Kumiyo and
               Yamamoto, Yasuhiro",
  booktitle = "Proceedings of the {SIGCHI} {Conference} on {Human} {Factors} in
               {Computing} {Systems}",
  publisher = "Association for Computing Machinery",
  address   = "New York, NY, USA",
  pages     = "711--718",
  abstract  = "The complexity of many problems necessitates creating and
               exploring multiple, alternative solutions. However, current user
               interfaces do not cleanly support creating alternatives at a time
               when they are likely to be discovered: as users interactively
               modify data. This paper presents Parallel Paths, a novel model of
               interaction that facilitates generating, manipulating, and
               comparing alternative solutions. In contrast to existing
               approaches such as automated history capture tools, Parallel
               Paths emphasizes the active, simultaneous development of
               multiple, alternative solutions. We demonstrate this model of
               interaction in Parallel Pies, a user interface mechanism
               developed for image manipulation tasks that allows users to:
               easily create solution alternatives as they interact with a
               command; embed the alternatives in the same workspace; manipulate
               the alternatives independently or simultaneously as if they were
               the same object; and perform side-by-side comparisons of each.
               Results from an initial evaluation are presented, along with
               implications for future designs.",
  series    = "CHI '04",
  month     =  apr,
  year      =  2004,
  keywords  = "experimentation, exploration, interaction models, parallel
               exploration, what-if tools"
}

@INPROCEEDINGS{Jacobs2018-zd,
  title     = "Extending {Manual} {Drawing} {Practices} with {Artist}-{Centric}
               {Programming} {Tools}",
  author    = "Jacobs, Jennifer and Brandt, Joel and Mech, Radomír and Resnick,
               Mitchel",
  booktitle = "Proceedings of the 2018 {CHI} {Conference} on {Human} {Factors}
               in {Computing} {Systems}",
  publisher = "Association for Computing Machinery",
  address   = "New York, NY, USA",
  pages     = "1--13",
  abstract  = "Procedural art, or art made with programming, suggests
               opportunities to extend traditional arts like painting and
               drawing; however, this potential is limited by tools that
               conflict with manual practices. Programming languages present
               learning barriers and manual drawing input is not a first class
               primitive in common programming models. We hypothesize that by
               developing programming languages and environments that align with
               how manual artists work, we can build procedural systems that
               enhance, rather than displace, manual art. To explore this, we
               developed Dynamic Brushes, a programming and drawing environment
               motivated by interviews with artists. Dynamic Brushes enables the
               creation of ad-hoc drawing tools that transform stylus inputs to
               procedural patterns. Applications range from transforming
               individual strokes to behaviors that draw multiple strokes
               simultaneously, respond to temporal events, and leverage external
               data. Results from an extended evaluation with artists provide
               guidelines for learnable, expressive systems that blend manual
               and procedural creation.",
  series    = "CHI '18",
  month     =  apr,
  year      =  2018,
  keywords  = "generative art, procedural art, programming"
}

@ARTICLE{Shneiderman1997-pu,
  title   = "Direct manipulation vs. interface agents",
  author  = "Shneiderman, Ben and Maes, Pattie",
  journal = "Interactions",
  volume  =  4,
  number  =  6,
  pages   = "42--61",
  month   =  nov,
  year    =  1997
}

@ARTICLE{Shneiderman2020-wm,
  title    = "Bridging the {Gap} {Between} {Ethics} and {Practice}: {Guidelines}
              for {Reliable}, {Safe}, and {Trustworthy} {Human}-centered {AI}
              {Systems}",
  author   = "Shneiderman, Ben",
  journal  = "ACM Transactions on Interactive Intelligent Systems",
  volume   =  10,
  number   =  4,
  pages    = "26:1--26:31",
  abstract = "This article attempts to bridge the gap between widely discussed
              ethical principles of Human-centered AI (HCAI) and practical steps
              for effective governance. Since HCAI systems are developed and
              implemented in multiple organizational structures, I propose 15
              recommendations at three levels of governance: team, organization,
              and industry. The recommendations are intended to increase the
              reliability, safety, and trustworthiness of HCAI systems: (1)
              reliable systems based on sound software engineering practices,
              (2) safety culture through business management strategies, and (3)
              trustworthy certification by independent oversight. Software
              engineering practices within teams include audit trails to enable
              analysis of failures, software engineering workflows, verification
              and validation testing, bias testing to enhance fairness, and
              explainable user interfaces. The safety culture within
              organizations comes from management strategies that include
              leadership commitment to safety, hiring and training oriented to
              safety, extensive reporting of failures and near misses, internal
              review boards for problems and future plans, and alignment with
              industry standard practices. The trustworthiness certification
              comes from industry-wide efforts that include government
              interventions and regulation, accounting firms conducting external
              audits, insurance companies compensating for failures,
              non-governmental and civil society organizations advancing design
              principles, and professional organizations and research institutes
              developing standards, policies, and novel ideas. The larger goal
              of effective governance is to limit the dangers and increase the
              benefits of HCAI to individuals, organizations, and society.",
  month    =  oct,
  year     =  2020,
  keywords = "Artificial Intelligence, design, Human-centered AI, Human-Computer
              Interaction, independent oversight, management strategies,
              reliable, safe, software engineering practices, trustworthy"
}

@MISC{Engelbart1962-ir,
  title  = "Augmenting {Human} {Intellect}",
  author = "Engelbart, Douglas",
  year   =  1962
}

@INPROCEEDINGS{Roberts2018-wn,
  title     = "Magenta.js: {A} {JavaScript} {API} for {Augmenting} {Creativity}
               with {Deep} {Learning}",
  author    = "Roberts, Adam and Hawthorne, Curtis and Simon, Ian",
  booktitle = "Joint {Workshop} on {Machine} {Learning} for {Music} ({ICML})",
  year      =  2018
}

@ARTICLE{Kietzmann2020-tm,
  title    = "Deepfakes: {Trick} or treat?",
  author   = "Kietzmann, Jan and Lee, Linda W and McCarthy, Ian P and Kietzmann,
              Tim C",
  journal  = "Bus. Horiz.",
  volume   =  63,
  number   =  2,
  pages    = "135--146",
  abstract = "Although manipulations of visual and auditory media are as old as
              media themselves, the recent entrance of deepfakes has marked a
              turning point in the creation of fake content. Powered by the
              latest technological advances in artificial intelligence and
              machine learning, deepfakes offer automated procedures to create
              fake content that is harder and harder for human observers to
              detect. The possibilities to deceive are endless—including
              manipulated pictures, videos, and audio—and organizations must be
              prepared as this will undoubtedly have a large societal impact. In
              this article, we provide a working definition of deepfakes
              together with an overview of its underlying technology. We
              classify different deepfake types and identify risks and
              opportunities to help organizations think about the future of
              deepfakes. Finally, we propose the R.E.A.L. framework to manage
              deepfake risks: Record original content to ensure deniability,
              Expose deepfakes early, Advocate for legal protection, and
              Leverage trust to counter credulity. Following these principles,
              we hope that our society can be more prepared to counter deepfake
              tricks as we appreciate deepfake treats.",
  series   = "ARTIFICIAL INTELLIGENCE AND MACHINE LEARNING",
  month    =  mar,
  year     =  2020,
  keywords = "Artificial intelligence, Deep neural networks, Deepfakes, Fake
              news, Machine learning",
  language = "en"
}

@ARTICLE{Radford2019-yy,
  title    = "Language {Models} are {Unsupervised} {Multitask} {Learners}",
  author   = "Radford, Alec and Wu, Jeffrey and Child, Rewon and Luan, David and
              Amodei, Dario and Sutskever, Ilya",
  pages    =  24,
  abstract = "Natural language processing tasks, such as question answering,
              machine translation, reading comprehension, and summarization, are
              typically approached with supervised learning on taskspeciﬁc
              datasets. We demonstrate that language models begin to learn these
              tasks without any explicit supervision when trained on a new
              dataset of millions of webpages called WebText. When conditioned
              on a document plus questions, the answers generated by the
              language model reach 55 F1 on the CoQA dataset - matching or
              exceeding the performance of 3 out of 4 baseline systems without
              using the 127,000+ training examples. The capacity of the language
              model is essential to the success of zero-shot task transfer and
              increasing it improves performance in a log-linear fashion across
              tasks. Our largest model, GPT-2, is a 1.5B parameter Transformer
              that achieves state of the art results on 7 out of 8 tested
              language modeling datasets in a zero-shot setting but still
              underﬁts WebText. Samples from the model reﬂect these improvements
              and contain coherent paragraphs of text. These ﬁndings suggest a
              promising path towards building language processing systems which
              learn to perform tasks from their naturally occurring
              demonstrations.",
  year     =  2019,
  language = "en"
}

@MISC{Jordan2018-sr,
  title    = "Artificial {Intelligence} — {The} {Revolution} {Hasn}’t {Happened}
              {Yet}",
  author   = "Jordan, Michael",
  journal  = "Medium",
  abstract = "Artificial Intelligence (AI) is the mantra of the current era. The
              phrase is intoned by technologists, academicians, journalists and…",
  month    =  apr,
  year     =  2018,
  language = "en"
}

@ARTICLE{Dunbar2009-kg,
  title    = "Creativity {Evaluation} through {Latent} {Semantic} {Analysis}",
  author   = "Dunbar, Kevin and Forster, Eve",
  journal  = "Proceedings of the Annual Meeting of the Cognitive Science Society",
  volume   =  31,
  number   =  31,
  abstract = "Author(s): Dunbar, Kevin; Forster, Eve",
  year     =  2009,
  language = "en"
}

@ARTICLE{Lamb2018-ir,
  title    = "Evaluating {Computational} {Creativity}: {An} {Interdisciplinary}
              {Tutorial}",
  author   = "Lamb, Carolyn and Brown, Daniel G and Clarke, Charles L A",
  journal  = "ACM Computing Surveys",
  volume   =  51,
  number   =  2,
  pages    = "28:1--28:34",
  abstract = "This article is a tutorial for researchers who are designing
              software to perform a creative task and want to evaluate their
              system using interdisciplinary theories of creativity. Researchers
              who study human creativity have a great deal to offer
              computational creativity. We summarize perspectives from
              psychology, philosophy, cognitive science, and computer science as
              to how creativity can be measured both in humans and in computers.
              We survey how these perspectives have been used in computational
              creativity research and make recommendations for how they should
              be used.",
  month    =  feb,
  year     =  2018,
  keywords = "Computational aesthetics, computational creativity, digital art"
}

@ARTICLE{Boden1998-yn,
  title    = "Creativity and artificial intelligence",
  author   = "Boden, Margaret A",
  journal  = "Artif. Intell.",
  volume   =  103,
  number   =  1,
  pages    = "347--356",
  abstract = "Creativity is a fundamental feature of human intelligence, and a
              challenge for AI. AI techniques can be used to create new ideas in
              three ways: by producing novel combinations of familiar ideas; by
              exploring the potential of conceptual spaces; and by making
              transformations that enable the generation of previously
              impossible ideas. AI will have less difficulty in modelling the
              generation of new ideas than in automating their evaluation.",
  series   = "Artificial Intelligence 40 years later",
  month    =  aug,
  year     =  1998,
  language = "en"
}

@MISC{McLeavey_Payne2019-im,
  title   = "{MuseNet}",
  author  = "McLeavey Payne, Christine",
  journal = "OpenAI blog",
  month   =  apr,
  year    =  2019
}

@ARTICLE{Bodily2018-en,
  title    = "Explainability: {An} {Aesthetic} for {Aesthetics} in
              {Computational} {Creative} {Systems}",
  author   = "Bodily, Paul M and Ventura, Dan",
  pages    =  8,
  abstract = "Of continued interest in the ﬁeld of Computational Creativity (CC)
              is the question of what characteristics are required for
              autonomous creativity. Many characteristics have been proposed
              including the possession of an autonomous aesthetic. Paramount to
              the idea of an autonomous aesthetic is the need for a
              meta-aesthetic: an aesthetic which guides the system in selecting
              its own aesthetic. We review how aesthetics have (and have not)
              been used in CC systems to date, including examples of autonomous
              aesthetics. We formalize the idea of a meta-aesthetic in an
              extension of Wiggins’ 2006 framework for describing computational
              systems generally. We propose explainability as an effective
              meta-aesthetic for autonomous creative systems and make some
              comments about the explainability of creativity and of
              explainability itself.",
  year     =  2018,
  language = "en"
}

@BOOK{Florida2010-lv,
  title  = "The {Great} {Reset}: {How} {New} {Ways} of {Living} and {Working}
            {Drive} {Post}-{Crash} {Prosperity}",
  author = "Florida, Richard",
  month  =  jan,
  year   =  2010
}

@INPROCEEDINGS{Engel2019-nj,
  title  = "{GANSynth}: Adversarial Neural Audio Synthesis",
  author = "Engel, Jesse and Agrawal, Kumar Krishna and Chen, Shuo and
            Gulrajani, Ishaan and Donahue, Chris and Roberts, Adam",
  year   =  2019
}

@BOOK{Goodfellow2016-su,
  title     = "Deep Learning",
  author    = "Goodfellow, Ian and Bengio, Yoshua and Courville, Aaron",
  publisher = "MIT Press",
  abstract  = "An introduction to a broad range of topics in deep learning,
               covering mathematical and conceptual background, deep learning
               techniques used in industry, and research perspectives.“Written
               by three experts in the field, Deep Learning is the only
               comprehensive book on the subject.”—Elon Musk, cochair of OpenAI;
               cofounder and CEO of Tesla and SpaceXDeep learning is a form of
               machine learning that enables computers to learn from experience
               and understand the world in terms of a hierarchy of concepts.
               Because the computer gathers knowledge from experience, there is
               no need for a human computer operator to formally specify all the
               knowledge that the computer needs. The hierarchy of concepts
               allows the computer to learn complicated concepts by building
               them out of simpler ones; a graph of these hierarchies would be
               many layers deep. This book introduces a broad range of topics in
               deep learning. The text offers mathematical and conceptual
               background, covering relevant concepts in linear algebra,
               probability theory and information theory, numerical computation,
               and machine learning. It describes deep learning techniques used
               by practitioners in industry, including deep feedforward
               networks, regularization, optimization algorithms, convolutional
               networks, sequence modeling, and practical methodology; and it
               surveys such applications as natural language processing, speech
               recognition, computer vision, online recommendation systems,
               bioinformatics, and videogames. Finally, the book offers research
               perspectives, covering such theoretical topics as linear factor
               models, autoencoders, representation learning, structured
               probabilistic models, Monte Carlo methods, the partition
               function, approximate inference, and deep generative models. Deep
               Learning can be used by undergraduate or graduate students
               planning careers in either industry or research, and by software
               engineers who want to begin using deep learning in their products
               or platforms. A website offers supplementary material for both
               readers and instructors.",
  month     =  nov,
  year      =  2016,
  language  = "en"
}

@MISC{noauthor_undated-tg,
  title        = "Inflection",
  abstract     = "Inflection is an AI-first company, redefining human-computer
                  interaction",
  howpublished = "\url{https://inflection.ai/}",
  note         = "Accessed: 2022-4-30",
  language     = "en"
}

@MISC{Fein2022-ct,
  title        = "The Language Interface",
  author       = "Fein, Daniel",
  booktitle    = "Medium",
  abstract     = "He ultimately came up with “language interface,” at least for
                  now. This is more than just a one-off thought by Altman,
                  though. In recent weeks, we have seen many of the most
                  respected people in the…",
  month        =  apr,
  year         =  2022,
  howpublished = "\url{https://medium.com/@drfein/the-language-interface-c8096393383f}",
  note         = "Accessed: 2022-4-30",
  language     = "en"
}

@MISC{noauthor_undated-cf,
  title        = "About Us",
  howpublished = "\url{https://www.adept.ai/about-us}",
  note         = "Accessed: 2022-4-30"
}

@MISC{noauthor_undated-er,
  title        = "Adept",
  howpublished = "\url{https://www.adept.ai/}",
  note         = "Accessed: 2022-4-30"
}

@MISC{Apple_Inc_undated-pi,
  title        = "Human Interface Guidelines",
  author       = "{Apple Inc}",
  abstract     = "Get in-depth information and UI resources for designing great
                  apps that integrate seamlessly with Apple platforms.",
  howpublished = "\url{https://developer.apple.com/design/human-interface-guidelines/}",
  note         = "Accessed: 2022-4-30"
}

@MISC{noauthor_undated-tx,
  title        = "Tackling multiple tasks with a single visual language model",
  abstract     = "We introduce Flamingo, a single visual language model (VLM)
                  that sets a new state of the art in few-shot learning on a
                  wide range of open-ended multimodal tasks.",
  howpublished = "\url{https://www.deepmind.com/blog/tackling-multiple-tasks-with-a-single-visual-language-model}",
  note         = "Accessed: 2022-5-3",
  language     = "en"
}

@BOOK{Tatarkiewicz2012-oh,
  title     = "A history of six ideas: An essay in aesthetics",
  author    = "Tatarkiewicz, W",
  publisher = "Springer",
  address   = "Dordrecht, Netherlands",
  edition   =  1980,
  series    = "Melbourne International Philosophy Series",
  month     =  dec,
  year      =  2012,
  language  = "en"
}

@BOOK{Rubin2023-lw,
  title     = "The creative act: A way of being",
  author    = "Rubin, Rick",
  publisher = "Penguin Press",
  address   = "New York, NY",
  abstract  = "The \#1 New York Times bestseller. ``A gorgeous and inspiring
               work of art on creation, creativity, the work of the artist. It
               will gladden the hearts of writers and artists everywhere, and
               get them working...",
  month     =  jan,
  year      =  2023,
  language  = "en"
}

@BOOK{Scharf1968-na,
  title     = "Art and Photography",
  author    = "Scharf, A",
  publisher = "Allen Lane",
  abstract  = "Analyzes the relationship between art and photography in England
               and France since the mid-nineteenth century.",
  year      =  1968
}

@BOOK{Sontag1978-ki,
  title     = "On Photography",
  author    = "Sontag, Susan",
  publisher = "Allan Lane, Penguin Books",
  address   = "London",
  year      =  1978
}

@MISC{Juhlaviikot2021-hi,
  title     = "Brian Eno at Helsinki Festival: Generative Systems",
  author    = "Juhlaviikot, Helsinki Festival /",
  publisher = "Youtube",
  abstract  = "Generative Systems. An excerpt from a conversation with Brian Eno
               hosted by Marko Ahtisaari, Artistic Director, Helsinki Festival
               for the opening of the Hels...",
  month     =  aug,
  year      =  2021
}

@ARTICLE{Wiggins2006-zd,
  title     = "A preliminary framework for description, analysis and comparison
               of creative systems",
  author    = "Wiggins, Geraint A",
  journal   = "Knowl. Based Syst.",
  publisher = "Elsevier BV",
  volume    =  19,
  number    =  7,
  pages     = "449--458",
  abstract  = "I summarise and attempt to clarify some concepts presented in and
               arising from Margaret Boden’s (1990) descriptive hierarchy of
               creativity, by beginning to formalise the ideas she proposes. The
               aim is to move towards a model which allows detailed comparison,
               and hence better understanding, of systems which exhibit
               behaviour which would be called “creative” in humans. The work
               paves the way for the description of naturalistic, multi-agent
               creative AI systems, which create in a societal context.I
               demonstrate some simple reasoning about creative behaviour based
               on the new framework, to show how it might be useful for the
               analysis and study of creative systems. In particular, I identify
               some crucial properties of creative systems, in terms of the
               framework components, some of which may usefully be proven a
               priori of a given system.I suggest that Boden’s descriptive
               framework, once elaborated in detail, is more uniform and more
               powerful than it first appears.",
  month     =  nov,
  year      =  2006,
  language  = "en"
}

@MISC{Gibbons_undated-yi,
  title        = "User Need Statements",
  author       = "Gibbons, Sarah",
  booktitle    = "Nielsen Norman Group",
  abstract     = "User need statements, also called problem statements or
                  point-of-view statements, are a powerful, fundamental tool for
                  defining and aligning on the problem you are going to solve.",
  howpublished = "\url{https://www.nngroup.com/articles/user-need-statements/}",
  note         = "Accessed: 2022-6-28",
  language     = "en"
}

@MISC{Gupta2022-va,
  title        = "Deepmind Researchers Propose the Standardised Test Suite
                  ({STS}): A Novel Method for Evaluating Agents that are Trained
                  to Interact with Human Participants in a {3D} virtual world",
  author       = "Gupta, Khushboo",
  booktitle    = "MarkTechPost",
  abstract     = "Deepmind Researchers Propose the Standardised Test Suite
                  (STS): a Novel Method for Evaluating Agents that are Trained
                  to Interact with Human Participants in a 3D Virtual World",
  month        =  may,
  year         =  2022,
  howpublished = "\url{https://www.marktechpost.com/2022/05/30/deepmind-researchers-propose-the-standardised-test-suite-sts-a-novel-method-for-evaluating-agents-that-are-trained-to-interact-with-human-participants-in-a-3d-virtual-world/}",
  note         = "Accessed: 2022-6-2",
  language     = "en"
}

@MISC{Harvard_Advanced_Leadership_Initiative2021-fx,
  title     = "Human-{AI} interaction: From artificial intelligence to human
               intelligence augmentation",
  author    = "{Harvard Advanced Leadership Initiative}",
  publisher = "Youtube",
  abstract  = "Elena Glassman, Harvard SEAS, discusses how automation and
               artificial intelligence produces data that still needs to be
               interpreted by humans.",
  month     =  jun,
  year      =  2021
}

@MISC{noauthor_undated-ap,
  howpublished = "\url{https://www.researchgate.net/publication/242394690\_Creativity\_Support\_Tool\_Evaluation\_Methods\_and\_Metrics}",
  note         = "Accessed: 2022-6-23"
}

@BOOK{Malafouris2013-by,
  title     = "How things shape the mind",
  author    = "Malafouris, Lambros",
  publisher = "The MIT Press",
  abstract  = "An account of the different ways in which things have become
               cognitive extensions of the human body, from prehistory to the
               present.An increasingly influential",
  month     =  jul,
  year      =  2013,
  language  = "en"
}

@BOOK{Moggridge2007-sp,
  title     = "Designing interactions",
  author    = "Moggridge, Bill",
  publisher = "MIT Press",
  address   = "Cambridge, Mass.",
  year      =  2007,
  keywords  = "Human-computer interaction"
}

@BOOK{Boden2003-hk,
  title     = "The creative mind",
  author    = "Boden, Margaret A",
  publisher = "Routledge",
  address   = "London, England",
  edition   =  2,
  abstract  = "How is it possible to think new thoughts? What is creativity and
               can science explain it? And just how did Coleridge dream up the
               creatures of The Ancient Mariner? When The Creative Mind: Myths
               and Mechanisms was first published, Margaret A. Boden's bold and
               provocative exploration of creativity broke new ground. Boden
               uses examples such as jazz improvisation, chess, story writing,
               physics, and the music of Mozart, together with computing models
               from the field of artificial intelligence to uncove",
  month     =  sep,
  year      =  2003,
  language  = "en"
}

@BOOK{Preece2015-ts,
  title     = "Interaction Design - Beyond Human-computer Interaction {4E}",
  author    = "Preece, Jennifer and Sharp, Helen and Rogers, Yvonne",
  publisher = "Wiley",
  edition   =  4,
  month     =  feb,
  year      =  2015,
  language  = "en"
}

@BOOK{Preece2015-ei,
  title     = "Interaction Design - Beyond Human-computer Interaction {4E}",
  author    = "Preece, Jennifer and Sharp, Helen and Rogers, Yvonne",
  publisher = "Wiley",
  edition   =  4,
  month     =  feb,
  year      =  2015,
  language  = "en"
}

@ARTICLE{Norman2010-sh,
  title     = "Natural user interfaces are not natural",
  author    = "Norman, Donald A",
  journal   = "Interactions",
  publisher = "Association for Computing Machinery (ACM)",
  volume    =  17,
  number    =  3,
  pages     = "6--10",
  abstract  = "``I believe we will look back on 2010 as the year we expanded
               beyond the mouse and keyboard and started incorporating more
               natural forms of interaction such as touch, speech,...",
  month     =  may,
  year      =  2010,
  language  = "en"
}

@MISC{noauthor_undated-ok,
  title        = "Natural user interfaces are not natural",
  abstract     = "``I believe we will look back on 2010 as the year we expanded
                  beyond the mouse and keyboard and started incorporating more
                  natural forms of interaction such as touch, speech,...",
  howpublished = "\url{https://interactions.acm.org/archive/view/may-june-2010/natural-user-interfaces-are-not-natural1}",
  note         = "Accessed: 2022-6-20",
  language     = "en"
}

@INBOOK{Zank2022-mx,
  title     = "Martin Buber",
  author    = "Zank, Michael and Braiterman, Zachary",
  editor    = "Zalta, Edward N",
  booktitle = "The Stanford Encyclopedia of Philosophy",
  publisher = "Metaphysics Research Lab, Stanford University",
  edition   = "Spring 2022",
  year      =  2022
}

@ARTICLE{Scrivener_undated-ev,
  title   = "Towards the Operationalisation of Design Research as Reflection in
             and on Action and Practice",
  author  = "{Scrivener}",
  journal = "the future. Doctoral education in design: Proceedings …"
}

@ARTICLE{Schon_undated-jd,
  title   = "The Reflective Practitioner: How Professionals Think in Action.
             Arena",
  author  = "{Schön}",
  journal = "Farnham: Ashgate Publishing"
}

@ARTICLE{Kaur2019-dp,
  title    = "Building Shared Mental Models between Humans and {AI} for
              Effective Collaboration",
  author   = "Kaur, Harmanpreet",
  abstract = "This paper proposes methods for building shared mental models
              between humans and AI to enable human-AI collaboration at a level
              where both can be equal partners working on a shared task.
              Intelligent systems have become increasingly common in settings
              ranging from performing everyday tasks more easily to
              decision-making for complex domains (e.g., healthcare, autonomous
              driving, criminal justice). Given this rising ubiquity of
              artificial intelligence (AI), both researchers and industry
              practitioners are exploring ways to better integrate AI agents in
              tasks that people do at home or work. However, these systems are
              currently limited because of gaps in the understanding between
              humans and their AI counterparts. In this paper, we propose
              methods for building shared mental models between humans and AI to
              enable human-AI collaboration at a level where both can be equal
              partners working on a shared task. We ground our approach in
              existing literature from CSCW and UX design.",
  year     =  2019,
  language = "en"
}

@MISC{noauthor_undated-co,
  title        = "[No title]",
  howpublished = "\url{https://www.midjourney.com/auth/signin/?callbackUrl=https\%3A\%2F\%2Fwww.midjourney.com\%2Faccount\%2F\%3FcallbackUrl\%3D\%252Fapp\%252F}",
  note         = "Accessed: 2022-7-1",
  language     = "en"
}

@MISC{noauthor_undated-vw,
  title        = "[No title]",
  howpublished = "\url{https://www.midjourney.com/auth/signin/?callbackUrl=https\%3A\%2F\%2Fwww.midjourney.com\%2Faccount\%2F\%3FcallbackUrl\%3D\%252Fapp\%252F}",
  note         = "Accessed: 2022-7-1",
  language     = "en"
}

@ARTICLE{Metz2021-zo,
  title     = "A.{I}. Can Now Write Its Own Computer Code. That’s Good News for
               Humans",
  author    = "Metz, Cade",
  journal   = "The New York Times",
  publisher = "The New York Times",
  abstract  = "A new technology called Codex generates programs in 12 coding
               languages and even translates between them. But it is not a
               threat to professional programmers.",
  month     =  sep,
  year      =  2021,
  language  = "en"
}

@ARTICLE{Friedman2021-xg,
  title    = "Image Co-Creation by Non-Programmers and Generative Adversarial
              Networks",
  author   = "Friedman, D and Pollak, D",
  journal  = "IUI Workshops",
  abstract = "A new course intended for non-programmer MA students in
              human-computer interaction, aimed at training them in authoring
              content using generative models, finds ways to obtain their
              creative needs by mostly exploring the dataset level (as opposed
              to the model architecture). Generative models such as generative
              adversarial networks are now being studied extensively.
              Eventually, however, many of them are intended for non-programmers
              to work with, e.g. designers, artists, or other content creators.
              What happens when such individuals are confronted with using GANs?
              We present a case study – a new course intended for non-programmer
              MA students in human-computer interaction, aimed at training them
              in authoring content using generative models. As their final
              assignment, the students were asked to train generative
              adversarial networks in order to generate images from a predefined
              category of their choice. The students either used a graphical
              user interface (GUI)-based software or modified preexisting python
              code using simplified Google Colab notebooks. We present several
              lessons learned from this course. First, we analyze the joint
              human-AI creation process and recognize points where students
              could intervene, with anecdotal examples of how they creatively
              explored these opportunities. Interestingly, while the majority of
              algorithmic research is focused on how to make models more
              controllable (e.g., via conditioning or latent space
              disentanglement), the students found ways to obtain their creative
              needs by mostly exploring the dataset level (as opposed to the
              model architecture). Additionally, we present the results of a
              short survey, comparing the two modes of work (GUI vs code).",
  year     =  2021,
  language = "en"
}

@INPROCEEDINGS{Inkpen2020-ce,
  title     = "Does my {AI} help or hurt? Exploring human-{AI} complementarity",
  author    = "Inkpen, Kori",
  booktitle = "Proceedings of the 28th ACM Conference on User Modeling,
               Adaptation and Personalization",
  publisher = "ACM",
  address   = "New York, NY, USA",
  abstract  = "This talk will highlight important directions for Human-AI
               research, and explore the interplay between humans and AI
               systems. In a world where the use of AI is growing and evolving,
               where will we be in 5 years? 10 years? 20 years? What role will
               AI play in our society, and how will humans and AI interact?
               While there will undoubtedly be scenarios where AI systems will
               be able to outperform humans, there will also continue to be
               instances where humans will be a critical part of the process. As
               researchers explore improvements to AI systems, we also need to
               explore the interplay between humans and AI, and continue to
               evolve our understanding of how humans and AI systems can work
               together, effectively harnessing the benefits of both systems
               [3]. Designing effective interaction between the human and the AI
               systems is critical for future use of Human-AI systems [1].
               Merely building an AI system that blindly sends recommendations
               to users has been shown in some cases to decrease human
               performance [2]. Different models can also have differential
               impact on user's trust of the model, adherence to the
               recommendation, and can impact bias in decision making tasks.
               This talk will highlight important directions for Human-AI
               research.",
  month     =  jul,
  year      =  2020,
  language  = "en"
}

@ARTICLE{Kantosalo2020-zf,
  title    = "Five {C}'s for Human-Computer Co-Creativity - An Update on
              Classical Creativity Perspectives",
  author   = "Kantosalo, Anna and Takala, T",
  journal  = "ICCC",
  abstract = "A domain independent framework for discussing human–computer
              co-creativity is presented that allows the attribution of
              creativity not only to individual creators but to a collective of
              creators, recognising the importance of meta-level communication
              to the creative collaboration, and the variety of creative
              contributions that emerge during a co-Creative process. This paper
              presents a domain independent framework for discussing
              human–computer co-creativity. It expands on Rhodes’ (1961) four
              perspectives on creativity and their later adaptations to
              socio-cultural views of creativity and computational creativity.
              The new framework allows the attribution of creativity not only to
              individual creators but to a collective of creators, recognising
              the importance of meta-level communication to the creative
              collaboration, and the variety of creative contributions that
              emerge during a co-creative process. It also elaborates on the
              different communities and contexts surrounding co-creative
              collaboration and thus facilitates the analysis, evaluation and
              study of human– computer co-creativity by allowing researchers to
              describe and situate their work in the field.",
  year     =  2020,
  language = "en"
}

@INPROCEEDINGS{Newn2020-mv,
  title     = "Nonverbal communication in human-{AI} interaction: Opportunities
               and challenges",
  author    = "Newn, Joshua and Singh, Ronal and Allison, Fraser and Madumal,
               Prashan and Velloso, Eduardo and Vetere, Frank",
  booktitle = "Human Computer Interaction and Emerging Technologies: Adjunct
               Proceedings from the INTERACT 2019 Workshops",
  publisher = "Cardiff University Press",
  abstract  = "This work investigated whether an artificial agent, given the
               ability to observe human gaze, can make inferences on intentions,
               and how aspects of these inferences can be communicated to a
               human collaborator. In recent years, we have explored the use of
               gaze—an important nonverbal communication signal and cue in
               everyday human-human interaction—for use with AI systems.
               Specifically, our work investigated whether an artificial agent,
               given the ability to observe human gaze, can make inferences on
               intentions, and how aspects of these inferences can be
               communicated to a human collaborator. We leveraged a range of
               humancomputer interaction techniques to inform the design of a
               gaze-enabled artificial agent that can predict and communicate
               predictions. In this paper, we include a snapshot of how AI and
               HCI can be brought together to inform the design of an
               explainable interface for an artificial agent. To conclude, we
               outline the challenges we faced when designing AI systems that
               incorporate nonverbal communication stemming from our work.",
  month     =  may,
  year      =  2020,
  language  = "en"
}

@INPROCEEDINGS{Hwang2022-fi,
  title     = "{AI} in your mind: Counterbalancing perceived agency and
               experience in human-{AI} interaction",
  author    = "Hwang, Angel Hsing-Chi and Won, Andrea Stevenson",
  booktitle = "CHI Conference on Human Factors in Computing Systems Extended
               Abstracts",
  publisher = "ACM",
  address   = "New York, NY, USA",
  abstract  = "This mixed-methods study attempts to capture users’ conception of
               AI through the two-dimensional mind perception framework
               (perceived agency vs. experience) in cognitive psychology and a
               series of drawing tasks to apply users” mind maps of AI entities
               to highlight risks in human-AI interaction (HAII) and propose
               design solutions accordingly. In this mixed-methods study, we
               attempt to capture users’ conception of AI through the
               two-dimensional mind perception framework (perceived agency vs.
               experience) in cognitive psychology [13] and a series of drawing
               tasks. Our data illustrate how participants perceive AI entities
               with physical embodiment, depicting AI through devices, imaginary
               human figures, or full techno-ecosystems. Furthermore, we apply
               users’ mind maps of AI entities to highlight risks in human-AI
               interaction (HAII) and propose design solutions accordingly. We
               posit HAII research and development should be cognizant that
               users possess existing AI images and should exploit them as
               starting points for design improvement.",
  month     =  apr,
  year      =  2022,
  language  = "en"
}

@INPROCEEDINGS{Muller2022-lh,
  title     = "{GenAICHI}: Generative {AI} and {HCI}",
  author    = "Muller, Michael and Chilton, Lydia B and Kantosalo, Anna and
               Martin, Charles Patrick and Walsh, Greg",
  booktitle = "CHI Conference on Human Factors in Computing Systems Extended
               Abstracts",
  publisher = "ACM",
  address   = "New York, NY, USA",
  abstract  = "This workshop applies human centered themes to a new and powerful
               technology, generative artificial intelligence (AI). Unlike AI
               systems that produce decisions or descriptions, generative AI
               systems can produce new and creative content that can include
               images, texts, music, video, and other forms of design. The
               results are often similar to results produced by humans. However,
               it is not yet clear how humans make sense of generative AI
               algorithms or their outcomes. It is also not yet clear how humans
               can control and more generally, interact with, these powerful
               capabilities. Finally, it is not clear what kinds of
               collaboration patterns will emerge when creative humans and
               creative technologies work together. It is time to convene the
               interdisciplinary research domain of generative AI and HCI.
               Participation in this invitational workshop is open to seasoned
               scholars and early career researchers. We solicit descriptions of
               completed projects, works-in-progress, and provocations. Together
               we will develop theories and practices in this intriguing new
               domain.",
  month     =  apr,
  year      =  2022,
  language  = "en"
}

@MISC{Wikipedia_contributors2022-jy,
  title        = "Dialogic",
  author       = "{Wikipedia contributors}",
  booktitle    = "Wikipedia, The Free Encyclopedia",
  abstract     = "Dialogic refers to the use of conversation or shared dialogue
                  to explore the meaning of something. (This is as opposed to
                  monologic which refers to one entity with all the information
                  simply giving it to others without exploration and
                  clarification of meaning through discussion.) The word
                  dialogic relates to or is characterized by dialogue and its
                  use. A dialogic is communication presented in the form of
                  dialogue. Dialogic processes refer to implied meaning in words
                  uttered by a speaker and interpreted by a listener. Dialogic
                  works carry on a continual dialogue that includes interaction
                  with previous information presented. The term is used to
                  describe concepts in literary theory and analysis as well as
                  in philosophy.",
  month        =  jan,
  year         =  2022,
  howpublished = "\url{https://en.wikipedia.org/w/index.php?title=Dialogic\&oldid=1063645144}",
  note         = "Accessed: --"
}

@BOOK{noauthor_1955-ld,
  title    = "A Proposal for the Dartmouth Summer Research Project on Artificial
              Intelligence",
  year     =  1955,
  language = "en"
}

@MISC{Wikipedia_contributors2022-co,
  title        = "Brian Eno",
  author       = "{Wikipedia contributors}",
  booktitle    = "Wikipedia, The Free Encyclopedia",
  abstract     = ".mw-parser-output
                  .infobox-subbox{padding:0;border:none;margin:-3px;width:auto;min-width:100\%;font-size:100\%;clear:none;float:none;background-color:transparent}.mw-parser-output
                  .infobox-3cols-child{margin:auto}.mw-parser-output .infobox
                  .navbar{font-size:100\%}body.skin-minerva .mw-parser-output
                  .infobox-header,body.skin-minerva .mw-parser-output
                  .infobox-subheader,body.skin-minerva .mw-parser-output
                  .infobox-above,body.skin-minerva .mw-parser-output
                  .infobox-title,body.skin-minerva .mw-parser-output
                  .infobox-image,body.skin-minerva .mw-parser-output
                  .infobox-full-data,body.skin-minerva .mw-parser-output
                  .infobox-below{text-align:center}",
  month        =  jun,
  year         =  2022,
  howpublished = "\url{https://en.wikipedia.org/w/index.php?title=Brian\_Eno\&oldid=1094408719}",
  note         = "Accessed: --"
}

@MISC{Chronicle_pop_music_critic1996-tq,
  title        = "{Q} and A With Brian Eno",
  author       = "{CHRONICLE POP MUSIC CRITIC}",
  booktitle    = "San Francisco Chronicle",
  abstract     = "On his last visit to San Francisco, in 1988, Eno erected a
                  fascinating soundscape called...",
  month        =  jun,
  year         =  1996,
  howpublished = "\url{https://www.sfgate.com/default/article/Q-and-A-With-Brian-Eno-2979740.php}",
  note         = "Accessed: 2022-7-5",
  language     = "en"
}

@MISC{Sirna2022-eb,
  title        = "Can Artificial Intelligence replace human creativity?",
  author       = "Sirna, Guido",
  booktitle    = "Medium",
  abstract     = "“Can machines think?” is the question that Alan Turing
                  introduced in 1950 when he published “Computing Machinery and
                  Intelligence” in which he proposed the famous Turing test as a
                  criterion for…",
  month        =  may,
  year         =  2022,
  howpublished = "\url{https://medium.com/@guidosirna/can-artificial-intelligence-replace-human-creativity-b5e96ccd356a}",
  note         = "Accessed: 2022-7-5",
  language     = "en"
}

@BOOK{Frana2021-gd,
  title     = "Encyclopedia of Artificial Intelligence: The Past, Present, and
               Future of {AI}",
  author    = "Frana, Philip L and Klein, Michael J",
  publisher = "ABC-CLIO",
  abstract  = "This authoritative reference work will provide readers with a
               complete overview of artificial intelligence (AI), including its
               historic development and current status, existing and projected
               AI applications, and present and potential future impact on the
               United States and the world.Some people believe that artificial
               intelligence (AI) will revolutionize modern life in ways that
               improve human existence. Others say that the promise of AI is
               overblown. Still others contend that AI applications could pose a
               grave threat to the economic security of millions of people by
               taking their jobs and otherwise rendering them ``obsolete''—or,
               even worse, that AI could actually spell the end of the human
               race.This volume will help users understand the reasons AI
               development has both spirited defenders and alarmed critics;
               explain theories and innovations like Moore's Law, mindcloning,
               and Technological Singularity that drive AI research and debate;
               and give readers the information they need to make their own
               informed judgment about the promise and peril of this technology.
               All of this coverage is presented using language and terminology
               accessible to a lay audience. Introduction explaining the
               historical evolution of AI Chronology of important AI-related
               events Authoritative entries on leading pioneers, entrepreneurs,
               and thinkers; AI concepts and theories; AI's potential impact on
               different facets of society; and major movies and other cultural
               touchstones exploring AI technology",
  month     =  apr,
  year      =  2021,
  language  = "en"
}

@BOOK{Eno2020-ip,
  title     = "A Year with Swollen Appendices: Brian Eno's Diary",
  author    = "Eno, Brian",
  publisher = "Faber \& Faber",
  abstract  = "The diary and essays of Brian Eno republished twenty-five years
               on with a new introduction by the artist in a beautiful hardback
               edition.'One of the seminal books about music . . . an invaluable
               insight into the mind and working practices of one of the
               industry's undeniable geniuses.'GUARDIANAt the end of 1994, Brian
               Eno resolved to keep a diary. His plans to go to the cinema,
               theatre and galleries fell quickly to the wayside. What he did do
               - and write - however, was astonishing: ruminations on his
               collaborative work with David Bowie, U2, James and Jah Wobble,
               interspersed with correspondence and essays dating back to 1978.
               These 'appendices' covered topics from the generative and ambient
               music Eno pioneered to what he believed the role of an artist and
               their art to be, alongside adroit commentary on quotidian
               tribulations and happenings around the world.This beautiful
               25th-anniversary hardcover edition has been redesigned in the
               same size as the diary that eventually became this book. It
               features two ribbons, pink paper delineating the appendices
               (matching the original edition) and a two-tone paper-over-board
               cover, which pays homage to the original design.An intimate
               insight into one of the most influential creative artists of our
               time, A Year with Swollen Appendices is an essential classic.",
  month     =  nov,
  year      =  2020,
  language  = "en"
}

@BOOK{Reichardt1968-eo,
  title     = "Cybernetic Serendipity: The Computer and the Arts",
  author    = "Reichardt, Jasia",
  publisher = "Studio International",
  year      =  1968,
  language  = "en"
}

@MISC{noauthor_undated-fa,
  title        = "Jon {McCormack} – Art/Work",
  howpublished = "\url{https://jonmccormack.info/}",
  note         = "Accessed: 2022-7-7",
  language     = "en"
}

@MISC{noauthor_undated-uz,
  title        = "Ollie Bown",
  howpublished = "\url{http://www.olliebown.com/}",
  note         = "Accessed: 2022-7-7",
  language     = "en"
}

@MISC{noauthor_undated-lb,
  title        = "William Latham History",
  abstract     = "Mutator 1 + 2. Evolutionary Art by William Latham At The
                  Phoenix Gallery Brighton. UK. Dates: September 7th to October
                  13th 2013.",
  howpublished = "\url{http://latham-mutator.com/}",
  note         = "Accessed: 2022-7-7",
  language     = "en"
}

@ARTICLE{Mordvintsev2015-oj,
  title  = "Inceptionism: Going deeper into neural networks",
  author = "Mordvintsev, Alexander and Olah, Christopher and Tyka, Mike",
  year   =  2015
}

@ARTICLE{Levy2015-si,
  title    = "Inside Deep Dreams: How Google Made Its Computers Go Crazy",
  author   = "Levy, Steven",
  journal  = "Wired",
  abstract = "Why the neural net project creating wild visions has meaning for
              art, science, philosophy — and our view of reality",
  month    =  dec,
  year     =  2015,
  language = "en"
}

@MISC{Dohmke2022-hh,
  title        = "{GitHub} Copilot is generally available to all developers",
  author       = "Dohmke, Thomas",
  abstract     = "We’re making GitHub Copilot, an AI pair programmer that
                  suggests code in your editor, generally available to all
                  developers for $10 USD/month or $100 USD/year. It will also be
                  free to use for verified students and maintainers of popular
                  open source projects.",
  month        =  jun,
  year         =  2022,
  howpublished = "\url{https://github.blog/2022-06-21-github-copilot-is-generally-available-to-all-developers/}",
  note         = "Accessed: 2022-7-8"
}

@ARTICLE{Gpt-2020-df,
  title     = "A robot wrote this entire article. Are you scared yet, human?",
  author    = "{GPT-}",
  journal   = "The Guardian",
  publisher = "The Guardian",
  abstract  = "We asked GPT-3, OpenAI’s powerful new language generator, to
               write an essay for us from scratch. The assignment? To convince
               us robots come in peace",
  month     =  sep,
  year      =  2020
}

@MISC{Biswas2021-un,
  title        = "All Recent Books Written By {GPT}-3",
  author       = "Biswas, Debolina",
  abstract     = "GPT-3 is extremely popular among the machine learning
                  community for it can generate human-like stories.",
  month        =  oct,
  year         =  2021,
  howpublished = "\url{https://analyticsindiamag.com/all-recent-books-written-by-gpt-3/}",
  note         = "Accessed: 2022-7-8"
}

@ARTICLE{Purtill2022-ak,
  title     = "Danny's workmate is called {GPT}-3. You've probably read its work
               without realising it's an {AI}",
  author    = "Purtill, James",
  journal   = "ABC News",
  publisher = "ABC News",
  abstract  = "You may not have heard of GPT-3, but there's a good chance you've
               read its work, used a website that runs its code, or even
               conversed with it through a chatbot or a character in a game.",
  month     =  may,
  year      =  2022
}

@MISC{noauthor_undated-mm,
  title        = "Sudowrite",
  abstract     = "Bust writer's block and be more creative with our magical
                  writing AI.",
  howpublished = "\url{https://www.sudowrite.com/}",
  note         = "Accessed: 2022-7-8",
  language     = "en"
}

@MISC{noauthor_undated-sx,
  title        = "Jasper - The Best {AI} Writing Assistant",
  abstract     = "Create content 5x faster with artificial intelligence. Jasper
                  is the highest quality AI copywriting tool with over 3,000
                  5-star reviews. Best for writing blog posts, social media
                  content, and marketing copy.",
  howpublished = "\url{https://www.jasper.ai/}",
  note         = "Accessed: 2022-7-8"
}

@MISC{Dickson2022-bg,
  title        = "{GitHub} Copilot is now public — here’s what you need to know",
  author       = "Dickson, Ben",
  booktitle    = "VentureBeat",
  abstract     = "What we know about Copilot’s effect on real programming tasks,
                  told by its creators and developers who have used it in their
                  day-to-day work.",
  month        =  jun,
  year         =  2022,
  howpublished = "\url{https://venturebeat.com/2022/06/29/github-copilot-is-now-public-heres-what-you-need-to-know/}",
  note         = "Accessed: 2022-7-8",
  language     = "en"
}

@MISC{Schreiner2022-lp,
  title        = "{DALL}-{E} 2 Test: Can you tell the difference between {AI}
                  and human art?",
  author       = "Schreiner, Maximilian",
  booktitle    = "MIXED",
  abstract     = "DALL-E 2 and similar AI systems create authentic images. Can
                  you still tell the difference between man-made art and
                  machine-made art?",
  month        =  jun,
  year         =  2022,
  howpublished = "\url{https://mixed-news.com/en/dall-e-2-test-can-you-tell-the-difference-between-ai-and-human-art/}",
  note         = "Accessed: 2022-7-8",
  language     = "en"
}

@MISC{Romero2022-ob,
  title        = "{DALL·E} 2, Explained: The Promise and Limitations of a
                  Revolutionary {AI}",
  author       = "Romero, Alberto",
  booktitle    = "Towards Data Science",
  abstract     = "DALL·E 2 is the newest AI model by OpenAI. If you’ve seen some
                  of its creations and think they’re amazing, keep reading to
                  understand why you’re totally right — but also wrong.",
  month        =  jun,
  year         =  2022,
  howpublished = "\url{https://towardsdatascience.com/dall-e-2-explained-the-promise-and-limitations-of-a-revolutionary-ai-3faf691be220}",
  note         = "Accessed: 2022-7-8",
  language     = "en"
}

@MISC{Github_undated-sa,
  title       = "Your {AI} pair programmer",
  author      = "{Github}",
  institution = "Github",
  abstract    = "GitHub Copilot works alongside you directly in your editor,
                 suggesting whole lines or entire functions for you.",
  language    = "en"
}

@MISC{Altman2022-nc,
  title        = "{DALL•E} 2",
  author       = "Altman, Sam",
  booktitle    = "Sam Altman blog",
  abstract     = "Today we did a research launch of DALL•E 2, a new AI tool that
                  can create and edit images from natural language instructions.
                  Most importantly, we hope people love the tool and find it
                  useful....",
  month        =  apr,
  year         =  2022,
  howpublished = "\url{https://blog.samaltman.com/dall-star-e-2}",
  note         = "Accessed: 2022-7-8"
}

@MISC{Jang2022-ev,
  title        = "{DALL·E} 2 Research Preview Update",
  author       = "Jang, Joanne",
  year         =  2022,
  howpublished = "\url{https://openai.com/blog/dall-e-2-update/}",
  note         = "Accessed: 2022-7-8"
}

@MISC{noauthor_2022-wy,
  title       = "Your {AI} pair programmer",
  institution = "Github",
  abstract    = "GitHub Copilot works alongside you directly in your editor,
                 suggesting whole lines or entire functions for you.",
  year        =  2022,
  language    = "en"
}

@MISC{noauthor_2021-qk,
  title        = "{HCI} and {ML}: Putting People First",
  booktitle    = "Magenta",
  abstract     = "The goal of the Magenta project is not just to build powerful
                  generative models, but to use those models to empower people
                  to realize their creative goals. I...",
  month        =  dec,
  year         =  2021,
  howpublished = "\url{https://magenta.tensorflow.org/people-first-hci-ml-collaborations}",
  note         = "Accessed: 2022-7-12",
  language     = "en"
}

@BOOK{Frichot2018-ri,
  title     = "Creative Ecologies: Theorizing the Practice of Architecture",
  author    = "Frichot, Hélène",
  publisher = "Bloomsbury Publishing",
  abstract  = "Architect and philosopher Hélène Frichot examines how the
               discipline of architecture is theorized and practiced at the
               periphery. Eschewing a conventionally direct approach to
               architectural objects – to iconic buildings and big-name
               architects – she instead explores the background of architectural
               practice, to introduce the creative ecologies in which
               architecture exists only in relation to other objects and ideas.
               Consisting of a series of philosophical encounters with
               architectural practice that are neither neatly located in one
               domain nor the other, this book is concerned with 'other ways of
               doing architecture'. It examines architecture at the limits where
               it is muddied by alternative disciplinary influences – whether
               art practice, philosophy or literature. Frichot meets a range of
               creative characters who work at the peripheries, and who
               challenge the central assumptions of the discipline, showing that
               there is no 'core of architecture' – there is rather architecture
               as a multiplicity of diverse concerns in engagement with local
               environments and worlds.From an author well-known in the
               disciplines of architecture and philosophy for her scholarship on
               Deleuze, this is a radical, accessible, and highly-original
               approach to design research, deftly engaging with an array of
               current topics from the Anthropocene to affect theory, new
               materialism contemporary feminism.",
  month     =  dec,
  year      =  2018,
  language  = "en"
}

@MISC{noauthor_undated-ae,
  title       = "Mubert-Text-to-Music: A simple notebook demonstrating
                 prompt-based music generation via Mubert {API}",
  institution = "Github",
  abstract    = "A simple notebook demonstrating prompt-based music generation
                 via Mubert API - MubertAI/Mubert-Text-to-Music: A simple
                 notebook demonstrating prompt-based music generation via Mubert
                 API",
  language    = "en"
}

@BOOK{Howkins2018-jl,
  title     = "Creative ecologies: where thinking is a proper job",
  author    = "Howkins, John",
  publisher = "Routledge",
  abstract  = "… Creative ecologies allow everybody to have a go. … I give no
               guarantee that creative ecologies will be sustainable. But … Some
               governments welcome creative ecologies as the most …",
  year      =  2018
}

@ARTICLE{Stankeviciene2011-gi,
  title     = "Creative ecologies: developing and managing new concepts of
               creative economy",
  author    = "Stankevičienė, Jelena and Levickaitė, Rasa and Braškutė, Monika
               and Noreikaitė, Elinga",
  journal   = "Business, Management and Economics Engineering",
  publisher = "journals.vilniustech.lt",
  volume    =  9,
  number    =  2,
  pages     = "277--294",
  abstract  = "The idea of creativity is becoming more and more relevant and is
               ob­served in various fields, such as contemporary economics,
               technology and science. This article is based on the creative
               ecology theory which has emerged from the creative economy theory
               developed by economist John Howkins. According to him, it is
               fundamental to understand the current crisis in the natural
               environment and economy, and the balance of creativity and
               control required in our response. The article is based on three
               research questions: 1) what are the fundamental prin­ciples of
               creativity and the process of sustainable creation; 2) how can
               one de­velop high quality ideas and turn them into reality; 3) is
               it possible for the reckless consuming society to share
               sustainable creative products and how could this be achieved.
               Creative economy is a rapidly growing sector of world market.
               Howkins (2010) uses the creative ecologies theory to analyse
               human creativity and abilities to create. Creative ecology is
               presented as “a niche where diverse individuals ex­press
               themselves in a systemic and adaptive way, using ideas to produce
               new ideas; and where others support this endeavour even if they
               don’t understand it”. Four as­pects (diversity, change, learning,
               adaptation) of ecological thinking are presented as directly
               related to creativity and innovations, thus extremely important
               to any contemporary organisation seeking leadership in the
               creative economy. Looking into the new concept of creativity,
               authors of the article came to the conclusion that a sustainable
               relationship between creativity and science is a necessary tool
               for change, development and management of new concepts of
               creative economy. The article is based on the project Creative
               Ecologies: Creating, Developing and Sharing Sustainable Ideas
               presented by the authors in the Euroweek 2011 confer­ence
               Water4World. The project received two awards – the 1st prize in
               the project section and The Best Project of the Euroweek 2011.",
  month     =  nov,
  year      =  2011,
  keywords  = "creative ecologies; creative economy; new concepts",
  language  = "en"
}

@BOOK{Morton2021-ay,
  title     = "All Art is Ecological",
  author    = "Morton, Timothy",
  publisher = "Penguin UK",
  abstract  = "In twenty short books, Penguin brings you the classics of the
               environmental movement.Provocative and playful, All Art is
               Ecological explores the strangeness of living in an age of mass
               extinction, and shows us that emotions and experience are the
               basis for a deep philosophical engagement with ecology.Over the
               past 75 years, a new canon has emerged. As life on Earth has
               become irrevocably altered by humans, visionary thinkers around
               the world have raised their voices to defend the planet, and
               affirm our place at the heart of its restoration. Their words
               have endured through the decades, becoming the classics of a
               movement. Together, these books show the richness of
               environmental thought, and point the way to a fairer, saner,
               greener world.",
  month     =  aug,
  year      =  2021,
  language  = "en"
}

@MISC{Github2022-xd,
  title       = "Your {AI} pair programmer",
  author      = "{Github}",
  institution = "Github",
  abstract    = "GitHub Copilot works alongside you directly in your editor,
                 suggesting whole lines or entire functions for you.",
  year        =  2022,
  language    = "en"
}

@MISC{OpenAI2022-ma,
  title        = "{OpenAI} {API}",
  author       = "{OpenAI}",
  abstract     = "An API for accessing new AI models developed by OpenAI",
  year         =  2022,
  howpublished = "\url{https://beta.openai.com/docs/guides/embeddings}",
  note         = "Accessed: 2022-8-21",
  language     = "en"
}

@MISC{Smith2022-dm,
  title        = "A Traveler’s Guide to the Latent Space",
  author       = "Smith, Ethan",
  booktitle    = "Notion",
  abstract     = "A new tool that blends your everyday work apps into one. It's
                  the all-in-one workspace for you and your team",
  year         =  2022,
  howpublished = "\url{https://sweet-hall-e72.notion.site/A-Traveler-s-Guide-to-the-Latent-Space-85efba7e5e6a40e5bd3cae980f30235f}",
  note         = "Accessed: 2024-12-19",
  language     = "en"
}

@BOOK{Norman1988-uq,
  title     = "The Design of Everyday Things",
  author    = "Norman, Donald",
  publisher = "Basic Books",
  address   = "New York, NY",
  year      =  1988
}


@INCOLLECTION{Lepper2015-tz,
  title     = "{ISSUES} {IN} {LEARNING} {AND} {MOTIVATIONJohn} {C}. Me Cullers",
  author    = "Lepper, M R and Greene, D",
  booktitle = "The Hidden Costs of Reward",
  publisher = "Psychology Press",
  pages     = "23--36",
  month     =  sep,
  year      =  2015
}

@ARTICLE{Lepper1997-aw,
  title     = "Intrinsic and extrinsic motivation: A developmental perspective",
  author    = "Lepper, M and Sethi, S and Dialdin, Dania A and Drake, Michael",
  journal   = "Developmental psychopathology: Perspectives on adjustment, risk,
               and disorder",
  publisher = "books.google.com",
  pages     = "23--50",
  year      =  1997
}

@MISC{Paul2023-cq,
  title        = "Creativity",
  author       = "Paul, Elliot Samuel and Stokes, Dustin",
  booktitle    = "\textit{The Stanford Encyclopedia of Philosophy }(Spring 2024
                  Edition) , Edward N. Zalta \& Uri Nodelman (eds.)",
  month        =  feb,
  year         =  2023,
  howpublished = "\url{https://plato.stanford.edu/entries/creativity/}",
  note         = "Accessed: 2025-4-27"
}

@ARTICLE{Lepper2000-qg,
  title     = "Turning “play” into “work” and “work” into “play”: 25 Years of
               research on intrinsic versus extrinsic motivation",
  author    = "Lepper, M and Henderlong, Jennifer",
  journal   = "Intrinsic and extrinsic motivation",
  publisher = "Elsevier",
  pages     = "257--307",
  year      =  2000
}

@ARTICLE{Guilford1950-hs,
  title     = "Creativity",
  author    = "Guilford, J P",
  journal   = "Am. Psychol.",
  publisher = "American Psychological Association (APA)",
  volume    =  5,
  number    =  9,
  pages     = "444--454",
  month     =  sep,
  year      =  1950,
  keywords  = "PERSONALITY TESTS",
  language  = "en"
}

@MISC{Design-Council2004-fv,
  title        = "The Double Diamond Framework for Innovation",
  author       = "{Design Council}",
  booktitle    = "Design Council",
  abstract     = "Helping designers and non-designers across the globe tackle
                  some of the most complex social, economic and environmental
                  problems.",
  year         =  2004,
  howpublished = "\url{https://www.designcouncil.org.uk/}",
  note         = "Accessed: 2025-4-27",
  language     = "en"
}

@MISC{Zao-Sanders2024-qo,
  title        = "How People Are Really Using {GenAI}",
  author       = "Zao-Sanders, Marc",
  publisher    = "Harvard Business Review",
  abstract     = "There are many use cases for generative AI, spanning a vast
                  number of areas of domestic and work life. Looking through
                  thousands of comments on sites such as Reddit and Quora, the
                  author’s team found that the use of this technology is as
                  wide-ranging as the problems we encounter in our lives. The
                  100 categories they identified can be divided into six
                  top-level themes, which give an immediate sense of what
                  generative AI is being used for: Technical Assistance \&
                  Troubleshooting (23\%), Content Creation \& Editing (22\%),
                  Personal \& Professional Support (17\%), Learning \& Education
                  (15\%), Creativity \& Recreation (13\%), Research, Analysis \&
                  Decision Making (10\%).",
  month        =  mar,
  year         =  2024,
  howpublished = "\url{https://hbr.org/2024/03/how-people-are-really-using-genai}",
  note         = "Accessed: 2025-4-27",
  language     = "en"
}

@ARTICLE{Schaffer1994-gy,
  title     = "Making up discovery",
  author    = "Schaffer, S",
  editor    = "Boden, Margaret A",
  journal   = "Dimensions of creativity.",
  publisher = "The MIT Press",
  volume    =  242,
  pages     = "13--51",
  year      =  1994
}

@ARTICLE{Brand2018-cy,
  title     = "Pace layering: How complex systems learn and keep learning",
  author    = "Brand, Stewart",
  journal   = "Journal of Design and Science",
  publisher = "PubPub",
  month     =  jan,
  year      =  2018
}

@MISC{noauthor_undated-aw,
  title        = "An Image is Worth One Word: Personalizing Text-to-Image
                  Generation using Textual Inversion",
  abstract     = "Textual Inversions for personalized Text-to-Image generation",
  howpublished = "\url{https://textual-inversion.github.io/}",
  note         = "Accessed: 2022-8-30"
}

@MISC{Koomen2025-eu,
  title        = "{AI} Horseless Carriages",
  author       = "Koomen, Pete",
  abstract     = "An essay about bad AI app design",
  year         =  2025,
  howpublished = "\url{https://koomen.dev/essays/horseless-carriages/}",
  note         = "Accessed: 2025-4-25",
  language     = "en"
}

@MISC{OpenAI2022-oh,
  title        = "{OpenAI} {API}",
  author       = "{OpenAI}",
  abstract     = "An API for accessing new AI models developed by OpenAI",
  year         =  2022,
  howpublished = "\url{https://beta.openai.com/docs/introduction}",
  note         = "Accessed: 2022-11-17",
  language     = "en"
}

@MISC{Singhal2001-gx,
  title        = "Modern Information Retrieval: A Brief Overview",
  author       = "Singhal, Amit",
  publisher    = "160592857366.free.fr",
  abstract     = "For thousands of years people have realized the importance of
                  archiving and finding information. With the advent of
                  computers, it became possible to store large amounts of
                  information; and finding useful information from such
                  collections became a necessity. The field of Information
                  Retrieval (IR) was born in the 1950s out of this necessity.
                  Over the last forty years, the field has matured considerably.
                  Several IR systems are used on an everyday basis by a wide
                  variety of users. This article is a brief overview of the key
                  advances in the field of Information Retrieval, and a
                  description of where the state-of-the-art is at in the field.",
  year         =  2001,
  howpublished = "\url{http://160592857366.free.fr/joe/ebooks/ShareData/Modern\%20Information\%20Retrieval\%20-\%20A\%20Brief\%20Overview.pdf}",
  note         = "Accessed: 2022-11-17"
}

@BOOK{Hermann2011-gl,
  title     = "The sonification handbook",
  author    = "Hermann, Thomas and Hunt, Andy and Neuhoff, John G",
  publisher = "Logos Verlag Berlin",
  abstract  = "… data given that, prior to sonification , all data visualization
               used … of those tasks that was born to be sonified : at its heart
               is one or … of auditory display and sonification applications
               that have …",
  year      =  2011
}

@MISC{Think2017-nw,
  title     = "3 Brain Systems That Control Your Behavior: Reptilian, Limbic,
               Neo Cortex | Robert Sapolsky",
  author    = "Think, Big",
  publisher = "Youtube",
  abstract  = "3 Brain Systems That Control Your Behavior: Reptilian, Limbic,
               Neo CortexWatch the newest video from Big Think:
               https://bigth.ink/NewVideoJoin Big Think Edge...",
  month     =  jun,
  year      =  2017,
  keywords  = "Big Think; BigThink; BigThink.com; Education; Educational;
               Lifelong Learning; EDU; robert sapolsky; brain strata; limbic;
               reptilian; neo cortex; brain; behavior; robert sapolsky
               depression; robert sapolsky religion; robert sapolsky free will;
               robert sapolsky stress; robert sapolsky behave; robert sapolsky
               human behavioral biology; robert sapolsky behavioral biology;
               robert sapolsky baboons; why did i do that; a lesson in brain
               behavior; systems that control your behavior"
}

@MISC{Wikipedia_contributors2022-ad,
  title        = "Somatic marker hypothesis",
  author       = "{Wikipedia contributors}",
  booktitle    = "Wikipedia, The Free Encyclopedia",
  abstract     = "The somatic marker hypothesis, formulated by Antonio Damasio
                  and associated researchers, proposes that emotional processes
                  guide (or bias) behavior, particularly decision-making.[1][2]",
  month        =  nov,
  year         =  2022,
  howpublished = "\url{https://en.wikipedia.org/w/index.php?title=Somatic\_marker\_hypothesis\&oldid=1120132092}",
  note         = "Accessed: --"
}

@ARTICLE{Mardakheh2022-ud,
  title     = "A strata-based approach to discussing artistic data sonification",
  author    = "Mardakheh, Milad Khosravi and Wilson, Scott",
  journal   = "Leonardo",
  publisher = "MIT Press",
  volume    =  55,
  number    =  5,
  pages     = "516--520",
  abstract  = "Abstract Much discussion surrounding data sonification for
               musical and artistic purposes focuses on seeming contradictions
               that arise from the ways in which this practice differs from that
               of data sonification as a scientific tool. Over the past 30
               years, this debate has become a rabbit hole of questions and
               arguments regarding the nature of music/sound-art and data
               sonification, and of their relationships with one another. In the
               following article, the authors identify three
               areas/classifications of artistic sonification, using a “strata”
               metaphor with the hope of bringing clarity to this discussion, as
               well as enabling reflection on the nature of science-art
               collaborations using this approach.",
  month     =  oct,
  year      =  2022,
  language  = "en"
}

@MISC{Popova2021-qn,
  title        = "Place, Personhood, and the Hippocampus: The Fascinating
                  Science of Magnetism, Autonoeic Consciousness, and What Makes
                  Us Who We Are",
  author       = "Popova, Maria",
  booktitle    = "The Marginalian",
  abstract     = "“Often the places we grow up in… influence how we perceive and
                  conceptualize the world, give us metaphors to live by, and
                  shape the purpose that drives us.”",
  month        =  sep,
  year         =  2021,
  howpublished = "\url{https://www.themarginalian.org/2021/09/24/wayfinding-m-r-oconnor/}",
  note         = "Accessed: 2025-3-11",
  language     = "en"
}

@MISC{UnknownUnknown-ke,
  title        = "Paper page - {LongVU}: Spatiotemporal Adaptive Compression for
                  Long Video-Language Understanding",
  abstract     = "Join the discussion on this paper page",
  howpublished = "\url{https://huggingface.co/papers/2410.17434}",
  note         = "Accessed: 2024-10-31"
}

@MISC{Dzieza2022-qj,
  title        = "How Kindle novelists are using {ChatGPT}",
  author       = "Dzieza, Josh",
  abstract     = "Authors of Kindle genre fiction have been experimenting with
                  AI tools. One novelist discusses how writers are thinking
                  about ChatGPT.",
  month        =  dec,
  year         =  2022,
  howpublished = "\url{https://www.theverge.com/23520625/chatgpt-openai-amazon-kindle-novel}",
  note         = "Accessed: 2022-12-26"
}

@MISC{Leeds2021-hc,
  title        = "A neural net wrote my book. Kidding. Sort of",
  author       = "Leeds, Leanne",
  booktitle    = "Leanne Leeds",
  abstract     = "The following section includes tips, tricks, and my experience
                  using Sudowrite, an app created using GPT-3 to assist writers
                  in writing fiction. This blog assumes you know what this is
                  and have some familiarity with it. If not, the last section
                  links to some info. Sudowrite Tips and Tricks My first days
                  with Sudowrite More on AI-Assisted Writing Sudowrite Tips and
                  Tricks The following are some tips and tricks I discovered
                  while using Sudowrite. Because there is no right or wrong way
                  to use AI in your writing, none of these posts should be
                  interpreted as ``the way things should be done.'' It's just a
                  suggestion to get you started. Dates of posting are provided,
                  with the oldest being first. (Sudowrite changes and progresses
                  fairly frequently, so keep that in mind.) My first days with
                  Sudowrite When I was interested in giving this a whirl, I
                  found little on it regarding authors, so I thought I'd add my
                  experience here. The following blog posts chronicle my
                  experience with Sudowrite if/when I have some insight. It's
                  not necessarily going to be ongoing. Dates are provided,
                  oldest is first. Sudowrite/\#AI Tools \& Articles Tools I use:
                  Sudowrite Quillbot LitRPG Adventures - a must-have for fantasy
                  writers. Articles and Info New Yorker: The Computers Are
                  Getting Better at Writing The Creative Penn (Youtube): The
                  AI-Augmented Author. Writing With GPT-3 With Paul Bellow The
                  Creative Penn (Youtube): Writing Fiction With AI. Sudowrite
                  With Amit Gupta The Verge: The Great Fiction of AI: The
                  strange world of high-speed semi-automated genre fiction - a
                  long form article that yours truly appears in. Sudowrite an AI
                  Writing tool for authors: Features and Demonstration on the
                  Business of Writing Podcast featuring author Elizabeth Ann
                  West.",
  month        =  jun,
  year         =  2021,
  howpublished = "\url{https://leanneleeds.com/sudowrite/}",
  note         = "Accessed: 2022-12-26",
  language     = "en"
}

@ARTICLE{Brown1990-jd,
  title     = "A statistical approach to machine translation",
  author    = "Brown, Peter F and Cocke, John and Pietra, Stephen A Della and
               Pietra, Vincent J Della and Jelinek, Fredrick and Lafferty, John
               D and Mercer, Robert L and Roossin, Paul S",
  journal   = "Comput. Linguist.",
  publisher = "MIT Press",
  address   = "Cambridge, MA, USA",
  volume    =  16,
  number    =  2,
  pages     = "79--85",
  abstract  = "In this paper, we present a statistical approach to machine
               translation. We describe the application of our approach to
               translation from French to English and give preliminary results.",
  month     =  jun,
  year      =  1990
}

@MISC{OpenAI2022-wx,
  title        = "Introducing {ChatGPT}",
  author       = "{OpenAI}",
  booktitle    = "openai.com",
  abstract     = "We’ve trained a model called ChatGPT which interacts in a
                  conversational way. The dialogue format makes it possible for
                  ChatGPT to answer followup questions, admit its mistakes,
                  challenge incorrect premises, and reject inappropriate
                  requests.",
  month        =  nov,
  year         =  2022,
  howpublished = "\url{https://openai.com/index/chatgpt/}",
  note         = "Accessed: 2024-9-11",
  language     = "en"
}

@ARTICLE{Ray2023-fu,
  title     = "{ChatGPT}: A comprehensive review on background, applications,
               key challenges, bias, ethics, limitations and future scope",
  author    = "Ray, Partha Pratim",
  journal   = "Internet of Things and Cyber-Physical Systems",
  publisher = "Elsevier BV",
  volume    =  3,
  pages     = "121--154",
  abstract  = "In recent years, artificial intelligence (AI) and machine
               learning have been transforming the landscape of scientific
               research. Out of which, the chat…",
  month     =  jan,
  year      =  2023,
  language  = "en"
}

@ARTICLE{Karwowski2018-ot,
  title    = "Measuring creative self-efficacy and creative personal identity",
  author   = "Karwowski, Maciej and Lebuda, Izabela and Wiśniewska, Ewa",
  journal  = "The International Journal of Creativity \& Problem Solving",
  volume   =  28,
  number   =  1,
  pages    = "45--57",
  abstract = "This paper presents the Short Scale of Creative Self (SSCS)—an
              instrument to measure trait-like creative self-efficacy and
              creative personal identity: characteristics of growing importance
              in creativity literature. Study 1 (N = 1,582) confirmed the
              assumed factor structure of the SSCS as well as high internal
              consistency of both sub-scales. Study 2 (N = 186) demonstrated
              high reliability of measurement over time, and Study 3 (N = 80)
              showed robust correlations with the scale previously used for
              measuring creative self-efficacy. Study 4 (N = 385) revealed
              positive links of creative self-efficacy and creative personal
              identity with self-reported originality and Test for Creative
              Thinking (TCT-DP), and weaker, yet expected links with
              intelligence, as well as positive relations with self-esteem,
              emotional intelligence and intrinsic motivation. Study 5 (N = 115)
              showed statistically significant relations of the new scales with
              divergent thinking. We discuss the promises and shortcomings of
              applying the SSCS in the school settings. (PsycINFO Database
              Record (c) 2019 APA, all rights reserved)",
  month    =  apr,
  year     =  2018
}

@ARTICLE{Clark2008-ui,
  title    = "Supersizing the Mind: Embodiment, Action, and Cognitive Extension",
  author   = "Clark, Andy",
  abstract = "Abstract. Studies of mind, thought, and reason have tended to
              marginalize the role of bodily form, real-world action, and
              environmental backdrop. In recent year",
  month    =  dec,
  year     =  2008
}

@PHDTHESIS{Ianigro2022-ge,
  title     = "Plecto: Investigating the Musical Affordances of Continuous Time
               Recurrent Neural Networks",
  author    = "Ianigro, Steffan",
  publisher = "UNSW Sydney",
  abstract  = "``Plecto: Investigating the musical affordances of Continuous
               Time Recurrent Neural Networks'' is a practice-based research
               project that investigates how continuous time recurrent neural
               networks (CTRNNs) can be applied to the problem of achieving
               gestural control in improvised electronic music. One of the
               challenges of improvising using computers is manipulating
               different compositional layers during a performance while
               maintaining granular and expressive control. Artists turn to
               concepts such as artificial life to solve this problem and pursue
               software agents with complex, responsive and organic qualities
               that lead to the perception of lifelikeness. Guided by this
               theme, I propose a design for a low frequency oscillator (LFO),
               called Plecto, for use within existing composition workflows that
               harnesses the idiosyncratic behaviours of CTRNNs as a gestural
               agent within improvised electronic music performances. CTRNNs
               have been used in studies of biological modelling such as animal
               locomotion, and also of minimally cognitive behaviours such as
               basic object perception. Their ability to produce lifelike
               abstract forms makes them well suited as a source of gestural
               control. Oliver Bown and Sebastian Lexer have applied CTRNNs to
               musical event generation, using evolutionary algorithms (EA) to
               search for different CTRNN behaviours. I have extended this
               approach, using a novelty search (NS) variant for the open-ended
               discovery of CTRNN configurations, each exhibiting novel
               behaviours that can be applied to different musical problems.
               Through a series of computational studies, I have explored the
               lifelike qualities of CTRNNs best suited for gestural control and
               a novelty search algorithm design for their discovery. An
               iterative design process was also undertaken, establishing clear
               design principles adopted to build a usable representation of the
               CTRNN algorithm within an LFO device built for the Ableton Live
               environment. Evaluation of the tool was conducted through a user
               survey and practice-based case studies that incorporate the
               device into my own improvised electronic music workflow as a
               gestural agent. The primary outcomes of this research are a suite
               of software that can be adopted by the broader community of
               practitioners and a series of compositions reflecting the impacts
               of the CTRNN algorithm on my creative process.",
  year      =  2022,
  keywords  = "Gesture; Electronic Music Improvisation; Continuous Time
               Recurrent Neural Network; Plecto LFO; Improvisation; Lifelike;
               Low Frequency Oscillator; Ableton Live; Max for Live; Genetic
               Algorithm; Novelty Search; Electronic Music Composition;
               Interaction Design; Practice-based Research; Evolutionary
               Computation",
  school    = "UNSW Sydney",
  language  = "en"
}

@MISC{noauthor_undated-tf,
  title       = "techniques\_to\_improve\_reliability.md at main ·
                 openai/openai-cookbook",
  institution = "Github",
  abstract    = "Examples and guides for using the OpenAI API. Contribute to
                 openai/openai-cookbook development by creating an account on
                 GitHub.",
  language    = "en"
}

@MISC{Neuroscience_News2023-ed,
  title        = "How anesthesia blocks consciousness",
  author       = "{Neuroscience News}",
  booktitle    = "Neuroscience News",
  abstract     = "A new study reveals insights into how general anesthesia
                  affects consciousness and sensory perception.",
  month        =  nov,
  year         =  2023,
  howpublished = "\url{https://neurosciencenews.com/consciousness-anesthesia-25181/}",
  note         = "Accessed: 2023-11-12",
  language     = "en"
}

@ARTICLE{Pillai2021-ur,
  title    = "Era of Unpredictable Earthquakes to Predictable: A New Perspective
              to Predict Earthquakes to Mitigate Loss of Life and Destruction of
              Property in Japan, California and Mexico",
  author   = "Pillai, S P",
  journal  = "Austin Environmental Sciences",
  abstract = "Era of Unpredictable Earthquakes to Predictable: A New Perspective
              to Predict Earthquakes to Mitigate Loss of Life and Destruction of
              Property in Japan, California and Mexico",
  month    =  mar,
  year     =  2021
}

@MISC{noauthor_undated-ew,
  title        = "{OpenAI} {API}",
  abstract     = "An API for accessing new AI models developed by OpenAI",
  howpublished = "\url{https://platform.openai.com/docs/guides/embeddings/limitations-risks}",
  note         = "Accessed: 2023-4-13",
  language     = "en"
}

@ARTICLE{noauthor_undated-tq,
  title     = "Do schools kill creativity? | Sir Ken Robinson",
  author    = "{TED}",
  publisher = "Youtube",
  abstract  = "Visit http://TED.com to get our entire library of TED Talks,
               transcripts, translations, personalized talk recommendations and
               more.Sir Ken Robinson makes an ...",
  month     =  jan,
  year      =  2007,
  keywords  = "Ken; Robinson; TED; TEDTalks; Talks; TED2006; education;
               educational; system; creativity; innovation; schooling; school;
               curiosity"
}

@MISC{Nakajima_undated-er,
  title       = "babyagi",
  author      = "Nakajima, Yohei",
  institution = "Github",
  abstract    = "Contribute to yoheinakajima/babyagi development by creating an
                 account on GitHub.",
  language    = "en"
}

@ARTICLE{Beghetto2007-bg,
  title    = "Toward a broader conception of creativity: A case for ``mini-c''
              creativity",
  author   = "Beghetto, Ronald A and Kaufman, James C",
  journal  = "Psychology of Aesthetics, Creativity, and the Arts",
  volume   =  1,
  number   =  2,
  pages    = "73--79",
  abstract = "In this article the authors argue that a new category of
              creativity, called ``mini-c'' creativity, is needed to advance
              creativity theory and research. Mini-c creativity differs from
              little-c (everyday) or Big-C (eminent) creativity as it refers to
              the creative processes involved in the construction of personal
              knowledge and understanding. The authors discuss how the category
              of mini-c creativity addresses gaps in current conceptions of
              creativity, offers researchers a new and important unit of
              analysis, and helps to better frame the domain question in
              creativity research. Implications for creativity research are also
              discussed. (PsycINFO Database Record (c) 2017 APA, all rights
              reserved)",
  month    =  may,
  year     =  2007
}

@MISC{LaPorte_undated-js,
  title        = "Listen to Wikipedoa",
  author       = "LaPorte, Stephen and Hashemi, Mahmoud",
  abstract     = "Listen to recent changes on Wikipedia",
  howpublished = "\url{http://listen.hatnote.com/}",
  note         = "Accessed: 2023-4-13"
}

@MISC{The_Museum_of_Modern_Art2023-tp,
  title     = "{AI} Art: How artists are using and confronting machine learning
               | {HOW} {TO} {SEE} {LIKE} A {MACHINE}",
  author    = "{The Museum of Modern Art}",
  publisher = "Youtube",
  abstract  = "For the latest episode of our How to See series, we spoke with
               three artists—Kate Crawford, Trevor Paglen, and Refik Anadol—who
               engage with the ways that AI ...",
  month     =  mar,
  year      =  2023,
  keywords  = "moma; museum of modern art; new york; art; artist; museum;
               contemporary"
}

@MISC{Wikipedia-contributors2024-hr,
  title        = "Socratic method",
  author       = "{Wikipedia contributors}",
  booktitle    = "Wikipedia, The Free Encyclopedia",
  publisher    = "Wikimedia Foundation, Inc.",
  abstract     = "Marcello Bacciarelli's Alcibiades Being Taught by Socrates
                  (1776)",
  month        =  nov,
  year         =  2024,
  howpublished = "\url{https://en.wikipedia.org/wiki/Socratic\_method}"
}

@ARTICLE{Nails2005-iq,
  title  = "Socrates",
  author = "Nails, Debra and Monoson, S Sara",
  month  =  sep,
  year   =  2005
}

@BOOK{Buber1923-us,
  title  = "{I} and Thou",
  author = "Buber, Martin",
  year   =  1923
}

@MISC{UnknownUnknown-fl,
  title        = "Charles Baudelaire, “On Photography,” from The Salon of 1859",
  howpublished = "\url{https://www.csus.edu/indiv/o/obriene/art109/readings/11\%20baudelaire\%20photography.htm}",
  note         = "Accessed: 2024-12-6"
}

@MISC{Baudelaire1955-ae,
  title        = "The Mirror of Art: Critical Studies",
  author       = "Baudelaire, Charles",
  booktitle    = "Phaidon Press Ltd., London",
  abstract     = "Hardcover - Phaidon Press Ltd., London - 1955 - Condition:
                  Good - The collected critical writing of Baudelaire, including
                  his Salons of 1845, 1846 and 1859 plus his Essence of Laughter
                  and other essays. With numerous b/w plates. Spine is sunned.
                  Contents clean and tight. Good+ - The Mirror of Art: Critical
                  Studies",
  year         =  1955,
  howpublished = "\url{https://www.abebooks.com/Mirror-Art-Critical-Studies-Charles-Baudelaire/30932257309/bd}",
  note         = "Accessed: 2024-12-6",
  language     = "en"
}

@BOOK{Turkle2005-cy,
  title     = "The second self: Computers and the human spirit",
  author    = "Turkle, Sherry",
  publisher = "MIT Press",
  address   = "London, England",
  abstract  = "A new edition of the classic primer in the psychology of
               computation, with a new introduction, a new epilogue, and
               extensive notes added to the original text.In The Second Self,
               Sherry Turkle looks at the computer not as a ``tool,'' but as
               part of our social and psychological lives; she looks beyond how
               we use computer games and spreadsheets to explore how the
               computer affects our awareness of ourselves, of one another, and
               of our relationship with the world. ``Technology,'' she writes,
               ``catalyzes changes not only in what we do but in how we think.''
               First published in 1984, The Second Self is still essential
               reading as a primer in the psychology of computation. This
               twentieth anniversary edition allows us to reconsider two decades
               of computer culture—to (re)experience what was and is most novel
               in our new media culture and to view our own contemporary
               relationship with technology with fresh eyes. Turkle frames this
               classic work with a new introduction, a new epilogue, and
               extensive notes added to the original text.Turkle talks to
               children, college students, engineers, AI scientists, hackers,
               and personal computer owners—people confronting machines that
               seem to think and at the same time suggest a new way for us to
               think—about human thought, emotion, memory, and understanding.
               Her interviews reveal that we experience computers as being on
               the border between inanimate and animate, as both an extension of
               the self and part of the external world. Their special place
               betwixt and between traditional categories is part of what makes
               them compelling and evocative. (In the introduction to this
               edition, Turkle quotes a PDA user as saying, ``When my Palm
               crashed, it was like a death. I thought I had lost my mind.'')
               Why we think of the workings of a machine in psychological
               terms—how this happens, and what it means for all of us—is the
               ever more timely subject of The Second Self.",
  series    = "The MIT Press",
  month     =  sep,
  year      =  2005,
  language  = "en"
}

@ARTICLE{Zank2004-dh,
  title  = "Martin Buber",
  author = "Zank, Michael and Braiterman, Zachary",
  month  =  apr,
  year   =  2004
}

@MISC{noauthor_undated-bf,
  title        = "Real-Time Latent Consistency Model Image-to-Image {ControlNet}
                  - a Hugging Face Space by radames",
  abstract     = "Discover amazing ML apps made by the community",
  howpublished = "\url{https://huggingface.co/spaces/radames/Real-Time-Latent-Consistency-Model}",
  note         = "Accessed: 2024-2-29"
}

@MISC{Dylan2023-ma,
  title        = "Stop using text-to-image.this blender + real-time latent
                  consistency workflow is way more fun, and shows how you can
                  use Generative {AI} collaboratively, instead of as a creative
                  slot machinetry it yourself here https://t.co/{QyiR5IDQI2}
                  pic.twitter.com/{pSsMiA33Rj}",
  author       = "{dylan}",
  booktitle    = "Twitter",
  month        =  nov,
  year         =  2023,
  howpublished = "\url{https://twitter.com/dylan\_ebert\_/status/1724885074313642424}",
  note         = "Accessed: 2024-2-29",
  language     = "en"
}

@MISC{Nebelong2024-jz,
  title        = "The next stage of {AI} image gen is going to be all about
                  control. Human creativity is a beautiful thing, and the images
                  we all have in our heads is much better expressed through
                  motion, brush-strokes, song, tone of voice than through a
                  simple text prompt.``Make a tree with a…
                  pic.twitter.com/{2lRJAMhxf3}",
  author       = "Nebelong, Martin",
  booktitle    = "Twitter",
  month        =  feb,
  year         =  2024,
  howpublished = "\url{https://twitter.com/MartinNebelong/status/1761864757051630028}",
  note         = "Accessed: 2024-2-29",
  language     = "en"
}

@PROCEEDINGS{noauthor_2017-wt,
  title     = "Proceedings of the {12th} international audio mostly conference
               on augmented and participatory sound and music experiences",
  publisher = "ACM",
  address   = "New York, NY, USA",
  month     =  aug,
  year      =  2017
}

@MISC{Vox2023-ab,
  title     = "An {AI} artist explains his workflow",
  author    = "{Vox}",
  publisher = "Youtube",
  abstract  = "How it works — and why it takes a surprisingly long time to make
               something good.Subscribe and turn on notifications 🔔 so you
               don't miss any videos: http://...",
  month     =  may,
  year      =  2023,
  keywords  = "AI art; Midjourney; Vox.com; ai; art process; explain; explainer;
               machine learning; process; vox; stable diffusion; stelfie;
               stelfie the time traveller; stelfie creator; ai selfie; ai art;
               digital art; sketching; sketch to finished drawing; illustrator;
               photoshop; realistic photoshop; muhammed ali; denoise; ai art
               tutorial; how to make ai art"
}

@MISC{Drummond2023-av,
  title        = "A note on this year’s Power issue – and why we published {AI}
                  deepfakes",
  author       = "Drummond, Matthew",
  booktitle    = "Australian Financial Review",
  abstract     = "When our overt, covert and cultural power lists appear on
                  afr.com towards the end of the week, you’ll notice some rather
                  bizarre images of our power listers.",
  month        =  sep,
  year         =  2023,
  howpublished = "\url{https://www.afr.com/politics/federal/a-note-on-this-year-s-power-issue-and-why-we-published-ai-deepfakes-20230907-p5e2wu}",
  note         = "Accessed: 2024-3-4",
  language     = "en"
}

@MISC{Drummond2023-bh,
  title        = "What we learnt when making {AI} images for the 2023 Power
                  issue",
  author       = "Drummond, Matthew",
  booktitle    = "Australian Financial Review",
  abstract     = "Our team taught artificial intelligence to make portraits,
                  like this one of Margot Robbie. The results show how it’s
                  learning about 21st-century culture.",
  month        =  sep,
  year         =  2023,
  howpublished = "\url{https://www.afr.com/politics/federal/what-we-learnt-when-making-ai-images-for-the-2023-power-issue-20230830-p5e0jp}",
  note         = "Accessed: 2024-3-4",
  language     = "en"
}

@MISC{noauthor_undated-sl,
  title        = "Jerry Uelsmann",
  abstract     = "Born in Detroit on June 11, 1934, Jerry Uelsmann received his
                  B.F.A. degree at the Rochester Institute of Technology in 1957
                  and his M.S. and M.F.A. at Indiana University in 1960. He
                  began teaching photography at the University of Florida in
                  Gainesville in 1960 (“my first job offer”). He became a
                  graduate research professor of art at the university in 1974,
                  and is now retired from teaching. He lives in Gainesville,
                  Florida.",
  howpublished = "\url{https://www.uelsmann.net/}",
  note         = "Accessed: 2024-3-4"
}

@MISC{noauthor_undated-mg,
  title        = "{ERIK} {JOHANSSON}",
  booktitle    = "ERIK JOHANSSON",
  abstract     = "Website of Swedish surreal photographer Erik Johansson.",
  howpublished = "\url{https://www.erikjo.com/}",
  note         = "Accessed: 2024-3-4",
  language     = "en"
}

@MISC{Robertson2018-yi,
  title        = "{OLPC’s} \$100 laptop was going to change the world — then it
                  all went wrong",
  author       = "Robertson, Adi",
  abstract     = "The \$100 OLPC laptop was supposed to revolutionize education
                  and close the digital divide. But in just a few years it was
                  recognized as a failure, a symbol of tech industry hubris, a
                  one-size-fits-all American solution to complex global
                  problems.",
  month        =  apr,
  year         =  2018,
  howpublished = "\url{https://www.theverge.com/2018/4/16/17233946/olpcs-100-laptop-education-where-is-it-now}",
  note         = "Accessed: 2024-3-21"
}

@MISC{UnknownUnknown-dq,
  title        = "Self-Discovering Interpretable Diffusion Latent Directions for
                  Responsible Text-to-Image Generation",
  howpublished = "\url{https://arxiv.org/html/2311.17216v2}",
  note         = "Accessed: 2024-10-30",
  language     = "en"
}

@MISC{Sacasas_undated-ud,
  title        = "Waste Your Time, Your Life May Depend On It",
  author       = "Sacasas, L M",
  howpublished = "\url{https://theconvivialsociety.substack.com/p/waste-your-time-your-life-may-depend}",
  note         = "Accessed: 2023-5-30"
}

@BOOK{Keith_Sawyer2014-et,
  title     = "Group Creativity: Music, Theater, Collaboration",
  author    = "Keith Sawyer, R",
  publisher = "Psychology Press",
  abstract  = "Group Creativity explores the unique form of creativity that
               emerges from collaborating groups. Dr. Sawyer draws on his
               studies of jazz ensembles and improvisational theater groups to
               develop a model of creative group processes. He applies this
               model of group creativity to a wide range of collaborating
               groups, including group learning in classrooms and innovative
               teams in organizations. In group creativity, a group comes
               together to collaboratively create in real time. The creative
               inspiration emerges from the interaction and communication among
               the members, and makes the result more than the sum of its parts.
               The dynamic, moment-to-moment communication among jazz musicians
               and improvising actors is the primary topic of the book. Sawyer
               explores performers' close listening and sensitivity, the
               submerging of the ego to the group mind, and the ways that
               performers work together to create something better than and
               different from what one solitary individual could create alone.
               These explorations provide insight into all forms of group
               creativity and collaboration.",
  month     =  apr,
  year      =  2014,
  language  = "en"
}

@BOOK{Paulus2003-iy,
  title     = "Group Creativity: Innovation through Collaboration",
  author    = "Paulus, Paul B and Nijstad, Bernard A",
  publisher = "Oxford University Press",
  abstract  = "Creativity often leads to the development of original ideas that
               are useful or influential, and maintaining creativity is crucial
               for the continued development of organizations in particular and
               society in general. Most research and writing has focused on
               individual creativity. Yet, in recent years there has been an
               increasing acknowledgment of the importance of the social and
               contextual factors in creativity. Even with the information
               explosion and the growing necessity for specialization, the
               development of innovations still requires group interaction at
               various stages in the creative process. Most organizations
               increasingly rely on the work of creative teams where each
               individual is an expert in a particular area. This volume
               summarizes the exciting new research developments on the
               processes involved in group creativity and innovation, and
               explores the relationship between group processes, group context,
               and creativity. It draws from a broad range of research
               perspectives, including those investigating cognition, groups,
               creativity, information systems, and organizational psychology.
               These different perspectives have been brought together in one
               volume in order to focus attention on this developing literature
               and its implications for theory and application. The chapters in
               this volume are organized into two sections. The first focuses on
               how group decision making is affected by factors such as
               cognitive fixation and flexibility, group diversity, minority
               dissent, group decision-making, brainstorming, and group support
               systems. Special attention is devoted to the various processes
               and conditions that can inhibit or facilitate group creativity.
               The second section explores how various contextual and
               environmental factors affect the creative processes of groups.
               The chapters explore issues of group autonomy, group
               socialization, mentoring, team innovation, knowledge transfer,
               and creativity at the level of cultures and societies. The
               research presented in this section makes it clear that a full
               understanding of group creativity cannot be accomplished without
               adequate attention to the group environment. It will be a useful
               source of information for scholars, practitioners, and students
               wishing to understand and facilitate group creativity.",
  month     =  sep,
  year      =  2003,
  language  = "en"
}

@INPROCEEDINGS{Murphy2013-fy,
  title     = "Survey of metrics for human-robot interaction",
  author    = "Murphy, Robin R and Schreckenghost, Debra",
  booktitle = "2013 8th ACM/IEEE International Conference on Human-Robot
               Interaction (HRI)",
  pages     = "197--198",
  abstract  = "This paper examines 29 papers that have proposed or applied
               metrics for human-robot interaction. The 42 metrics are
               categorized as to the object being directly measured: the human
               (7), the robot (6), or the system (29). Systems metrics are
               further subdivided into productivity, efficiency, reliability,
               safety, and coactivity. While 42 seems to be a large set, many
               metrics do not have a functional, or generalizable, mechanism for
               measuring that feature. In practice, metrics for system
               interactions are often inferred through observations of the robot
               or the human, introducing noise and error in analysis. The
               metrics do not completely capture the impact of autonomy on HRI
               as they typically focus on the agents, not the capabilities. As a
               result the current metrics are not helpful for determining what
               autonomous capabilities and interactions are appropriate for what
               tasks.",
  month     =  mar,
  year      =  2013,
  keywords  = "Robots;Human-robot interaction;Extraterrestrial measurements;Time
               measurement;Productivity;Reliability;human-robot
               interaction;metrics;autonomy"
}

@INPROCEEDINGS{Freedy2007-oa,
  title     = "Measurement of trust in human-robot collaboration",
  author    = "Freedy, Amos and DeVisser, Ewart and Weltman, Gershon and
               Coeyman, Nicole",
  booktitle = "2007 International Symposium on Collaborative Technologies and
               Systems",
  pages     = "106--114",
  abstract  = "We describe a Collaborative Performance Model that captures the
               critical performance attributes of the distinctive human-robotic
               decision and control environment. The literature and our initial
               experimental studies show that the element of trust in
               human-robot collaboration is an extremely important factor in the
               Performance Model, and accordingly we have focused much of our
               attention on deriving suitable and practical measures of this
               variable. In this paper we describe the formulation of a
               decision-analytical based measure of trust as well as the results
               of two initial experiments designed to examine trust in a
               tactical human-robot collaborative task performed in our new
               Mixed Initiative Team Performance Assessment System (MITPAS)
               simulation environment.",
  month     =  may,
  year      =  2007,
  keywords  = "Robots;Automation;Collaboration;Training;Robot
               kinematics;Adaptation model;Firing;Human Robot
               Collaboration;Mixed-Initiative Systems;Human-Robot Performance
               Modeling;Measurement of Trust"
}

@MISC{Steinberg2023-jb,
  title        = "Adobe Flies Towards Generative {AI}",
  author       = "Steinberg, Jon",
  booktitle    = "The Information",
  abstract     = "Hi, welcome to your Weekend.For about 11 months after OpenAI
                  released its text-to-image generator Dall-E 2 in April 2022,
                  many of us wondered when Adobe would come to market with a
                  rival product, which could be neatly integrated into design
                  programs like Photoshop, Illustrator and Premiere.The ...",
  month        =  jun,
  year         =  2023,
  howpublished = "\url{https://www.theinformation.com/articles/adobe-flies-towards-generative-ai?utm\_source=sg\&utm\_medium=email\&utm\_campaign=article\_email\&utm\_content=article-10747}",
  note         = "Accessed: 2023-6-27"
}

@MISC{Steinberg2023-vm,
  title        = "Adobe Flies Towards Generative {AI}",
  author       = "Steinberg, Jon",
  booktitle    = "The Information",
  abstract     = "Hi, welcome to your Weekend.For about 11 months after OpenAI
                  released its text-to-image generator Dall-E 2 in April 2022,
                  many of us wondered when Adobe would come to market with a
                  rival product, which could be neatly integrated into design
                  programs like Photoshop, Illustrator and Premiere.The ...",
  month        =  jun,
  year         =  2023,
  howpublished = "\url{https://www.theinformation.com/articles/adobe-flies-towards-generative-ai?utm\_source=sg\&utm\_medium=email\&utm\_campaign=article\_email\&utm\_content=article-10747}",
  note         = "Accessed: 2023-6-27"
}

@BOOK{Talbot2011-gg,
  title     = "The Vivaldi Compendium",
  author    = "Talbot, Michael",
  publisher = "Boydell \& Brewer",
  abstract  = "‘The Vivaldi Compendium’ will serve as the most reliable and
               up-to-date source of quick reference on the composer Antonio
               Vivaldi and his music. This takes the form of a dictionary
               listing persons, places, musical works and many other topics
               connected with Vivaldi; its alphabetically arranged entries are
               copiously cross-referenced so as to guide the reader towards
               related topics. ‘The Vivaldi Compendium’ also provides a gateway
               to further reading. This is achieved via an extensive
               bibliography, to which reference is made in most of the
               dictionary entries. These two sections are complemented by an
               article-length biography of the composer and a carefully
               organized list of his works. Knowledge about Vivaldi and his
               music is still advancing at an incredible rate - many discoveries
               occurred while the book was in preparation - and every effort has
               been made to ensure that ‘The Vivaldi Compendium’ represents the
               latest in Vivaldi research, drawing on the author's close
               involvement with Vivaldi and Venetian music over four decades.
               MICHAEL TALBOT is Emeritus Professor of Music at the University
               of Liverpool and a Fellow of the British Academy. He is known
               internationally for his studies of late-baroque Italian music,
               which include recent books on Vivaldi's chamber cantatas [2003]
               and the same composer's fugal writing [2007].",
  year      =  2011
}

@ARTICLE{Davenport2022-sa,
  title    = "How Generative {AI} Is Changing Creative Work",
  author   = "Davenport, Thomas H and Mittal, Nitin",
  journal  = "Harvard Business Review",
  abstract = "Generative AI models for businesses threaten to upend the world of
              content creation, with substantial impacts on marketing, software,
              design, entertainment, and interpersonal communications. These
              models are able to produce text and images: blog posts, program
              code, poetry, and artwork. The software uses complex machine
              learning models to predict the next word based on previous word
              sequences, or the next image based on words describing previous
              images. Companies need to understand how these tools work, and how
              they can add value.",
  month    =  nov,
  year     =  2022
}

@BOOK{Dunne2013-uv,
  title     = "Speculative Everything: Design, Fiction, and Social Dreaming",
  author    = "Dunne, Anthony and Raby, Fiona",
  publisher = "MIT Press",
  abstract  = "How to use design as a tool to create not only things but ideas,
               to speculate about possible futures.Today designers often focus
               on making technology easy to use, sexy, and consumable. In
               Speculative Everything, Anthony Dunne and Fiona Raby propose a
               kind of design that is used as a tool to create not only things
               but ideas. For them, design is a means of speculating about how
               things could be—to imagine possible futures. This is not the
               usual sort of predicting or forecasting, spotting trends and
               extrapolating; these kinds of predictions have been proven wrong,
               again and again. Instead, Dunne and Raby pose “what if” questions
               that are intended to open debate and discussion about the kind of
               future people want (and do not want).Speculative Everything
               offers a tour through an emerging cultural landscape of design
               ideas, ideals, and approaches. Dunne and Raby cite examples from
               their own design and teaching and from other projects from fine
               art, design, architecture, cinema, and photography. They also
               draw on futurology, political theory, the philosophy of
               technology, and literary fiction. They show us, for example,
               ideas for a solar kitchen restaurant; a flypaper robotic clock; a
               menstruation machine; a cloud-seeding truck; a phantom-limb
               sensation recorder; and devices for food foraging that use the
               tools of synthetic biology. Dunne and Raby contend that if we
               speculate more—about everything—reality will become more
               malleable. The ideas freed by speculative design increase the
               odds of achieving desirable futures.",
  month     =  dec,
  year      =  2013,
  language  = "en"
}

@MISC{UnknownUnknown-qv,
  title       = "codecarbon: Track emissions from Compute and recommend ways to
                 reduce their impact on the environment",
  institution = "Github",
  abstract    = "Track emissions from Compute and recommend ways to reduce their
                 impact on the environment. - mlco2/codecarbon",
  language    = "en"
}

@ARTICLE{noauthor_2014-ev,
  title    = "Post-photography: when artists go wild with cameras - in pictures",
  journal  = "The Guardian",
  abstract = "A disembodied leg stands alone on stage; a man unfolds a motorway.
              Welcome to the weird world of post-photography, an exciting new
              form of image manipulation that mixes digital and analogue methods
              to cook up the unexpected",
  month    =  oct,
  year     =  2014,
  language = "en"
}

@MISC{Ted2012-vc,
  title     = "Impossible photography | Erik Johansson",
  author    = "{TED}",
  publisher = "Youtube",
  abstract  = "http://www.ted.com Erik Johansson creates realistic photos of
               impossible scenes -- capturing ideas, not moments. In this witty
               how-to, the Photoshop wizard d...",
  month     =  feb,
  year      =  2012,
  keywords  = "Erik Johansson; creativity; culture; photography; technology;
               TED; TEDTalk; TEDTalks; TED Talk; TED Talks"
}

@BOOK{Bohm1996-fo,
  title     = "On Dialogue",
  author    = "Bohm, David",
  publisher = "Routledge",
  abstract  = "Never before has there been a greater need for deeper listening
               and more open communication to cope with the complex problems
               facing our organizations, businesses and societies. Renowned
               scientist David Bohm believed there was a better way for humanity
               to discover meaning and to achieve harmony. He identified
               creative dialogue, a sharing of assumptions and understanding, as
               a means by which the individual, and society as a whole, can
               learn more about themselves and others, and achieve a renewed
               sense of purpose.",
  year      =  1996,
  language  = "en"
}

@MISC{noauthor_undated-ti,
  title        = "Deep Fakes – Threats and Countermeasures",
  booktitle    = "Federal Office for Information Security",
  howpublished = "\url{https://www.bsi.bund.de/EN/Themen/Unternehmen-und-Organisationen/Informationen-und-Empfehlungen/Kuenstliche-Intelligenz/Deepfakes/deepfakes\_node.html}",
  note         = "Accessed: 2024-3-13",
  language     = "en"
}

@INPROCEEDINGS{Pigrem2017-sa,
  title     = "Datascaping",
  author    = "Pigrem, Jon and Barthet, Mathieu",
  booktitle = "Proceedings of the 12th International Audio Mostly Conference on
               Augmented and Participatory Sound and Music Experiences",
  publisher = "ACM",
  address   = "New York, NY, USA",
  month     =  aug,
  year      =  2017
}

@INPROCEEDINGS{Rocchesso2008-qp,
  title     = "Sonic interaction design",
  author    = "Rocchesso, Davide and Serafin, Stefania and Behrendt, Frauke and
               Bernardini, Nicola and Bresin, Roberto and Eckel, Gerhard and
               Franinovic, Karmen and Hermann, Thomas and Pauletto, Sandra and
               Susini, Patrick and Visell, Yon",
  booktitle = "CHI '08 Extended Abstracts on Human Factors in Computing Systems",
  publisher = "ACM",
  address   = "New York, NY, USA",
  month     =  apr,
  year      =  2008
}

@BOOK{Hermann2011-ng,
  title     = "The Sonification Handbook",
  editor    = "Hermann, Thomas and Hunt, Andy and Neuhoff, John G",
  publisher = "Logos Verlag Berlin",
  address   = "Berlin, Germany",
  month     =  dec,
  year      =  2011,
  language  = "en"
}

@ARTICLE{Muller2012-hg,
  title     = "Participatory design: The third space in human–computer
               interaction",
  author    = "Muller, M J and Druin, A",
  journal   = "Human Computer Interaction Handbook",
  publisher = "taylorfrancis.com",
  abstract  = "This chapter discusses methods that go beyond merely adding
               users—methods to create new settings and experiences that can
               assist computer professionals to work in partnership …",
  year      =  2012
}

@MISC{Henebery2023-ce,
  title        = "How teacher burnout is exacerbating Australia's school
                  workforce crisis",
  author       = "Henebery, Brett",
  publisher    = "The Educator K/12",
  abstract     = "Poor teacher working conditions hinder new policies to attract
                  teachers, leading to high staff turnover, two experts say",
  month        =  feb,
  year         =  2023,
  howpublished = "\url{https://www.theeducatoronline.com/k12/news/how-teacher-burnout-is-exacerbating-australias-school-workforce-crisis/281966}",
  note         = "Accessed: 2023-7-28",
  language     = "en"
}

@ARTICLE{Heaven2023-wa,
  title    = "The inside story of how {ChatGPT} was built from the people who
              made it",
  author   = "Heaven, Will Douglas",
  journal  = "MIT Technology Review",
  abstract = "Exclusive conversations that take us behind the scenes of a
              cultural phenomenon.",
  month    =  mar,
  year     =  2023,
  language = "en"
}

@MISC{OpenAI2024-ug,
  title        = "Introducing canvas",
  author       = "{OpenAI}",
  booktitle    = "OpenAI",
  abstract     = "Canvas is a new way to write and code with ChatGPT.",
  month        =  oct,
  year         =  2024,
  howpublished = "\url{https://openai.com/index/introducing-canvas/}",
  note         = "Accessed: 2024-12-28",
  language     = "en"
}

@MISC{Whitney2024-pp,
  title        = "Why Claude's Artifacts is the coolest feature {I}'ve seen in
                  generative {AI} so far",
  author       = "Whitney, Lance",
  booktitle    = "ZDNET",
  abstract     = "The Artifacts feature is now available to all Claude users
                  across the Free, Pro, and Team plans - on desktop and mobile.
                  Here's how it works and why it's such a game-changer.",
  month        =  aug,
  year         =  2024,
  howpublished = "\url{https://www.zdnet.com/article/why-claudes-artifacts-is-the-coolest-feature-ive-seen-in-generative-ai-so-far/}",
  note         = "Accessed: 2024-12-28",
  language     = "en"
}

@MISC{Proce2024-os,
  title        = "Calling all artists. This is making the rounds. There is hope
                  for us yet! pic.twitter.com/{aURCnLGko1}",
  author       = "Proce, Vincent",
  booktitle    = "Twitter",
  month        =  apr,
  year         =  2024,
  howpublished = "\url{https://twitter.com/vproceart/status/1781854966027579889}",
  note         = "Accessed: 2024-4-30",
  language     = "en"
}

@MISC{Novak_undated-yd,
  title        = "Former Pixar Animator Gives One Big Reason {AI} Video Won’t
                  Work in Hollywood",
  author       = "Novak, Matt",
  howpublished = "\url{https://gizmodo.com.au/2024/04/former-pixar-animator-gives-one-big-reason-ai-video-wont-work-in-hollywood/}",
  note         = "Accessed: 2024-4-30"
}

@INPROCEEDINGS{Rezwana2023-gj,
  title     = "User perspectives on ethical challenges in human-{AI}
               co-creativity: A design fiction study",
  author    = "Rezwana, Jeba and Maher, Mary Lou",
  booktitle = "Creativity and Cognition",
  publisher = "ACM",
  address   = "New York, NY, USA",
  month     =  jun,
  year      =  2023
}

@ARTICLE{Talbot2011-jr,
  title     = "The Vivaldi compendium",
  author    = "Talbot, M",
  journal   = "Choice",
  publisher = "American Library Association",
  volume    =  49,
  number    =  03,
  pages     = "49--1209--49--1209",
  abstract  = "The Vivaldi Compendium will serve as the most reliable and
               up-to-date source of quick reference on the composer Antonio
               Vivaldi and his music. This takes the form of a dictionary
               listing persons, places, musical works and many other topics
               connected with Vivaldi; its alphabetically arranged entries are
               copiously cross-referenced so as to guide the reader towards
               related topics. The Vivaldi Compendium also provides a gateway to
               further reading. This is achieved via an extensive bibliography,
               to which reference is made in most of the dictionary entries.
               These two sections are complemented by an article-length
               biography of the composer and a carefully organized list of his
               works. Knowledge about Vivaldi and his music is still advancing
               at an incredible rate - many discoveries occurred while the book
               was in preparation - and every effort has been made to ensure
               that The Vivaldi Compendium represents the latest in Vivaldi
               research, drawing on the author's close involvement with Vivaldi
               and Venetian music over four decades. MICHAEL TALBOT is Emeritus
               Professor of Music at the University of Liverpool and a Fellow of
               the British Academy. He is known internationally for his studies
               of late-baroque Italian music, which include recent books on
               Vivaldi's chamber cantatas (2003) and the same composer's fugal
               writing (2007).",
  month     =  nov,
  year      =  2011,
  language  = "en"
}

@INPROCEEDINGS{Quinn2001-wc,
  title     = "The Climate Symphony and Other Sonifications of Ice Core, Radar,
               {DNA}, Seismic and Solar Wind Data",
  author    = "Quinn, M",
  booktitle = "Proceedings of the 2001 International Conference on Auditory
               Display, Helsinki Finnland",
  year      =  2001
}

@MISC{UnknownUnknown-he,
  title        = "Man-Computer Symbiosis",
  howpublished = "\url{https://groups.csail.mit.edu/medg/people/psz/Licklider.html}",
  note         = "Accessed: 2024-11-8"
}

@ARTICLE{Licklider1960-md,
  title     = "Man-Computer Symbiosis",
  author    = "Licklider, J C R",
  journal   = "IRE Trans. Hum. Factors Electron.",
  publisher = "Institute of Electrical and Electronics Engineers (IEEE)",
  volume    = "HFE-1",
  number    =  1,
  pages     = "4--11",
  abstract  = "Man-computer symbiosis is an expected development in cooperative
               interaction between men and electronic computers. It will involve
               very close coupling between the human and the electronic members
               of the partnership. The main aims are 1) to let computers
               facilitate formulative thinking as they now facilitate the
               solution of formulated problems, and 2) to enable men and
               computers to cooperate in making decisions and controlling
               complex situations without inflexible dependence on predetermined
               programs. In the anticipated symbiotic partnership, men will set
               the goals, formulate the hypotheses, determine the criteria, and
               perform the evaluations. Computing machines will do the
               routinizable work that must be done to prepare the way for
               insights and decisions in technical and scientific thinking.
               Preliminary analyses indicate that the symbiotic partnership will
               perform intellectual operations much more effectively than man
               alone can perform them. Prerequisites for the achievement of the
               effective, cooperative association include developments in
               computer time sharing, in memory components, in memory
               organization, in programming languages, and in input and output
               equipment.",
  month     =  mar,
  year      =  1960,
  language  = "en"
}

@MISC{UnknownUnknown-hf,
  title        = "Gordon Pask",
  howpublished = "\url{https://www.pangaro.com/Pask-Archive/guardian-obit.html}",
  note         = "Accessed: 2024-11-26"
}

@MISC{SubstackUnknown-lj,
  title        = "Introducing the Substack app",
  author       = "{Substack}",
  abstract     = "Discover and discuss great writing with the most interesting
                  readers.",
  howpublished = "\url{https://substack.com/app?utm\_source=email}",
  note         = "Accessed: 2024-12-11",
  language     = "en"
}

@MISC{noauthor_undated-dk,
  title       = "video at main · google-gemini/starter-applets",
  institution = "Github",
  abstract    = "Google AI Studio Starter Apps. Contribute to
                 google-gemini/starter-applets development by creating an
                 account on GitHub.",
  language    = "en"
}

@ARTICLE{Rafner2021-tm,
  title     = "Deskilling, Upskilling, and Reskilling: a Case for Hybrid
               Intelligence",
  author    = "Rafner, Janet and Dellermann, Dominik and Hjorth, Arthur and
               Verasztó, Dóra and Kampf, Constance and Mackay, Wendy and
               Sherson, Jacob",
  journal   = "Morals \& Machines",
  publisher = "Nomos Verlag",
  volume    =  1,
  number    =  2,
  pages     = "24--39",
  abstract  = "Advances in AI technology affect knowledge work in diverse
               fields, including healthcare, engineering, and management.
               Although automation and machine support can increase efficiency
               and lower costs, it can also, as an unintended consequence,
               deskill workers, who lose valuable skills that would otherwise be
               maintained as part of their daily work. Such deskilling has a
               wide range of negative effects on multiple stakeholders --
               employees, organizations, and society at large. This essay
               discusses deskilling in the age of AI on three levels -
               individual, organizational and societal. Deskilling is
               furthermore analyzed through the lens of four different levels of
               human-AI configurations and we argue that one of them, Hybrid
               Intelligence, could be particularly suitable to help manage the
               risk of deskilling human experts. Hybrid Intelligence system
               design and implementation can explicitly take such risks into
               account and instead foster upskilling of workers. Hybrid
               Intelligence may thus, in the long run, lower costs and improve
               performance and job satisfaction, as well as prevent management
               from creating unintended organization-wide deskilling.",
  year      =  2021
}

@MISC{Alexander2024-pz,
  title        = "How Did You Do On The {AI} Art Turing Test?",
  author       = "Alexander, Scott",
  abstract     = "...",
  year         =  2024,
  howpublished = "\url{https://www.astralcodexten.com/p/how-did-you-do-on-the-ai-art-turing}",
  note         = "Accessed: 2024-11-21"
}

@MISC{Metz2016-vs,
  title        = "In Two Moves, {AlphaGo} and Lee Sedol Redefined the Future",
  author       = "Metz, Cade",
  booktitle    = "WIRED",
  abstract     = "Although machines are now capable of moments of genius, humans
                  have hardly lost the ability to generate their own.",
  month        =  mar,
  year         =  2016,
  howpublished = "\url{https://www.wired.com/2016/03/two-moves-alphago-lee-sedol-redefined-future/}",
  note         = "Accessed: 2025-2-17",
  language     = "en"
}

@MISC{Metz2016-dm,
  title        = "The Sadness and Beauty of Watching Google's {AI} Play Go",
  author       = "Metz, Cade",
  booktitle    = "WIRED",
  abstract     = "At first, the Go champion thought the move was rather odd.
                  Then he saw it was wonderful.",
  month        =  mar,
  year         =  2016,
  howpublished = "\url{https://www.wired.com/2016/03/sadness-beauty-watching-googles-ai-play-go/}",
  note         = "Accessed: 2025-2-17",
  language     = "en"
}

@MISC{Github2024-io,
  title       = "Github Copilot",
  author      = "{Github}",
  institution = "Github",
  abstract    = "GitHub is where people build software. More than 100 million
                 people use GitHub to discover, fork, and contribute to over 420
                 million projects.",
  year        =  2024,
  language    = "en"
}

@ARTICLE{Roose2022-iq,
  title     = "An A.{I}.-Generated Picture Won an Art Prize. Artists Aren’t
               Happy",
  author    = "Roose, Kevin",
  journal   = "The New York Times",
  publisher = "The New York Times",
  abstract  = "“I won, and I didn’t break any rules,” the artwork’s creator
               says.",
  month     =  sep,
  year      =  2022,
  language  = "en"
}

@MISC{Ocampo2022-lx,
  title        = "{AI} art is everywhere right now. Even experts don’t know what
                  it will mean",
  author       = "Ocampo, Rodolfo",
  booktitle    = "The Conversation",
  abstract     = "AI art tools like DALL-E, Midjourney and Stable Diffusion are
                  starting a revolution in the way art is made.",
  year         =  2022,
  howpublished = "\url{http://theconversation.com/ai-art-is-everywhere-right-now-even-experts-dont-know-what-it-will-mean-189800}",
  note         = "Accessed: 2024-12-26",
  language     = "en"
}

@MISC{Loh2024-fb,
  title        = "Creativity as Search: Mapping Latent Space",
  author       = "Loh, Bryan",
  booktitle    = "Runway Research",
  abstract     = "Creative exploration can be viewed as a search process in a
                  space of possibilities. We create solutions, evaluate them,
                  and refine them until we reach a result that we are happy
                  with. The latent spaces of our generative models provide a
                  direct software analog to this abstract space, where each
                  point in latent space represents a possible creation
                  conforming to patterns learned from data.",
  year         =  2024,
  howpublished = "\url{https://runwayml.com/research/creativity-as-search-mapping-latent-space}",
  note         = "Accessed: 2024-12-20",
  language     = "en"
}

@MISC{Deresiewicz2023-jx,
  title        = "Why {AI} Will Never Rival Human Creativity",
  author       = "Deresiewicz, William",
  booktitle    = "Persuasion",
  abstract     = "Predictive mechanisms preclude the originality needed for true
                  art.",
  month        =  may,
  year         =  2023,
  howpublished = "\url{https://www.persuasion.community/p/why-ai-will-never-rival-human-creativity}",
  note         = "Accessed: 2024-12-20",
  language     = "en"
}

@MISC{Lee2024-tu,
  title        = "Good creative tools are virtuosic and open-ended",
  author       = "Lee, Linus",
  year         =  2024,
  howpublished = "\url{https://thesephist.com/posts/virtuosity/}",
  note         = "Accessed: 2025-2-26",
  language     = "en"
}

@ARTICLE{Chappell2005-ka,
  title  = "Plato on Knowledge in the Theaetetus",
  author = "Chappell, Sophie-Grace",
  month  =  may,
  year   =  2005
}

@MISC{Foster2025-az,
  title        = "Generative {AI} will soon be a thing of the past",
  author       = "Foster, Brian",
  booktitle    = "Glass Almanac",
  abstract     = "In a world where artificial intelligence seems to be evolving
                  at a breathtaking pace, it might come as a surprise to learn
                  that one expert believes ... Continue Reading →",
  month        =  jan,
  year         =  2025,
  howpublished = "\url{https://glassalmanac.com/generative-ai-will-soon-be-a-thing-of-the-past/}",
  note         = "Accessed: 2025-1-18",
  language     = "en"
}

@MISC{SXSW2023-wg,
  title     = "{OpenAI} Co-founder Greg Brockman on {ChatGPT}, {DALL·E} and the
               Impact of Generative {AI} | {SXSW} 2023",
  author    = "{SXSW}",
  publisher = "Youtube",
  abstract  = "The past year proved that AI is here to stay. We have seen AI
               disrupt every major industry, from search engines to art and
               music. The change will be felt in ...",
  month     =  mar,
  year      =  2023,
  keywords  = "SXSW; South By Southwest; Southby; Fest; Festival; Austin; Texas;
               Conference; Lineup; Keynote; Speaker; Panel; Interview; Music;
               Film; Movie; Interactive; Tech; Technology; Gaming; Video Games;
               Media; Entertainment; News; Business; Creative; Entrepreneur;
               Development; Red Carpet; Live; Performance; Showcase; Concert;
               TV; Television; artificial intelligence; ai; chatgpt; dall-e"
}

@MISC{OpenAI2022-pj,
  title        = "Aligning language models to follow instructions",
  author       = "{OpenAI}",
  booktitle    = "OpenAI",
  abstract     = "We’ve trained language models that are much better at
                  following user intentions than GPT-3 while also making them
                  more truthful and less toxic, using techniques developed
                  through our alignment research. These InstructGPT models,
                  which are trained with humans in the loop, are now deployed as
                  the default language models on our API.",
  year         =  2022,
  howpublished = "\url{https://openai.com/index/instruction-following/}",
  note         = "Accessed: 2024-12-29",
  language     = "en"
}

@MISC{Prathyush2024-ly,
  title        = "Prathyush on {X}: ``A powerful way to think about user
                  interfaces is as them being bases of a latent space manifold.
                  There is a nascent niche of interesting experiments exploring
                  these and {I} will try to curate some of these that came into
                  my notice in this thread.'' / {X}",
  author       = "{Prathyush}",
  booktitle    = "X (formerly Twitter)",
  year         =  2024,
  howpublished = "\url{https://x.com/prathyvsh/status/1852215239850225943}",
  note         = "Accessed: 2024-12-29",
  language     = "en"
}

@MISC{Pichai2024-ao,
  title        = "Introducing Gemini 2.0: our new {AI} model for the agentic era",
  author       = "Pichai, Sundar",
  booktitle    = "Google",
  abstract     = "Today, we’re announcing Gemini 2.0, our most capable AI model
                  yet.",
  month        =  dec,
  year         =  2024,
  howpublished = "\url{https://blog.google/technology/google-deepmind/google-gemini-ai-update-december-2024/}",
  note         = "Accessed: 2024-12-29",
  language     = "en"
}

@MISC{Dive2024-sp,
  title     = "Controlling Blender with my voice using {LLM}",
  author    = "Dive, Polyfjord Deep",
  publisher = "Youtube",
  abstract  = "Experimenting with Googles' new Gemini 2.0 Flash Experimental to
               control Blender with my voice!Tools used:Blender -
               https://www.blender.org/Tinytask - https:...",
  month     =  dec,
  year      =  2024
}

@ARTICLE{Barke2019-ad,
  title     = "Role clarity deficiencies can wreck agile teams",
  author    = "Barke, Helena and Prechelt, L",
  journal   = "PeerJ Comput. Sci.",
  publisher = "peerj.com",
  volume    =  5,
  abstract  = "Background One of the twelve agile principles is to build
               projects around motivated individuals and trust them to get the
               job done. Such agile teams must self-organize, but this involves
               conflict, making self-organization difficult. One area of
               difficulty is agreeing on everybody’s role. Background What
               dynamics arise in a self-organizing team from the negotiation of
               everybody’s role? Method We conceptualize observations from five
               agile teams (work observations, interviews) by Charmazian
               Grounded Theory Methodology. Results We define role as something
               transient and implicit, not fixed and named. The roles are
               characterized by the responsibilities and expectations of each
               team member. Every team member must understand and accept their
               own roles (Local role clarity) and everbody else’s roles
               (Team-wide role clarity). Role clarity allows a team to work
               smoothly and effectively and to develop its members’ skills fast.
               Lack of role clarity creates friction that not only hampers the
               day-to-day work, but also appears to lead to high employee
               turnover. Agile coaches are critical to create and maintain role
               clarity. Conclusions Agile teams should pay close attention to
               the levels of Local role clarity of each member and Team-wide
               role clarity overall, because role clarity deficits are highly
               detrimental.",
  month     =  dec,
  year      =  2019
}

@MISC{Sandzer-bell2024-hy,
  title        = "How Suno works for musicians",
  author       = "Sandzer-bell, Ezra",
  booktitle    = "LinkedIn",
  year         =  2024,
  howpublished = "LinkedIn Post",
  language     = "en"
}

@MISC{Eno2024-rj,
  title        = "{AI’s} Walking Dog",
  author       = "Eno, Brian",
  booktitle    = "Boston Review",
  abstract     = "Today’s tech inverts the value of the creative process.",
  month        =  dec,
  year         =  2024,
  howpublished = "\url{https://www.bostonreview.net/forum\_response/ais-walking-dog/}",
  note         = "Accessed: 2024-12-30",
  language     = "en"
}

@MISC{Xyz2024-um,
  title        = "(1) Purz.xyz on {X}: ``Sora - my main takeaways. - Probably
                  only worth it on the Pro plan. - No videos of humans on the
                  Plus plan. - Very strange and choppy motion on everything but
                  the subject. - Doesn’t adhere to prompt well, especially for
                  actions and camera motions. - It’s a very expensive'' / {X}",
  author       = "Xyz, Purz",
  booktitle    = "X (formerly Twitter)",
  year         =  2024,
  howpublished = "\url{https://x.com/PurzBeats/status/1866276091251335370}",
  note         = "Accessed: 2024-12-30",
  language     = "en"
}

@INPROCEEDINGS{Ashktorab2021-ie,
  title     = "Effects of communication directionality and {AI} agent
               differences in human-{AI} interaction",
  author    = "Ashktorab, Zahra and Dugan, Casey and Johnson, James and Pan,
               Qian and Zhang, Wei and Kumaravel, Sadhana and Campbell, Murray",
  booktitle = "Proceedings of the 2021 CHI Conference on Human Factors in
               Computing Systems",
  publisher = "ACM",
  address   = "New York, NY, USA",
  month     =  may,
  year      =  2021
}

@MISC{Sloan2016-fj,
  title        = "Writing with the machine",
  author       = "Sloan, Robin",
  booktitle    = "Robin Sloan",
  abstract     = "It’s like writing with a deranged but very well-read parrot on
                  your shoulder.",
  month        =  may,
  year         =  2016,
  howpublished = "\url{https://www.robinsloan.com/notes/writing-with-the-machine/}",
  note         = "Accessed: 2025-1-9",
  language     = "en"
}

@MISC{Samuel2019-gc,
  title        = "How I’m using {AI} to write my next novel",
  author       = "Samuel, Sigal",
  booktitle    = "Vox",
  abstract     = "Try out OpenAI’s neural network. It may boost your creativity.",
  month        =  aug,
  year         =  2019,
  howpublished = "\url{https://www.vox.com/future-perfect/2019/8/30/20840194/ai-art-fiction-writing-language-gpt-2}",
  note         = "Accessed: 2025-1-9",
  language     = "en"
}

@ARTICLE{Torrance1972-br,
  title   = "Predictive validity of the Torrance tests of creative thinking",
  author  = "Torrance, E",
  journal = "Journal of Creative Behavior",
  volume  =  6,
  pages   = "236--262",
  month   =  dec,
  year    =  1972
}

@ARTICLE{Wallas1926-ky,
  title    = "The art of thought",
  author   = "Wallas, G",
  journal  = "Franklin Watts",
  abstract = "Preface | Synopsis of Chapters | Chapter I Psychology and Thought
              | Chapter II Consciousness and Will | Chapter III Thought Before
              Art | Chapter IV Stages of Control | Chapter V Thought and Emotion
              | Chapter VI Thought and Habit | Chapter VII Effort and Energy |
              Chapter VIII Types of Thought | Chapter IX Dissociation of
              Consciousness | Chapter X The Thinker at School | Chapter XI
              Public Education | Chapter XII Teaching and Doing | Index",
  year     =  1926
}

@MISC{Nielsen1994-df,
  title        = "10 Usability Heuristics for User Interface Design",
  author       = "Nielsen, Jakob",
  booktitle    = "Nielsen Norman Group",
  abstract     = "Jakob Nielsen's 10 general principles for interaction design.
                  They are called ``heuristics'' because they are broad rules of
                  thumb and not specific usability guidelines.",
  month        =  apr,
  year         =  1994,
  howpublished = "\url{https://www.nngroup.com/articles/ten-usability-heuristics/}",
  note         = "Accessed: 2025-1-10",
  language     = "en"
}

@ARTICLE{Yilmaz2016-ka,
  title     = "Evidence-based design heuristics for idea generation",
  author    = "Yilmaz, Seda and Daly, Shanna R and Seifert, Colleen M and
               Gonzalez, Richard",
  journal   = "Des. Stud.",
  publisher = "Elsevier BV",
  volume    =  46,
  pages     = "95--124",
  abstract  = "How do product designers create multiple concepts to consider? To
               address this question, we combine evidence from four empirical
               studies of design process and outcomes, including award-winning
               products, multiple concepts for a project by an experienced
               industrial designer, and concept sets from 48 industrial and
               engineering designers for a single design problem. This
               compilation of over 3450 design process outcomes is analyzed to
               extract concept variations evident across design problems and
               solutions. The resulting set of patterns, in the form of 77
               Design Heuristics, catalog how designers appear to introduce
               intentional variation into conceptual product designs. These
               heuristics provide ‘cognitive shortcuts’ that can help designers
               generate more, and more varied, candidate concepts to consider in
               the early phases of design.",
  month     =  sep,
  year      =  2016
}

@ARTICLE{Gonzalez-Holland2017-xv,
  title     = "Examination of the use of Nielsen’s 10 usability heuristics \&
               outlooks for the future",
  author    = "Gonzalez-Holland, Emily and Whitmer, Daphne and Moralez, Larry
               and Mouloua, Mustapha",
  journal   = "Proc. Hum. Factors Ergon. Soc. Annu. Meet.",
  publisher = "SAGE Publications",
  volume    =  61,
  number    =  1,
  pages     = "1472--1475",
  abstract  = "Heuristics are commonly employed throughout various stages of the
               design process to evaluate the usability of interfaces. Heuristic
               Evaluation (HE) provides researchers with a cost effective and
               practical means to effectively assess designs. In this article,
               we aim to outline the development and application of one of the
               most frequently cited set of heuristic evaluation tools,
               Nielsen’s (1994) 10 usability heuristics. Nielsen’s heuristics
               have not only been applied to various modalities of interface
               design, but have also been compared to other usability evaluation
               methods. Moreover, in many cases they have been modified so that
               they can be applied in an ever-changing socio-technical
               environment. In reviewing these developments, we propose
               theoretical and practical implications of these heuristic methods
               and present an outlook for the future. We argue that with the
               rapid expansion and growth of technology in the last 20 years,
               Nielsen’s 10 usability heuristics may need an update to remain
               consistent with modern usability problems.",
  month     =  sep,
  year      =  2017,
  language  = "en"
}

@INCOLLECTION{Yilmaz2011-ut,
  title     = "Design heuristics: Cognitive strategies for creativity in idea
               generation",
  author    = "Yilmaz, Seda and Seifert, Colleen M and Gonzalez, Richard",
  booktitle = "Design Computing and Cognition ’10",
  publisher = "Springer Netherlands",
  address   = "Dordrecht",
  pages     = "35--53",
  abstract  = "This paper explores the use of heuristics as cognitive strategies
               invoked during the process of design. We propose new heuristics
               for design that provide ways to explore the problem space of
               potential designs, and often lead to the generation of creative
               solutions. We test whether Design Heuristics can be taught to
               novices, and whether doing so will improve the creativity of
               their resulting designs. In the present empirical study, we
               evaluate a set of six instructional heuristics, and validate
               their effectiveness with product concepts generated by novice
               designers. Six hundred and seventy three drawings were created by
               120 first-year college students under four instructional
               conditions. Drawings were coded according to the use of
               heuristics, and scored for creativity. The results showed that
               the most creative concepts emerged from the experimental
               conditions where heuristics were introduced. Heuristics appeared
               to help the participants “jump” into a new problem space,
               resulting in more varied designs, and a greater number of designs
               judged as more creative. Our findings suggest that the simple
               demonstration of design heuristics may, at times, be sufficient
               to stimulate variation and creativity in design.",
  year      =  2011,
  language  = "en"
}

@MISC{OpenAI2024-ro,
  title        = "Memory and new controls for {ChatGPT}",
  author       = "{OpenAI}",
  booktitle    = "OpenAI",
  abstract     = "We’re testing the ability for ChatGPT to remember things you
                  discuss to make future chats more helpful. You’re in control
                  of ChatGPT’s memory.",
  month        =  feb,
  year         =  2024,
  howpublished = "\url{https://openai.com/index/memory-and-new-controls-for-chatgpt/}",
  note         = "Accessed: 2025-1-30",
  language     = "en"
}

@BOOK{Creswell2012-om,
  title     = "Qualitative inquiry and research design: Choosing among five
               approaches",
  author    = "Creswell, John W",
  publisher = "SAGE Publications",
  address   = "Thousand Oaks, CA",
  edition   =  3,
  month     =  may,
  year      =  2012
}

@BOOK{Wagner2015-oj,
  title     = "Arrival of the fittest: How nature innovates",
  author    = "Wagner, Andreas",
  publisher = "Current",
  abstract  = "“Natural selection can preserve innovations, but it cannot create
               them. Nature’s many innovations—some uncannily perfect—call for
               natural principles that accelerate life’s...",
  month     =  oct,
  year      =  2015,
  language  = "en"
}

@MISC{Leach2025-yv,
  title        = "Michael used {AI} to write a work email. It ended up costing
                  him \$2000",
  author       = "Leach, Maddison",
  booktitle    = "9News",
  month        =  apr,
  year         =  2025,
  howpublished = "\url{https://amp.9news.com.au/article/aad554ec-0d8b-49c1-9047-f497e75ce3a2}",
  note         = "Accessed: 2025-4-11",
  language     = "en"
}

@MISC{Caleb2024-ga,
  title        = "Profiles and Moodboards",
  author       = "{Caleb}",
  booktitle    = "Midjourney",
  abstract     = "Hi everyone, we’re releasing an early version of our new model
                  personalization infrastructure today Flagship features * You
                  can now have multiple personalization profiles * Setting up
                  personalization is now much faster (up to 5x faster) * You can
                  now personalize models with moodboards of uploaded images Try
                  it out at midjourney.",
  month        =  dec,
  year         =  2024,
  howpublished = "\url{https://updates.midjourney.com/profiles-and-moodboards/}",
  note         = "Accessed: 2025-1-30",
  language     = "en"
}

@MISC{Popova2021-dl,
  title        = "Nietzsche on Walking and Creativity",
  author       = "Popova, Maria",
  booktitle    = "The Marginalian",
  abstract     = "“Our first questions about the value of a book, of a human
                  being, or a musical composition are: Can they walk? Even more,
                  can they dance?”",
  month        =  dec,
  year         =  2021,
  howpublished = "\url{https://www.themarginalian.org/2021/12/12/nietzsche-walking/}",
  note         = "Accessed: 2025-3-11",
  language     = "en"
}

@ARTICLE{Guilford1967-py,
  title     = "The nature of human intelligence",
  author    = "Guilford, J P",
  journal   = "Produits Pharm.",
  publisher = "McGraw-Hill The nature of human intelligence.",
  year      =  1967
}

@ARTICLE{Clark1998-yi,
  title     = "The Extended Mind",
  author    = "Clark, A and Chalmers, D",
  journal   = "Analysis",
  publisher = "[Analysis Committee, Oxford University Press]",
  volume    =  58,
  number    =  1,
  pages     = "7--19",
  abstract  = "Where does the mind stop and the rest of the world begin? The
               question invites two standard replies. Some accept the intuitive
               demarcations of skin and skull, and say that what is outside the
               body is outside the mind. Others are impressed by arguments
               suggesting that the meaning of our words ``just ain't in the
               head'', and hold that this externalism about meaning carries over
               into an externalism about mind. We propose to pursue a third
               position. We will advocate an externalism about mind, but one
               that is in no way grounded in the debatable role of external
               reference in fixing the contents of our mental states. Rather, we
               advocate an *active externalism*, based on the active role of the
               environment in driving cognitive processes.",
  month     =  jan,
  year      =  1998
}

@MISC{Anthropic2024-tc,
  title        = "Claude 3.5 Sonnet",
  author       = "{Anthropic}",
  abstract     = "Introducing Claude 3.5 Sonnet—our most intelligent model yet.
                  Sonnet now outperforms competitor models and Claude 3 Opus on
                  key evaluations, at twice the speed.",
  month        =  jun,
  year         =  2024,
  howpublished = "\url{https://www.anthropic.com/news/claude-3-5-sonnet}",
  note         = "Accessed: 2025-2-16",
  language     = "en"
}

@MISC{Leonardo2024-yh,
  title        = "Phoenix by Leonardo.Ai - meet the future of {AI} image
                  generation",
  author       = "Leonardo, A I",
  abstract     = "Phoenix delivers exceptional prompt adherence, coherent text
                  in images and provides iterative prompting capabilities with
                  Edit with AI. Phoenix is Leonardo.Ai's first foundational
                  model and is currently in preview.",
  year         =  2024,
  howpublished = "\url{https://leonardo.ai/phoenix/}",
  note         = "Accessed: 2025-2-16",
  language     = "en"
}

@MISC{Udio2024-rc,
  title        = "Udio",
  author       = "{Udio}",
  booktitle    = "Udio",
  abstract     = "Discover, create, and share music with the world. Use the
                  latest technology to create AI music in seconds.",
  year         =  2024,
  howpublished = "\url{https://www.udio.com/?utm\_source=google\&utm\_medium=cpc\&utm\_campaign=22053140610\&utm\_content=171283075654\&utm\_term=\%EF\%BD\%95\%EF\%BD\%84\%EF\%BD\%89\%EF\%BD\%8F\&gad\_source=1\&gclid=CjwKCAiAk8G9BhA0EiwAOQxmfpSm-uPG6UtJJ4dIyBzCuGLgWbdmhZCtETUdsxgq2SOPpW8aAmCo4BoCB0QQAvD\_BwE}",
  note         = "Accessed: 2025-2-16",
  language     = "en"
}

@MISC{Runway2024-zs,
  title        = "Runway Research",
  author       = "{Runway}",
  booktitle    = "Runway",
  abstract     = "Gen-3 Alpha is the first of the next generation of foundation
                  models trained by Runway on a new infrastructure built for
                  large-scale multimodal training. It is a major improvement in
                  fidelity, consistency, and motion over Gen-2, and a step
                  towards building General World Models.",
  year         =  2024,
  howpublished = "\url{https://runwayml.com/research/introducing-gen-3-alpha}",
  note         = "Accessed: 2025-2-16",
  language     = "en"
}

@MISC{OpenAI2024-em,
  title        = "Hello {GPT}-{4o}",
  author       = "{OpenAI}",
  booktitle    = "OpenAI",
  abstract     = "We’re announcing GPT-4 Omni, our new flagship model which can
                  reason across audio, vision, and text in real time.",
  month        =  may,
  year         =  2024,
  howpublished = "\url{https://openai.com/index/hello-gpt-4o/}",
  note         = "Accessed: 2025-2-16",
  language     = "en"
}

@ARTICLE{Sutskever2011-ne,
  title    = "Generating text with recurrent Neural Networks",
  author   = "Sutskever, I and Martens, James and Hinton, Geoffrey E",
  journal  = "ICML",
  pages    = "1017--1024",
  abstract = "Recurrent Neural Networks (RNNs) are very powerful sequence models
              that do not enjoy widespread use because it is extremely difficult
              to train them properly. Fortunately, recent advances in
              Hessian-free optimization have been able to overcome the
              difficulties associated with training RNNs, making it possible to
              apply them successfully to challenging sequence problems. In this
              paper we demonstrate the power of RNNs trained with the new
              Hessian-Free optimizer (HF) by applying them to character-level
              language modeling tasks. The standard RNN architecture, while
              effective, is not ideally suited for such tasks, so we introduce a
              new RNN variant that uses multiplicative (or ``gated'')
              connections which allow the current input character to determine
              the transition matrix from one hidden state vector to the next.
              After training the multiplicative RNN with the HF optimizer for
              five days on 8 high-end Graphics Processing Units, we were able to
              surpass the performance of the best previous single method for
              character-level language modeling – a hierarchical non-parametric
              sequence model. To our knowledge this represents the largest
              recurrent neural network application to date.",
  month    =  jun,
  year     =  2011
}

@ARTICLE{Bengio2000-id,
  title     = "10.1162/153244303322533223",
  author    = "Bengio, Yoshua and Ducharme, Réjean and Vincent, Pascal and
               Jauvin, Christian",
  editor    = "Kandola, Jaz and Hofmann, Thomas and Poggio, Tomaso and
               Shawe-Taylor, John",
  journal   = "Appl. Phys. Lett.",
  publisher = "Test accounts",
  volume    =  1,
  number    =  6,
  pages     = "1137--1155",
  year      =  2000,
  language  = "en"
}

@MISC{Suno2024-wa,
  title        = "Suno",
  author       = "{Suno}",
  booktitle    = "Suno",
  abstract     = "Suno is building a future where anyone can make great music.",
  year         =  2024,
  howpublished = "\url{https://suno.com/home}",
  note         = "Accessed: 2025-2-16",
  language     = "en"
}

@MISC{OpenAI2024-ua,
  title        = "Sora",
  author       = "{OpenAI}",
  abstract     = "Sora is OpenAI’s video generation model, designed to take
                  text, image, and video inputs and generate a new video as an
                  output. Users can create videos in various formats, generate
                  new content from text, or enhance, remix, and blend their own
                  assets.",
  year         =  2024,
  howpublished = "\url{https://openai.com/sora/}",
  note         = "Accessed: 2025-2-16",
  language     = "en"
}

@MISC{Mordvintsev2015-oz,
  title        = "{DeepDream} - a code example for visualizing Neural Networks",
  author       = "Mordvintsev, Alexander and Olah, Christopher and Tyka, Mike",
  booktitle    = "Research Blog",
  year         =  2015,
  howpublished = "\url{https://web.archive.org/web/20150708233542/http://googleresearch.blogspot.com/2015/07/deepdream-code-example-for-visualizing.html}",
  note         = "Accessed: 2024-12-19",
  language     = "en"
}

@ARTICLE{Hu2023-ie,
  title     = "{ChatGPT} sets record for fastest-growing user base - analyst
               note",
  author    = "Hu, Krystal",
  journal   = "Reuters",
  publisher = "Reuters",
  abstract  = "ChatGPT, the popular chatbot from OpenAI, is estimated to have
               reached 100 million monthly active users in January, just two
               months after launch, making it the fastest-growing consumer
               application in history, according to a UBS study on Wednesday.",
  month     =  feb,
  year      =  2023,
  language  = "en"
}

@MISC{Chow2024-tv,
  title        = "Willonius Hatcher",
  author       = "Chow, Andrew R",
  booktitle    = "Time",
  abstract     = "Find out why Willonius Hatcher made TIME’s list of the most
                  influential people in artificial intelligence.",
  month        =  sep,
  year         =  2024,
  howpublished = "\url{https://time.com/7012740/king-willonius/}",
  note         = "Accessed: 2025-2-17",
  language     = "en"
}

@MISC{Obrist2024-qp,
  title        = "{AI} choirs: Holly Herndon and Mat Dryhurst on data training
                  as art-making",
  author       = "Obrist, Hans Ulrich",
  booktitle    = "Art Basel",
  abstract     = "The digital pioneers speak to Serpentine’s Hans Ulrich Obrist
                  ahead of the unveiling of The Call, a radical reinvention of
                  choral tradition in the age of machine learning",
  month        =  feb,
  year         =  2024,
  howpublished = "\url{https://www.artbasel.com/stories/ai-holly-herndon-mat-dryhurst-data-training-art-making}",
  note         = "Accessed: 2025-2-17",
  language     = "en"
}

@ARTICLE{Jordanous2012-kw,
  title     = "A Standardised Procedure for Evaluating Creative Systems:
               Computational Creativity Evaluation Based on What it is to be
               Creative",
  author    = "Jordanous, Anna",
  journal   = "Cognit. Comput.",
  publisher = "Springer Science and Business Media LLC",
  volume    =  4,
  number    =  3,
  pages     = "246--279",
  abstract  = "Computational creativity is a flourishing research area, with a
               variety of creative systems being produced and developed.
               Creativity evaluation has not kept pace with system development
               with an evident lack of systematic evaluation of the creativity
               of these systems in the literature. This is partially due to
               difficulties in defining what it means for a computer to be
               creative; indeed, there is no consensus on this for human
               creativity, let alone its computational equivalent. This paper
               proposes a Standardised Procedure for Evaluating Creative Systems
               (SPECS). SPECS is a three-step process: stating what it means for
               a particular computational system to be creative, deriving and
               performing tests based on these statements. To assist this
               process, the paper offers a collection of key components of
               creativity, identified empirically from discussions of human and
               computational creativity. Using this approach, the SPECS
               methodology is demonstrated through a comparative case study
               evaluating computational creativity systems that improvise music.",
  month     =  sep,
  year      =  2012,
  language  = "en"
}

@ARTICLE{Runco2012-ta,
  title     = "The standard definition of creativity",
  author    = "Runco, Mark A and Jaeger, Garrett J",
  journal   = "Creat. Res. J.",
  publisher = "Informa UK Limited",
  volume    =  24,
  number    =  1,
  pages     = "92--96",
  month     =  jan,
  year      =  2012,
  language  = "en"
}

@ARTICLE{Runco2012-mk,
  title     = "The standard definition of creativity",
  author    = "Runco, Mark A and Jaeger, Garrett J",
  journal   = "Creat. Res. J.",
  publisher = "Informa UK Limited",
  volume    =  24,
  number    =  1,
  pages     = "92--96",
  month     =  jan,
  year      =  2012,
  language  = "en"
}

@ARTICLE{Sternberg1998-oz,
  title     = "The concept of creativity: Prospects and paradigms",
  author    = "Sternberg, R and Lubart, T",
  editor    = "Sternberg, Robert J",
  journal   = "Handbook of creativity.",
  publisher = "Cambridge University Press, ix",
  volume    =  490,
  pages     = "3--15",
  abstract  = "If one wanted to select the best novelist, artist, entrepreneur,
               or even chief executive officer, one would most likely want
               someone who is creative. Indeed, today many CEOs are selected not
               for their pleasant personalities (it's hard to be perceived as
               pleasant when you may have to fire 20\% of the company) or their
               learning and memory skills (they use computers or subordinates to
               remember the details for them), but for their creative vision of
               how to turn a company around. Creativity is the ability to
               produce work that is both novel (i.e., original, unexpected) and
               appropriate (i.e., useful, adaptive concerning task constraints)
               (Lubart, 1994; Ochse, 1990; Sternberg, 1988a; Sternberg \&
               Lubart, 1991, 1995, 1996). Creativity is a topic of wide scope
               that is important at both the individual and societal levels for
               a wide range of task domains. At an individual level, creativity
               is relevant, for example, when one is solving problems on the job
               and in daily life. At a societal level, creativity can lead to
               new scientific findings, new movements in art, new inventions,
               and new social programs. The economic importance of creativity is
               clear because new products or services create jobs. Furthermore,
               individuals, organizations, and societies must adapt existing
               resources to changing task demands to remain competitive.",
  month     =  oct,
  year      =  1998
}

@ARTICLE{Amabile1983-lj,
  title     = "The social psychology of creativity: A componential
               conceptualization",
  author    = "Amabile, Teresa M",
  journal   = "J. Pers. Soc. Psychol.",
  publisher = "American Psychological Association (APA)",
  volume    =  45,
  number    =  2,
  pages     = "357--376",
  month     =  aug,
  year      =  1983,
  language  = "en"
}

@ARTICLE{Pataranutaporn2023-ld,
  title     = "Influencing human–AI interaction by priming beliefs about {AI}
               can increase perceived trustworthiness, empathy and effectiveness",
  author    = "Pataranutaporn, Pat and Liu, Ruby and Finn, Ed and Maes, Pattie",
  journal   = "Nat. Mach. Intell.",
  publisher = "Springer Science and Business Media LLC",
  volume    =  5,
  number    =  10,
  pages     = "1076--1086",
  abstract  = "As conversational agents powered by large language models become
               more human-like, users are starting to view them as companions
               rather than mere assistants. Our study explores how changes to a
               person’s mental model of an AI system affects their interaction
               with the system. Participants interacted with the same
               conversational AI, but were influenced by different priming
               statements regarding the AI’s inner motives: caring, manipulative
               or no motives. Here we show that those who perceived a caring
               motive for the AI also perceived it as more trustworthy,
               empathetic and better-performing, and that the effects of priming
               and initial mental models were stronger for a more sophisticated
               AI model. Our work also indicates a feedback loop in which the
               user and AI reinforce the user’s mental model over a short time;
               further work should investigate long-term effects. The research
               highlights the importance of how AI systems are introduced can
               notably affect the interaction and how the AI is experienced. The
               recent accessibility of large language models brought them into
               contact with a large number of users and, due to the social
               nature of language, it is hard to avoid prescribing human
               characteristics such as intentions to a chatbot. Pataranutaporn
               and colleagues investigated how framing a bot as helpful or
               manipulative can influence this perception and the behaviour of
               the humans that interact with it.",
  month     =  oct,
  year      =  2023,
  language  = "en"
}

@ARTICLE{De_Freitas2023-lx,
  title     = "Psychological factors underlying attitudes toward {AI} tools",
  author    = "De Freitas, Julian and Agarwal, Stuti and Schmitt, Bernd and
               Haslam, Nick",
  journal   = "Nat. Hum. Behav.",
  publisher = "Springer Science and Business Media LLC",
  volume    =  7,
  number    =  11,
  pages     = "1845--1854",
  abstract  = "What are the psychological factors driving attitudes toward
               artificial intelligence (AI) tools, and how can resistance to AI
               systems be overcome when they are beneficial? Here we first
               organize the main sources of resistance into five main
               categories: opacity, emotionlessness, rigidity, autonomy and
               group membership. We relate each of these barriers to fundamental
               aspects of cognition, then cover empirical studies providing
               correlational or causal evidence for how the barrier influences
               attitudes toward AI tools. Second, we separate each of the five
               barriers into AI-related and user-related factors, which is of
               practical relevance in developing interventions towards the
               adoption of beneficial AI tools. Third, we highlight potential
               risks arising from these well-intentioned interventions. Fourth,
               we explain how the current Perspective applies to various
               stakeholders, including how to approach interventions that carry
               known risks, and point to outstanding questions for future work.
               In this Perspective, the authors examine the psychological
               factors that shape attitudes towards AI tools, while also
               investigating strategies to overcome resistance when AI systems
               offer clear benefits.",
  month     =  nov,
  year      =  2023,
  language  = "en"
}

@ARTICLE{Eshraghian2020-ni,
  title     = "Human ownership of artificial creativity",
  author    = "Eshraghian, Jason K",
  journal   = "Nat. Mach. Intell.",
  publisher = "Springer Science and Business Media LLC",
  volume    =  2,
  number    =  3,
  pages     = "157--160",
  abstract  = "Advances in generative algorithms have enhanced the quality and
               accessibility of artificial intelligence (AI) as a tool in
               building synthetic datasets. By generating photorealistic images
               and videos, these networks can pose a major technological
               disruption to a broad range of industries from medical imaging to
               virtual reality. However, as artwork developed by generative
               algorithms and cognitive robotics enters the arena, the notion of
               human-driven creativity has been thoroughly tested. When
               creativity is automated by the programmer, in a style determined
               by the trainer, using features from information available in
               public and private datasets, who is the proprietary owner of the
               rights in AI-generated artworks and designs? This Perspective
               seeks to provide an answer by systematically exploring the key
               issues in copyright law that arise at each phase of artificial
               creativity, from programming to deployment. Ultimately, four
               guiding actions are established for artists, programmers and end
               users that utilize AI as a tool such that they may be
               appropriately awarded the necessary proprietary rights. As
               artists are beginning to employ deep learning techniques to
               create new and interesting art, questions arise about how
               copyright and ownership apply to those works. This Perspective
               discusses how artists, programmers and users can ensure clarity
               about the ownership of their creations.",
  month     =  mar,
  year      =  2020,
  language  = "en"
}

@ARTICLE{Simonton1999-yc,
  title     = "Creativity as blind variation and selective retention : Is the
               creative process Darwinian ?",
  author    = "Simonton, D",
  journal   = "Psychological Inquiry",
  publisher = "Taylor \& Francis, Ltd.",
  volume    =  10,
  number    =  4,
  pages     = "309--328",
  abstract  = "Darwinism provides not only a theory of biological evolution but
               also supplies a more generic process applicable to many phenomena
               in the behavioral sciences. Among these applications is the
               blind-variation and selective-retention model of creativity
               proposed by Campbell (1960). Research over the past 4 decades
               lends even more sup port to Campbell’s model. This support is
               indicated by reviewing the experimental, psychometric, and
               historiometric literature on creativity. Then 4 major objections
               to the Darwinian model are examined (sociocultural determinism,
               individual volition, human rationality, and domain expertise).
               The article concludes by speculating whether the Darwinian model
               may actually subsume all alternative theories of creativity as
               special cases of the larger framework.",
  year      =  1999
}

@MISC{UnknownUnknown-ot,
  title        = "Accelerating scientific breakthroughs with an {AI}
                  co-scientist",
  howpublished = "\url{https://research.google/blog/accelerating-scientific-breakthroughs-with-an-ai-co-scientist/}",
  note         = "Accessed: 2025-2-24",
  language     = "en"
}

@BOOK{Donald1986-hx,
  title     = "User centered system design: New perspectives on human-computer
               interaction",
  author    = "Donald, Norman and Stephen, Draper",
  editor    = "Norman, Donald A and Draper, Stephen W",
  publisher = "Lawrence Erlbaum Associates",
  address   = "Mahwah, NJ",
  edition   =  1,
  abstract  = "This comprehensive volume is the product of an intensive
               collaborative effort among researchers across the United States,
               Europe and Japan. The result -- a change in the way we think of
               humans and computers.",
  month     =  jan,
  year      =  1986,
  language  = "en"
}

@BOOK{Norman2013-hs,
  title     = "The design of everyday things",
  author    = "Norman, Donald A",
  publisher = "MIT Press",
  address   = "London, England",
  series    = "The MIT Press",
  month     =  dec,
  year      =  2013
}

@ARTICLE{Gu2024-lo,
  title     = "Enhancing social participation of older adults to promote Active
               Ageing in high-density urban communities: A case study of Tseung
               Kwan {O}, Hong Kong",
  author    = "Gu, Chenxuan and Chan, Sylvia Man Ha and van Ameijde, Jeroen",
  journal   = "U\&U10",
  publisher = "Hong Kong Institute of Urban Design Limited",
  abstract  = "Ongoing urbanisation and ageing populations pose multifaceted
               challenges, particularly in high-density cities such as Hong
               Kong. As the concepts of “Ageing in Place” and “Active Ageing”
               become more prevalent globally, the role of public spaces in
               providing social opportunities for older people is more widely
               discussed. This study has examined how public space features
               influence the activities and experiences of older adults in
               high-density urban communities. The research focused on the role
               of the built environment in active ageing, the levels and needs
               of social participation among older adults, and the impact of
               public space features on the social participation of older
               adults. Through precedent studies, the study identified
               age-friendly practices around the world to create an integrated
               framework for the evaluation of the needs for public spaces in
               the context of Active Ageing. Based on this framework, the
               project examined the Po Lam and Kin Ming Public Housing Estates
               in Tseung Kwan O, Hong Kong, through field observations and
               interviews with older residents. The research has identified key
               factors influencing the social participation of older adults in
               high-density urban areas, including pleasant and clean
               environments, community facilities, places supporting social
               interaction, access to nature, and accessibility. The paper
               concludes with urban design and planning recommendations for
               promoting the social participation of older adults in Hong Kong.
               Ultimately, this work contributes to the creation of more
               age-friendly environments that support social and psychological
               well-being.",
  month     =  aug,
  year      =  2024
}

@BOOK{Brown2009-tz,
  title     = "Change by design: How design thinking transforms organizations
               and inspires innovation",
  author    = "Brown, Tim",
  publisher = "HarperCollins eBooks",
  month     =  sep,
  year      =  2009,
  language  = "en"
}

@MISC{Barrar2024-sb,
  title        = "How Jacob Collier helped shape the new {MusicFX} {DJ}",
  author       = "Barrar, Jamie",
  booktitle    = "Google",
  abstract     = "Google Labs worked with Jacob Collier to improve and simplify
                  MusicFX DJ.",
  month        =  oct,
  year         =  2024,
  howpublished = "\url{https://blog.google/technology/ai/jacob-collier-labs-sessions/}",
  note         = "Accessed: 2025-2-25",
  language     = "en"
}

@MISC{UnknownUnknown-lq,
  title        = "The canvas feature is junk : r/{ChatGPT}",
  howpublished = "\url{https://www.reddit.com/r/ChatGPT/comments/1fxiwxr/the\_canvas\_feature\_is\_junk/}",
  note         = "Accessed: 2025-2-25",
  language     = "en"
}

@ARTICLE{Cohen1995-wt,
  title   = "The further exploits of Aaron, painter",
  author  = "Cohen, Harold",
  journal = "Stanford Humanities Review, Volume 4, Issue 2",
  month   =  jul,
  year    =  1995
}

@ARTICLE{Mukherjee2023-gv,
  title     = "Managing the creative frontier of generative {AI}: The
               novelty-usefulness tradeoff",
  author    = "Mukherjee, A and Chang, Hannah H",
  journal   = "California Management Review",
  publisher = "ink.library.smu.edu.sg",
  year      =  2023
}

@ARTICLE{Pascual-Leone2001-lh,
  title     = "The brain that plays music and is changed by it",
  author    = "Pascual-Leone, A",
  journal   = "Ann. N. Y. Acad. Sci.",
  publisher = "Wiley",
  volume    =  930,
  number    =  1,
  pages     = "315--329",
  abstract  = "Playing a musical instrument demands extensive procedural and
               motor learning that results in plastic reorganization of the
               human brain. These plastic changes seem to include the rapid
               unmasking of existing connections and the establishment of new
               ones. Therefore, both functional and structural changes take
               place in the brain of instrumentalists as they learn to cope with
               the demands of their activity. Neuroimaging techniques allow
               documentation of these plastic changes in the human brain. These
               plastic changes are fundamental to the accomplishment of skillful
               playing, but they pose a risk for the development of motor
               control dysfunctions that may give rise to overuse syndromes and
               focal, task-specific dystonia.",
  month     =  jun,
  year      =  2001,
  keywords  = "Brain plasticity; Musical training",
  language  = "en"
}

@MISC{Schaad2025-ca,
  title     = "{AI} Interfaces Of The Future | Design Review",
  author    = "Schaad, Raphael",
  publisher = "Youtube",
  abstract  = "AI is dramatically changing the way we interact with software. So
               for this episode of Design Review, YC General Partner Aaron
               Epstein sat down with Raphael S...",
  month     =  feb,
  year      =  2025,
  keywords  = "YC; Y Combinator"
}

@ARTICLE{Saunders2015-ao,
  title     = "Computational Social Creativity",
  author    = "Saunders, Rob and Bown, O",
  journal   = "Artif. Life",
  publisher = "ieeexplore.ieee.org",
  volume    =  21,
  pages     = "366--378",
  abstract  = "This article reviews the development of computational models of
               creativity where social interactions are central. We refer to
               this area as computational social creativity. Its context is
               described, including the broader study of creativity, the
               computational modeling of other social phenomena, and
               computational models of individual creativity. Computational
               modeling has been applied to a number of areas of social
               creativity and has the potential to contribute to our
               understanding of creativity. A number of requirements for
               computational models of social creativity are common in
               artificial life and computational social science simulations.
               Three key themes are identified: (1) computational social
               creativity research has a critical role to play in understanding
               creativity as a social phenomenon and advancing computational
               creativity by making clear epistemological contributions in ways
               that would be challenging for other approaches; (2) the
               methodologies developed in artificial life and computational
               social science carry over directly to computational social
               creativity; and (3) the combination of computational social
               creativity with individual models of creativity presents
               significant opportunities and poses interesting challenges for
               the development of integrated models of creativity that have yet
               to be realized.",
  month     =  aug,
  year      =  2015
}

@ARTICLE{Riedl2006-dm,
  title     = "Story planning as exploratory creativity: Techniques for
               expanding the narrative search space",
  author    = "Riedl, Mark O and Young, R Michael",
  journal   = "New Gener. Comput.",
  publisher = "Springer Science and Business Media LLC",
  volume    =  24,
  number    =  3,
  pages     = "303--323",
  abstract  = "The authoring of fictional stories is considered a creative
               process. The purpose of most story authoring is not to invent a
               new style or genre of story that will be accepted by the
               population but to invent a single narrative that is novel enough
               to be tellable. Computational story generation systems are more
               limited than human authors in the space of narratives that can be
               considered because it is often the case that story generation
               systems are constrained to operate within a fixed representation
               of the story world. These limitations can impact whether a story
               generation system is considered creative or not. In this paper,
               we describe a story planning system, Fabulist. Fabulist however
               is constrained by the world model input by the system user. We
               present two algorithms that enable story planning systems such as
               Fabulist to break outside the bounds of the initial world model
               in order to search a larger space of narratives.",
  month     =  sep,
  year      =  2006,
  language  = "en"
}

@ARTICLE{Colton2012-xn,
  title     = "Full-{FACE} Poetry Generation",
  author    = "Colton, S and Goodwin, J and Veale, T",
  journal   = "Int Conf Control Commun Comput India",
  publisher = "researchgate.net",
  pages     = "95--102",
  abstract  = "We describe a corpus-based poetry generation system which uses
               templates to construct poems according to given constraints on
               rhyme, meter, stress, sentiment, word frequency and word
               similarity. Moreover, the software constructs a mood for the day
               by analysing newspaper articles; uses this to determine both an
               article to base a poem on and a template for the poem; creates an
               aesthetic based on relevance to the article, lyricism, sentiment
               and flamboyancy; searches for an instantiation of the template
               which maximises the aesthetic; and provides a commentary for the
               whole process to add value to the creative act. We describe the
               processes behind this approach, present some experimental results
               which helped infine tuning, and provide some illustrative poems
               and commentaries. We argue that this is the first poetry system
               which generates examples, forms concepts, invents aesthetics and
               frames its work, and so can be assessed favourably with respect
               to the FACE model for comparing creative systems.",
  year      =  2012
}

@ARTICLE{PeaseUnknown-en,
  author    = "Pease, A and Colton, S",
  publisher = "researchgate.net"
}

@MISC{Osmani2024-br,
  title        = "The 70\% problem: Hard truths about {AI}-assisted coding",
  author       = "Osmani, Addy",
  booktitle    = "Elevate",
  abstract     = "A field guide and why we need to rethink our expectations",
  month        =  dec,
  year         =  2024,
  howpublished = "\url{https://addyo.substack.com/p/the-70-problem-hard-truths-about}",
  note         = "Accessed: 2025-3-7",
  language     = "en"
}

@ARTICLE{Moruzzi2022-tx,
  title    = "The (Artificial) Physicality of Creativity: How Embodiment
              Influences Perceptions of Creativity",
  author   = "Moruzzi, Caterina",
  pages    = "78--86",
  abstract = "The generation of artifacts through computational creativity (CC)
              systems is hitting the headlines with increasing frequency.
              Although impressive, this paper will not focus on the outcomes
              achieved by these systems, but rather on a specific dimension of
              artistic processes: embodiment. I discuss the results of a recent
              factorial survey study aimed at testing the influence that
              embodiment has on the evaluation of creativity. These findings
              show that the physical dimension of artificial systems interacting
              with human artists contributes to the perception of the interplay
              between artificial and human agents as a creative collaboration. I
              propose that a closer study of the dynamics of interaction between
              embodied machines, human artists, and the public can facilitate
              progress in both the artistic and the technology sector.",
  month    =  jun,
  year     =  2022
}

@ARTICLE{Moruzzi2020-bb,
  title   = "Should human artists fear {AI}? A report on the perception of
             creative {AI}",
  author  = "Moruzzi, Caterina",
  journal = "Proceedings of xCoAx2020",
  pages   = "170--185",
  year    =  2020
}

@ARTICLE{Guilford1967-sj,
  title     = "Creativity: Yesterday, today and tomorrow",
  author    = "Guilford, J P",
  journal   = "J. Creat. Behav.",
  publisher = "Wiley",
  volume    =  1,
  number    =  1,
  pages     = "3--14",
  abstract  = "ABSTRACT Nineteenth century science neglected creativity, and the
               limited twentieth century approach (to 1950) was largely
               anecdotal. Recently, research has multiplied, although it has
               involved little experimental hypothesis testing. Creativity
               comprises many discrete abilities which often do not correlate
               very much with each other, and creativity and IQ correlate
               substantially only at lower IQ levels. Much work has been done in
               developing evaluative criteria for creative scientific
               production, and on teaching and learning creativity. Future basic
               research should concern transfer recall, transformations,
               reclassification, elaboration, incubation, environmental
               conditions, and motivation. The social consequences of releasing
               creative abilities are potentially enormous.",
  month     =  jan,
  year      =  1967,
  language  = "en"
}

@ARTICLE{Guilford1956-kt,
  title     = "The structure of intellect",
  author    = "Guilford, J",
  journal   = "Psychol. Bull.",
  publisher = "psycnet.apa.org",
  volume    =  53,
  number    =  4,
  pages     = "267--293",
  month     =  jul,
  year      =  1956
}

@INCOLLECTION{Guilford1961-rf,
  title     = "Three faces of intellect",
  author    = "Guilford, J P",
  editor    = "Jenkins, James J",
  booktitle = "Studies in individual differences: The search for intelligence",
  publisher = "Appleton-Century-Crofts",
  address   = "East Norwalk",
  volume    =  774,
  pages     = "756--774",
  year      =  1961,
  language  = "en"
}

@INCOLLECTION{Csikszentmihalyi2014-cq,
  title     = "Creativity and genius: A systems perspective",
  author    = "Csikszentmihalyi, Mihaly",
  booktitle = "The Systems Model of Creativity",
  publisher = "Springer Netherlands",
  address   = "Dordrecht",
  pages     = "99--125",
  year      =  2014
}

@BOOK{Csikszentmihalyi2015-rq,
  title     = "The systems model of creativity: The collected works of Mihaly
               Csikszentmihalyi",
  author    = "Csikszentmihalyi, Mihaly",
  publisher = "Springer",
  address   = "Dordrecht, Netherlands",
  edition   =  2014,
  month     =  jan,
  year      =  2015,
  language  = "en"
}

@ARTICLE{Csikszentmihalyi1988-pg,
  title     = "Motivation and creativity: Toward a synthesis of structural and
               energistic approaches to cognition",
  author    = "Csíkszentmihályi, M",
  journal   = "New Ideas in Psychology",
  publisher = "Elsevier",
  volume    =  6,
  pages     = "159--176",
  year      =  1988
}

@BOOK{Csikszentmihalyi1996-qq,
  title     = "Creativity: Flow and the psychology of discovery and",
  author    = "Csikszentmihalyi, Mihaly",
  publisher = "HarperCollins eBooks",
  abstract  = "Read 370 reviews from the world’s largest community for readers.
               Creativity is about capturing those moments that make life worth
               living. The author's obj…",
  series    = "Harper Perennial Modern Classics",
  year      =  1996,
  language  = "en"
}

@ARTICLE{Perez-y-Perez1999-ma,
  title  = "{MEXICA}: a computer model of creativity in writing",
  author = "Pérez y Pérez, Rafael",
  year   =  1999
}

@MISC{Miller2020-dq,
  title        = "{DeepDream}: How Alexander Mordvintsev Excavated the
                  Computer’s Hidden Layers",
  author       = "Miller, Arthur",
  booktitle    = "The MIT Press Reader",
  abstract     = "A Google researcher looks into the mind of a computer.",
  month        =  jul,
  year         =  2020,
  howpublished = "\url{https://thereader.mitpress.mit.edu/deepdream-how-alexander-mordvintsev-excavated-the-computers-hidden-layers/}",
  note         = "Accessed: 2025-3-12",
  language     = "en"
}

@ARTICLE{Rayner2016-wx,
  title     = "Can Google’s Deep Dream become an art machine?",
  author    = "Rayner, Alex",
  journal   = "The Guardian",
  publisher = "The Guardian",
  abstract  = "The company’s neural network has created a slew of beautiful and
               at times terrifying images, and is being harnessed to create
               unique artwork",
  month     =  mar,
  year      =  2016
}

@MISC{Campbell-Dollaghan2016-wd,
  title        = "Inside Google's First {DeepDream} Art Show",
  author       = "Campbell-Dollaghan, Kelsey",
  booktitle    = "Fast Company",
  abstract     = "An exhibition about neural networking unpacks the esoteric
                  world of artificial intelligence.",
  month        =  mar,
  year         =  2016,
  howpublished = "\url{https://www.fastcompany.com/3057368/inside-googles-first-deepdream-art-show}",
  note         = "Accessed: 2025-3-12",
  language     = "en"
}

@MISC{Mordvintsev2015-si,
  title        = "Inceptionism: Going Deeper into Neural Networks",
  author       = "Mordvintsev, Alexander and Olah, Christopher and Tyka, Mike",
  abstract     = "Posted by Alexander Mordvintsev, Software Engineer,
                  Christopher Olah, Software Engineering Intern and Mike Tyka,
                  Software EngineerUpdate - 13/07/20...",
  year         =  2015,
  howpublished = "\url{https://research.google/blog/inceptionism-going-deeper-into-neural-networks/}",
  note         = "Accessed: 2025-3-12",
  language     = "en"
}

@MISC{Machine2019-cg,
  title        = "How Brian Eno Created ``Ambient 1: Music For Airports''",
  author       = "Machine, Reverb",
  booktitle    = "Reverb Machine",
  abstract     = "In 1978, Brian Eno released Ambient 1: Music for Airports, a
                  landmark album in ambient and electronic music. Although it
                  wasn't the first ambient",
  month        =  jul,
  year         =  2019,
  howpublished = "\url{https://reverbmachine.com/blog/deconstructing-brian-eno-music-for-airports/}",
  note         = "Accessed: 2025-3-26",
  language     = "en"
}

@MISC{Brian1996-tj,
  title        = "Generative Music",
  author       = "Brian, Eno",
  booktitle    = "InMotion Magazine",
  year         =  1996,
  howpublished = "\url{https://www.inmotionmagazine.com/eno1.html}",
  note         = "Accessed: 2025-3-26"
}

@ARTICLE{Adams2010-dk,
  title     = "David Cope: 'You pushed the button and out came hundreds and
               thousands of sonatas'",
  author    = "Adams, Tim",
  journal   = "The Guardian",
  publisher = "The Guardian",
  abstract  = "Tim Adams meets composer David Cope, who has spent the last 30
               years teaching computers to create classical music",
  month     =  jul,
  year      =  2010
}

@ARTICLE{Abel2025-dj,
  title    = "People say they prefer stories written by humans over
              {AI}-generated works, yet new study suggests that’s not quite true",
  author   = "Abel, Martin and Johnson, Reed",
  journal  = "The Conversation",
  abstract = "Participants in a study were willing to spend just as much time
              and money on an AI-generated story as one they were told was
              written by a human.",
  month    =  mar,
  year     =  2025,
  language = "en"
}

@ARTICLE{Hofstadter1995-sn,
  title     = "Fluid concepts and creative analogies: Computer models of the
               fundamental mechanisms of thought",
  author    = "Hofstadter, D R",
  publisher = "Basic books",
  year      =  1995
}

@ARTICLE{Minsky1961-bj,
  title     = "Steps toward artificial intelligence",
  author    = "Minsky, Marvin",
  journal   = "Proc. IRE",
  publisher = "Institute of Electrical and Electronics Engineers (IEEE)",
  volume    =  49,
  number    =  1,
  pages     = "8--30",
  abstract  = "The problems of heuristic programming-of making computers solve
               really difficult problems-are divided into five main areas:
               Search, Pattern-Recognition, Learning, Planning, and Induction. A
               computer can do, in a sense, only what it is told to do. But even
               when we do not know how to solve a certain problem, we may
               program a machine (computer) to Search through some large space
               of solution attempts. Unfortunately, this usually leads to an
               enormously inefficient process. With Pattern-Recognition
               techniques, efficiency can often be improved, by restricting the
               application of the machine's methods to appropriate problems.
               Pattern-Recognition, together with Learning, can be used to
               exploit generalizations based on accumulated experience, further
               reducing search. By analyzing the situation, using Planning
               methods, we may obtain a fundamental improvement by replacing the
               given search with a much smaller, more appropriate exploration.
               To manage broad classes of problems, machines will need to
               construct models of their environments, using some scheme for
               Induction. Wherever appropriate, the discussion is supported by
               extensive citation of the literature and by descriptions of a few
               of the most successful heuristic (problem-solving) programs
               constructed to date.",
  month     =  jan,
  year      =  1961,
  language  = "en"
}

@ARTICLE{Colton2015-qr,
  title    = "The Painting Fool Sees! New Projects with the Automated Painter",
  author   = "Colton, Simon and Halskov, Jakob and Ventura, Dan and Gouldstone,
              Ian and Cook, Michael and Ferrer, Blanca Pérez",
  pages    = "189--196",
  abstract = "In The Painting Fool project, we aim to build an automated painter
              which is taken seriously as a creative artist in its own right,
              one day. We report here the most recent advances, where we have
              integrated machine vision capabilities from the DARCI system into
              The Painting Fool, to enhance its abilities before, during and
              after the painting process. These advances have enabled new art
              projects, including a commission from an Artificial Intelligence
              company, and we report on this collaboration, which is one of the
              first instances in Computational Creativity research where
              creative software has been commissioned directly. The new projects
              have advanced The Painting Fool as an independent artist able to
              produce more diverse styles which break away from simulating
              natural media. The projects have also raised a philosophical
              question about whether software artists need to see in the same
              way as people, which we briefly discuss.",
  month    =  jun,
  year     =  2015
}

@ARTICLE{Perez-y-Perez2023-ws,
  title     = "An introduction to narrative generators: how computers create
               works of fiction",
  author    = "Pérez y Pérez, Rafael and Sharples, Mike",
  publisher = "Oxford University Press",
  abstract  = "This book describes how computer programs can generate narratives
               and how studies of computational narrative can illuminate how
               humans tell stories. It is designed for readers with little or no
               background in computer science but who are interested in
               understanding the core processes underlying AI systems. We refer
               to this phenomenon as the AI knowledge gap. This book contributes
               to filling the AI knowledge gap in the field of automatic
               narrative generation and to enhancing the dissemination of
               information about automatic storytelling. The book introduces the
               most relevant techniques employed over the last 60 years for the
               development of computer models for narrative generation,
               avoiding, as much as possible, the use of technical language. The
               techniques studied are narrative templates, problem-solving,
               planning, author engagement and reflection, and statistical
               methods such as deep neural networks. Throughout the book, we
               offer introductions to relevant concepts related to automatic
               storytelling, followed by descriptions of well-known computer
               programs that illustrate how such concepts are employed. The book
               compares ways that researchers have characterised the automatic
               generation of narratives and covers the core properties that
               distinguish this area of knowledge. In the final chapter, we
               reflect on some of the implications for society from the
               development of automatic narrative generator systems",
  year      =  2023
}

@ARTICLE{Hochreiter1997-eu,
  title     = "Long short-term memory",
  author    = "Hochreiter, S and Schmidhuber, J",
  journal   = "Neural Comput.",
  publisher = "MIT Press - Journals",
  volume    =  9,
  number    =  8,
  pages     = "1735--1780",
  abstract  = "Learning to store information over extended time intervals by
               recurrent backpropagation takes a very long time, mostly because
               of insufficient, decaying error backflow. We briefly review
               Hochreiter's (1991) analysis of this problem, then address it by
               introducing a novel, efficient, gradient-based method called long
               short-term memory (LSTM). Truncating the gradient where this does
               not do harm, LSTM can learn to bridge minimal time lags in excess
               of 1000 discrete-time steps by enforcing constant error flow
               through constant error carousels within special units.
               Multiplicative gate units learn to open and close access to the
               constant error flow. LSTM is local in space and time; its
               computational complexity per time step and weight is O(1). Our
               experiments with artificial data involve local, distributed,
               real-valued, and noisy pattern representations. In comparisons
               with real-time recurrent learning, back propagation through time,
               recurrent cascade correlation, Elman nets, and neural sequence
               chunking, LSTM leads to many more successful runs, and learns
               much faster. LSTM also solves complex, artificial long-time-lag
               tasks that have never been solved by previous recurrent network
               algorithms.",
  month     =  nov,
  year      =  1997,
  language  = "en"
}

@BOOK{Cope2000-cq,
  title     = "The Algorithmic Composer",
  author    = "Cope, David",
  publisher = "A-R Editions",
  address   = "Middleton, WI",
  series    = "Computer Music and Digital Audio Series",
  month     =  jun,
  year      =  2000
}

@ARTICLE{Cope1992-pq,
  title     = "Computer Modeling of Musical Intelligence in {EMI}",
  author    = "Cope, D",
  journal   = "Computer Music Journal",
  publisher = "JSTOR",
  volume    =  16,
  pages     =  69,
  abstract  = "Musical intelligence may be defined as the ``simulation of
               musical thinking.'' The algorithm presented in this article
               reflects the author's approach to music composition and hence
               represents one ``simulation of musical thinking.''
               Implementations of this algorithm create new compositions by way
               of a reflexive pattern-matcher combined with an augmented
               transition network (ATN). This subprogram of the Experiments in
               Musical Intelligence (EMI) software package requires only that it
               be loaded with music in a given style. Although the entire code
               of the EMI program is not provided here, the algorithm in Fig. 1
               and the respective code, as well as the ideas presented in the
               books and articles by the author listed in the References, should
               serve as a useful introduction to the EMI program. While music
               naturally includes timbre, dynamics, performance practice
               (Dannenberg 1989), and so on, research with EMI has thus far
               focused exclusively on pitch and duration. This is not meant to
               denigrate other areas of possible study. However, this limitation
               confines the research to a reasonable",
  month     =  jan,
  year      =  1992
}

@BOOK{Suchman1987-fs,
  title     = "Plans and situated actions: The problem of human-machine
               communication",
  author    = "Suchman, Lucy A",
  publisher = "Cambridge University Press",
  address   = "Cambridge, England",
  edition   =  2,
  month     =  nov,
  year      =  1987
}

@ARTICLE{Noy2023-ao,
  title    = "Experimental evidence on the productivity effects of generative
              artificial intelligence",
  author   = "Noy, Shakked and Zhang, Whitney",
  journal  = "Science",
  volume   =  381,
  number   =  6654,
  pages    = "187--192",
  abstract = "We examined the productivity effects of a generative artificial
              intelligence (AI) technology, the assistive chatbot ChatGPT, in
              the context of midlevel professional writing tasks. In a
              preregistered online experiment, we assigned occupation-specific,
              incentivized writing tasks to 453 college-educated professionals
              and randomly exposed half of them to ChatGPT. Our results show
              that ChatGPT substantially raised productivity: The average time
              taken decreased by 40\% and output quality rose by 18\%.
              Inequality between workers decreased, and concern and excitement
              about AI temporarily rose. Workers exposed to ChatGPT during the
              experiment were 2 times as likely to report using it in their real
              job 2 weeks after the experiment and 1.6 times as likely 2 months
              after the experiment.",
  month    =  jul,
  year     =  2023,
  language = "en"
}

@ARTICLE{Hayes1983-ca,
  title     = "Steps toward graceful interaction in spoken and written
               man-machine communication",
  author    = "Hayes, Philip J and Reddy, D Raj",
  journal   = "Int. J. Man. Mach. Stud.",
  publisher = "Elsevier BV",
  volume    =  19,
  number    =  3,
  pages     = "231--284",
  abstract  = "Natural language processing is often seen as a way to provide
               easy-to-use and flexible interfaces to interactive computer
               systems. White natural language interfaces typically perform well
               in response to straightforward requests and questions within
               their domain of discourse, they often fail to interact gracefully
               with their users in less predictable circumstances. Most current
               systems cannot, for instance: respond reasonably to input not
               conforming to a rigid grammar; ask for and understand
               clarification if their user's input is unclear; offer
               clarification of their own output if the user asks for it; or
               interact to resolve any ambiguities that may arise when the user
               attempts to describe things to the system.We believe that
               graceful interaction in these and the many other contingencies
               that can arise in human conversation is essential if interfaces
               are ever to appear co-operative and helpful, and hence be
               suitable for the casual or naive user, and more habitable for the
               experienced user. In this paper, we attempt to outline key
               components of graceful interaction, to identify major problems
               involved in realizing them, and in some cases to suggest the
               shape of solutions.To this end we propose a decomposition of
               graceful interaction into a number of relatively independent
               skills: skills involved in parsing elliptical, fragmented, and
               otherwise ungrammatical input; in ensuring robust communication;
               in explaining abilities and limitations, actions and the motives
               behind them; in keeping track of the focus of attention of a
               dialogue; in identifying things from descriptions, even if
               ambiguous or unsatisfiable; and in describing things in terms
               appropriate for the context. We suggest these skills are
               necessary for graceful interaction in general and form a good
               working basis for graceful interaction in a certain large class
               of application domains, which we define. None of these components
               appear individually much beyond the current state of the art, at
               least for suitably restricted domains of discourse. Thus, we
               advocate research into the construction of gracefully interacting
               systems as an activity likely to pay major dividends in improved
               man-machine communication in a relatively short time.",
  month     =  sep,
  year      =  1983,
  language  = "en"
}

@ARTICLE{March1991-nz,
  title     = "Exploration and exploitation in organizational learning",
  author    = "March, James G",
  journal   = "Organ. Sci.",
  publisher = "Institute for Operations Research and the Management Sciences
               (INFORMS)",
  volume    =  2,
  number    =  1,
  pages     = "71--87",
  abstract  = "This paper considers the relation between the exploration of new
               possibilities and the exploitation of old certainties in
               organizational learning. It examines some complications in
               allocating resources between the two, particularly those
               introduced by the distribution of costs and benefits across time
               and space, and the effects of ecological interaction. Two general
               situations involving the development and use of knowledge in
               organizations are modeled. The first is the case of mutual
               learning between members of an organization and an organizational
               code. The second is the case of learning and competitive
               advantage in competition for primacy. The paper develops an
               argument that adaptive processes, by refining exploitation more
               rapidly than exploration, are likely to become effective in the
               short run but self-destructive in the long run. The possibility
               that certain common organizational practices ameliorate that
               tendency is assessed.",
  month     =  feb,
  year      =  1991,
  language  = "en"
}

@ARTICLE{Greene1974-rf,
  title     = "Effects of extrinsic rewards on children's subsequent intrinsic
               interest",
  author    = "Greene, D and Lepper, M",
  journal   = "Child Dev.",
  publisher = "JSTOR",
  volume    =  45,
  number    =  4,
  pages     = "1141--1145",
  abstract  = "GREENE, DAVID, and LEPPER, MARK R. Effects of Extrinsic Rewards
               on Children's Subsequent Intrinsic Interest. CHILD DEVELOPMENT,
               1974, 45, 1141-1145. Preschool children were asked, in individual
               sessions, to engage in an activity of high initial interest,
               either for its own sake or in order to obtain an extrinsic
               reward. Subsequently, children who had undertaken the target
               activity as a means to some ulterior end showed less intrinsic
               interest in this activity, as measured unobtrusively several
               weeks later in the children's classrooms, than control subjects
               who had either received the same reward unexpectedly or had
               engaged in the activity without expectation or receipt of
               extrinsic rewards.",
  month     =  dec,
  year      =  1974
}

@ARTICLE{Templeton2024-jm,
  title   = "Scaling Monosemanticity: Extracting Interpretable Features from
             Claude 3 Sonnet",
  author  = "Templeton, Adly and Conerly, Tom and Marcus, Jonathan and Lindsey,
             Jack and Bricken, Trenton and Chen, Brian and Pearce, Adam and
             Citro, Craig and Ameisen, Emmanuel and Jones, Andy and Cunningham,
             Hoagy and Turner, Nicholas L and McDougall, Callum and MacDiarmid,
             Monte and Freeman, C Daniel and Sumers, Theodore R and Rees, Edward
             and Batson, Joshua and Jermyn, Adam and Carter, Shan and Olah,
             Chris and Henighan, Tom",
  journal = "Transformer Circuits Thread",
  year    =  2024
}

@ARTICLE{Sawyer2007-rw,
  title     = "Group genius : the creative power of collaboration",
  author    = "Sawyer, R",
  journal   = "xiii",
  publisher = "Basic Books Group genius",
  volume    =  274,
  year      =  2007
}

@ARTICLE{Ganuthula2024-wg,
  title    = "The paradox of augmentation: A theoretical model of {AI}-induced
              skill atrophy",
  author   = "Ganuthula, Venkat Ram Reddy",
  journal  = "Social Science Research Network",
  abstract = "This paper presents the ``Paradox of Augmentation,'' a theoretical
              framework that seeks to model the im",
  month    =  oct,
  year     =  2024,
  keywords = "artificial intelligence, skill, augmentation, human capital"
}

@MISC{UnknownUnknown-md,
  title        = "Black Forest Labs - Frontier {AI} Lab",
  abstract     = "Amazing AI models from the Black Forest.",
  howpublished = "\url{https://blackforestlabs.ai/}",
  note         = "Accessed: 2025-6-9",
  language     = "en"
}

@INCOLLECTION{Bown2011-zp,
  title     = "Creative agency: A clearer goal for artificial life in the arts",
  author    = "Bown, Oliver and McCormack, Jon",
  booktitle = "Advances in Artificial Life. Darwin Meets von Neumann",
  publisher = "Springer Berlin Heidelberg",
  address   = "Berlin, Heidelberg",
  pages     = "254--261",
  series    = "Lecture notes in computer science",
  year      =  2011
}

@INCOLLECTION{Norman1986-kg,
  title     = "Cognitive Engineering",
  author    = "Norman, Donald A",
  booktitle = "User Centered System Design",
  publisher = "CRC Press",
  address   = "Boca Raton",
  pages     = "31--62",
  month     =  jan,
  year      =  1986
}

@BOOK{Csikszentmihalyi1997-ui,
  title     = "Creativity: Flow and the psychology of discovery and invention",
  author    = "Csikszentmihalyi, Mihaly",
  publisher = "HarperCollins Publishers Creativity",
  volume    =  456,
  year      =  1997
}

@ARTICLE{Rappaport1988-yg,
  title     = "Cognitive primitives",
  author    = "Rappaport, Alain T",
  journal   = "Int. J. Man. Mach. Stud.",
  publisher = "Elsevier BV",
  volume    =  29,
  number    =  6,
  pages     = "733--747",
  abstract  = "This paper addresses the problem of the level of abstraction at
               which knowledge-based system computational primitives must be
               developed so as to facilitate the knowledge acquisition process.
               Low-level programming or the use of task-level methodologies as
               they exist now, respectively prevent rapid learning and
               develop-ment and lock the knowledge designer in rigid
               problem-solving paradigms. We explore the principles underlying
               the design of a compromise-level set of primitives called
               cognitive primitives. They are domain and task-independent
               computational primitives which can be used to map an expert's
               behaviour into an artificial formalism and integrate it in
               existing environments. Flexible task- or domain-level functions
               can emerge from working with these primitives. Examples are
               presented of the design and use of this computational approach.
               This new approach leads to the design of tools whose functions
               more closely match human expert knowledge, which is difficult to
               decompile and thus to represent in more classic formalisms.",
  month     =  jan,
  year      =  1988,
  language  = "en"
}

@ARTICLE{Adams2025-cx,
  title     = "Essex man who used {AI} to create deepfake pornography is jailed",
  author    = "Adams, Lewis",
  journal   = "BBC",
  publisher = "BBC News",
  abstract  = "A judge says Brandon Tyler shows ``the worst kind of toxic
               masculinity'' in his offending.",
  month     =  apr,
  year      =  2025
}

@MISC{Kavukcuoglu2025-kb,
  title        = "Gemini 2.0 is now available to everyone",
  author       = "Kavukcuoglu, Koray",
  booktitle    = "Google",
  abstract     = "We’re announcing new updates to Gemini 2.0 Flash, plus
                  introducing Gemini 2.0 Flash-Lite and Gemini 2.0 Pro
                  Experimental.",
  month        =  feb,
  year         =  2025,
  howpublished = "\url{https://blog.google/technology/google-deepmind/gemini-model-updates-february-2025/}",
  note         = "Accessed: 2025-6-8",
  language     = "en"
}

@INBOOK{Schlosser2019-jk,
  title     = "Agency",
  author    = "Schlosser, Markus",
  editor    = "Zalta, Edward N",
  booktitle = "The Stanford Encyclopedia of Philosophy",
  publisher = "Metaphysics Research Lab, Stanford University",
  edition   = "Winter 2019",
  year      =  2019
}

@TECHREPORT{US-Copyright-Office-Review-Board2023-nw,
  title       = "Second Request for Reconsideration for Refusal to Register
                 Théâtre {D}'opéra Spatial ({SR} \#1-11743923581; Correspondence
                 {ID}: 1-{5T5320R})",
  author      = "{U.S. Copyright Office Review Board}",
  institution = "United States Copyright Office",
  address     = "Washington, DC",
  month       =  sep,
  year        =  2023
}

@MISC{OpenAI2025-wr,
  title        = "Sycophancy in {GPT}-{4o}: what happened and what we’re doing
                  about it",
  author       = "{OpenAI}",
  booktitle    = "OpenAI Blog",
  abstract     = "We have rolled back last week’s GPT‑4o update in ChatGPT so
                  people are now using an earlier version with more balanced
                  behavior. The update we removed was overly flattering or
                  agreeable—often described as sycophantic.",
  year         =  2025,
  howpublished = "\url{https://openai.com/index/sycophancy-in-gpt-4o/}",
  note         = "Accessed: 2025-6-13",
  language     = "en"
}

@MISC{Unknown2025-wl,
  title        = "Australian Cybernetic: A point through time",
  booktitle    = "ANU School of Cybernetics",
  abstract     = "Australian Cybernetic: a point through time assembled a story
                  about futures, and about how we dream up the blueprints that
                  shape us and that propel us into ways of thinking and being.",
  month        =  jun,
  year         =  2025,
  howpublished = "\url{https://cybernetics.anu.edu.au/futures/australian-cybernetic/}",
  note         = "Accessed: 2025-6-14",
  language     = "en"
}

@BOOK{Vear2024-aq,
  title     = "The Routledge international handbook of practice-based research",
  editor    = "Vear, Craig",
  publisher = "Routledge",
  address   = "London, England",
  month     =  oct,
  year      =  2024,
  language  = "en"
}

@BOOK{Vear2021-cx,
  title     = "The Routledge international handbook of practice-based research",
  author    = "Vear, Craig and Candy, Linda and Edmonds, Ernest",
  publisher = "Routledge",
  address   = "London",
  month     =  nov,
  year      =  2021
}

@BOOK{Marmor1997-ka,
  title     = "The eye of the artist",
  author    = "Marmor, Michael F and Ravin, J G",
  publisher = "Mosby",
  address   = "London, England",
  month     =  jan,
  year      =  1997
}

@BOOK{Robinson1896-mo,
  title     = "The Elements of a Pictorial Photograph",
  author    = "Robinson, Henry Peach",
  publisher = "Lund",
  year      =  1896
}

@ARTICLE{Rezwana2023-rt,
  title    = "Towards designing engaging and ethical human-centered {AI}
              partners for human-{AI} co-creativity",
  author   = "Rezwana, Jeba",
  abstract = "Human-AI co-creativity involves a human and an AI collaborating as
              partners on creative tasks such as generating music or art. This
              research domain is particularly timely as AI becomes increasingly
              prevalent in collaborative spaces. With the availability of
              ChatGPT, DALL. E 2 and other generative AI tools, co-creative AI
              is gaining popularity. Unlike general human-computer interaction,
              human-AI co-creation establishes a complex relationship where AI
              actively contributes, assumes human-like roles, and generates
              novel content blended with the user's contribution. Therefore,
              designing engaging and ethical co-creative systems poses
              challenges due to the open-ended nature of human-AI interaction.
              This dissertation contributes empirically and theoretically to the
              design of engaging and ethical human-centered co-creative AI. It
              focuses on four main areas: designing interaction, the impact of
              AI-to-human …",
  year     =  2023
}

@ARTICLE{Sohl-Dickstein2015-sm,
  title         = "Deep Unsupervised Learning using Nonequilibrium
                   Thermodynamics",
  author        = "Sohl-Dickstein, Jascha and Weiss, Eric A and Maheswaranathan,
                   Niru and Ganguli, Surya",
  journal       = "arXiv [cs.LG]",
  abstract      = "A central problem in machine learning involves modeling
                   complex data-sets using highly flexible families of
                   probability distributions in which learning, sampling,
                   inference, and evaluation are still analytically or
                   computationally tractable. Here, we develop an approach that
                   simultaneously achieves both flexibility and tractability.
                   The essential idea, inspired by non-equilibrium statistical
                   physics, is to systematically and slowly destroy structure in
                   a data distribution through an iterative forward diffusion
                   process. We then learn a reverse diffusion process that
                   restores structure in data, yielding a highly flexible and
                   tractable generative model of the data. This approach allows
                   us to rapidly learn, sample from, and evaluate probabilities
                   in deep generative models with thousands of layers or time
                   steps, as well as to compute conditional and posterior
                   probabilities under the learned model. We additionally
                   release an open source reference implementation of the
                   algorithm.",
  month         =  mar,
  year          =  2015,
  archivePrefix = "arXiv",
  primaryClass  = "cs.LG"
}

@INPROCEEDINGS{Clark2018-yf,
  title     = "Creative writing with a machine in the loop",
  author    = "Clark, Elizabeth and Ross, Anne Spencer and Tan, Chenhao and Ji,
               Yangfeng and Smith, Noah A",
  booktitle = "23rd International Conference on Intelligent User Interfaces",
  publisher = "ACM",
  address   = "New York, NY, USA",
  month     =  mar,
  year      =  2018
}

@MISC{noauthor_undated-og,
  title = "dcai-typ-2023.pdf"
}

@ARTICLE{Bohm2006-vl,
  title     = "Unfolding meaning: A weekend of dialogue with David Bohm",
  author    = "Bohm, D",
  publisher = "api.taylorfrancis.com",
  abstract  = "… In Unfolding Meaning , David Bohm, one of the most provocative
               and original thinkers of our time, argues that there are other
               ways of thinking to bring about a different, more …",
  year      =  2006
}

@MISC{noauthor_undated-qf,
  title = "Deep Learning by Ian Goodfellow, Yoshua Bengio, Aaron Courville
           (z-lib.org).pdf"
}

@INPROCEEDINGS{Fan2019-qq,
  title     = "Collabdraw: An environment for collaborative sketching with an
               artificial agent",
  author    = "Fan, Judith E and Dinculescu, Monica and Ha, David",
  booktitle = "Proceedings of the 2019 on Creativity and Cognition",
  publisher = "ACM",
  address   = "New York, NY, USA",
  month     =  jun,
  year      =  2019
}

@INPROCEEDINGS{Steinfeld2006-qj,
  title     = "Common metrics for human-robot interaction",
  author    = "Steinfeld, Aaron and Fong, Terrence and Kaber, David and Lewis,
               Michael and Scholtz, Jean and Schultz, Alan and Goodrich, Michael",
  booktitle = "Proceedings of the 1st ACM SIGCHI/SIGART conference on
               Human-robot interaction",
  publisher = "Association for Computing Machinery",
  address   = "New York, NY, USA",
  pages     = "33--40",
  abstract  = "This paper describes an effort to identify common metrics for
               task-oriented human-robot interaction (HRI). We begin by
               discussing the need for a toolkit of HRI metrics. We then
               describe the framework of our work and identify important biasing
               factors that must be taken into consideration. Finally, we
               present suggested common metrics for standardization and a case
               study. Preparation of a larger, more detailed toolkit is in
               progress.",
  series    = "HRI '06",
  month     =  mar,
  year      =  2006,
  keywords  = "human-robot interaction, metrics, unmanned ground vehicles"
}

@INPROCEEDINGS{Lawton2023-tb,
  title     = "When is a tool a tool? User perceptions of system agency in
               human–AI co-creative drawing",
  author    = "Lawton, Tomas and Grace, Kazjon and Ibarrola, Francisco J",
  booktitle = "Proceedings of the 2023 ACM Designing Interactive Systems
               Conference",
  publisher = "ACM",
  address   = "New York, NY, USA",
  month     =  jul,
  year      =  2023
}

@ARTICLE{Colton2020-fo,
  title    = "On the Machine Condition and its Creative Expression",
  author   = "Colton, S and Pease, A and Guckelsberger, C and Mccormack, J and
              Llano, M T",
  journal  = "Int Conf Control Commun Comput India",
  pages    = "342--349",
  abstract = "The human condition can be characterised as the most es- sential
              characteristics, events and situations which describe human
              existence. We propose that a parallel discussion of the machine
              condition could improve public understanding of computational
              systems in general, and advance perception of creativity in
              computational creativity systems in particular. We present a
              framework for machines to creatively express their existence,
              sketch some aspects of the machine condition, and describe
              potential beneﬁts of this approach.",
  year     =  2020
}

@ARTICLE{Amershi2014-ro,
  title     = "Power to the people: The role of humans in interactive machine
               learning",
  author    = "Amershi, Saleema and Cakmak, Maya and Knox, William Bradley and
               Kulesza, Todd",
  journal   = "AI Mag.",
  publisher = "Wiley",
  volume    =  35,
  number    =  4,
  pages     = "105--120",
  abstract  = "Intelligent systems that learn interactively from their end-users
               are quickly becoming widespread. Until recently, this progress
               has been fueled mostly by advances in machine learning; however,
               more and more researchers are realizing the importance of
               studying users of these systems. In this article we promote this
               approach and demonstrate how it can result in better user
               experiences and more effective learning systems. We present a
               number of case studies that characterize the impact of
               interactivity, demonstrate ways in which some existing systems
               fail to account for the user, and explore new ways for learning
               systems to interact with their users. We argue that the design
               process for interactive machine learning systems should involve
               users at all stages: explorations that reveal human interaction
               patterns and inspire novel interaction methods, as well as
               refinement stages to tune details of the interface and choose
               among alternatives. After giving a glimpse of the progress that
               has been made so far, we discuss the challenges that we face in
               moving the field forward.",
  month     =  dec,
  year      =  2014,
  language  = "en"
}

@INPROCEEDINGS{Verheijden2023-gn,
  title     = "Collaborative diffusion: Boosting designerly co-creation with
               generative {AI}",
  author    = "Verheijden, Mathias Peter and Funk, Mathias",
  booktitle = "Extended Abstracts of the 2023 CHI Conference on Human Factors in
               Computing Systems",
  publisher = "ACM",
  address   = "New York, NY, USA",
  month     =  apr,
  year      =  2023,
  language  = "en"
}

@ARTICLE{Kim2023-zq,
  title     = "The effect of {AI}-based inspiration on human design ideation",
  author    = "Kim, Jingoog and Maher, Mary Lou",
  journal   = "Int. J. Des. Creat. Innov.",
  publisher = "Informa UK Limited",
  pages     = "1--18",
  month     =  jan,
  year      =  2023,
  language  = "en"
}

@ARTICLE{O-Toole2024-ji,
  title     = "Extending human creativity with {AI}",
  author    = "O'Toole, Katherine and Horvát, Emőke-Ágnes",
  journal   = "Journal of Creativity",
  publisher = "Elsevier BV",
  volume    =  34,
  number    =  2,
  pages     =  100080,
  abstract  = "The development of generative AI has led to novel ways that
               technology can be integrated into creative activities. However,
               this has also raised conce…",
  month     =  aug,
  year      =  2024,
  language  = "en"
}

@ARTICLE{Copet2023-mh,
  title         = "Simple and Controllable Music Generation",
  author        = "Copet, Jade and Kreuk, Felix and Gat, Itai and Remez, Tal and
                   Kant, David and Synnaeve, Gabriel and Adi, Yossi and
                   Défossez, Alexandre",
  journal       = "arXiv [cs.SD]",
  abstract      = "We tackle the task of conditional music generation. We
                   introduce MusicGen, a single Language Model (LM) that
                   operates over several streams of compressed discrete music
                   representation, i.e., tokens. Unlike prior work, MusicGen is
                   comprised of a single-stage transformer LM together with
                   efficient token interleaving patterns, which eliminates the
                   need for cascading several models, e.g., hierarchically or
                   upsampling. Following this approach, we demonstrate how
                   MusicGen can generate high-quality samples, both mono and
                   stereo, while being conditioned on textual description or
                   melodic features, allowing better controls over the generated
                   output. We conduct extensive empirical evaluation,
                   considering both automatic and human studies, showing the
                   proposed approach is superior to the evaluated baselines on a
                   standard text-to-music benchmark. Through ablation studies,
                   we shed light over the importance of each of the components
                   comprising MusicGen. Music samples, code, and models are
                   available at https://github.com/facebookresearch/audiocraft",
  month         =  jun,
  year          =  2023,
  archivePrefix = "arXiv",
  primaryClass  = "cs.SD"
}

@INPROCEEDINGS{Colton2021-bt,
  title  = "Computational Creativity: The Final Frontier?",
  author = "Colton, Simon and Wiggins, Geraint A",
  year   =  2021
}

@MISC{Toner-Rodgers_undated-sk,
  title  = "Artificial Intelligence, Scientific Discovery, and Product
            Innovation",
  author = "Toner-Rodgers, Aidan"
}

@BOOK{Bratton2015-re,
  title     = "The Stack",
  author    = "Bratton, Benjamin",
  publisher = "MIT Press",
  address   = "Cambridge, Mass.",
  series    = "Software Studies",
  year      =  2015
}

@INPROCEEDINGS{Rezwana2022-ui,
  title     = "Understanding user perceptions, collaborative experience and user
               engagement in different human-{AI} interaction designs for
               co-creative systems",
  author    = "Rezwana, Jeba and Maher, Mary Lou",
  booktitle = "Creativity and Cognition",
  publisher = "ACM",
  address   = "New York, NY, USA",
  abstract  = "The study involves user interaction with two prototypes of a
               co-creative system that contributes sketches as design
               inspirations during a design task and shows improved
               collaborative experience and user engagement with the system
               incorporating AI-to-human communication. Human-AI co-creativity
               involves humans and AI collaborating on a shared creative product
               as partners. In a creative collaboration, communication is an
               essential component among collaborators. In many existing
               co-creative systems, users can communicate with the AI, usually
               using buttons or sliders. Typically, the AI in co-creative
               systems cannot communicate back to humans, limiting their
               potential to be perceived as partners rather than just a tool.
               This paper presents a study with 38 participants to explore the
               impact of two interaction designs, with and without AI-to-human
               communication, on user engagement, collaborative experience and
               user perception of a co-creative AI. The study involves user
               interaction with two prototypes of a co-creative system that
               contributes sketches as design inspirations during a design task.
               The results show improved collaborative experience and user
               engagement with the system incorporating AI-to-human
               communication. Users perceive co-creative AI as more reliable,
               personal, and intelligent when the AI communicates to users. The
               findings can be used to design effective co-creative systems, and
               the insights can be transferred to other fields involving
               human-AI interaction and collaboration.",
  month     =  jun,
  year      =  2022,
  language  = "en"
}

@ARTICLE{Rezwana2022-uf,
  title         = "Identifying ethical issues in {AI} partners in human-{AI}
                   co-creation",
  author        = "Rezwana, Jeba and Maher, Mary Lou",
  journal       = "arXiv [cs.HC]",
  abstract      = "Human-AI co-creativity involves humans and AI collaborating
                   on a shared creative product as partners. In many existing
                   co-creative systems, users communicate with the AI using
                   buttons or sliders. However, typically, the AI in co-creative
                   systems cannot communicate back to humans, limiting their
                   potential to be perceived as partners. This paper starts with
                   an overview of a comparative study with 38 participants to
                   explore the impact of AI-to-human communication on user
                   perception and engagement in co-creative systems and the
                   results show improved collaborative experience and user
                   engagement with the system incorporating AI-to-human
                   communication. The results also demonstrate that users
                   perceive co-creative AI as more reliable, personal and
                   intelligent when it can communicate with the users. The
                   results indicate a need to identify potential ethical issues
                   from an engaging communicating co-creative AI. Later in the
                   paper, we present some potential ethical issues in human-AI
                   co-creation and propose to use participatory design fiction
                   as the research methodology to investigate the ethical issues
                   associated with a co-creative AI that communicates with
                   users.",
  month         =  apr,
  year          =  2022,
  archivePrefix = "arXiv",
  primaryClass  = "cs.HC"
}

@INPROCEEDINGS{Bougueng-Tchemeube2023-nm,
  title     = "Evaluating human-{AI} interaction via usability, user experience
               and acceptance measures for {MMM}-{C}: A creative {AI} system for
               music composition",
  author    = "Bougueng Tchemeube, Renaud and Ens, Jeffrey and Plut, Cale and
               Pasquier, Philippe and Safi, Maryam and Grabit, Yvan and Rolland,
               Jean-Baptiste",
  booktitle = "Proceedings of the Thirty-Second International Joint Conference
               on Artificial Intelligence",
  publisher = "International Joint Conferences on Artificial Intelligence
               Organization",
  address   = "California",
  pages     = "5769--5778",
  abstract  = "With the rise of artificial intelligence (AI), there has been
               increasing interest in human-AI co-creation in a variety of
               artistic domains including music as AI-driven systems are
               frequently able to generate human-competitive artifacts. Now, the
               implications of such systems for the musical practice are being
               investigated. This paper reports on a thorough evaluation of the
               user adoption of the Multi-Track Music Machine (MMM) as a minimal
               co-creative AI tool for music composers. To do this, we integrate
               MMM into Cubase, a popular Digital Audio Workstation (DAW), by
               producing a ``1-parameter'' plugin interface named MMM-Cubase,
               which enables human-AI co-composition. We conduct a 3-part mixed
               method study measuring usability, user experience and technology
               acceptance of the system across two groups of expert-level
               composers: hobbyists and professionals. Results show positive
               usability and acceptance scores. Users report experiences of
               novelty, surprise and ease of use from using the system, and
               limitations on controllability and predictability of the
               interface when generating music. Findings indicate no significant
               difference between the two user groups.",
  month     =  aug,
  year      =  2023
}

@INPROCEEDINGS{Yang2022-vs,
  title     = "{AI} as an active writer: Interaction strategies with generated
               text in human-{AI} collaborative fiction writing 56-65",
  author    = "Yang, Daijin and Zhou, Yanpeng and Zhang, Zhiyuan and Li, Toby
               Jia-Jun and Ray, L C",
  booktitle = "Joint Proceedings of the ACM IUI Workshops 2022,",
  pages     = "56--65",
  abstract  = "Machine Learning (ML) has become an important part of the
               creative process for human fiction writers, allowing them to
               utilize various sources of information and be inspired by
               strategies and data previously seldom explored. To investigate
               how human writers collaborate with ML systems in fiction writing,
               we prototyped a web-based human-AI collaborative writing tool
               that allows writers to shorten, edit, summarize, and regenerate
               text produced by AI. To investigate the dynamics of human-AI
               interaction in fiction co-writing, we used a ``finish each
               other’s story'' approach where humans and machines took turns
               writing collaborative fiction. In results from a preliminary
               study with 9 users, we found that users took inspiration from
               unexpected text generated by the machine, that users expected
               reduced fluency and coherence in the machine text when allowed to
               edit the output, and that they perceived a mental model of the AI
               as an active writer in the collaborative process rather than
               simply as a passive AI writing assistant. This study provides
               design implications on supporting co-creative writing of humans
               and machines.",
  year      =  2022
}

@INPROCEEDINGS{Davis2016-te,
  title     = "Empirically studying participatory sense-making in abstract
               drawing with a co-creative cognitive agent",
  author    = "Davis, Nicholas and Hsiao, Chih-Pin and Yashraj Singh, Kunwar and
               Li, Lisa and Magerko, Brian",
  booktitle = "Proceedings of the 21st International Conference on Intelligent
               User Interfaces",
  publisher = "ACM",
  address   = "New York, NY, USA",
  abstract  = "This paper reports on the design and evaluation of a co-creative
               drawing partner called the Drawing Apprentice, which was designed
               to improvise and collaborate on abstract sketches with users in
               real time. The system qualifies as a new genre of creative
               technologies termed ``casual creators'' that are meant to
               creatively engage users and provide enjoyable creative
               experiences rather than necessarily helping users make a higher
               quality creative product. We introduce the conceptual framework
               of participatory sense-making and describe how it can help model
               and understand open-ended collaboration. We report the results of
               a user study comparing human-human collaboration to
               human-computer collaboration using the Drawing Apprentice system.
               Based on insights from the user study, we present a set of design
               recommendations for co-creative agents.",
  month     =  mar,
  year      =  2016
}

@ARTICLE{Zhou2024-yy,
  title     = "Generative artificial intelligence, human creativity, and art",
  author    = "Zhou, Eric and Lee, Dokyun",
  journal   = "PNAS Nexus",
  publisher = "Oxford University Press (OUP)",
  volume    =  3,
  number    =  3,
  pages     = "gae052",
  abstract  = "Recent artificial intelligence (AI) tools have demonstrated the
               ability to produce outputs traditionally considered creative. One
               such system is text-to-image generative AI (e.g. Midjourney,
               Stable Diffusion, DALL-E), which automates humans' artistic
               execution to generate digital artworks. Utilizing a dataset of
               over 4 million artworks from more than 50,000 unique users, our
               research shows that over time, text-to-image AI significantly
               enhances human creative productivity by 25\% and increases the
               value as measured by the likelihood of receiving a favorite per
               view by 50\%. While peak artwork Content Novelty, defined as
               focal subject matter and relations, increases over time, average
               Content Novelty declines, suggesting an expanding but inefficient
               idea space. Additionally, there is a consistent reduction in both
               peak and average Visual Novelty, captured by pixel-level
               stylistic elements. Importantly, AI-assisted artists who can
               successfully explore more novel ideas, regardless of their prior
               originality, may produce artworks that their peers evaluate more
               favorably. Lastly, AI adoption decreased value capture (favorites
               earned) concentration among adopters. The results suggest that
               ideation and filtering are likely necessary skills in the
               text-to-image process, thus giving rise to ``generative
               synesthesia''-the harmonious blending of human exploration and AI
               exploitation to discover new creative workflows.",
  month     =  mar,
  year      =  2024,
  keywords  = "art; creative workflow; generative AI; human-AI collaboration;
               impact of AI",
  language  = "en"
}

@MISC{Demke_undated-aw,
  title        = "Overcoming algorithmic bias as a measure of computational
                  creativity",
  author       = "Demke, Jonathan and Ventura, Dan",
  howpublished = "\url{https://computationalcreativity.net/iccc24/papers/ICCC24\_paper\_42.pdf}",
  note         = "Accessed: 2024-7-9"
}

@ARTICLE{Zhong2024-ij,
  title         = "Generative {AI} as a tool or leader? Exploring {AI}-augmented
                   thinking in student programming tasks",
  author        = "Zhong, Tianlong and Zhu, Gaoxia and Lim, Kang You and Ong,
                   Yew Soon",
  journal       = "arXiv [cs.HC]",
  abstract      = "The increasing use of Generative Artificial Intelligence
                   (GAI) tools in education highlights the need to understand
                   their influence on individuals' thinking processes and
                   agency. This research explored 20 university students'
                   interaction with GAI during programming. Participants
                   completed surveys, recorded their screens during an hour-long
                   programming session, and reflected on their GAI use. To
                   analyse the data, we developed an AI-augmented thinking
                   coding scheme with four dimensions: Question Formulation,
                   Solution Development, Solution Analysis and Evaluation, and
                   Solution Refinement. Participants were categorised into
                   human-led and AI-led groups based on the time ratio of
                   human-generating source code versus copying source code from
                   GAI. T-tests indicated that the human-led group spent
                   significantly more time on Solution Development and Solution
                   Refinement than the AI-led group. Sequential pattern mining
                   revealed distinct patterns of the two groups: the human-led
                   group often refined GAI outputs, while the AI-led group
                   frequently relied on direct answers from GAI. Correlation
                   analyses found that positive attitudes towards AI, critical
                   thinking, and programming self-efficacy positively correlated
                   with Question Formulation; critical thinking was positively
                   related to Solution Refinement; and programming self-efficacy
                   was negatively associated with Solution Analysis and
                   Evaluation. This study enhances understanding of the thinking
                   process in GAI-supported programming.",
  month         =  nov,
  year          =  2024,
  archivePrefix = "arXiv",
  primaryClass  = "cs.HC"
}

@ARTICLE{Haase2024-yp,
  title    = "Human-{AI} Co-Creativity: Exploring Synergies Across Levels of
              Creative Collaboration",
  author   = "Haase, Jennifer and Pokutta, Sebastian",
  abstract = "Human-AI co-creativity represents a transformative shift in how
              humans and generative AI tools collaborate in creative processes.
              This chapter explores the synergies between human ingenuity and AI
              capabilities across four levels of interaction: Digital Pen, AI
              Task Specialist, AI Assistant, and AI Co-Creator. While earlier
              digital tools primarily facilitated creativity, generative AI
              systems now contribute actively, demonstrating autonomous
              creativity in producing novel and valuable outcomes. Empirical
              evidence from mathematics showcases how AI can extend human
              creative potential, from computational problem-solving to
              co-creative partnerships yielding breakthroughs in longstanding
              challenges. By analyzing these collaborations, the chapter
              highlights AI's potential to enhance human creativity without
              replacing it, underscoring the importance of balancing AI's
              contributions with human oversight and contextual understanding.
              This integration pushes the boundaries of creative achievements,
              emphasizing the need for human-centered AI systems that foster
              collaboration while preserving the unique qualities of human
              creativity.",
  month    =  nov,
  year     =  2024
}

@ARTICLE{Kobis2021-bb,
  title     = "Artificial intelligence versus Maya Angelou: Experimental
               evidence that people cannot differentiate {AI}-generated from
               human-written poetry",
  author    = "Köbis, Nils and Mossink, Luca D",
  journal   = "Comput. Human Behav.",
  publisher = "Elsevier BV",
  volume    =  114,
  number    =  106553,
  pages     =  106553,
  abstract  = "The release of openly available, robust natural language
               generation algorithms (NLG) has spurred much public attention and
               debate. One reason lies in …",
  month     =  jan,
  year      =  2021,
  language  = "en"
}

@INPROCEEDINGS{Robinson2021-vj,
  title     = "Smooth operator: Tuning robot perception through artificial
               movement sound",
  author    = "Robinson, Frederic Anthony and Velonaki, Mari and Bown, Oliver",
  booktitle = "Proceedings of the 2021 ACM/IEEE International Conference on
               Human-Robot Interaction",
  publisher = "ACM",
  address   = "New York, NY, USA",
  month     =  mar,
  year      =  2021
}

@INPROCEEDINGS{Ding2024-ta,
  title     = "Advancing {GUI} for generative {AI}: Charting the design space of
               human-{AI} interactions through task creativity and complexity",
  author    = "Ding, Zijian",
  booktitle = "Companion Proceedings of the 29th International Conference on
               Intelligent User Interfaces",
  publisher = "ACM",
  address   = "New York, NY, USA",
  month     =  mar,
  year      =  2024,
  language  = "en"
}

@INPROCEEDINGS{Shneiderman1997-tv,
  title     = "Direct manipulation for comprehensible, predictable and
               controllable user interfaces",
  author    = "Shneiderman, Ben",
  booktitle = "Proceedings of the 2nd international conference on Intelligent
               user interfaces - IUI '97",
  publisher = "ACM Press",
  address   = "New York, New York, USA",
  abstract  = "Direct manipulation user interfaces have proven their worth over
               two decades, but they are still in their youth. Dramatic
               opportunities exist to develop direct manipulation programming to
               create end-user programming tools, dynamic queries to perform
               information search in large databases, and information
               visualization to support network database browsing. Direct
               manipulation depends on visual representation of the objects and
               actions of interest, physical . actions or pointing instead of
               complex syntax, and rapid incremental reversible operations whose
               effect on the object of interest is immediately visible. This
               strategy can lead to user interfaces that are comprehensible,
               predictable and controllable. Direct manipulation interfaces are
               seen as more likely candidates to influence advanced user
               interfaces than adaptive, autonomous, intelligent agents. User
               control and responsibility are highly desirable. Note: This paper
               is adapted, with permission of the publisher, from the
               forthcoming book: Designing the User Znte~ace: Strategies for
               Effective Human-Computer Interaction (3rd Edition), Addison
               Wesley, Reading, MA (1997).",
  year      =  1997,
  language  = "en"
}

@ARTICLE{Touvron2023-sp,
  title         = "Llama 2: Open foundation and fine-tuned chat models",
  author        = "Touvron, Hugo and Martin, Louis and Stone, Kevin and Albert,
                   Peter and Almahairi, Amjad and Babaei, Yasmine and Bashlykov,
                   Nikolay and Batra, Soumya and Bhargava, Prajjwal and Bhosale,
                   Shruti and Bikel, Dan and Blecher, Lukas and Ferrer, Cristian
                   Canton and Chen, Moya and Cucurull, Guillem and Esiobu, David
                   and Fernandes, Jude and Fu, Jeremy and Fu, Wenyin and Fuller,
                   Brian and Gao, Cynthia and Goswami, Vedanuj and Goyal, Naman
                   and Hartshorn, Anthony and Hosseini, Saghar and Hou, Rui and
                   Inan, Hakan and Kardas, Marcin and Kerkez, Viktor and Khabsa,
                   Madian and Kloumann, Isabel and Korenev, Artem and Koura,
                   Punit Singh and Lachaux, Marie-Anne and Lavril, Thibaut and
                   Lee, Jenya and Liskovich, Diana and Lu, Yinghai and Mao,
                   Yuning and Martinet, Xavier and Mihaylov, Todor and Mishra,
                   Pushkar and Molybog, Igor and Nie, Yixin and Poulton, Andrew
                   and Reizenstein, Jeremy and Rungta, Rashi and Saladi, Kalyan
                   and Schelten, Alan and Silva, Ruan and Smith, Eric Michael
                   and Subramanian, Ranjan and Tan, Xiaoqing Ellen and Tang,
                   Binh and Taylor, Ross and Williams, Adina and Kuan, Jian
                   Xiang and Xu, Puxin and Yan, Zheng and Zarov, Iliyan and
                   Zhang, Yuchen and Fan, Angela and Kambadur, Melanie and
                   Narang, Sharan and Rodriguez, Aurelien and Stojnic, Robert
                   and Edunov, Sergey and Scialom, Thomas",
  journal       = "arXiv [cs.CL]",
  abstract      = "In this work, we develop and release Llama 2, a collection of
                   pretrained and fine-tuned large language models (LLMs)
                   ranging in scale from 7 billion to 70 billion parameters. Our
                   fine-tuned LLMs, called Llama 2-Chat, are optimized for
                   dialogue use cases. Our models outperform open-source chat
                   models on most benchmarks we tested, and based on our human
                   evaluations for helpfulness and safety, may be a suitable
                   substitute for closed-source models. We provide a detailed
                   description of our approach to fine-tuning and safety
                   improvements of Llama 2-Chat in order to enable the community
                   to build on our work and contribute to the responsible
                   development of LLMs.",
  month         =  jul,
  year          =  2023,
  archivePrefix = "arXiv",
  primaryClass  = "cs.CL"
}

@ARTICLE{Kantosalo2016-hg,
  title    = "From {Isolation} to {Involvement}: {Adapting} {Machine}
              {Creativity} {Software} to {Support} {Human}-{Computer}
              {Co}-{Creation}",
  author   = "Kantosalo, Anna and Toivanen, Jukka M and Xiao, Ping and Toivonen,
              Hannu",
  pages    =  7,
  abstract = "This paper investigates how to transform machine creativity
              systems into interactive tools that support human-computer
              co-creation. We use three case studies to identify common issues
              in this transformation, under the perspective of User-Centered
              Design. We also analyse the interactivity and creative behavior of
              the three platforms in terms of Wiggins’ formalization of
              creativity as a search. We arrive at the conclusion that adapting
              creative software for supporting human-computer cocreation
              requires redesigning some major aspects of the software, which
              guides our on-going project of building an interactive poetry
              composition tool.",
  year     =  2016,
  language = "en"
}


@ARTICLE{Turing1950-aq,
  title     = "Computing Machinery and Intelligence",
  author    = "Turing, Alan",
  journal   = "Mind",
  publisher = "Oxford University Press (OUP)",
  volume    = "LIX",
  number    =  236,
  pages     = "433--460",
  abstract  = "I propose to consider the question, ‘Can machines think?’ This
               should begin with definitions of the meaning of the terms
               ‘machine’ and ‘think’. The definit",
  month     =  oct,
  year      =  1950,
  language  = "en"
}

@INPROCEEDINGS{Sun2024-pb,
  title     = "Generative {AI} in the wild: Prospects, challenges, and
               strategies",
  author    = "Sun, Yuan and Jang, Eunchae and Ma, Fenglong and Wang, Ting",
  booktitle = "Proceedings of the CHI Conference on Human Factors in Computing
               Systems",
  publisher = "ACM",
  address   = "New York, NY, USA",
  volume    =  18,
  pages     = "1--16",
  month     =  may,
  year      =  2024,
  language  = "en"
}

@ARTICLE{Anantrasirichai2022-ps,
  title    = "Artificial intelligence in the creative industries: a review",
  author   = "Anantrasirichai, Nantheera and Bull, David",
  journal  = "Artificial Intelligence Review",
  volume   =  55,
  number   =  1,
  pages    = "589--656",
  abstract = "This paper reviews the current state of the art in artificial
              intelligence (AI) technologies and applications in the context of
              the creative industries. A brief background of AI, and
              specifically machine learning (ML) algorithms, is provided
              including convolutional neural networks (CNNs), generative
              adversarial networks (GANs), recurrent neural networks (RNNs) and
              deep Reinforcement Learning (DRL). We categorize creative
              applications into five groups, related to how AI technologies are
              used: (i) content creation, (ii) information analysis, (iii)
              content enhancement and post production workflows, (iv)
              information extraction and enhancement, and (v) data compression.
              We critically examine the successes and limitations of this
              rapidly advancing technology in each of these areas. We further
              differentiate between the use of AI as a creative tool and its
              potential as a creator in its own right. We foresee that, in the
              near future, ML-based AI will be adopted widely as a tool or
              collaborative assistant for creativity. In contrast, we observe
              that the successes of ML in domains with fewer constraints, where
              AI is the ‘creator’, remain modest. The potential of AI (or its
              developers) to win awards for its original creations in
              competition with human creatives is also limited, based on
              contemporary technologies. We therefore conclude that, in the
              context of creative industries, maximum benefit from AI will be
              derived where its focus is human-centric—where it is designed to
              augment, rather than replace, human creativity.",
  month    =  jan,
  year     =  2022
}

@ARTICLE{Nordstrom2023-ge,
  title     = "Evolving coagency between artists and {AI} in the spatial
               cocreative process of artmaking",
  author    = "Nordström, Paulina and Lundman, Riina and Hautala, Johanna",
  journal   = "Ann. Am. Assoc. Geogr.",
  publisher = "Informa UK Limited",
  volume    =  113,
  number    =  9,
  pages     = "2203--2218",
  month     =  oct,
  year      =  2023,
  language  = "en"
}

@INPROCEEDINGS{Chiou2023-vr,
  title     = "Designing with {AI}: An exploration of co-ideation with image
               generators",
  author    = "Chiou, Li-Yuan and Hung, Peng-Kai and Liang, Rung-Huei and Wang,
               Chun-Teng",
  booktitle = "Proceedings of the 2023 ACM Designing Interactive Systems
               Conference",
  publisher = "ACM",
  address   = "New York, NY, USA",
  month     =  jul,
  year      =  2023
}

@ARTICLE{Dhar2020-sd,
  title     = "The carbon impact of artificial intelligence",
  author    = "Dhar, Payal",
  journal   = "Nature Machine Intelligence",
  publisher = "Nature Publishing Group",
  volume    =  2,
  number    =  8,
  pages     = "423--425",
  abstract  = "The part that artificial intelligence plays in climate change has
               come under scrutiny, including from tech workers themselves who
               joined the global climate strike last year. Much can be done by
               developing tools to quantify the carbon cost of machine learning
               models and by switching to a sustainable artificial intelligence
               infrastructure.",
  month     =  aug,
  year      =  2020,
  language  = "en"
}

@ARTICLE{Hou2017-yh,
  title    = "Do pictures help? The effects of pictures and food names on menu
              evaluations",
  author   = "Hou, Yuansi and Yang, Wan and Sun, Yixia",
  journal  = "Int. J. Hosp. Manage.",
  volume   =  60,
  pages    = "94--103",
  abstract = "Presenting pictures along with food names on menus is a common
              practice in the restaurant industry. However, it is not clear
              whether adding pictures to menus always leads to positive effects.
              In addition, since more restaurant practitioners are creating
              ambiguous names for their dishes, it is valuable to study how
              pictures with different types of food names impact customers’
              attitudes and behavioral outcomes. In the current study, we
              examine the joint effect of pictures, food names, and individuals’
              information processing styles on consumers’ attitudes, willingness
              to pay, and purchase intentions. The results reveal that for
              common descriptive food names, adding pictures have a positive
              effect on consumers’ attitudes toward the menu item, their
              willingness to pay and their purchase intentions. More
              interestingly, for ambiguous food names, pictures have a positive
              effect only among verbalizers. Visualizers exhibit less favorable
              attitudes and behavioral outcomes after viewing ambiguously-named
              dishes with pictures than those without pictures.",
  month    =  jan,
  year     =  2017,
  keywords = "Menu design; Picture effect; Food names; Menu labeling; Menu
              pictures; Consumer information processing style"
}

@ARTICLE{Mozannar2023-qu,
  title         = "Effective Human-{AI} Teams via Learned Natural Language Rules
                   and Onboarding",
  author        = "Mozannar, Hussein and Lee, Jimin J and Wei, Dennis and
                   Sattigeri, Prasanna and Das, Subhro and Sontag, David",
  journal       = "arXiv [cs.LG]",
  abstract      = "People are relying on AI agents to assist them with various
                   tasks. The human must know when to rely on the agent,
                   collaborate with the agent, or ignore its suggestions. In
                   this work, we propose to learn rules grounded in data regions
                   and described in natural language that illustrate how the
                   human should collaborate with the AI. Our novel region
                   discovery algorithm finds local regions in the data as
                   neighborhoods in an embedding space that corrects the human
                   prior. Each region is then described using an iterative and
                   contrastive procedure where a large language model describes
                   the region. We then teach these rules to the human via an
                   onboarding stage. Through user studies on object detection
                   and question-answering tasks, we show that our method can
                   lead to more accurate human-AI teams. We also evaluate our
                   region discovery and description algorithms separately.",
  month         =  nov,
  year          =  2023,
  archivePrefix = "arXiv",
  primaryClass  = "cs.LG"
}

@ARTICLE{Gomez2023-bp,
  title         = "Designing {AI} Support for Human Involvement in {AI}-assisted
                   Decision Making: A Taxonomy of Human-{AI} Interactions from a
                   Systematic Review",
  author        = "Gomez, Catalina and Cho, Sue Min and Ke, Shichang and Huang,
                   Chien-Ming and Unberath, Mathias",
  journal       = "arXiv [cs.HC]",
  abstract      = "Efforts in levering Artificial Intelligence (AI) in decision
                   support systems have disproportionately focused on
                   technological advancements, often overlooking the alignment
                   between algorithmic outputs and human expectations. To
                   address this, explainable AI promotes AI development from a
                   more human-centered perspective. Determining what information
                   AI should provide to aid humans is vital, however, how the
                   information is presented, e. g., the sequence of
                   recommendations and the solicitation of interpretations, is
                   equally crucial. This motivates the need to more precisely
                   study Human-AI interaction as a pivotal component of AI-based
                   decision support. While several empirical studies have
                   evaluated Human-AI interactions in multiple application
                   domains in which interactions can take many forms, there is
                   not yet a common vocabulary to describe human-AI interaction
                   protocols. To address this gap, we describe the results of a
                   systematic review of the AI-assisted decision making
                   literature, analyzing 105 selected articles, which grounds
                   the introduction of a taxonomy of interaction patterns that
                   delineate various modes of human-AI interactivity. We find
                   that current interactions are dominated by simplistic
                   collaboration paradigms and report comparatively little
                   support for truly interactive functionality. Our taxonomy
                   serves as a valuable tool to understand how interactivity
                   with AI is currently supported in decision-making contexts
                   and foster deliberate choices of interaction designs.",
  month         =  oct,
  year          =  2023,
  archivePrefix = "arXiv",
  primaryClass  = "cs.HC"
}

@INPROCEEDINGS{Ocampo2024-dv,
  title     = "Integrating Generative {AI} into Creative Workflows: Dealing with
               Consistency, Scene Control, and Refinement in a Professional
               Image Generation Case Study",
  author    = "Ocampo, Rodolfo and Bown, Oliver",
  booktitle = "Proceedings of the 15th International Conference on Computational
               Creativity",
  year      =  2024
}



@ARTICLE{Zheng2023-pz,
  title         = "Judging {LLM}-as-a-Judge with {MT}-Bench and Chatbot Arena",
  author        = "Zheng, Lianmin and Chiang, Wei-Lin and Sheng, Ying and
                   Zhuang, Siyuan and Wu, Zhanghao and Zhuang, Yonghao and Lin,
                   Zi and Li, Zhuohan and Li, Dacheng and Xing, Eric P and
                   Zhang, Hao and Gonzalez, Joseph E and Stoica, Ion",
  journal       = "arXiv [cs.CL]",
  abstract      = "Evaluating large language model (LLM) based chat assistants
                   is challenging due to their broad capabilities and the
                   inadequacy of existing benchmarks in measuring human
                   preferences. To address this, we explore using strong LLMs as
                   judges to evaluate these models on more open-ended questions.
                   We examine the usage and limitations of LLM-as-a-judge,
                   including position, verbosity, and self-enhancement biases,
                   as well as limited reasoning ability, and propose solutions
                   to mitigate some of them. We then verify the agreement
                   between LLM judges and human preferences by introducing two
                   benchmarks: MT-bench, a multi-turn question set; and Chatbot
                   Arena, a crowdsourced battle platform. Our results reveal
                   that strong LLM judges like GPT-4 can match both controlled
                   and crowdsourced human preferences well, achieving over 80\%
                   agreement, the same level of agreement between humans. Hence,
                   LLM-as-a-judge is a scalable and explainable way to
                   approximate human preferences, which are otherwise very
                   expensive to obtain. Additionally, we show our benchmark and
                   traditional benchmarks complement each other by evaluating
                   several variants of LLaMA and Vicuna. The MT-bench questions,
                   3K expert votes, and 30K conversations with human preferences
                   are publicly available at
                   https://github.com/lm-sys/FastChat/tree/main/fastchat/llm\_judge.",
  month         =  jun,
  year          =  2023,
  archivePrefix = "arXiv",
  primaryClass  = "cs.CL"
}

@MISC{noauthor_undated-iv,
  title = "{9781315208060\_webpdf}.pdf"
}

@ARTICLE{noauthor_undated-vg,
  title = "{EurecaEffect}.pdf"
}

@ARTICLE{Kwon2022-uc,
  title         = "Diffusion Models already have a Semantic Latent Space",
  author        = "Kwon, Mingi and Jeong, Jaeseok and Uh, Youngjung",
  journal       = "arXiv [cs.CV]",
  abstract      = "Diffusion models achieve outstanding generative performance
                   in various domains. Despite their great success, they lack
                   semantic latent space which is essential for controlling the
                   generative process. To address the problem, we propose
                   asymmetric reverse process (Asyrp) which discovers the
                   semantic latent space in frozen pretrained diffusion models.
                   Our semantic latent space, named h-space, has nice properties
                   for accommodating semantic image manipulation: homogeneity,
                   linearity, robustness, and consistency across timesteps. In
                   addition, we introduce a principled design of the generative
                   process for versatile editing and quality boost ing by
                   quantifiable measures: editing strength of an interval and
                   quality deficiency at a timestep. Our method is applicable to
                   various architectures (DDPM++, iD- DPM, and ADM) and datasets
                   (CelebA-HQ, AFHQ-dog, LSUN-church, LSUN- bedroom, and
                   METFACES). Project page: https://kwonminki.github.io/Asyrp/",
  month         =  oct,
  year          =  2022,
  archivePrefix = "arXiv",
  primaryClass  = "cs.CV"
}

@ARTICLE{Bown2024-yx,
  title  = "”Coffee So Good, You'll Want to Slap Your Barista”: Evaluating
            Co-Creative Interaction Through Dialogic Actions",
  author = "Bown, Oliver",
  year   =  2024
}

@ARTICLE{Louie2021-hn,
  title         = "Expressive Communication: A Common Framework for Evaluating
                   Developments in Generative Models and Steering Interfaces",
  author        = "Louie, Ryan and Engel, Jesse and Huang, Anna",
  journal       = "arXiv [cs.HC]",
  abstract      = "There is an increasing interest from ML and HCI communities
                   in empowering creators with better generative models and more
                   intuitive interfaces with which to control them. In music, ML
                   researchers have focused on training models capable of
                   generating pieces with increasing long-range structure and
                   musical coherence, while HCI researchers have separately
                   focused on designing steering interfaces that support user
                   control and ownership. In this study, we investigate through
                   a common framework how developments in both models and user
                   interfaces are important for empowering co-creation where the
                   goal is to create music that communicates particular imagery
                   or ideas (e.g., as is common for other purposeful tasks in
                   music creation like establishing mood or creating
                   accompanying music for another media). Our study is
                   distinguished in that it measures communication through both
                   composer's self-reported experiences, and how listeners
                   evaluate this communication through the music. In an
                   evaluation study with 26 composers creating 100+ pieces of
                   music and listeners providing 1000+ head-to-head comparisons,
                   we find that more expressive models and more steerable
                   interfaces are important and complementary ways to make a
                   difference in composers communicating through music and
                   supporting their creative empowerment.",
  month         =  nov,
  year          =  2021,
  archivePrefix = "arXiv",
  primaryClass  = "cs.HC"
}

@BOOK{Kaiser_undated-gq,
  title  = "Creative Collaborations",
  author = "Kaiser, Marc Downie, Shelley Eshkar,"
}

@MISC{noauthor_undated-kc,
  title = "by Tim Brown"
}

@ARTICLE{noauthor_2013-uw,
  title     = "Novel {MRI} measure for diagnosis of progressive supranuclear
               palsy",
  journal   = "Nat. Rev. Neurol.",
  publisher = "Nature Publishing Group",
  volume    =  9,
  number    =  6,
  pages     = "298--298",
  month     =  may,
  year      =  2013,
  language  = "en"
}

@ARTICLE{Jones2011-yu,
  title    = "Movement disorders: Imaging differentiates progressive
              supranuclear palsy from Parkinson disease",
  author   = "Jones, Nick",
  journal  = "Nat. Rev. Neurol.",
  volume   =  7,
  number   =  4,
  pages    =  186,
  month    =  apr,
  year     =  2011,
  language = "en"
}

@ARTICLE{Min2023-ki,
  title    = "Cross species systems biology discovers glial {DDR2}, {STOM}, and
              {KANK2} as therapeutic targets in progressive supranuclear palsy",
  author   = "Min, Yuhao and Wang, Xue and İş, Özkan and Patel, Tulsi A and Gao,
              Junli and Reddy, Joseph S and Quicksall, Zachary S and Nguyen,
              Thuy and Lin, Shu and Tutor-New, Frederick Q and Chalk, Jessica L
              and Mitchell, Adriana O and Crook, Julia E and Nelson, Peter T and
              Van Eldik, Linda J and Golde, Todd E and Carrasquillo, Minerva M
              and Dickson, Dennis W and Zhang, Ke and Allen, Mariet and
              Ertekin-Taner, Nilüfer",
  journal  = "Nat. Commun.",
  volume   =  14,
  number   =  1,
  pages    =  6801,
  abstract = "Progressive supranuclear palsy (PSP) is a neurodegenerative
              parkinsonian disorder characterized by cell-type-specific tau
              lesions in neurons and glia. Prior work uncovered transcriptome
              changes in human PSP brains, although their cell-specificity is
              unknown. Further, systematic data integration and experimental
              validation platforms to prioritize brain transcriptional
              perturbations as therapeutic targets in PSP are currently lacking.
              In this study, we combine bulk tissue (n = 408) and single nucleus
              RNAseq (n = 34) data from PSP and control brains with
              transcriptome data from a mouse tauopathy and experimental
              validations in Drosophila tau models for systematic discovery of
              high-confidence expression changes in PSP with therapeutic
              potential. We discover, replicate, and annotate thousands of
              differentially expressed genes in PSP, many of which reside in
              glia-enriched co-expression modules and cells. We prioritize DDR2,
              STOM, and KANK2 as promising therapeutic targets in PSP with
              striking cross-species validations. We share our findings and data
              via our interactive application tool PSP RNAseq Atlas (
              https://rtools.mayo.edu/PSP\_RNAseq\_Atlas/ ). Our findings reveal
              robust glial transcriptome changes in PSP, provide a cross-species
              systems biology approach, and a tool for therapeutic target
              discoveries in PSP with potential application in other
              neurodegenerative diseases.",
  month    =  nov,
  year     =  2023,
  language = "en"
}

@ARTICLE{Messer2024-gl,
  title     = "Co-creating art with generative artificial intelligence:
               Implications for artworks and artists",
  author    = "Messer, Uwe",
  journal   = "Computers in Human Behavior: Artificial Humans",
  publisher = "Elsevier BV",
  volume    =  2,
  number    =  100056,
  pages     =  100056,
  abstract  = "Synthetic visual art is becoming a commodity due to generative
               artificial intelligence (AI). The trend of using AI for
               co-creation will not spare arti…",
  month     =  feb,
  year      =  2024,
  language  = "en"
}

@INCOLLECTION{Cason2017-zr,
  title     = "Synchronization to music as a tool for enhancing non-verbal
               communication in people with neurological diseases",
  author    = "Cason, Nia and Schiaratura, Loris and Samson, Séverine",
  booktitle = "The Routledge Companion to Embodied Music Interaction",
  publisher = "Routledge",
  pages     = "304--312",
  year      =  2017
}

@MISC{Leman2017-tg,
  title   = "The Interactive Dialectics of Musical Meaning Formation",
  author  = "Leman, Marc",
  journal = "The Routledge Companion to Embodied Music Interaction",
  pages   = "13--21",
  year    =  2017
}

@INCOLLECTION{Leman2017-rl,
  title     = "Introduction: what is embodied music interaction?",
  author    = "Leman, Marc and Lesaffre, Micheline and Maes, Pieter-Jan",
  booktitle = "The Routledge companion to embodied music interaction",
  publisher = "Routledge",
  pages     = "1--10",
  year      =  2017
}

@MISC{Amelynck2017-gq,
  title   = "Modeling Music Interaction",
  author  = "Amelynck, Denis",
  journal = "The Routledge Companion to Embodied Music Interaction",
  pages   = "323--331",
  year    =  2017
}

@MISC{Spada2017-hc,
  title   = "Coupling Music and Motion",
  author  = "Spada, Danilo and Bigand, Emmanuel",
  journal = "The Routledge Companion to Embodied Music Interaction",
  pages   = "261--268",
  year    =  2017
}

@MISC{Lesaffre2017-el,
  title   = "Monitoring Music and Movement Interaction in People with Dementia",
  author  = "Lesaffre, Micheline and Moens, Bart and Desmet, Frank",
  journal = "The Routledge Companion to Embodied Music Interaction",
  pages   = "294--303",
  year    =  2017
}

@MISC{Mota2017-lo,
  title   = "Gestural Interactions in Ensemble Performance",
  author  = "Mota, Davi and Loureiro, Mauricio and Laboissière, Rafael",
  journal = "The Routledge Companion to Embodied Music Interaction",
  pages   = "177--185",
  year    =  2017
}

@MISC{Cochrane2017-of,
  title   = "Group Flow",
  author  = "Cochrane, Tom",
  journal = "The Routledge Companion to Embodied Music Interaction",
  pages   = "133--140",
  year    =  2017
}

@INCOLLECTION{Nijs2017-oa,
  title     = "The merging of musician and musical instrument: Incorporation,
               presence, and levels of embodiment",
  author    = "Nijs, Luc",
  booktitle = "The Routledge companion to embodied music interaction",
  publisher = "Routledge",
  pages     = "49--57",
  year      =  2017
}

@MISC{Moran2017-yw,
  title   = "Agency in Embodied Music Interaction",
  author  = "Moran, Nikki",
  journal = "The Routledge Companion to Embodied Music Interaction",
  pages   = "105--112",
  year    =  2017
}

@MISC{Godoy2017-cg,
  title   = "Postures and Motion Shaping Musical Experience",
  author  = "Godøy, Rolf Inge",
  journal = "The Routledge Companion to Embodied Music Interaction",
  pages   = "113--121",
  year    =  2017
}

@MISC{Thompson1996-mo,
  title   = "Non-verbal communication",
  author  = "Thompson, Neil and Campling, Jo",
  journal = "People Skills",
  pages   = "93--103",
  year    =  1996
}

@MISC{Jensenius2017-cj,
  title   = "Sonic Microinteraction in “the Air”",
  author  = "Jensenius, Alexander Refsum",
  journal = "The Routledge Companion to Embodied Music Interaction",
  pages   = "429--437",
  year    =  2017
}

@INCOLLECTION{Malloch2017-gt,
  title     = "Embodied cognition and digital musical instruments: design and
               performance",
  author    = "Malloch, Joseph and Wanderley, Marcelo M",
  booktitle = "The Routledge companion to embodied music interaction",
  publisher = "Routledge",
  pages     = "438--447",
  year      =  2017
}

@ARTICLE{Ruiz2022-mb,
  title         = "{DreamBooth}: Fine Tuning Text-to-Image Diffusion Models for
                   Subject-Driven Generation",
  author        = "Ruiz, Nataniel and Li, Yuanzhen and Jampani, Varun and
                   Pritch, Yael and Rubinstein, Michael and Aberman, Kfir",
  journal       = "arXiv [cs.CV]",
  abstract      = "Large text-to-image models achieved a remarkable leap in the
                   evolution of AI, enabling high-quality and diverse synthesis
                   of images from a given text prompt. However, these models
                   lack the ability to mimic the appearance of subjects in a
                   given reference set and synthesize novel renditions of them
                   in different contexts. In this work, we present a new
                   approach for ``personalization'' of text-to-image diffusion
                   models. Given as input just a few images of a subject, we
                   fine-tune a pretrained text-to-image model such that it
                   learns to bind a unique identifier with that specific
                   subject. Once the subject is embedded in the output domain of
                   the model, the unique identifier can be used to synthesize
                   novel photorealistic images of the subject contextualized in
                   different scenes. By leveraging the semantic prior embedded
                   in the model with a new autogenous class-specific prior
                   preservation loss, our technique enables synthesizing the
                   subject in diverse scenes, poses, views and lighting
                   conditions that do not appear in the reference images. We
                   apply our technique to several previously-unassailable tasks,
                   including subject recontextualization, text-guided view
                   synthesis, and artistic rendering, all while preserving the
                   subject's key features. We also provide a new dataset and
                   evaluation protocol for this new task of subject-driven
                   generation. Project page: https://dreambooth.github.io/",
  month         =  aug,
  year          =  2022,
  archivePrefix = "arXiv",
  primaryClass  = "cs.CV"
}

@BOOK{Pask1976-mn,
  title     = "Conversation Theory: Applications in Education and Epistemology",
  author    = "Pask, Gordon",
  publisher = "Elsevier",
  year      =  1976,
  language  = "en"
}

@BOOK{Alemi2020-kl,
  title     = "The Amazing Journey of Reason: from {DNA} to Artificial
               Intelligence",
  author    = "Alemi, Mario",
  publisher = "Springer International Publishing",
  address   = "Cham, Switzerland",
  abstract  = "The Amazing Journey analyzes the latest results in chemistry,
               biology, neuroscience, anthropology and sociology under the light
               of the evolution of intelligence, seen as the ability of
               processing information.",
  series    = "SpringerBriefs in Computer Science",
  year      =  2020
}

@ARTICLE{Bown2014-cf,
  title     = "Empirically Grounding the Evaluation of Creative Systems:
               Incorporating Interaction Design",
  author    = "Bown, O",
  journal   = "ICCC",
  publisher = "Citeseer",
  abstract  = "In this paper I argue that the evaluation of artificial creative
               systems in the direct form currently practiced is not in itself
               empirically well-grounded, hindering the potential for
               incremental development in the field. I propose an approach to
               evaluation that is grounded …",
  year      =  2014
}

@ARTICLE{Bown2015-ig,
  title     = "Attributing Creative Agency: Are we doing it right?",
  author    = "Bown, O",
  journal   = "ICCC",
  publisher = "axon.cs.byu.edu",
  abstract  = "When contemplating the creativity of computational systems, a
               host of factors have been taken into consideration, many of which
               people have attempted to measure or otherwise operationalise:
               novelty, value, P-creativity versus H-creativity, exploration
               versus …",
  year      =  2015
}

@BOOK{Bown2021-os,
  title     = "Beyond the Creative Species: Making Machines That Make Art and
               Music",
  author    = "Bown, Oliver",
  publisher = "MIT Press",
  abstract  = "A multidisciplinary introduction to the field of computational
               creativity, analyzing the impact of advanced generative
               technologies on art and music.As algorithms get smarter, what
               role will computers play in the creation of music, art, and other
               cultural artifacts? Will they be able to create such things from
               the ground up, and will such creations be meaningful? In Beyond
               the Creative Species, Oliver Bown offers a multidisciplinary
               examination of computational creativity, analyzing the impact of
               advanced generative technologies on art and music. Drawing on a
               wide range of disciplines, including artificial intelligence and
               machine learning, design, social theory, the psychology of
               creativity, and creative practice research, Bown argues that to
               understand computational creativity, we must not only consider
               what computationally creative algorithms actually do, but also
               examine creative artistic activity itself.",
  month     =  feb,
  year      =  2021,
  language  = "en"
}

@ARTICLE{Chen2021-fo,
  title         = "Evaluating Large Language Models Trained on Code",
  author        = "Chen, Mark and Tworek, Jerry and Jun, Heewoo and Yuan, Qiming
                   and de Oliveira Pinto, Henrique Ponde and Kaplan, Jared and
                   Edwards, Harri and Burda, Yuri and Joseph, Nicholas and
                   Brockman, Greg and Ray, Alex and Puri, Raul and Krueger,
                   Gretchen and Petrov, Michael and Khlaaf, Heidy and Sastry,
                   Girish and Mishkin, Pamela and Chan, Brooke and Gray, Scott
                   and Ryder, Nick and Pavlov, Mikhail and Power, Alethea and
                   Kaiser, Lukasz and Bavarian, Mohammad and Winter, Clemens and
                   Tillet, Philippe and Such, Felipe Petroski and Cummings, Dave
                   and Plappert, Matthias and Chantzis, Fotios and Barnes,
                   Elizabeth and Herbert-Voss, Ariel and Guss, William Hebgen
                   and Nichol, Alex and Paino, Alex and Tezak, Nikolas and Tang,
                   Jie and Babuschkin, Igor and Balaji, Suchir and Jain,
                   Shantanu and Saunders, William and Hesse, Christopher and
                   Carr, Andrew N and Leike, Jan and Achiam, Josh and Misra,
                   Vedant and Morikawa, Evan and Radford, Alec and Knight,
                   Matthew and Brundage, Miles and Murati, Mira and Mayer, Katie
                   and Welinder, Peter and McGrew, Bob and Amodei, Dario and
                   McCandlish, Sam and Sutskever, Ilya and Zaremba, Wojciech",
  journal       = "arXiv [cs.LG]",
  abstract      = "We introduce Codex, a GPT language model fine-tuned on
                   publicly available code from GitHub, and study its Python
                   code-writing capabilities. A distinct production version of
                   Codex powers GitHub Copilot. On HumanEval, a new evaluation
                   set we release to measure functional correctness for
                   synthesizing programs from docstrings, our model solves
                   28.8\% of the problems, while GPT-3 solves 0\% and GPT-J
                   solves 11.4\%. Furthermore, we find that repeated sampling
                   from the model is a surprisingly effective strategy for
                   producing working solutions to difficult prompts. Using this
                   method, we solve 70.2\% of our problems with 100 samples per
                   problem. Careful investigation of our model reveals its
                   limitations, including difficulty with docstrings describing
                   long chains of operations and with binding operations to
                   variables. Finally, we discuss the potential broader impacts
                   of deploying powerful code generation technologies, covering
                   safety, security, and economics.",
  month         =  jul,
  year          =  2021,
  archivePrefix = "arXiv",
  primaryClass  = "cs.LG"
}

@ARTICLE{Mitchell2021-yj,
  title         = "Why {AI} is Harder Than We Think",
  author        = "Mitchell, Melanie",
  journal       = "arXiv [cs.AI]",
  abstract      = "Since its beginning in the 1950s, the field of artificial
                   intelligence has cycled several times between periods of
                   optimistic predictions and massive investment (``AI spring'')
                   and periods of disappointment, loss of confidence, and
                   reduced funding (``AI winter''). Even with today's seemingly
                   fast pace of AI breakthroughs, the development of
                   long-promised technologies such as self-driving cars,
                   housekeeping robots, and conversational companions has turned
                   out to be much harder than many people expected. One reason
                   for these repeating cycles is our limited understanding of
                   the nature and complexity of intelligence itself. In this
                   paper I describe four fallacies in common assumptions made by
                   AI researchers, which can lead to overconfident predictions
                   about the field. I conclude by discussing the open questions
                   spurred by these fallacies, including the age-old challenge
                   of imbuing machines with humanlike common sense.",
  month         =  apr,
  year          =  2021,
  archivePrefix = "arXiv",
  primaryClass  = "cs.AI"
}

@ARTICLE{Wu2021-op,
  title         = "{NÜWA}: Visual Synthesis Pre-training for Neural {visUal}
                   World {creAtion}",
  author        = "Wu, Chenfei and Liang, Jian and Ji, Lei and Yang, Fan and
                   Fang, Yuejian and Jiang, Daxin and Duan, Nan",
  journal       = "arXiv [cs.CV]",
  abstract      = "This paper presents a unified multimodal pre-trained model
                   called N\"UWA that can generate new or manipulate existing
                   visual data (i.e., images and videos) for various visual
                   synthesis tasks. To cover language, image, and video at the
                   same time for different scenarios, a 3D transformer
                   encoder-decoder framework is designed, which can not only
                   deal with videos as 3D data but also adapt to texts and
                   images as 1D and 2D data, respectively. A 3D Nearby Attention
                   (3DNA) mechanism is also proposed to consider the nature of
                   the visual data and reduce the computational complexity. We
                   evaluate N\"UWA on 8 downstream tasks. Compared to several
                   strong baselines, N\"UWA achieves state-of-the-art results on
                   text-to-image generation, text-to-video generation, video
                   prediction, etc. Furthermore, it also shows surprisingly good
                   zero-shot capabilities on text-guided image and video
                   manipulation tasks. Project repo is
                   https://github.com/microsoft/NUWA.",
  month         =  nov,
  year          =  2021,
  archivePrefix = "arXiv",
  primaryClass  = "cs.CV"
}

@ARTICLE{Pachet2003-wg,
  title     = "The Continuator: Musical Interaction With Style",
  author    = "Pachet, François",
  journal   = "Journal of New Music Research",
  publisher = "Routledge",
  volume    =  32,
  number    =  3,
  pages     = "333--341",
  abstract  = "We propose a system, the Continuator, that bridges the gap
               between two classes of traditionally incompatible musical
               systems: (1) interactive musical systems, limited in their
               ability to generate stylistically consistent material, and (2)
               music imitation systems, which are fundamentally not interactive.
               Our purpose is to allow musicians to extend their technical
               ability with stylistically consistent, automatically learnt
               material. This goal requires the ability for the system to build
               operational representations of musical styles in a real time
               context. Our approach is based on a Markov model of musical
               styles augmented to account for musical issues such as management
               of rhythm, beat, harmony, and imprecision. The resulting system
               is able to learn and generate music in any style, either in
               standalone mode, as continuations of musician?s input, or as
               interactive improvisation back up. Lastly, the very design of the
               system makes possible new modes of musical collaborative playing.
               We describe the architecture, implementation issues and
               experimentations conducted with the system in several real world
               contexts.",
  month     =  sep,
  year      =  2003
}

@ARTICLE{Pachet2017-in,
  title     = "Do jazz improvisers really interact?: The score effect in
               collective jazz improvisation",
  author    = "Pachet, F and Roy, P and Foulon, R",
  journal   = "to embodied music interaction",
  publisher = "taylorfrancis.com",
  abstract  = "This chapter assesses to what extent human musicians improvising
               jazz with a shared lead sheet actually interact with each other
               during solos. It proposes a framework for analysis, based on the
               comparison of correlation estimators computed when musicians play
               together and when they do not. The chapter illustrates the
               approach with the analysis of multi-track audio recordings of
               jazz performances. It considers the correlation between the solo
               player and the rhythm section, as well as between the members of
               the rhythm section. The chapter …",
  year      =  2017
}

@ARTICLE{Schiavio2017-au,
  title     = "Participatory sense-making in joint musical practices",
  author    = "Schiavio, A and De Jaegher, H",
  journal   = "Routledge companion to embodied …",
  publisher = "researchgate.net",
  abstract  = "Drawing from recent embodied and enactive frameworks in the
               cognitive sciences, in this chapter we explore musical
               interactivity as a form of 'participatory sense-making'. In
               providing conceptual grounding, we adopt the notion of 'mutual
               incorporation'inspired by the …",
  year      =  2017
}

@ARTICLE{Kirsh2013-xs,
  title     = "Embodied cognition and the magical future of interaction design",
  author    = "Kirsh, David",
  journal   = "ACM Trans. Comput.-Hum. Interact.",
  publisher = "Association for Computing Machinery",
  address   = "New York, NY, USA",
  volume    =  20,
  number    =  1,
  pages     = "1--30",
  abstract  = "The theory of embodied cognition can provide HCI practitioners
               and theorists with new ideas about interaction and new principles
               for better designs. I support this claim with four ideas about
               cognition: (1) interacting with tools changes the way we think
               and perceive -- tools, when manipulated, are soon absorbed into
               the body schema, and this absorption leads to fundamental changes
               in the way we perceive and conceive of our environments; (2) we
               think with our bodies not just with our brains; (3) we know more
               by doing than by seeing -- there are times when physically
               performing an activity is better than watching someone else
               perform the activity, even though our motor resonance system
               fires strongly during other person observation; (4) there are
               times when we literally think with things. These four ideas have
               major implications for interaction design, especially the design
               of tangible, physical, context aware, and telepresence systems.",
  month     =  apr,
  year      =  2013,
  keywords  = "interaction design, embodied cognition, situated cognition,
               distributed cognition, physical computation, mental simulation,
               tangible interfaces, Human-computer interaction"
}

@ARTICLE{Nichol2021-ne,
  title         = "{GLIDE}: Towards photorealistic image generation and editing
                   with text-guided diffusion models",
  author        = "Nichol, Alex and Dhariwal, Prafulla and Ramesh, Aditya and
                   Shyam, Pranav and Mishkin, Pamela and McGrew, Bob and
                   Sutskever, Ilya and Chen, Mark",
  journal       = "arXiv [cs.CV]",
  abstract      = "Diffusion models have recently been shown to generate
                   high-quality synthetic images, especially when paired with a
                   guidance technique to trade off diversity for fidelity. We
                   explore diffusion models for the problem of text-conditional
                   image synthesis and compare two different guidance
                   strategies: CLIP guidance and classifier-free guidance. We
                   find that the latter is preferred by human evaluators for
                   both photorealism and caption similarity, and often produces
                   photorealistic samples. Samples from a 3.5 billion parameter
                   text-conditional diffusion model using classifier-free
                   guidance are favored by human evaluators to those from
                   DALL-E, even when the latter uses expensive CLIP reranking.
                   Additionally, we find that our models can be fine-tuned to
                   perform image inpainting, enabling powerful text-driven image
                   editing. We train a smaller model on a filtered dataset and
                   release the code and weights at
                   https://github.com/openai/glide-text2im.",
  month         =  dec,
  year          =  2021,
  archivePrefix = "arXiv",
  primaryClass  = "cs.CV"
}

@ARTICLE{Puduppully2018-pi,
  title         = "Data-to-Text Generation with Content Selection and Planning",
  author        = "Puduppully, Ratish and Dong, Li and Lapata, Mirella",
  journal       = "arXiv [cs.CL]",
  abstract      = "Recent advances in data-to-text generation have led to the
                   use of large-scale datasets and neural network models which
                   are trained end-to-end, without explicitly modeling what to
                   say and in what order. In this work, we present a neural
                   network architecture which incorporates content selection and
                   planning without sacrificing end-to-end training. We
                   decompose the generation task into two stages. Given a corpus
                   of data records (paired with descriptive documents), we first
                   generate a content plan highlighting which information should
                   be mentioned and in which order and then generate the
                   document while taking the content plan into account.
                   Automatic and human-based evaluation experiments show that
                   our model outperforms strong baselines improving the
                   state-of-the-art on the recently released RotoWire dataset.",
  month         =  sep,
  year          =  2018,
  archivePrefix = "arXiv",
  primaryClass  = "cs.CL"
}

@ARTICLE{Dafoe2021-in,
  title    = "Cooperative {AI}: machines must learn to find common ground",
  author   = "Dafoe, Allan and Bachrach, Yoram and Hadfield, Gillian and
              Horvitz, Eric and Larson, Kate and Graepel, Thore",
  journal  = "Nature",
  volume   =  593,
  number   =  7857,
  pages    = "33--36",
  month    =  may,
  year     =  2021,
  keywords = "Computer science; Human behaviour; Machine learning; Society;
              Sociology; Technology",
  language = "en"
}

@INPROCEEDINGS{Amershi2019-vy,
  title     = "Guidelines for Human-{AI} Interaction",
  author    = "Amershi, Saleema and Weld, Dan and Vorvoreanu, Mihaela and
               Fourney, Adam and Nushi, Besmira and Collisson, Penny and Suh,
               Jina and Iqbal, Shamsi and Bennett, Paul N and Inkpen, Kori and
               Teevan, Jaime and Kikin-Gil, Ruth and Horvitz, Eric",
  booktitle = "Proceedings of the 2019 CHI Conference on Human Factors in
               Computing Systems",
  publisher = "ACM",
  address   = "New York, NY, USA",
  abstract  = "This work proposes 18 generally applicable design guidelines for
               human-AI interaction that can serve as a resource to
               practitioners working on the design of applications and features
               that harness AI technologies, and to researchers interested in
               the further development of human- AI interaction design
               principles. Advances in artificial intelligence (AI) frame
               opportunities and challenges for user interface design.
               Principles for human-AI interaction have been discussed in the
               human-computer interaction community for over two decades, but
               more study and innovation are needed in light of advances in AI
               and the growing uses of AI technologies in human-facing
               applications. We propose 18 generally applicable design
               guidelines for human-AI interaction. These guidelines are
               validated through multiple rounds of evaluation including a user
               study with 49 design practitioners who tested the guidelines
               against 20 popular AI-infused products. The results verify the
               relevance of the guidelines over a spectrum of interaction
               scenarios and reveal gaps in our knowledge, highlighting
               opportunities for further research. Based on the evaluations, we
               believe the set of design guidelines can serve as a resource to
               practitioners working on the design of applications and features
               that harness AI technologies, and to researchers interested in
               the further development of human-AI interaction design
               principles.",
  month     =  may,
  year      =  2019,
  language  = "en"
}

@ARTICLE{noauthor_2022-cr,
  title     = "Designing Creative {AI} Partners with {COFI}: A Framework for
               Modeling Interaction in Human-{AI} Co-Creative Systems",
  journal   = "ACM Trans. Comput.-Hum. Interact.",
  publisher = "Association for Computing Machinery",
  address   = "New York, NY, USA",
  abstract  = "Human-AI co-creativity involves both humans and AI collaborating
               on a shared creative product as partners. In a creative
               collaboration, interaction dynamics, such as turn-taking,
               contribution type, and communication, are the driving forces of
               the co-creative process. Therefore the interaction model is a
               critical and essential component for effective co-creative
               systems. There is relatively little research about interaction
               design in the co-creativity field, which is reflected in a lack
               of focus on interaction design in many existing co-creative
               systems. The primary focus of co-creativity research has been on
               the abilities of the AI. This paper focuses on the importance of
               interaction design in co-creative systems with the development of
               the Co-Creative Framework for Interaction design (COFI) that
               describes the broad scope of possibilities for interaction design
               in co-creative systems. Researchers can use COFI for modeling
               interaction in co-creative systems by exploring alternatives in
               this design space of interaction. COFI can also be beneficial
               while investigating and interpreting the interaction design of
               existing co-creative systems. We coded a dataset of existing 92
               co-creative systems using COFI and analyzed the data to show how
               COFI provides a basis to categorize the interaction models of
               existing co-creative systems. We identify opportunities to shift
               the focus of interaction models in co-creativity to enable more
               communication between the user and AI leading to human-AI
               partnerships.",
  month     =  feb,
  year      =  2022,
  keywords  = "Interaction design, Human-AI co-creativity, Framework"
}

@ARTICLE{Crandall2018-ev,
  title     = "Cooperating with machines",
  author    = "Crandall, Jacob W and Oudah, Mayada and {Tennom} and
               Ishowo-Oloko, Fatimah and Abdallah, Sherief and Bonnefon,
               Jean-François and Cebrian, Manuel and Shariff, Azim and Goodrich,
               Michael A and Rahwan, Iyad",
  journal   = "Nat. Commun.",
  publisher = "Springer Science and Business Media LLC",
  volume    =  9,
  number    =  1,
  pages     = "1--12",
  abstract  = "Since Alan Turing envisioned artificial intelligence, technical
               progress has often been measured by the ability to defeat humans
               in zero-sum encounters (e.g., Chess, Poker, or Go). Less
               attention has been given to scenarios in which human–machine
               cooperation is beneficial but non-trivial, such as scenarios in
               which human and machine preferences are neither fully aligned nor
               fully in conflict. Cooperation does not require sheer
               computational power, but instead is facilitated by intuition,
               cultural norms, emotions, signals, and pre-evolved dispositions.
               Here, we develop an algorithm that combines a state-of-the-art
               reinforcement-learning algorithm with mechanisms for signaling.
               We show that this algorithm can cooperate with people and other
               algorithms at levels that rival human cooperation in a variety of
               two-player repeated stochastic games. These results indicate that
               general human–machine cooperation is achievable using a
               non-trivial, but ultimately simple, set of algorithmic
               mechanisms. Artificial intelligence is now superior to humans in
               many fully competitive games, such as Chess, Go, and Poker. Here
               the authors develop a machine-learning algorithm that can
               cooperate effectively with humans when cooperation is beneficial
               but nontrivial, something humans are remarkably good at.",
  month     =  dec,
  year      =  2018,
  language  = "en"
}

@ARTICLE{Schultz2016-nk,
  title     = "Dopamine reward prediction error coding",
  author    = "Schultz, Wolfram",
  journal   = "Dialogues Clin. Neurosci.",
  publisher = "Informa UK Limited",
  volume    =  18,
  number    =  1,
  pages     = "23--32",
  abstract  = "Reward prediction errors consist of the differences between
               received and predicted rewards. They are crucial for basic forms
               of learning about rewards and make us strive for more rewards-an
               evolutionary beneficial trait. Most dopamine neurons in the
               midbrain of humans, monkeys, and rodents signal a reward
               prediction error; they are activated by more reward than
               predicted (positive prediction error), remain at baseline
               activity for fully predicted rewards, and show depressed activity
               with less reward than predicted (negative prediction error). The
               dopamine signal increases nonlinearly with reward value and codes
               formal economic utility. Drugs of addiction generate, hijack, and
               amplify the dopamine reward signal and induce exaggerated,
               uncontrolled dopamine effects on neuronal plasticity. The
               striatum, amygdala, and frontal cortex also show reward
               prediction error coding, but only in subpopulations of neurons.
               Thus, the important concept of reward prediction errors is
               implemented in neuronal hardware.",
  month     =  mar,
  year      =  2016,
  keywords  = "dopamine; neuro-physiology; neuron; prediction; reward; striatum;
               substantia nigra; ventral tegmental area",
  language  = "en"
}

@ARTICLE{Kaufman2009-vx,
  title     = "Beyond Big and little: The four {C} model of creativity",
  author    = "Kaufman, James C and Beghetto, Ronald A",
  journal   = "Rev. Gen. Psychol.",
  publisher = "SAGE Publications",
  volume    =  13,
  number    =  1,
  pages     = "1--12",
  abstract  = "Most investigations of creativity tend to take one of two
               directions: everyday creativity (also called “little-c”), which
               can be found in nearly all people, and eminent creativity (also
               called “Big-C”), which is reserved for the great. In this paper,
               the authors propose a Four C model of creativity that expands
               this dichotomy. Specifically, the authors add the idea of
               “mini-c,” creativity inherent in the learning process, and Pro-c,
               the developmental and effortful progression beyond little-c that
               represents professional-level expertise in any creative area. The
               authors include different transitions and gradations of these
               four dimensions of creativity, and then discuss advantages and
               examples of the Four C Model.",
  month     =  mar,
  year      =  2009,
  language  = "en"
}

@ARTICLE{Axelrod1981-ux,
  title    = "The evolution of cooperation",
  author   = "Axelrod, R and Hamilton, W D",
  journal  = "Science",
  volume   =  211,
  number   =  4489,
  pages    = "1390--1396",
  abstract = "Cooperation in organisms, whether bacteria or primates, has been a
              difficulty for evolutionary theory since Darwin. On the assumption
              that interactions between pairs of individuals occur on a
              probabilistic basis, a model is developed based on the concept of
              an evolutionarily stable strategy in the context of the Prisoner's
              Dilemma game. Deductions from the model, and the results of a
              computer tournament show how cooperation based on reciprocity can
              get started in an asocial world, can thrive while interacting with
              a wide range of other strategies, and can resist invasion once
              fully established. Potential applications include specific aspects
              of territoriality, mating, and disease.",
  month    =  mar,
  year     =  1981,
  language = "en"
}

@ARTICLE{Jansson1991-wy,
  title    = "Design fixation",
  author   = "Jansson, David G and Smith, Steven M",
  journal  = "Design Studies",
  volume   =  12,
  number   =  1,
  pages    = "3--11",
  abstract = "This paper reports on a series of experiments which were conducted
              to test the hypothesis that design fixation, defined as a blind
              adherence to a set of ideas or concepts limiting the output of
              conceptual design, is a measurable barrier in the conceptual
              design process. The results of the experiments clearly demonstrate
              the existence of design fixation. The paper related issues such as
              the nature of the phenomenon, some experimental issues which arise
              in such investigations, and directions for future research.",
  month    =  jan,
  year     =  1991,
  keywords = "conceptual design; engineering design; creativity"
}

@INPROCEEDINGS{Karimi2020-cf,
  title     = "Creative sketching partner: an analysis of human-{AI}
               co-creativity",
  author    = "Karimi, Pegah and Rezwana, Jeba and Siddiqui, Safat and Maher,
               Mary Lou and Dehbozorgi, Nasrin",
  booktitle = "Proceedings of the 25th International Conference on Intelligent
               User Interfaces",
  publisher = "Association for Computing Machinery",
  address   = "New York, NY, USA",
  pages     = "221--230",
  abstract  = "The creative sketching partner (CSP) is a proof of concept
               intelligent interface to inspire designers while sketching in
               response to a specified design task. With this interactive system
               we are studying the effect of an AI model of visual and
               conceptual similarity for selecting the Al's sketch response as
               an inspiration to the current state of the user's sketch.
               Specifically, we are interested in the user's behavior and
               response to an AI partner when engaged in a design task. By
               developing deep learning models of the sketches from a
               large-scale dataset, the user can control the amount of visual
               and conceptual similarity of the AI response when requesting
               inspiration from the CSP. We conducted a study with 50 design
               students to examine the participants' interaction behavior and
               their self reports. The participants' behavior maps into clusters
               that are co-related with three types of design creativity:
               combinatorial, exploratory, and transformational. Our findings
               demonstrate that the tool can facilitate ideation and overcome
               design fixation. In addition, analysis suggests that inspiration
               related to conceptual similarity is more associated with
               transformational creativity and inspiration related to visual
               similarity occurs more frequently during the detailed stages of
               design and is more prevalent with combinatorial creativity.",
  series    = "IUI '20",
  month     =  mar,
  year      =  2020,
  keywords  = "co-creativity, design creativity, collaboration, sketching"
}

@INPROCEEDINGS{Davis2013-jy,
  title     = "Human-Computer Co-Creativity: Blending Human and Computational
               Creativity",
  author    = "Davis, Nicholas Mark",
  booktitle = "Ninth Artificial Intelligence and Interactive Digital
               Entertainment Conference",
  publisher = "aaai.org",
  abstract  = "This paper describes a thesis exploring how computer programs can
               collaborate as equals in the artistic creative process. The
               proposed system, CoCo Sketch, encodes some rudimentary stylistic
               rules of abstract sketching and music theory to contribute
               supplemental lines and music while the user sketches. We describe
               a three-part research method that includes defining rudimentary
               stylistic rules for abstract line drawing, exploring the
               interaction design for artistic improvisation with a computer,
               and evaluating how CoCo Sketch affects the artistic creative
               process. We report on the initial results of early investigations
               into artistic style that describe cognitive, perceptual, and
               behavioral processes used in abstract artists making.",
  month     =  nov,
  year      =  2013,
  language  = "en"
}

@INPROCEEDINGS{Canaan2018-bd,
  title     = "Towards Game-based Metrics for Computational Co-Creativity",
  author    = "Canaan, Rodrigo and Menzel, Stefan and Togelius, Julian and
               Nealen, Andy",
  booktitle = "2018 IEEE Conference on Computational Intelligence and Games
               (CIG)",
  publisher = "ieeexplore.ieee.org",
  pages     = "1--8",
  abstract  = "We propose the following question: what game-like interactive
               system would provide a good environment for measuring the impact
               and success of a co-creative, cooperative agent? Creativity is
               often formulated in terms of novelty, value, surprise and
               interestingness. We review how these concepts are measured in
               current computational intelligence research and provide a mapping
               from modern electronic and tabletop games to open research
               problems in mixed-initiative systems and computational
               co-creativity. We propose application scenarios for future
               research, and a number of metrics under which the performance of
               cooperative agents in these environments will be evaluated.",
  month     =  aug,
  year      =  2018,
  keywords  = "Creativity;Predictive models;Games;Extraterrestrial
               measurements;Current measurement;Learning (artificial
               intelligence);artificial intelligence;cooperative systems;games"
}

@INPROCEEDINGS{Hoffmann2016-mg,
  title     = "On Modeling Human-Computer Co-Creativity",
  author    = "Hoffmann, Oliver",
  booktitle = "Knowledge, Information and Creativity Support Systems",
  publisher = "Springer International Publishing",
  pages     = "37--48",
  abstract  = "Do we have a scientific model of creativity as emerging from
               contributions of computer users, computer systems and their
               interaction? Such a model would require describing the creative
               process in general, conditions for human creativity, the added
               value of human-computer cooperation as well as the role and power
               of computing. All of these topics have been the subject of
               research, but they have been addressed in different research
               communities. Potential obstacles for combining research results
               from research fields such as knowledge engineering and creativity
               research and properties of a general model of Human-Computer
               Co-Creativity are discussed.",
  year      =  2016
}

@INPROCEEDINGS{Goel2015-wl,
  title     = "Using Watson for Enhancing Human-Computer Co-Creativity",
  author    = "Goel, Ashok and Creeden, Brian and Kumble, Mithun and Salunke,
               Shanu and Shetty, Abhinaya and Wiltgen, Bryan",
  booktitle = "2015 AAAI Fall Symposium Series",
  publisher = "aaai.org",
  abstract  = "We describe an experiment in using IBM’s Watson cognitive system
               to teach about human-computer co-creativity in a Georgia Tech
               Spring 2015 class on computational creativity. The project-based
               class used Watson to support biologically inspired design, a
               design paradigm that uses biological systems as analogues for
               inventing technological systems. The twenty-four students in the
               class self-organized into six teams of four students each, and
               developed semester-long projects that built on Watson to support
               biologically inspired design. In this paper, we describe this
               experiment in using Watson to teach about human-computer
               co-creativity, present one project in detail, and summarize the
               remaining five projects. We also draw lessons on building on
               Watson for (i) supporting biologically inspired design, and (ii)
               enhancing human-computer co-creativity.",
  month     =  sep,
  year      =  2015,
  language  = "en"
}

@ARTICLE{Kantosalo2020-ag,
  title     = "Five {C}'s for Human-Computer Co-Creativity-An Update on
               Classical Creativity Perspectives",
  author    = "Kantosalo, A and Takala, T",
  journal   = "ICCC",
  publisher = "computationalcreativity.net",
  abstract  = "… domain independent framework for discussing human –computer co
               - creativity . It expands on … , evaluation and study of human –
               computer co - creativity by allowing researchers to de…",
  year      =  2020
}

@ARTICLE{Kantosalo2020-nh,
  title     = "Modalities, Styles and Strategies: An Interaction Framework for
               Human-Computer Co-Creativity",
  author    = "Kantosalo, A and Ravikumar, P T and Grace, K and Takala, T",
  journal   = "ICCC",
  publisher = "computationalcreativity.net",
  abstract  = "… The goal of the framework is to equip co - creativity … of
               interactions between a human and a computationally creative …
               state of the art in human –computer co - creativity , but as a
               demon…",
  year      =  2020
}

@ARTICLE{Yannakakis2014-zs,
  title     = "Mixed-initiative co-creativity",
  author    = "Yannakakis, Georgios N and Liapis, Antonios and Alexopoulos,
               Constantine",
  publisher = "Foundations of Digital Games",
  abstract  = "Creating and designing with a machine: do we merely create
               together (co-create) or can a machine truly foster our creativity
               as human creators? When does such co-creation foster the
               co-creativity of both humans and machines? This paper
               investigates the simultaneous and/or iterative process of human
               and computational creators in a mixed-initiative fashion within
               the context of game design and attempts to draw from both theory
               and praxis towards answering the above questions. For this
               purpose, we first discuss the strong links between
               mixed-initiative co-creation and theories of human and
               computational creativity. We then introduce an assessment
               methodology of mixed-initiative co-creativity and, as a proof of
               concept, evaluate Sentient Sketchbook as a co-creation tool for
               game design. Core findings suggest that tools such as Sentient
               Sketchbook are not mere game authoring systems or mere enablers
               of creation but, instead, foster human creativity and realize
               mixed-initiative co-creativity.",
  year      =  2014,
  keywords  = "Artificial intelligence; Algorithms; Lateral thinking;
               conferenceObject",
  language  = "en"
}

@INPROCEEDINGS{Saffiotti2020-hp,
  title     = "On human-{AI} collaboration in artistic performance",
  author    = "Saffiotti, Alessandro and Fogel, Peter and Knudsen, Peter and de
               Miranda, Luis and Thörn, Oscar",
  booktitle = "First International Workshop on New Foundations for
               Human-Centered AI (NeHuAI) co-located with 24th European
               Conference on Artificial Intelligence (ECAI 2020), Santiago de
               Compostella, Spain, September 4, 2020",
  publisher = "CEUR-WS",
  pages     = "38--43",
  abstract  = "Live artistic performance, like music, dance or acting, provides
               an excellent domain to observe and analyze the mechanisms of
               human-human collaboration. In this note, we use this domain to
               study hu ...",
  year      =  2020,
  language  = "en"
}

@INPROCEEDINGS{Feldman2017-ip,
  title     = "Co-creation: Human and {AI} collaboration in creative expression",
  author    = "Feldman, Sara (salevati)",
  booktitle = "EVA London 2017",
  publisher = "BCS Learning \& Development",
  abstract  = "… AI systems, to help augment our creativity and become reactive
               to our emotional experiences. This allows for a collaboration
               between human and AI and … AI alone is not cable of creating …",
  month     =  jul,
  year      =  2017
}

@ARTICLE{Muller2020-nv,
  title    = "Mixed Initiative Generative {AI} Interfaces: An Analytic Framework
              for Generative {AI} Applications",
  author   = "Muller, Michael and Weisz, Justin D and Geyer, Werner",
  journal  = "computationalcreativity.net",
  abstract = "Recent advances in deep generative models have enabled a broad
              range of use cases, from drug design to music synthesis. Many of
              these applications will require a collaborative effort between
              humans who steer the generative process, and generative models to
              reach the desired outputs. However, our expressive power to
              describe interactions with these models has not kept pace. We
              review frameworks for mixed initiative user interfaces (Horvitz
              1999) and mixed initiative creative interfaces (Deterding et al.
              2017) and identify gaps due to …",
  year     =  2020
}

@ARTICLE{Radford2021-hb,
  title         = "Learning transferable visual models from natural language
                   supervision",
  author        = "Radford, Alec and Kim, Jong Wook and Hallacy, Chris and
                   Ramesh, Aditya and Goh, Gabriel and Agarwal, Sandhini and
                   Sastry, Girish and Askell, Amanda and Mishkin, Pamela and
                   Clark, Jack and Krueger, Gretchen and Sutskever, Ilya",
  journal       = "arXiv [cs.CV]",
  abstract      = "State-of-the-art computer vision systems are trained to
                   predict a fixed set of predetermined object categories. This
                   restricted form of supervision limits their generality and
                   usability since additional labeled data is needed to specify
                   any other visual concept. Learning directly from raw text
                   about images is a promising alternative which leverages a
                   much broader source of supervision. We demonstrate that the
                   simple pre-training task of predicting which caption goes
                   with which image is an efficient and scalable way to learn
                   SOTA image representations from scratch on a dataset of 400
                   million (image, text) pairs collected from the internet.
                   After pre-training, natural language is used to reference
                   learned visual concepts (or describe new ones) enabling
                   zero-shot transfer of the model to downstream tasks. We study
                   the performance of this approach by benchmarking on over 30
                   different existing computer vision datasets, spanning tasks
                   such as OCR, action recognition in videos, geo-localization,
                   and many types of fine-grained object classification. The
                   model transfers non-trivially to most tasks and is often
                   competitive with a fully supervised baseline without the need
                   for any dataset specific training. For instance, we match the
                   accuracy of the original ResNet-50 on ImageNet zero-shot
                   without needing to use any of the 1.28 million training
                   examples it was trained on. We release our code and
                   pre-trained model weights at https://github.com/OpenAI/CLIP.",
  month         =  feb,
  year          =  2021,
  archivePrefix = "arXiv",
  primaryClass  = "cs.CV"
}

@ARTICLE{Mikolov2013-ii,
  title    = "Efficient Estimation of Word Representations in Vector Space",
  author   = "Mikolov, Tomas and Chen, Kai and Corrado, Greg and Dean, Jeffrey",
  abstract = "We propose two novel model architectures for computing continuous
              vector representations of words from very large data sets. The
              quality of these representations is measured in a word similarity
              task, and the results are compared to the previously best
              performing techniques based on different types of neural networks.
              We observe large improvements in accuracy at much lower
              computational cost, i.e. it takes less than a day to learn high
              quality word vectors from a 1.6 billion words data set.
              Furthermore, we show that these vectors provide state-of-the-art
              performance on our test set for measuring syntactic and semantic
              word similarities.",
  month    =  jan,
  year     =  2013
}

@ARTICLE{Bohm1991-kl,
  title     = "Dialogue: A proposal",
  author    = "Bohm, David and Factor, Donald and Garrett, Peter",
  journal   = "Retrieved April",
  publisher = "dialogue-associates.com",
  volume    =  24,
  pages     =  2006,
  abstract  = "… Dialogue arose out of a series of conversations begun in 1983
               in which we inquired into David Bohm's … with various groups of
               people which in turn began to take the form of Dialogues . …",
  year      =  1991
}

@BOOK{Bohm2004-qh,
  title     = "On dialogue",
  author    = "Bohm, David and Senge, Peter M and Nichol, Lee",
  publisher = "Routledge",
  abstract  = "… On Dialogue is the most comprehensive documentation to date of
               the process David Bohm referred to simply as “ dialogue .” This
               revised and expanded edition of the original booklet of …",
  year      =  2004
}

@BOOK{Bohm2004-ly,
  title     = "On creativity",
  author    = "Bohm, David",
  publisher = "Routledge",
  year      =  2004
}

@INPROCEEDINGS{Kantosalo2016-nm,
  title     = "Modes for creative human-computer collaboration: Alternating and
               task-divided co-creativity",
  author    = "Kantosalo, Anna and Toivonen, Hannu",
  booktitle = "Proceedings of the seventh international conference on
               computational creativity",
  publisher = "computationalcreativity.net",
  pages     = "77--84",
  abstract  = "The analysis of human-computer co-creative systems in current
               literature is focused on a human perspective, highlighting the
               benefits of co-creative systems for human users. This study paper
               examines different styles of human-computer co-creation from a
               more computational perspective, presenting new concepts for
               analysis of computational agents in human-computer cocreation.
               Our perspective is based on Wiggins' formalization of creativity
               as a search. We formalize for co-creative scenarios involving an
               alternating, iterative …",
  year      =  2016
}

@INPROCEEDINGS{Bown2020-oc,
  title     = "A Speculative Exploration of the Role of Dialogue in
               Human-{ComputerCo}-creation",
  author    = "Bown, Oliver and Grace, Kazjon and Bray, Liam and Ventura, Dan",
  booktitle = "ICCC",
  publisher = "computationalcreativity.net",
  pages     = "25--32",
  abstract  = "In this paper we consider the notion of dialogic creative
               artificial intelligence (DCAI) systems, where co-creativity
               between a human user and a computational system is supported …",
  year      =  2020
}

@INCOLLECTION{Perrault1988-sr,
  title     = "Chapter 4 - Natural-Language Interfaces",
  author    = "Perrault, C Raymond and Grosz, Barbara J",
  editor    = "Shrobe, Howard E and {the American Association for Artificial
               Intelligence}",
  booktitle = "Exploring Artificial Intelligence",
  publisher = "Morgan Kaufmann",
  pages     = "133--172",
  abstract  = "Publisher Summary Since the early 1960s when support decreased
               for machine translation, much of the research on natural-language
               processing in North America has been motivated by its potential
               use for communicating with software systems. Natural-language
               systems have been developed to extract information from
               databases, to control (simulated) robots, to interact with
               graphic systems, to specify simulation problems, and to
               communicate with systems embodying expertise in some task or
               problem area. This chapter discusses the interfaces to database
               management systems. Apart from being among the earliest interface
               systems developed, interfaces to databases account for most of
               the natural-language interfaces (NLIs) implemented and they are
               the subject of a substantial literature. The chapter discusses
               the main system architectures used in NLIs and the body of
               techniques developed for them. In doing so, it distinguishes
               between the task of an interface and its domain. Natural language
               is but one of the methods available for human–machine
               interaction. The reasons for its attractiveness are obvious. They
               are: it provides an immediate vocabulary for talking about the
               contents of the database and a means of accessing information in
               the database independently of its structure and encodings,
               shields the user from the formal access language of the
               underlying system, and is available with a minimum of training to
               both novice and occasional user.",
  month     =  jan,
  year      =  1988
}

@ARTICLE{Ramesh2022-kc,
  title         = "Hierarchical Text-Conditional Image Generation with {CLIP}
                   Latents",
  author        = "Ramesh, Aditya and Dhariwal, Prafulla and Nichol, Alex and
                   Chu, Casey and Chen, Mark",
  journal       = "arXiv [cs.CV]",
  abstract      = "Contrastive models like CLIP have been shown to learn robust
                   representations of images that capture both semantics and
                   style. To leverage these representations for image
                   generation, we propose a two-stage model: a prior that
                   generates a CLIP image embedding given a text caption, and a
                   decoder that generates an image conditioned on the image
                   embedding. We show that explicitly generating image
                   representations improves image diversity with minimal loss in
                   photorealism and caption similarity. Our decoders conditioned
                   on image representations can also produce variations of an
                   image that preserve both its semantics and style, while
                   varying the non-essential details absent from the image
                   representation. Moreover, the joint embedding space of CLIP
                   enables language-guided image manipulations in a zero-shot
                   fashion. We use diffusion models for the decoder and
                   experiment with both autoregressive and diffusion models for
                   the prior, finding that the latter are computationally more
                   efficient and produce higher-quality samples.",
  month         =  apr,
  year          =  2022,
  archivePrefix = "arXiv",
  primaryClass  = "cs.CV"
}

@ARTICLE{Brown2020-pb,
  title         = "Language Models are Few-Shot Learners",
  author        = "Brown, Tom B and Mann, Benjamin and Ryder, Nick and Subbiah,
                   Melanie and Kaplan, Jared and Dhariwal, Prafulla and
                   Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and
                   Askell, Amanda and Agarwal, Sandhini and Herbert-Voss, Ariel
                   and Krueger, Gretchen and Henighan, Tom and Child, Rewon and
                   Ramesh, Aditya and Ziegler, Daniel M and Wu, Jeffrey and
                   Winter, Clemens and Hesse, Christopher and Chen, Mark and
                   Sigler, Eric and Litwin, Mateusz and Gray, Scott and Chess,
                   Benjamin and Clark, Jack and Berner, Christopher and
                   McCandlish, Sam and Radford, Alec and Sutskever, Ilya and
                   Amodei, Dario",
  journal       = "arXiv [cs.CL]",
  abstract      = "Recent work has demonstrated substantial gains on many NLP
                   tasks and benchmarks by pre-training on a large corpus of
                   text followed by fine-tuning on a specific task. While
                   typically task-agnostic in architecture, this method still
                   requires task-specific fine-tuning datasets of thousands or
                   tens of thousands of examples. By contrast, humans can
                   generally perform a new language task from only a few
                   examples or from simple instructions - something which
                   current NLP systems still largely struggle to do. Here we
                   show that scaling up language models greatly improves
                   task-agnostic, few-shot performance, sometimes even reaching
                   competitiveness with prior state-of-the-art fine-tuning
                   approaches. Specifically, we train GPT-3, an autoregressive
                   language model with 175 billion parameters, 10x more than any
                   previous non-sparse language model, and test its performance
                   in the few-shot setting. For all tasks, GPT-3 is applied
                   without any gradient updates or fine-tuning, with tasks and
                   few-shot demonstrations specified purely via text interaction
                   with the model. GPT-3 achieves strong performance on many NLP
                   datasets, including translation, question-answering, and
                   cloze tasks, as well as several tasks that require on-the-fly
                   reasoning or domain adaptation, such as unscrambling words,
                   using a novel word in a sentence, or performing 3-digit
                   arithmetic. At the same time, we also identify some datasets
                   where GPT-3's few-shot learning still struggles, as well as
                   some datasets where GPT-3 faces methodological issues related
                   to training on large web corpora. Finally, we find that GPT-3
                   can generate samples of news articles which human evaluators
                   have difficulty distinguishing from articles written by
                   humans. We discuss broader societal impacts of this finding
                   and of GPT-3 in general.",
  month         =  may,
  year          =  2020,
  archivePrefix = "arXiv",
  primaryClass  = "cs.CL"
}

@ARTICLE{Shneiderman2007-yh,
  title    = "Creativity support tools: accelerating discovery and innovation",
  author   = "Shneiderman, Ben",
  journal  = "Commun. ACM",
  volume   =  50,
  number   =  12,
  pages    = "20--32",
  abstract = "How can designers of programming interfaces, interactive tools,
              and rich social environments enable more people to be more
              creative more often?",
  month    =  dec,
  year     =  2007
}

@ARTICLE{Vaswani2017-pb,
  title     = "Attention is All you Need",
  author    = "Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit,
               Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, Łukasz and
               Polosukhin, Illia",
  journal   = "Adv. Neural Inf. Process. Syst.",
  publisher = "proceedings.neurips.cc",
  volume    =  30,
  abstract  = "… the number of attention heads and the attention key and value
               dimensions, keeping the amount of computation constant, as
               described in Section 3.2.2. While single-head attention is 0.9 …",
  year      =  2017
}

@ARTICLE{Kaplan2020-vz,
  title         = "Scaling Laws for Neural Language Models",
  author        = "Kaplan, Jared and McCandlish, Sam and Henighan, Tom and
                   Brown, Tom B and Chess, Benjamin and Child, Rewon and Gray,
                   Scott and Radford, Alec and Wu, Jeffrey and Amodei, Dario",
  journal       = "arXiv [cs.LG]",
  abstract      = "We study empirical scaling laws for language model
                   performance on the cross-entropy loss. The loss scales as a
                   power-law with model size, dataset size, and the amount of
                   compute used for training, with some trends spanning more
                   than seven orders of magnitude. Other architectural details
                   such as network width or depth have minimal effects within a
                   wide range. Simple equations govern the dependence of
                   overfitting on model/dataset size and the dependence of
                   training speed on model size. These relationships allow us to
                   determine the optimal allocation of a fixed compute budget.
                   Larger models are significantly more sample-efficient, such
                   that optimally compute-efficient training involves training
                   very large models on a relatively modest amount of data and
                   stopping significantly before convergence.",
  month         =  jan,
  year          =  2020,
  archivePrefix = "arXiv",
  primaryClass  = "cs.LG"
}

@ARTICLE{Ouyang2022-af,
  title         = "Training language models to follow instructions with human
                   feedback",
  author        = "Ouyang, Long and Wu, Jeff and Jiang, Xu and Almeida, Diogo
                   and Wainwright, Carroll L and Mishkin, Pamela and Zhang,
                   Chong and Agarwal, Sandhini and Slama, Katarina and Ray, Alex
                   and Schulman, John and Hilton, Jacob and Kelton, Fraser and
                   Miller, Luke and Simens, Maddie and Askell, Amanda and
                   Welinder, Peter and Christiano, Paul and Leike, Jan and Lowe,
                   Ryan",
  journal       = "arXiv [cs.CL]",
  abstract      = "Making language models bigger does not inherently make them
                   better at following a user's intent. For example, large
                   language models can generate outputs that are untruthful,
                   toxic, or simply not helpful to the user. In other words,
                   these models are not aligned with their users. In this paper,
                   we show an avenue for aligning language models with user
                   intent on a wide range of tasks by fine-tuning with human
                   feedback. Starting with a set of labeler-written prompts and
                   prompts submitted through the OpenAI API, we collect a
                   dataset of labeler demonstrations of the desired model
                   behavior, which we use to fine-tune GPT-3 using supervised
                   learning. We then collect a dataset of rankings of model
                   outputs, which we use to further fine-tune this supervised
                   model using reinforcement learning from human feedback. We
                   call the resulting models InstructGPT. In human evaluations
                   on our prompt distribution, outputs from the 1.3B parameter
                   InstructGPT model are preferred to outputs from the 175B
                   GPT-3, despite having 100x fewer parameters. Moreover,
                   InstructGPT models show improvements in truthfulness and
                   reductions in toxic output generation while having minimal
                   performance regressions on public NLP datasets. Even though
                   InstructGPT still makes simple mistakes, our results show
                   that fine-tuning with human feedback is a promising direction
                   for aligning language models with human intent.",
  month         =  mar,
  year          =  2022,
  archivePrefix = "arXiv",
  primaryClass  = "cs.CL"
}

@ARTICLE{Ramesh2022-tj,
  title         = "Hierarchical Text-Conditional Image Generation with {CLIP}
                   Latents",
  author        = "Ramesh, Aditya and Dhariwal, Prafulla and Nichol, Alex and
                   Chu, Casey and Chen, Mark",
  journal       = "arXiv [cs.CV]",
  abstract      = "Contrastive models like CLIP have been shown to learn robust
                   representations of images that capture both semantics and
                   style. To leverage these representations for image
                   generation, we propose a two-stage model: a prior that
                   generates a CLIP image embedding given a text caption, and a
                   decoder that generates an image conditioned on the image
                   embedding. We show that explicitly generating image
                   representations improves image diversity with minimal loss in
                   photorealism and caption similarity. Our decoders conditioned
                   on image representations can also produce variations of an
                   image that preserve both its semantics and style, while
                   varying the non-essential details absent from the image
                   representation. Moreover, the joint embedding space of CLIP
                   enables language-guided image manipulations in a zero-shot
                   fashion. We use diffusion models for the decoder and
                   experiment with both autoregressive and diffusion models for
                   the prior, finding that the latter are computationally more
                   efficient and produce higher-quality samples.",
  month         =  apr,
  year          =  2022,
  archivePrefix = "arXiv",
  primaryClass  = "cs.CV"
}

@ARTICLE{Ramesh2022-un,
  title     = "Hierarchical text-conditional image generation with clip latents",
  author    = "Ramesh, A and Dhariwal, P and Nichol, A and Chu, C and {others}",
  journal   = "arXiv preprint arXiv",
  publisher = "arxiv.org",
  abstract  = "Contrastive models like CLIP have been shown to learn robust
               representations of images that capture both semantics and style.
               To leverage these representations for image …",
  year      =  2022
}


@BOOK{Benjamin1935-wd,
  title     = "The work of art in the age of mechanical reproduction",
  author    = "Benjamin, Walter",
  publisher = "Createspace Independent Publishing Platform",
  address   = "North Charleston, SC",
  year      =  1935
}

@ARTICLE{Amabile1996-pt,
  title     = "Creativity in context: Update to the Social Psychology Of
               Creativity",
  author    = "Amabile, Teresa M",
  journal   = "xviii",
  publisher = "Westview Press Creativity in context",
  volume    =  317,
  abstract  = "Understanding And Assessing Creativity The Case For A Social
               Psychology Of Creativity. The Meaning And Measurement Of
               Creativity. A Consensual Technique For Creativity Assessment. A
               Theoretical Framework Social And Environmental Influences *
               Effects of Evaluation on Creativity * Effects of Reward and Task
               Constraint * Social Facilitation, Modeling, and Motivational
               Orientation * Other Social and Environmental Influences
               Implications * Implications for Enhancing Creativity * Toward a
               Comprehensive Psychology of Creativity",
  month     =  jun,
  year      =  1996
}

@ARTICLE{Mullins2002-ia,
  title     = "'It's a {PhD}, not a Nobel Prize': How experienced examiners
               assess research theses",
  author    = "Mullins, Gerry and Kiley, Margaret",
  journal   = "Stud. High. Educ.",
  publisher = "Informa UK Limited",
  volume    =  27,
  number    =  4,
  pages     = "369--386",
  abstract  = "Research to date on the examination process for postgraduate
               research theses has focused largely on the deconstruction of
               examiners' reports. This article reports on a study of the
               processes that experienced examiners go through, and the
               judgements they make before writing their reports. A sample of 30
               experienced examiners (defined as having examined the equivalent
               of at least five research theses over the last five years), from
               a range of disciplines in five universities was interviewed.
               Clear trends emerged with regard to: the criteria used by
               examiners and the levels of student performance expected by them;
               critical judgement points in the examination process; the
               examiners' perceptions of their own role in the process; the
               influence on examiners of previously published work, the views of
               the other examiner(s) and their knowledge of the student's
               supervisor and/or department, and the level of perceived
               responsibility between student and supervisor.",
  month     =  oct,
  year      =  2002
}

@INCOLLECTION{Colton2012-jc,
  title     = "The painting fool: Stories from building an automated painter",
  author    = "Colton, Simon",
  booktitle = "Computers and Creativity",
  publisher = "Springer Berlin Heidelberg",
  address   = "Berlin, Heidelberg",
  pages     = "3--38",
  abstract  = "‪S Colton‬, ‪Computers and creativity, 2012‬ - ‪Cited by 252‬",
  year      =  2012
}

@INPROCEEDINGS{Hwang2022-kv,
  title     = "Why or Why Not: Barriers of Adopting Generative {AI} in
               Human-{AI} Co-Creativity",
  author    = "Hwang, Hsing-Chi",
  booktitle = "GenAI Workshop CHI 2022",
  volume    =  1,
  year      =  2022
}

@ARTICLE{Alayrac2022-uj,
  title         = "Flamingo: a Visual Language Model for Few-Shot Learning",
  author        = "Alayrac, Jean-Baptiste and Donahue, Jeff and Luc, Pauline and
                   Miech, Antoine and Barr, Iain and Hasson, Yana and Lenc,
                   Karel and Mensch, Arthur and Millican, Katie and Reynolds,
                   Malcolm and Ring, Roman and Rutherford, Eliza and Cabi,
                   Serkan and Han, Tengda and Gong, Zhitao and Samangooei, Sina
                   and Monteiro, Marianne and Menick, Jacob and Borgeaud,
                   Sebastian and Brock, Andrew and Nematzadeh, Aida and
                   Sharifzadeh, Sahand and Binkowski, Mikolaj and Barreira,
                   Ricardo and Vinyals, Oriol and Zisserman, Andrew and
                   Simonyan, Karen",
  journal       = "arXiv [cs.CV]",
  abstract      = "Building models that can be rapidly adapted to numerous tasks
                   using only a handful of annotated examples is an open
                   challenge for multimodal machine learning research. We
                   introduce Flamingo, a family of Visual Language Models (VLM)
                   with this ability. Flamingo models include key architectural
                   innovations to: (i) bridge powerful pretrained vision-only
                   and language-only models, (ii) handle sequences of
                   arbitrarily interleaved visual and textual data, and (iii)
                   seamlessly ingest images or videos as inputs. Thanks to their
                   flexibility, Flamingo models can be trained on large-scale
                   multimodal web corpora containing arbitrarily interleaved
                   text and images, which is key to endow them with in-context
                   few-shot learning capabilities. We perform a thorough
                   evaluation of the proposed Flamingo models, exploring and
                   measuring their ability to rapidly adapt to a variety of
                   image and video understanding benchmarks. These include
                   open-ended tasks such as visual question-answering, where the
                   model is prompted with a question which it has to answer,
                   captioning tasks, which evaluate the ability to describe a
                   scene or an event, and close-ended tasks such as multiple
                   choice visual question-answering. For tasks lying anywhere on
                   this spectrum, we demonstrate that a single Flamingo model
                   can achieve a new state of the art for few-shot learning,
                   simply by prompting the model with task-specific examples. On
                   many of these benchmarks, Flamingo actually surpasses the
                   performance of models that are fine-tuned on thousands of
                   times more task-specific data.",
  month         =  apr,
  year          =  2022,
  archivePrefix = "arXiv",
  primaryClass  = "cs.CV"
}

@ARTICLE{Rezwana2022-am,
  title         = "Understanding User Perceptions, Collaborative Experience and
                   User Engagement in Different Human-{AI} Interaction Designs
                   for Co-Creative Systems",
  author        = "Rezwana, Jeba and Lou Maher, Mary",
  journal       = "arXiv [cs.HC]",
  abstract      = "Human-AI co-creativity involves humans and AI collaborating
                   on a shared creative product as partners. In a creative
                   collaboration, communication is an essential component among
                   collaborators. In many existing co-creative systems users can
                   communicate with the AI, usually using buttons or sliders.
                   Typically, the AI in co-creative systems cannot communicate
                   back to humans, limiting their potential to be perceived as
                   partners rather than just a tool. This paper presents a study
                   with 38 participants to explore the impact of two interaction
                   designs, with and without AI-to-human communication, on user
                   engagement, collaborative experience and user perception of a
                   co-creative AI. The study involves user interaction with two
                   prototypes of a co-creative system that contributes sketches
                   as design inspirations during a design task. The results show
                   improved collaborative experience and user engagement with
                   the system incorporating AI-to-human communication. Users
                   perceive co-creative AI as more reliable, personal, and
                   intelligent when the AI communicates to users. The findings
                   can be used to design effective co-creative systems, and the
                   insights can be transferred to other fields involving
                   human-AI interaction and collaboration.",
  month         =  apr,
  year          =  2022,
  archivePrefix = "arXiv",
  primaryClass  = "cs.HC"
}

@ARTICLE{Braun2012-te,
  title     = "Thematic analysis",
  author    = "Braun, Virginia and Clarke, Victoria",
  publisher = "American Psychological Association",
  abstract  = "… then demonstrates how to do thematic analysis, using a … We
               conclude by discussing how to conduct thematic analysis … Our
               worked example of thematic analysis uses data from four …",
  year      =  2012
}

@INPROCEEDINGS{Wang2020-cw,
  title     = "From Human-Human Collaboration to Human-{AI} Collaboration:
               Designing {AI} Systems That Can Work Together with People",
  author    = "Wang, Dakuo and Churchill, Elizabeth and Maes, Pattie and Fan,
               Xiangmin and Shneiderman, Ben and Shi, Yuanchun and Wang,
               Qianying",
  booktitle = "Extended Abstracts of the 2020 CHI Conference on Human Factors in
               Computing Systems",
  publisher = "Association for Computing Machinery",
  address   = "New York, NY, USA",
  pages     = "1--6",
  abstract  = "Artificial Intelligent (AI) and Machine Learning (ML) algorithms
               are coming out of research labs into the real-world applications,
               and recent research has focused a lot on Human-AI Interaction
               (HAI) and Explainable AI (XAI). However, Interaction is not the
               same as Collaboration. Collaboration involves mutual goal
               understanding, preemptive task co-management and shared progress
               tracking. Most of human activities today are done
               collaboratively, thus, to integrate AI into the
               already-complicated human workflow, it is critical to bring the
               Computer-Supported Cooperative Work (CSCW) perspective into the
               root of the algorithmic research and plan for a Human-AI
               Collaboration future of work. In this panel we ask: Can this
               future for trusted human-AI collaboration be realized? If so,
               what will it take? This panel will bring together HCI experts who
               work on human collaboration and AI applications in various
               application contexts, from industry and academia and from both
               the U.S. and China. Panelists will engage the audience through
               discussion of their shared and diverging visions, and through
               suggestions for opportunities and challenges for the future of
               human-AI collaboration.",
  series    = "CHI EA '20",
  month     =  apr,
  year      =  2020,
  keywords  = "ai-powered healthcare, ai partner, human-ai collaboration,
               explainable ai, group collaboration, trusted ai,
               computer-supported corporative work"
}

@ARTICLE{Janssen2019-sr,
  title     = "History and future of human-automation interaction",
  author    = "Janssen, Christian P and Donker, Stella F and Brumby, Duncan P
               and Kun, Andrew L",
  journal   = "Int. J. Hum. Comput. Stud.",
  publisher = "Elsevier BV",
  volume    =  131,
  pages     = "99--107",
  abstract  = "We review the history of human-automation interaction research,
               assess its current status and identify future directions. We
               start by reviewing articles that were published on this topic in
               the International Journal of Human-Computer Studies during the
               last 50 years. We find that over the years, automated systems
               have been used more frequently (1) in time-sensitive or
               safety-critical settings, (2) in embodied and situated systems,
               and (3) by non-professional users. Looking to the future, there
               is a need for human-automation interaction research to focus on
               (1) issues of function and task allocation between humans and
               machines, (2) issues of trust, incorrect use, and confusion, (3)
               the balance between focus, divided attention and attention
               management, (4) the need for interdisciplinary approaches to
               cover breadth and depth, (5) regulation and explainability, (6)
               ethical and social dilemmas, (7) allowing a human and humane
               experience, and (8) radically different human-automation
               interaction.",
  month     =  nov,
  year      =  2019,
  keywords  = "Automation; Human-automation interaction; Safety-critical
               systems; Autonomous agents; Embodied systems; Situated systems;
               Divided attention; Ethics; Robotics, Automated vehicles",
  language  = "en"
}

@ARTICLE{Riedelbauch2023-fl,
  title     = "Benchmarking teamwork of humans and cobots—an overview of
               metrics, strategies, and tasks",
  author    = "Riedelbauch, Dominik and Höllerich, Nico and Henrich, Dominik",
  journal   = "IEEE Access",
  publisher = "Institute of Electrical and Electronics Engineers (IEEE)",
  volume    =  11,
  pages     = "43648--43674",
  year      =  2023
}

@ARTICLE{Csikszentmihalyi1990-hu,
  title     = "Flow: the psychology of optimal experience",
  author    = "Csikszentmihalyi, M",
  journal   = "Choice",
  publisher = "American Library Association",
  volume    =  28,
  number    =  01,
  pages     = "28--0597--28--0597",
  abstract  = "More than anything else, men and women seek happiness. Aristotle",
  month     =  sep,
  year      =  1990
}

@INPROCEEDINGS{Hewett2005-ff,
  title     = "Creativity support tool evaluation methods and metrics",
  author    = "{Hewett} and {Czerwinski} and {Terry} and {others}",
  booktitle = "NSF Workshop Report Creativity Support Tools",
  year      =  2005
}

@INPROCEEDINGS{Zimmerman2007-zv,
  title     = "Research through design as a method for interaction design
               research in {HCI}",
  author    = "Zimmerman, John and Forlizzi, Jodi and Evenson, Shelley",
  booktitle = "Proceedings of the SIGCHI Conference on Human Factors in
               Computing Systems",
  publisher = "Association for Computing Machinery",
  address   = "New York, NY, USA",
  pages     = "493--502",
  abstract  = "For years the HCI community has struggled to integrate design in
               research and practice. While design has gained a strong foothold
               in practice, it has had much less impact on the HCI research
               community. In this paper we propose a new model for interaction
               design research within HCI. Following a research through design
               approach, designers produce novel integrations of HCI research in
               an attempt to make the right thing: a product that transforms the
               world from its current state to a preferred state. This model
               allows interaction designers to make research contributions based
               on their strength in addressing under-constrained problems. To
               formalize this model, we provide a set of four lenses for
               evaluating the research contribution and a set of three examples
               to illustrate the benefits of this type of research.",
  series    = "CHI '07",
  month     =  apr,
  year      =  2007,
  keywords  = "wicked problems, HCI research, design, design method, interaction
               design research, interaction design, design theory, research
               through design"
}

@INPROCEEDINGS{Gaver2012-pd,
  title     = "What should we expect from research through design?",
  author    = "Gaver, William",
  booktitle = "Proceedings of the SIGCHI Conference on Human Factors in
               Computing Systems",
  publisher = "Association for Computing Machinery",
  address   = "New York, NY, USA",
  pages     = "937--946",
  abstract  = "In this essay, I explore several facets of research through
               design in order to contribute to discussions about how the
               approach should develop. The essay has three parts. In the first,
               I review two influential theories from the Philosophy of Science
               to help reflect on the nature of design theory, concluding that
               research through design is likely to produce theories that are
               provisional, contingent, and aspirational. In the second part, I
               discuss three possible interpretations for the diversity of
               approaches to research through design, and suggest that this
               variation need not be seen as a sign of inadequate standards or a
               lack of cumulative progress in the field, but may be natural for
               a generative endeavour. In the final section, I suggest that,
               rather than aiming to develop increasingly comprehensive theories
               of design, practice based research might better view theory as
               annotation of realised design examples, and particularly
               portfolios of related pieces. Overall, I suggest that the design
               research community should be wary of impulses towards convergence
               and standardisation, and instead take pride in its aptitude for
               exploring and speculating, particularising and diversifying, and
               - especially - its ability to manifest the results in the form of
               new, conceptually rich artefacts.",
  series    = "CHI '12",
  month     =  may,
  year      =  2012,
  keywords  = "annotation, theory, research through design, portfolios,
               philosophy of science"
}

@ARTICLE{Cherry2014-ty,
  title     = "Quantifying the Creativity Support of Digital Tools through the
               Creativity Support Index",
  author    = "Cherry, Erin and Latulipe, Celine",
  journal   = "ACM Trans. Comput.-Hum. Interact.",
  publisher = "Association for Computing Machinery",
  address   = "New York, NY, USA",
  volume    =  21,
  number    =  4,
  pages     = "1--25",
  abstract  = "Creativity support tools help people engage creatively with the
               world, but measuring how well a tool supports creativity is
               challenging since creativity is ill-defined. To this end, we
               developed the Creativity Support Index (CSI), which is a
               psychometric survey designed for evaluating the ability of a
               creativity support tool to assist a user engaged in creative
               work. The CSI measures six dimensions of creativity support:
               Exploration, Expressiveness, Immersion, Enjoyment, Results Worth
               Effort, and Collaboration. The CSI allows researchers to
               understand not just how well a tool supports creative work
               overall, but what aspects of creativity support may need
               attention. In this article, we present the CSI, along with
               scenarios for how it can be deployed in a variety of HCI research
               settings and how the CSI scores can help target design
               improvements. We also present the iterative, rigorous development
               and validation process used to create the CSI.",
  month     =  jun,
  year      =  2014,
  keywords  = "psychometrics, evaluation, Creativity support tools, surveys"
}

@ARTICLE{Resnick2005-fs,
  title     = "Design Principles for Tools to Support Creative Thinking",
  author    = "Resnick, Mitchel and Myers, Brad and Nakakoji, Kumiyo and
               Shneiderman, Ben and Eisenberg, Mike",
  publisher = "unknown",
  volume    =  20,
  number    =  2,
  abstract  = "PDF | On Jan 1, 2005, Mitchel Resnick and others published Design
               Principles for Tools to Support Creative Thinking | Find, read
               and cite all the research you need on ResearchGate",
  month     =  jan,
  year      =  2005
}

@INPROCEEDINGS{Kruger2017-xa,
  title     = "From Tools Towards Cooperative Assistants",
  author    = "Krüger, Matti and Wiebel, Christiane B and Wersing, Heiko",
  booktitle = "Proceedings of the 5th International Conference on Human Agent
               Interaction",
  publisher = "Association for Computing Machinery",
  address   = "New York, NY, USA",
  pages     = "287--294",
  abstract  = "Endowing assistant systems with more autonomy establishes the
               transition from a human-controlled tool towards a self-directed
               agent capable of own decisions and goals. In this concept paper
               we suggest to perform the design of such an assistant agent
               according to principles of cooperativity. We first review
               definitions of cooperation between animals, humans and machines
               and then discuss advantages of cooperation also for a
               human-machine interaction system. We concentrate on the important
               roles of adaptivity and responsibility within the interaction. We
               argue that main benefits of a cooperative design are alleviation
               of typical automation issues like controllability, complacency,
               trust, and greater flexibility of the combined human-machine
               system in tasks with high variability.",
  series    = "HAI '17",
  month     =  oct,
  year      =  2017,
  keywords  = "adaptivity, autonomy, assistant systems, cooperation,
               human-machine interaction"
}

@ARTICLE{Bengler2012-jf,
  title     = "Interaction Principles for Cooperative Human-Machine Systems",
  author    = "Bengler, Klaus and Zimmermann, Markus and Bortot, Dino and
               Kienle, Martin and Damböck, Daniel",
  journal   = "it - Information Technology",
  publisher = "Oldenbourg Verlag",
  volume    =  54,
  number    =  4,
  pages     = "157--164",
  abstract  = "Human-machine systems with shared authority can be observed in
               different domains of assistance systems. This article creates a
               taxonomy of the most important aspects of human-machine
               cooperation in five layers: intention, modes of cooperation,
               allocation, interfaces and contact. This is investigated with
               help of driver assistance and Human-Robot Interaction.
               Furthermore, a perspective for possibilities of cross-domain
               generalization is given.",
  month     =  aug,
  year      =  2012
}

@BOOK{Karwowski2017-jp,
  title     = "The Creative Self: Effect of Beliefs, Self-Efficacy, Mindset, and
               Identity",
  author    = "Karwowski, Maciej and Kaufman, James C",
  publisher = "Academic Press",
  abstract  = "The Creative Self reviews and summarizes key theories, studies,
               and new ideas about the role and significance self-beliefs play
               in one’s creativity. It untangles the interrelated constructs of
               creative self-efficacy, creative metacognition, creative
               identity, and creative self-concept. It explores how and when
               creative self-beliefs are formed as well as how creative
               self-beliefs can be strengthened. Part I discusses how creativity
               plays a part in one’s self-identity and its relationship with
               free will and efficacy. Part II discusses creativity present in
               day-to-day life across the lifespan. Part III highlights the
               intersection of the creative self with other variables such as
               mindset, domains, the brain, and individual differences. Part IV
               explores methodology and culture in relation to creativity. Part
               V, discusses additional constructs or theories that offer promise
               for future research on creativity. Explores how beliefs about
               one’s creativity are part of one’s identity Investigates the
               development of self-beliefs about creativity Identifies external
               and personality factors influencing self-beliefs about creativity
               Incorporates worldwide research with cross-disciplinary
               contributors",
  month     =  feb,
  year      =  2017,
  language  = "en"
}

@MISC{Hellendoorn_undated-yw,
  title       = "Code-{LMs}: Guide to using pre-trained large language models of
                 source code",
  author      = "Hellendoorn, Vincent",
  institution = "Github",
  abstract    = "Guide to using pre-trained large language models of source code
                 - VHellendoorn/Code-LMs: Guide to using pre-trained large
                 language models of source code",
  language    = "en"
}

@INPROCEEDINGS{Xu2022-je,
  title     = "A systematic evaluation of large language models of code",
  author    = "Xu, Frank F and Alon, Uri and Neubig, Graham and Hellendoorn,
               Vincent Josua",
  booktitle = "Proceedings of the 6th ACM SIGPLAN International Symposium on
               Machine Programming",
  publisher = "Association for Computing Machinery",
  address   = "New York, NY, USA",
  pages     = "1--10",
  abstract  = "Large language models (LMs) of code have recently shown
               tremendous promise in completing code and synthesizing code from
               natural language descriptions. However, the current
               state-of-the-art code LMs (e.g., Codex) are not publicly
               available, leaving many questions about their model and data
               design decisions. We aim to fill in some of these blanks through
               a systematic evaluation of the largest existing models: Codex,
               GPT-J, GPT-Neo, GPT-NeoX-20B, and CodeParrot, across various
               programming languages. Although Codex itself is not open-source,
               we find that existing opensource models do achieve close results
               in some programming languages, although targeted mainly for
               natural language modeling. We further identify an important
               missing piece in the form of a large open-source model trained
               exclusively on a multi-lingual corpus of code. We release a new
               model, PolyCoder, with 2.7B parameters based on the GPT-2
               architecture, that was trained on 249GB of code across 12
               programming languages on a single machine. In the C programming
               language, PolyCoder outperforms all models including Codex. Our
               trained models are open-source and publicly available at
               https://github.com/VHellendoorn/Code-LMs, which enables future
               research and application in this area. We have an online appendix
               at https://arxiv.org/abs/2202.13169.",
  series    = "MAPS 2022",
  month     =  jun,
  year      =  2022,
  keywords  = "evaluation, code language model, code generation, pretraining,
               open-source"
}

@ARTICLE{noauthor_undated-ly,
  title     = "Research-led practice in design research used to best demonstrate
               design theories",
  author    = "Kuys, Blair and Thong, Christine and Kotlarewski, Nathan James
               and Thompson-Whiteside, Scott",
  journal   = "DRS 2014",
  publisher = "unknown",
  abstract  = "There is contention in the design research community surrounding
               the legitimacy of industrial design practice used in design
               research in academia. This study claims that research-led
               practice in design research within the context of universities
               through industry-sponsored projects is deserving of scholarly
               recognition. It can be argued that research-led practice in
               design research provides a platform for demonstrating the
               applicability of design theories in practice. Design practice is
               inspired and directed by research where concepts generated
               through industrial design practice provide evidence that
               research-led industrial design practice has the ability to
               generate a new body of knowledge. It is the research that informs
               decisions concerning the design process; and by default informing
               practice of 'research-led industrial design practice'. To
               substantiate this, two research-led industrial design practice
               case studies from Swinburne University of Technology, Melbourne,
               Australia are highlighted to show how design theories are used in
               practice to benefit industries separate to academic environments.",
  month     =  jun,
  year      =  2014
}

@ARTICLE{Candy2006-qh,
  title   = "Practice based research: A guide",
  author  = "Candy, Linda",
  journal = "CCS report",
  volume  =  1,
  number  =  2,
  pages   = "1--19",
  year    =  2006
}

@ARTICLE{Frayling1994-qa,
  title     = "Research in Art and Design (Royal College of Art Research Papers,
               Vol 1, No 1, 1993/4)",
  author    = "Frayling, Christopher",
  publisher = "Royal College of Art",
  address   = "London",
  pages     =  9,
  abstract  = "An exploration of the nature of research in art and design. What
               constitutes research in these fields and how does it differ from
               practice-led art and design? The author also considers the
               prevailing and misleading stereotypes of the researcher which
               distract us from the true nature of the task.",
  year      =  1994,
  language  = "en"
}

@INCOLLECTION{Zimmerman2014-qa,
  title     = "Research Through Design in {HCI}",
  author    = "Zimmerman, John and Forlizzi, Jodi",
  editor    = "Olson, Judith S and Kellogg, Wendy A",
  booktitle = "Ways of Knowing in HCI",
  publisher = "Springer New York",
  address   = "New York, NY",
  pages     = "167--189",
  abstract  = "In Research through Design (RtD), researchers generate new
               knowledge by understanding the current state and then suggesting
               an improved future state in the form of a design. It involves
               deep reflection in iteratively understanding the people, problem,
               and context around a situation that researchers feel they can
               improve.",
  year      =  2014
}

@ARTICLE{Csikszentmihalyi_undated-ct,
  title   = "Flow and the psychology of discovery and invention",
  author  = "{Csikszentmihalyi}",
  journal = "HarperPerennial, New York"
}

@ARTICLE{Read_undated-bq,
  title   = "Endurability, engagement and expectations: Measuring children's fun",
  author  = "{Read} and {MacFarlane} and {Casey}",
  journal = "design and children"
}

@ARTICLE{Makela2018-mj,
  title     = "Documentation as a practice-led research tool for reflection on
               experiential knowledge",
  author    = "Mäkelä, Maarit and Nimkulrat, Nithikul",
  journal   = "FORMakademisk",
  publisher = "OsloMet - Oslo Metropolitan University",
  volume    =  11,
  number    =  2,
  abstract  = "Practice-led research has been under debate for three decades.
               One of its major issues concerns how the researcher who is also
               the practitioner documents and reflects on her creative process
               in relation to a research topic. This article reviews and
               discusses documentation and reflection in practice-led research
               through three cases of doctoral dissertations that were completed
               at Aalto University in Finland. Through the cases the article
               examines the role the documentation and reflection of creative
               processes and products in these studies. In conclusion,
               documentation in the practice-led research context functions as
               conscious reflection on and in action. Any means of
               documentation, for example diary writing, photographing, or
               sketching, can serve as a mode of reflection.",
  month     =  may,
  year      =  2018,
  language  = "en"
}

@ARTICLE{Saharia2022-qj,
  title         = "Photorealistic Text-to-Image Diffusion Models with Deep
                   Language Understanding",
  author        = "Saharia, Chitwan and Chan, William and Saxena, Saurabh and
                   Li, Lala and Whang, Jay and Denton, Emily and Ghasemipour,
                   Seyed Kamyar Seyed and Ayan, Burcu Karagol and Sara Mahdavi,
                   S and Lopes, Rapha Gontijo and Salimans, Tim and Ho, Jonathan
                   and Fleet, David J and Norouzi, Mohammad",
  journal       = "arXiv [cs.CV]",
  abstract      = "We present Imagen, a text-to-image diffusion model with an
                   unprecedented degree of photorealism and a deep level of
                   language understanding. Imagen builds on the power of large
                   transformer language models in understanding text and hinges
                   on the strength of diffusion models in high-fidelity image
                   generation. Our key discovery is that generic large language
                   models (e.g. T5), pretrained on text-only corpora, are
                   surprisingly effective at encoding text for image synthesis:
                   increasing the size of the language model in Imagen boosts
                   both sample fidelity and image-text alignment much more than
                   increasing the size of the image diffusion model. Imagen
                   achieves a new state-of-the-art FID score of 7.27 on the COCO
                   dataset, without ever training on COCO, and human raters find
                   Imagen samples to be on par with the COCO data itself in
                   image-text alignment. To assess text-to-image models in
                   greater depth, we introduce DrawBench, a comprehensive and
                   challenging benchmark for text-to-image models. With
                   DrawBench, we compare Imagen with recent methods including
                   VQ-GAN+CLIP, Latent Diffusion Models, and DALL-E 2, and find
                   that human raters prefer Imagen over other models in
                   side-by-side comparisons, both in terms of sample quality and
                   image-text alignment. See https://imagen.research.google/ for
                   an overview of the results.",
  month         =  may,
  year          =  2022,
  archivePrefix = "arXiv",
  primaryClass  = "cs.CV"
}

@ARTICLE{Anantrasirichai2022-vy,
  title     = "Artificial intelligence in the creative industries: a review",
  author    = "Anantrasirichai, Nantheera and Bull, David",
  journal   = "Artif. Intell. Rev.",
  publisher = "Springer Science and Business Media LLC",
  volume    =  55,
  number    =  1,
  pages     = "589--656",
  abstract  = "AbstractThis paper reviews the current state of the art in
               artificial intelligence (AI) technologies and applications in the
               context of the creative industries. A brief background of AI, and
               specifically machine learning (ML) algorithms, is provided
               including convolutional neural networks (CNNs), generative
               adversarial networks (GANs), recurrent neural networks (RNNs) and
               deep Reinforcement Learning (DRL). We categorize creative
               applications into five groups, related to how AI technologies are
               used: (i) content creation, (ii) information analysis, (iii)
               content enhancement and post production workflows, (iv)
               information extraction and enhancement, and (v) data compression.
               We critically examine the successes and limitations of this
               rapidly advancing technology in each of these areas. We further
               differentiate between the use of AI as a creative tool and its
               potential as a creator in its own right. We foresee that, in the
               near future, ML-based AI will be adopted widely as a tool or
               collaborative assistant for creativity. In contrast, we observe
               that the successes of ML in domains with fewer constraints, where
               AI is the ‘creator’, remain modest. The potential of AI (or its
               developers) to win awards for its original creations in
               competition with human creatives is also limited, based on
               contemporary technologies. We therefore conclude that, in the
               context of creative industries, maximum benefit from AI will be
               derived where its focus is human-centric—where it is designed to
               augment, rather than replace, human creativity.",
  month     =  jan,
  year      =  2022,
  language  = "en"
}

@ARTICLE{Novick_undated-fg,
  title   = "What is mixed-initiative interaction",
  author  = "{Novick} and {Sutton}",
  journal = "Proceedings of the AAAI spring symposium on"
}

@ARTICLE{Bansal2019-mp,
  title    = "Beyond Accuracy: The Role of Mental Models in Human-{AI} Team
              Performance",
  author   = "Bansal, Gagan and Nushi, Besmira and Kamar, Ece and Lasecki,
              Walter S and Weld, Daniel S and Horvitz, E",
  journal  = "AAAI 2019",
  abstract = "This work highlights two key properties of an AI’s error boundary,
              parsimony and stochasticity, and a property of the task,
              dimensionality, and shows experimentally how these properties
              affect humans’ mental models of AI capabilities and the resulting
              team performance. Decisions made by human-AI teams (e.g.,
              AI-advised humans) are increasingly common in high-stakes domains
              such as healthcare, criminal justice, and finance. Achieving high
              team performance depends on more than just the accuracy of the AI
              system: Since the human and the AI may have different expertise,
              the highest team performance is often reached when they both know
              how and when to complement one another. We focus on a factor that
              is crucial to supporting such complementary: the human’s mental
              model of the AI capabilities, specifically the AI system’s error
              boundary (i.e. knowing “When does the AI err?”). Awareness of this
              lets the human decide when to accept or override the AI’s
              recommendation. We highlight two key properties of an AI’s error
              boundary, parsimony and stochasticity, and a property of the task,
              dimensionality. We show experimentally how these properties affect
              humans’ mental models of AI capabilities and the resulting team
              performance. We connect our evaluations to related work and
              propose goals, beyond accuracy, that merit consideration during
              model selection and optimization to improve overall human-AI team
              performance.",
  year     =  2019,
  language = "en"
}

@INPROCEEDINGS{Zhu2018-zd,
  title     = "Explainable {AI} for designers: A human-centered perspective on
               mixed-initiative co-creation",
  author    = "Zhu, Jichen and Liapis, Antonios and Risi, Sebastian and Bidarra,
               Rafael and Youngblood, G Michael",
  booktitle = "2018 IEEE Conference on Computational Intelligence and Games
               (CIG)",
  publisher = "IEEE",
  abstract  = "This vision paper proposes a new research area of eXplainable AI
               for Designers (XAID), specifically for game designers, and
               illustrates the initial XAID framework through three use cases,
               which require an understanding both of the innate properties of
               the AI techniques and users’ needs. Growing interest in
               eXplainable Artificial Intelligence (XAI) aims to make AI and
               machine learning more understandable to human users. However,
               most existing work focuses on new algorithms, and not on
               usability, practical interpretability and efficacy on real users.
               In this vision paper, we propose a new research area of
               eXplainable AI for Designers (XAID), specifically for game
               designers. By focusing on a specific user group, their needs and
               tasks, we propose a human-centered approach for facilitating game
               designers to co-create with AI/ML techniques through XAID. We
               illustrate our initial XAID framework through three use cases,
               which require an understanding both of the innate properties of
               the AI techniques and users’ needs, and we identify key open
               challenges.",
  month     =  aug,
  year      =  2018,
  language  = "en"
}

@INPROCEEDINGS{Oh2018-mu,
  title     = "{I} lead, you help but only with enough details",
  author    = "Oh, Changhoon and Song, Jungwoo and Choi, Jinhan and Kim,
               Seonghyeon and Lee, Sungwoo and Suh, Bongwon",
  booktitle = "Proceedings of the 2018 CHI Conference on Human Factors in
               Computing Systems",
  publisher = "ACM",
  address   = "New York, NY, USA",
  abstract  = "A prototype, DuetDraw, an AI interface that allows users and the
               AI agent to draw pictures collaboratively and implications for
               user interfaces where users can collaborate with AI in creative
               works are discussed. Recent advances in artificial intelligence
               (AI) have increased the opportunities for users to interact with
               the technology. Now, users can even collaborate with AI in
               creative activities such as art. To understand the user
               experience in this new user--AI collaboration, we designed a
               prototype, DuetDraw, an AI interface that allows users and the AI
               agent to draw pictures collaboratively. We conducted a user study
               employing both quantitative and qualitative methods. Thirty
               participants performed a series of drawing tasks with the
               think-aloud method, followed by post-hoc surveys and interviews.
               Our findings are as follows: (1) Users were significantly more
               content with DuetDraw when the tool gave detailed instructions.
               (2) While users always wanted to lead the task, they also wanted
               the AI to explain its intentions but only when the users wanted
               it to do so. (3) Although users rated the AI relatively low in
               predictability, controllability, and comprehensibility, they
               enjoyed their interactions with it during the task. Based on
               these findings, we discuss implications for user interfaces where
               users can collaborate with AI in creative works.",
  month     =  apr,
  year      =  2018,
  language  = "en"
}

@INPROCEEDINGS{Dellermann2019-ze,
  title     = "The future of human-{AI} collaboration: A taxonomy of design
               knowledge for hybrid intelligence systems",
  author    = "Dellermann, Dominik and Calma, Adrian and Lipusch, Nikolaus and
               Weber, Thorsten and Weigel, Sascha and Ebel, Philipp",
  booktitle = "Proceedings of the 52nd Hawaii International Conference on System
               Sciences",
  publisher = "Hawaii International Conference on System Sciences",
  abstract  = "Recent technological advances, especially in the field of machine
               learning, provide astonishing progress on the road towards
               artificial general intelligence. However, tasks in current
               real-world business applications cannot yet be solved by machines
               alone. We, therefore, identify the need for developing
               socio-technological ensembles of humans and machines. Such
               systems possess the ability to accomplish complex goals by
               combining human and artificial intelligence to collectively
               achieve superior results and continuously improve by learning
               from each other. Thus, the need for structured design knowledge
               for those systems arises. Following a taxonomy development
               method, this article provides three main contributions: First, we
               present a structured overview of interdisciplinary research on
               the role of humans in the machine learning pipeline. Second, we
               envision hybrid intelligence systems and conceptualize the
               relevant dimensions for system design for the first time.
               Finally, we offer useful guidance for system developers during
               the implementation of such applications.",
  year      =  2019,
  language  = "en"
}

@ARTICLE{Liapis2016-bv,
  title    = "Can Computers Foster Human Users’ Creativity? Theory and Praxis of
              Mixed-Initiative Co-Creativity",
  author   = "Liapis, Antonios and Yannakakis, Georgios N and Alexopoulos,
              Constantine and Lopes, P",
  abstract = "This article discusses the impact of artificially intelligent
              computers to the process of design, play and educational
              activities. A computational process which has the necessary
              intelligence and creativity to take a proactive role in such
              activities can not only support human creativity but also foster
              it and prompt lateral thinking. The argument is made both from the
              perspective of human creativity, where the computational input is
              treated as an external stimulus which triggers re-framing of
              humans’ routines and mental associations, but also from the
              perspective of computational creativity where human input and
              initiative constrains the search space of the algorithm, enabling
              it to focus on specific possible solutions to a problem rather
              than globally search for the optimal. The article reviews four
              mixed-initiative tools (for design and educational play) based on
              how they contribute to human-machine co-creativity. These
              paradigms serve different purposes, afford different human
              interaction methods and incorporate different computationally
              creative processes. Assessing how co-creativity is facilitated on
              a per-paradigm basis strengthens the theoretical argument and
              provides an initial seed for future work in the burgeoning domain
              of mixed-initiative interaction.",
  year     =  2016,
  language = "en"
}

@INPROCEEDINGS{Louie2020-aq,
  title     = "Novice-{AI} music co-creation via {AI}-steering tools for deep
               generative models",
  author    = "Louie, Ryan and Coenen, Andy and Huang, Cheng Zhi and Terry,
               Michael and Cai, Carrie J",
  booktitle = "Proceedings of the 2020 CHI Conference on Human Factors in
               Computing Systems",
  publisher = "ACM",
  address   = "New York, NY, USA",
  abstract  = "AI-steering tools were developed that increased users' trust,
               control, comprehension, and sense of collaboration with the AI,
               but also contributed to a greater sense of self-efficacy and
               ownership of the composition relative to the AI. While generative
               deep neural networks (DNNs) have demonstrated their capacity for
               creating novel musical compositions, less attention has been paid
               to the challenges and potential of co-creating with these musical
               AIs, especially for novices. In a needfinding study with a widely
               used, interactive musical AI, we found that the AI can overwhelm
               users with the amount of musical content it generates, and
               frustrate them with its non-deterministic output. To better match
               co-creation needs, we developed AI-steering tools, consisting of
               Voice Lanes that restrict content generation to particular
               voices; Example-Based Sliders to control the similarity of
               generated content to an existing example; Semantic Sliders to
               nudge music generation in high-level directions (happy/sad,
               conventional/surprising); and Multiple Alternatives of generated
               content to audition and choose from. In a summative study (N=21),
               we discovered the tools not only increased users' trust, control,
               comprehension, and sense of collaboration with the AI, but also
               contributed to a greater sense of self-efficacy and ownership of
               the composition relative to the AI.",
  month     =  apr,
  year      =  2020,
  language  = "en"
}

@ARTICLE{Kantosalo2016-de,
  title    = "Modes for Creative Human-Computer Collaboration: Alternating and
              Task-Divided Co-Creativity",
  author   = "Kantosalo, Anna and Toivonen, Hannu (tt)",
  journal  = "ICCC",
  abstract = "Different styles of human- computer co-creation from a more
              computational perspective are examined, presenting new concepts
              for analysis of computational agents in human-computer cocreation.
              The analysis of human-computer co-creative systems in current
              literature is focused on a human perspective, highlighting the
              benefits of co-creative systems for human users. This study paper
              examines different styles of human-computer co-creation from a
              more computational perspective, presenting new concepts for
              analysis of computational agents in human-computer cocreation. Our
              perspective is based on Wiggins’ formalization of creativity as a
              search. We formalize for co-creative scenarios involving an
              alternating, iterative approach to co-creation, which we call
              alternating cocreativity and briefly discuss its non-alternating
              counterpart, task-divided co-creativity. With focus on alternating
              co-creativity, we analyze the co-creative process and discuss new
              modes and roles for the creative agents within it. Finally, we
              illustrate our theoretical findings in the context of current
              co-creative systems and discuss their relation to the roles and
              expectations presented in",
  year     =  2016,
  language = "en"
}

@INPROCEEDINGS{McCormack2019-yh,
  title     = "In a silent way",
  author    = "McCormack, Jon and Gifford, Toby and Hutchings, Patrick and Llano
               Rodriguez, Maria Teresa and Yee-King, Matthew and d'Inverno, Mark",
  booktitle = "Proceedings of the 2019 CHI Conference on Human Factors in
               Computing Systems",
  publisher = "ACM",
  address   = "New York, NY, USA",
  abstract  = "A collaborative improvising AI drummer is developed that
               communicates its confidence through an emoticon-based
               visualisation that shows a positive correlation between
               extra-musical communication of machine internal state and human
               musical engagement. Collaboration is built on trust, and
               establishing trust with a creative Artificial Intelligence is
               difficult when the decision process or internal state driving its
               behaviour isn't exposed. When human musicians improvise together,
               a number of extra-musical cues are used to augment musical
               communication and expose mental or emotional states which affect
               musical decisions and the effectiveness of the collaboration. We
               developed a collaborative improvising AI drummer that
               communicates its confidence through an emoticon-based
               visualisation. The AI was trained on musical performance data, as
               well as real-time skin conductance, of musicians improvising with
               professional drummers, exposing both musical and extra-musical
               cues to inform its generative process. Uni- and bi-directional
               extra-musical communication with real and false values were
               tested by experienced improvising musicians. Each condition was
               evaluated using the FSS-2 questionnaire, as a proxy for musical
               engagement. The results show a positive correlation between
               extra-musical communication of machine internal state and human
               musical engagement.",
  month     =  may,
  year      =  2019,
  language  = "en"
}

@INPROCEEDINGS{Liang2019-gy,
  title     = "Implicit Communication of Actionable Information in Human-{AI}
               teams",
  author    = "Liang, Claire and Proft, Julia and Andersen, Erik and Knepper,
               Ross A",
  booktitle = "Proceedings of the 2019 CHI Conference on Human Factors in
               Computing Systems",
  publisher = "ACM",
  address   = "New York, NY, USA",
  abstract  = "In a user study with 904 completed games and 246 completed
               surveys, human players randomly paired with an implicature AI are
               71\% more likely to think their partner is human than players
               paired with a non-implicatureAI. Humans expect their
               collaborators to look beyond the explicit interpretation of their
               words. Implicature is a common form of implicit communication
               that arises in natural language discourse when an utterance
               leverages context to imply information beyond what the words
               literally convey. Whereas computational methods have been
               proposed for interpreting and using different forms of
               implicature, its role in human and artificial agent collaboration
               has not yet been explored in a concrete domain. The results of
               this paper provide insights to how artificial agents should be
               structured to facilitate natural and efficient communication of
               actionable information with humans. We investigated implicature
               by implementing two strategies for playing Hanabi, a cooperative
               card game that relies heavily on communication of actionable
               implicit information to achieve a shared goal. In a user study
               with 904 completed games and 246 completed surveys, human players
               randomly paired with an implicature AI are 71\% more likely to
               think their partner is human than players paired with a
               non-implicature AI. These teams demonstrated game performance
               similar to other state of the art approaches.",
  month     =  may,
  year      =  2019,
  language  = "en"
}

@INPROCEEDINGS{Huang2020-fh,
  title     = "{AI} song contest: Human-{AI} co-creation in songwriting",
  author    = "Huang, Cheng-Zhi Anna and Koops, Hendrik Vincent and Newton-Rex,
               Ed and Dinculescu, Monica and Cai, Carrie",
  publisher = "Zenodo",
  abstract  = "Machine learning is challenging the way we make music. Although
               research in deep generative models has dramatically improved the
               capability and fluency of music models, recent work has shown
               that it can be challenging for humans to partner with this new
               class of algorithms. In this paper, we present findings on what
               13 musician/developer teams, a total of 61 users, needed when
               co-creating a song with AI, the challenges they faced, and how
               they leveraged and repurposed existing characteristics of AI to
               overcome some of these challenges. Many teams adopted modular
               approaches, such as independently running multiple smaller models
               that align with the musical building blocks of a song, before
               re-combining their results. As ML models are not easily
               steerable, teams also generated massive numbers of samples and
               curated them post-hoc, or used a range of strategies to direct
               the generation or algorithmically ranked the samples. Ultimately,
               teams not only had to manage the ``flare and focus'' aspects of
               the creative process, but also juggle that with a parallel
               process of exploring and curating multiple ML models and outputs.
               These findings reflect a need to design machine learning-powered
               music interfaces that are more decomposable, steerable,
               interpretable, and adaptive, which in return will enable artists
               to more effectively explore how AI can extend their personal
               expression.",
  year      =  2020,
  language  = "en"
}

@INPROCEEDINGS{Weisz2021-iu,
  title     = "Perfection not required? Human-{AI} partnerships in code
               translation",
  author    = "Weisz, Justin D and Muller, Michael and Houde, Stephanie and
               Richards, John and Ross, Steven I and Martinez, Fernando and
               Agarwal, Mayank and Talamadupula, Kartik",
  booktitle = "26th International Conference on Intelligent User Interfaces",
  publisher = "ACM",
  address   = "New York, NY, USA",
  abstract  = "This study highlights how UI features such as confidence
               highlighting and alternate translations help software engineers
               work with and better understand generative NMT models. Generative
               models have become adept at producing artifacts such as images,
               videos, and prose at human-like levels of proficiency. New
               generative techniques, such as unsupervised neural machine
               translation (NMT), have recently been applied to the task of
               generating source code, translating it from one programming
               language to another. The artifacts produced in this way may
               contain imperfections, such as compilation or logical errors. We
               examine the extent to which software engineers would tolerate
               such imperfections and explore ways to aid the detection and
               correction of those errors. Using a design scenario approach, we
               interviewed 11 software engineers to understand their reactions
               to the use of an NMT model in the context of application
               modernization, focusing on the task of translating source code
               from one language to another. Our three-stage scenario sparked
               discussions about the utility and desirability of working with an
               imperfect AI system, how acceptance of that system’s outputs
               would be established, and future opportunities for generative AI
               in application modernization. Our study highlights how UI
               features such as confidence highlighting and alternate
               translations help software engineers work with and better
               understand generative NMT models.",
  month     =  apr,
  year      =  2021,
  language  = "en"
}

@INPROCEEDINGS{Long2019-lw,
  title     = "Designing co-creative {AI} for public spaces",
  author    = "Long, Duri and Jacob, Mikhail and Magerko, Brian",
  booktitle = "Proceedings of the 2019 on Creativity and Cognition",
  publisher = "ACM",
  address   = "New York, NY, USA",
  abstract  = "Artificial intelligence (AI) is becoming increasingly pervasive
               in our everyday lives. There are consequently many common
               misconceptions about what AI is, what it is capable of, and how
               it works. Compounding the issue, opportunities to learn about AI
               are often limited to audiences who already have access to and
               knowledge about technology. Increasing access to AI in public
               spaces has the potential to broaden public AI literacy, and
               experiences involving co-creative (i.e. collaboratively creative)
               AI are particularly well-suited for engaging a broad range of
               participants. This paper explores how to design co-creative AI
               for public interaction spaces, drawing both on existing
               literature and our own experiences designing co-creative AI for
               public venues. It presents a set of design principles that can
               aid others in the development of co-creative AI for public spaces
               as well as guide future research agendas.",
  month     =  jun,
  year      =  2019,
  language  = "en"
}

@ARTICLE{Khadpe2020-jf,
  title     = "Conceptual metaphors impact perceptions of human-{AI}
               collaboration",
  author    = "Khadpe, Pranav and Krishna, Ranjay and Fei-Fei, Li and Hancock,
               Jeffrey T and Bernstein, Michael S",
  journal   = "Proc. ACM Hum. Comput. Interact.",
  publisher = "Association for Computing Machinery (ACM)",
  volume    =  4,
  number    = "CSCW2",
  pages     = "1--26",
  abstract  = "It is suggested that projecting competence may help attract new
               users, but those users may discard the agent unless it can
               quickly correct with a lower competence metaphor, and that users
               are drawn to systems that project higher competence and warmth.
               With the emergence of conversational artificial intelligence (AI)
               agents, it is important to understand the mechanisms that
               influence users' experiences of these agents. In this paper, we
               study one of the most common tools in the designer's toolkit:
               conceptual metaphors. Metaphors can present an agent as akin to a
               wry teenager, a toddler, or an experienced butler. How might a
               choice of metaphor influence our experience of the AI agent?
               Sampling a set of metaphors along the dimensions of warmth and
               competence---defined by psychological theories as the primary
               axes of variation for human social perception---we perform a
               study $(N=260)$ where we manipulate the metaphor, but not the
               behavior, of a Wizard-of-Oz conversational agent. Following the
               experience, participants are surveyed about their intention to
               use the agent, their desire to cooperate with the agent, and the
               agent's usability. Contrary to the current tendency of designers
               to use high competence metaphors to describe AI products, we find
               that metaphors that signal low competence lead to better
               evaluations of the agent than metaphors that signal high
               competence. This effect persists despite both high and low
               competence agents featuring identical, human-level performance
               and the wizards being blind to condition. A second study confirms
               that intention to adopt decreases rapidly as competence projected
               by the metaphor increases. In a third study, we assess effects of
               metaphor choices on potential users' desire to try out the system
               and find that users are drawn to systems that project higher
               competence and warmth. These results suggest that projecting
               competence may help attract new users, but those users may
               discard the agent unless it can quickly correct with a lower
               competence metaphor. We close with a retrospective analysis that
               finds similar patterns between metaphors and user attitudes
               towards past conversational agents such as Xiaoice, Replika,
               Woebot, Mitsuku, and Tay.",
  month     =  oct,
  year      =  2020,
  language  = "en"
}

@ARTICLE{Karimi2019-io,
  title    = "Deep Learning in a Computational Model for Conceptual Shifts in a
              Co-Creative Design System",
  author   = "Karimi, Pegah and Maher, M and Davis, N and Grace, Kazjon",
  journal  = "ICCC",
  abstract = "The paper presents the results of a user study showing that
              increasing novelty in the AI contribution is associated with
              higher creative outcomes, whereas low novelty leads to less
              creative outcomes. This paper presents a computational model for
              conceptual shifts, based on a novelty metric applied to a vector
              representation generated through deep learning. This model is
              integrated into a co-creative design system, which enables a
              partnership between an AI agent and a human designer interacting
              through a sketching canvas. The AI agent responds to the human
              designer's sketch with a new sketch that is a conceptual shift:
              intentionally varying the visual and conceptual similarity with
              increasingly more novelty. The paper presents the results of a
              user study showing that increasing novelty in the AI contribution
              is associated with higher creative outcomes, whereas low novelty
              leads to less creative outcomes.",
  year     =  2019,
  language = "en"
}

@ARTICLE{Coenen2021-ym,
  title    = "Wordcraft: a Human-{AI} Collaborative Editor for Story Writing",
  author   = "Coenen, Andy and Davis, Luke and Ippolito, Daphne and Reif, Emily
              and Yuan, Ann",
  journal  = "ArXiv",
  abstract = "Wordcraft, an AI-assisted editor for story writing in which a
              writer and a dialog system collaborate to write a story is
              proposed, which provides a sandbox for writers to probe the
              boundaries of transformer-based language models and paves the way
              for future human-in-the-loop training pipelines and novel
              evaluation methods. As neural language models grow in
              effectiveness, they are increasingly being applied in real-world
              settings. However these applications tend to be limited in the
              modes of interaction they support. In this extended abstract, we
              propose Wordcraft, an AI-assisted editor for story writing in
              which a writer and a dialog system collaborate to write a story.
              Our novel interface uses few-shot learning and the natural
              affordances of conversation to support a variety of interactions.
              Our editor provides a sandbox for writers to probe the boundaries
              of transformer-based language models and paves the way for future
              human-in-the-loop training pipelines and novel evaluation methods.",
  year     =  2021,
  language = "en"
}

@ARTICLE{Guzdial2019-tz,
  title    = "An Interaction Framework for Studying Co-Creative {AI}",
  author   = "Guzdial, Matthew J and Riedl, Mark O",
  journal  = "ArXiv",
  abstract = "A general framework for turn-based interaction between human users
              and AI agents designed to support human creativity, called
              co-creative systems is proposed and can be used to better
              understand the space of possible designs of co-Creative systems
              and reveal future research directions. Machine learning has been
              applied to a number of creative, design-oriented tasks. However,
              it remains unclear how to best empower human users with these
              machine learning approaches, particularly those users without
              technical expertise. In this paper we propose a general framework
              for turn-based interaction between human users and AI agents
              designed to support human creativity, called {co-creative
              systems}. The framework can be used to better understand the space
              of possible designs of co-creative systems and reveal future
              research directions. We demonstrate how to apply this framework in
              conjunction with a pair of recent human subject studies, comparing
              between the four human-AI systems employed in these studies and
              generating hypotheses towards future studies.",
  year     =  2019,
  language = "en"
}

@ARTICLE{McCormack2020-ix,
  title     = "Design considerations for real-time collaboration with creative
               artificial intelligence",
  author    = "McCormack, Jon and Hutchings, Patrick and Gifford, Toby and
               Yee-King, Matthew and Llano, Maria Teresa and D'inverno, Mark",
  journal   = "Organised sound",
  publisher = "Cambridge University Press (CUP)",
  volume    =  25,
  number    =  1,
  pages     = "41--52",
  abstract  = "Machines incorporating techniques from artificial intelligence
               and machine learning can work with human users on a
               moment-to-moment, real-time basis to generate creative outcomes,
               performances and artefacts. We define such systems collaborative,
               creative AI systems, and in this article, consider the
               theoretical and practical considerations needed for their design
               so as to support improvisation, performance and co-creation
               through real-time, sustained, moment-to-moment interaction. We
               begin by providing an overview of creative AI systems, examining
               strengths, opportunities and criticisms in order to draw out the
               key considerations when designing AI for human creative
               collaboration. We argue that the artistic goals and creative
               process should be first and foremost in any design. We then draw
               from a range of research that looks at human collaboration and
               teamwork, to examine features that support trust, cooperation,
               shared awareness and a shared information space. We highlight the
               importance of understanding the scope and perception of two-way
               communication between human and machine agents in order to
               support reflection on conflict, error, evaluation and flow. We
               conclude with a summary of the range of design challenges for
               building such systems in provoking, challenging and enhancing
               human creative activity through their creative agency.",
  month     =  apr,
  year      =  2020,
  language  = "en"
}

@INPROCEEDINGS{Wang2021-uy,
  title     = "Towards mutual theory of mind in human-{AI} interaction: How
               language reflects what students perceive about a virtual teaching
               assistant",
  author    = "Wang, Qiaosi and Saha, Koustuv and Gregori, Eric and Joyner,
               David and Goel, Ashok",
  booktitle = "Proceedings of the 2021 CHI Conference on Human Factors in
               Computing Systems",
  publisher = "ACM",
  address   = "New York, NY, USA",
  abstract  = "It is found that students’ perception of Jill Watson’s
               anthropomorphism and intelligence changed significantly over
               time, andRegression analyses reveal that linguistic verbosity,
               readability, sentiment, diversity, and adaptability reflect
               student perception of JW. Building conversational agents that can
               conduct natural and prolonged conversations has been a major
               technical and design challenge, especially for community-facing
               conversational agents. We posit Mutual Theory of Mind as a
               theoretical framework to design for natural long-term human-AI
               interactions. From this perspective, we explore a community’s
               perception of a question-answering conversational agent through
               self-reported surveys and computational linguistic approach in
               the context of online education. We first examine long-term
               temporal changes in students’ perception of Jill Watson (JW), a
               virtual teaching assistant deployed in an online class discussion
               forum. We then explore the feasibility of inferring students’
               perceptions of JW through linguistic features extracted from
               student-JW dialogues. We find that students’ perception of JW’s
               anthropomorphism and intelligence changed significantly over
               time. Regression analyses reveal that linguistic verbosity,
               readability, sentiment, diversity, and adaptability reflect
               student perception of JW. We discuss implications for building
               adaptive community-facing conversational agents as long-term
               companions and designing towards Mutual Theory of Mind in
               human-AI interaction.",
  month     =  may,
  year      =  2021,
  language  = "en"
}

@INPROCEEDINGS{Eiband2021-vj,
  title     = "How to support users in understanding intelligent systems?
               Structuring the discussion",
  author    = "Eiband, Malin and Buschek, Daniel and Hussmann, Heinrich",
  booktitle = "26th International Conference on Intelligent User Interfaces",
  publisher = "ACM",
  address   = "New York, NY, USA",
  abstract  = "This work reviews the literature in HCI through the lens of
               implied user questions to synthesise a conceptual framework
               integrating user mindsets, user involvement, and knowledge
               outcomes to reveal, differentiate and classify current notions in
               prior work. The opaque nature of many intelligent systems
               violates established usability principles and thus presents a
               challenge for human-computer interaction. Research in the field
               therefore highlights the need for transparency, scrutability,
               intelligibility, interpretability and explainability, among
               others. While all of these terms carry a vision of supporting
               users in understanding intelligent systems, the underlying
               notions and assumptions about users and their interaction with
               the system often remain unclear. We review the literature in HCI
               through the lens of implied user questions to synthesise a
               conceptual framework integrating user mindsets, user involvement,
               and knowledge outcomes to reveal, differentiate and classify
               current notions in prior work. This framework aims to resolve
               conceptual ambiguity in the field and enables researchers to
               clarify their assumptions and become aware of those made in prior
               work. We thus hope to advance and structure the dialogue in the
               HCI research community on supporting users in understanding
               intelligent systems.",
  month     =  apr,
  year      =  2021,
  language  = "en"
}

@ARTICLE{Llano2022-ti,
  title     = "Explainable Computational Creativity",
  author    = "Llano, Maria Teresa and d'Inverno, Mark and Yee-King, Matthew and
               McCormack, Jon and Ilsar, Alon and Pease, Alison and Colton,
               Simon",
  journal   = "ICCC",
  publisher = "arXiv",
  abstract  = "Human collaboration with systems within the Computational
               Creativity (CC) field is often restricted to shallow
               interactions, where the creative processes, of systems and humans
               alike, are carried out in isolation, without any (or little)
               intervention from the user, and without any discussion about how
               the unfolding decisions are taking place. Fruitful co-creation
               requires a sustained ongoing interaction that can include
               discussions of ideas, comparisons to previous/other works,
               incremental improvements and revisions, etc. For these
               interactions, communication is an intrinsic factor. This means
               giving a voice to CC systems and enabling two-way communication
               channels between them and their users so that they can: explain
               their processes and decisions, support their ideas so that these
               are given serious consideration by their creative collaborators,
               and learn from these discussions to further improve their
               creative processes. For this, we propose a set of design
               principles for CC systems that aim at supporting greater
               co-creation and collaboration with their human collaborators.",
  year      =  2022,
  language  = "en"
}

@INPROCEEDINGS{Law2019-ns,
  title     = "Negotiating the creative space in human-robot collaborative
               design",
  author    = "Law, Matthew V and Jeong, Jihyun and Kwatra, Amritansh and Jung,
               Malte F and Hoffman, Guy",
  booktitle = "Proceedings of the 2019 on Designing Interactive Systems
               Conference",
  publisher = "ACM",
  address   = "New York, NY, USA",
  abstract  = "We describe a physical interactive system for human-robot
               collaborative design (HRCD) consisting of a tangible user
               interface (TUI) and a robotic arm that simultaneously manipulates
               the TUI with the human designer. In an observational study of 12
               participants exploring a complex design problem together with the
               robot, we find that human designers have to negotiate both the
               physical and the creative space with the machine. They also often
               ascribe social meaning to the robot's pragmatic behaviors. Based
               on these findings, we propose four considerations for future HRCD
               systems: managing the shared workspace, communicating preferences
               about design goals, respecting different design styles, and
               taking into account the social meaning of design acts.",
  month     =  jun,
  year      =  2019,
  language  = "en"
}

@INPROCEEDINGS{Hodhod2016-mx,
  title     = "Closing the cognitive gap between humans and interactive
               narrative agents using shared mental models",
  author    = "Hodhod, Rania and Magerko, Brian",
  booktitle = "Proceedings of the 21st International Conference on Intelligent
               User Interfaces",
  publisher = "ACM",
  address   = "New York, NY, USA",
  abstract  = "This paper proposes a new formal approach for negotiating shared
               mental models between humans and computational improvisational
               agents (improv agents) based on our sociocognitive studies of
               human improvisers. Negotiation of shared mental models serves as
               a core mechanism for improv agents to co-create stories with each
               other and with human interactors. The model aims to narrow the
               gap between human and machine intelligence by providing AI agents
               that, in the presence of incomplete knowledge about an improv
               scene, can use procedural representations not only to understand
               human parties but also to negotiate their mental models with
               them. The described approach allows flexible modeling of
               ambiguous, non-Boolean knowledge through the use of fuzzy logic
               and situation calculus that allows reasoning under uncertainty in
               a dynamic improvisational setting.",
  month     =  mar,
  year      =  2016,
  language  = "en"
}

@ARTICLE{Wright2020-nt,
  title    = "A Comparative Analysis of Industry Human-{AI} Interaction
              Guidelines",
  author   = "Wright, Austin P and Wang, Zijie J and Park, Haekyu and Guo, G and
              Sperrle, F and El-Assady, Mennatallah and Endert, A and Keim, D
              and Chau, Duen Horng",
  journal  = "ArXiv",
  abstract = "This work has surveyed all of the design guidelines from each of
              these major companies and developed a single, unified structure of
              guidelines, giving developers a centralized reference of AI design
              guidelines. With the recent release of AI interaction guidelines
              from Apple, Google, and Microsoft, there is clearly interest in
              understanding the best practices in human-AI interaction. However,
              industry standards are not determined by a single company, but
              rather by the synthesis of knowledge from the whole community. We
              have surveyed all of the design guidelines from each of these
              major companies and developed a single, unified structure of
              guidelines, giving developers a centralized reference. We have
              then used this framework to compare each of the surveyed companies
              to find differences in areas of emphasis. Finally, we encourage
              people to contribute additional guidelines from other companies,
              academia, or individuals, to provide an open and extensible
              reference of AI design guidelines at this https URL.",
  year     =  2020,
  language = "en"
}

@ARTICLE{Kantosalo2019-pz,
  title    = "Human-Computer Co-Creativity : Designing, Evaluating and Modelling
              Computational Collaborators for Poetry Writing",
  author   = "Kantosalo, Anna",
  abstract = "Human-computer co-creativity examines creative collaboration
              between humans and artificially intelligent computational agents.
              Human-computer co-creativity researchers assume that instead of
              using computational systems to merely automate creative tasks,
              computational creativity methods can be leveraged to design
              computational collaborators capable of sharing creative
              responsibility with a human collaborator. This has potential for
              extending both human and computational creative capability. This
              thesis focuses on the case of one human and one computational
              collaborator. More specifically this thesis studies how children
              collaborate with a computational collaborator called the Poetry
              Machine in the linguistically creative task of writing poems. This
              thesis investigates three topics related to human-computer
              co-creativity: The design of human-computer co-creative systems,
              their evaluation and the modelling of human-computer co-creative
              processes. These topics are approached from two perspectives: an
              interaction design perspective and a computational creativity
              perspective. The interaction design perspective provides practical
              methods for the design and evaluation of interactive systems as
              well as methodological frameworks for analysing design practices
              in the field. The computational creativity perspective then again
              provides a theoretical view to the evaluation and modelling of
              human-computer cocreativity. The thesis itself consists of five
              papers.",
  year     =  2019,
  language = "en"
}

@ARTICLE{Winston2017-nb,
  title    = "Turn-Taking with Improvisational Co-Creative Agents",
  author   = "Winston, Lauren and Magerko, Brian",
  journal  = "AIIDE",
  abstract = "Turn-taking is the ability for agents to lead or follow in social
              interactions. Turn-taking between humans and intelligent agents
              has been studied in human-robot interaction but has not been
              applied to improvisational, dance-based interactions. User
              understanding and experience of turn-taking in an improvisational,
              dance-based system known as LuminAI was investigated in a
              preliminary study of 11 participants. The results showed a trend
              towards users understanding the difference between turn-taking and
              non-turn-taking versions of LuminAI but reduced user experience in
              the turn-taking version.",
  year     =  2017,
  language = "en"
}

@ARTICLE{Liapis2016-zt,
  title    = "Boosting computational creativity with human interaction in
              mixed-initiative co-creation tasks",
  author   = "Liapis, Antonios and Yannakakis, Georgios N",
  abstract = "This paper attempts to connect mixed-initiative design with
              established theories of computational creativity, and adapt the
              latter to accommodate a human initiative impacting computationally
              creative processes and outcomes. Research in computational
              creativity often focuses on autonomously creative systems, which
              incorporate creative processes and result in creative outcomes.
              However, the integration of artificially intelligent processes in
              human-computer interaction tools necessitates that we identify how
              computational creativity can be shaped and ultimately enhanced by
              human intervention. This paper attempts to connect
              mixed-initiative design with established theories of computational
              creativity, and adapt the latter to accommodate a human initiative
              impacting computationally creative processes and outcomes. Several
              case studies of mixed-initiative tools for design and play are
              used to corroborate the arguments",
  year     =  2016,
  language = "en"
}

@ARTICLE{Buschek2021-ks,
  title    = "Nine Potential Pitfalls when Designing Human-{AI} Co-Creative
              Systems",
  author   = "Buschek, Daniel and Mecke, Lukas and Lehmann, Florian and Dang,
              Hai",
  journal  = "IUI Workshops",
  abstract = "This position paper examines potential pitfalls on the way towards
              achieving human-AI co-creation with generative models in a way
              that is beneficial to the users’ interests and collects a set of
              nine potential pitfalls, based on the literature and experiences
              as researchers working at the intersection of HCI and AI. This
              position paper examines potential pitfalls on the way towards
              achieving human-AI co-creation with generative models in a way
              that is beneficial to the users’ interests. In particular, we
              collected a set of nine potential pitfalls, based on the
              literature and our own experiences as researchers working at the
              intersection of HCI and AI. We illustrate each pitfall with
              examples and suggest ideas for addressing it. Reflecting on all
              pitfalls, we discuss and conclude with implications for future
              research directions. With this collection, we hope to contribute
              to a critical and constructive discussion on the roles of humans
              and AI in co-creative interactions, with an eye on related
              assumptions and potential side-effects for creative practices and
              beyond.",
  year     =  2021,
  language = "en"
}

@INPROCEEDINGS{Zhang2021-ej,
  title     = "{COSMIC}: A conversational interface for human-{AI} music
               co-creation",
  author    = "Zhang, Yixiao and Xia, Gus and Levy, Mark and Dixon, Simon",
  booktitle = "NIME 2021",
  publisher = "PubPub",
  abstract  = "COSMIC is a chatbot with a two-fold design philosophy: to
               understand human creative intent and to help humans in their
               creation. In this paper, we propose COSMIC, a COnverSational
               Interface for Human-AI MusIc Co-Creation. It is a chatbot with a
               two-fold design philosophy: to understand human creative intent
               and to help humans in their creation. The core Natural Language
               Processing (NLP) module is responsible for three functions: 1)
               understanding human needs in chat, 2) cross-modal interaction
               between natural language understanding and music generation
               models, and 3) mixing and coordinating multiple algorithms to
               complete the composition.",
  year      =  2021,
  language  = "en"
}

@ARTICLE{Bown2020-zn,
  title    = "A Speculative Exploration of the Role of Dialogue in
              Human-{ComputerCo}-creation",
  author   = "Bown, O and Grace, Kazjon and Bray, Liam and Ventura, Dan",
  journal  = "ICCC",
  abstract = "The paper motivates the pursuit of dialogic interaction and
              provides some explanation of why it has been defined through its
              impacts rather than its mechanism of action. In this paper we
              consider the notion of dialogic creative artificial intelligence
              (DCAI) systems, where co-creativity between a human user and a
              computational system is supported through dialogic interaction. By
              dialogue we mean both traditional language-based communication for
              explicit critique and persuasion (dialogue about creative
              artefacts) as well as a broader potentially non-linguistic notion
              of dialogue that emerges through the exchange of suggestions and
              changes (dialogue through creative artefacts). To capture this, we
              define DCAI as occurring when both system and user are able to
              influence each others’ creative objectives. The paper motivates
              our pursuit of dialogic interaction and provides some explanation
              of why we have defined it through its impacts rather than its
              mechanism of action. We provide two analyses to support our
              argument: an exploration of a commercial creativity support tool
              that has an extensive vocabulary for describing artefacts
              abstractly but does not meet our definition of dialogic
              interaction, and a case study of a creative interaction between
              two human professionals that exhibits dialogic interaction
              throughout. For the latter we consider how studies of human-human
              co-creation can offer non-obvious design concepts that might be
              applied to co-creative DCAI",
  year     =  2020,
  language = "en"
}

@INPROCEEDINGS{Zheng2022-qw,
  title     = "{UX} research on conversational human-{AI} interaction: A
               literature review of the {ACM} digital library",
  author    = "Zheng, Qingxiao and Tang, Yiliu and Liu, Yiren and Liu, Weizi and
               Huang, Yun",
  booktitle = "CHI Conference on Human Factors in Computing Systems",
  publisher = "ACM",
  address   = "New York, NY, USA",
  abstract  = "Early conversational agents (CAs) focused on dyadic human-AI
               interaction between humans and the CAs, followed by the
               increasing popularity of polyadic human-AI interaction, in which
               CAs are designed to mediate human-human interactions. CAs for
               polyadic interactions are unique because they encompass hybrid
               social interactions, i.e., human-CA, human-to-human, and
               human-to-group behaviors. However, research on polyadic CAs is
               scattered across different fields, making it challenging to
               identify, compare, and accumulate existing knowledge. To promote
               the future design of CA systems, we conducted a literature review
               of ACM publications and identified a set of works that conducted
               UX (user experience) research. We qualitatively synthesized the
               effects of polyadic CAs into four aspects of human-human
               interactions, i.e., communication, engagement, connection, and
               relationship maintenance. Through a mixed-method analysis of the
               selected polyadic and dyadic CA studies, we developed a suite of
               evaluation measurements on the effects. Our findings show that
               designing with social boundaries, such as privacy, disclosure,
               and identification, is crucial for ethical polyadic CAs. Future
               research should also advance usability testing methods and
               trust-building guidelines for conversational AI.",
  month     =  apr,
  year      =  2022,
  language  = "en"
}

@ARTICLE{Xu2021-ap,
  title    = "Human-{AI} interaction: An emerging interdisciplinary domain for
              enabling human-centered {AI}",
  author   = "Xu, Wei and Ge, Liezhong and Gao, Zaifeng",
  journal  = "ArXiv",
  abstract = "This paper analyzes the new challenges faced by AI systems and
              further elaborates the “Human-Centered AI” (HCAI) approach, and
              systematically proposes an emerging interdisciplinary domain of
              ``Human-AI Interaction'' (HAII), and defines the objective,
              methodology, and scope. The new characteristics of AI technology
              have brought new challenges to the research and development of AI
              systems. AI technology has benefited humans, but if improperly
              developed, it will harm humans. At present, there is no systematic
              interdisciplinary approach to effectively deal with these new
              challenges. This paper analyzes the new challenges faced by AI
              systems and further elaborates the “Human-Centered AI” (HCAI)
              approach we proposed in 2019. In order to enable the
              implementation of the HCAI approach, we systematically propose an
              emerging interdisciplinary domain of ``Human-AI Interaction''
              (HAII), and define the objective, methodology, and scope. Based on
              literature review and analyses, this paper summarizes the main
              areas of the HAII research and application as well as puts forward
              the future research agenda for HAII. Finally, the paper provides
              strategic recommendations for future implementation of the HCAI
              approach and HAII work.",
  year     =  2021,
  language = "en"
}

@BOOK{Markova2003-wk,
  title     = "Dialogicality and Social Representations: The Dynamics of Mind",
  author    = "Markova, Ivana and Marková, Ivana",
  publisher = "Cambridge University Press",
  abstract  = "This book develops a theory of social knowledge based on
               dialogicality, the capacity of the human mind to conceive and
               communicate about social reality in relation or opposition to
               otherness, and the theory of social representations. It argues
               that dialogicality is the sine qua non of the human mind and
               change is at the centre of all social phenomena. Ivana Markova's
               new book is unique in bringing together the concept of dialogue
               and social knowledge and will be an important contribution to
               social psychology and discourse and communication studies.",
  month     =  nov,
  year      =  2003,
  language  = "en"
}

@ARTICLE{Maher2012-oj,
  title     = "Computational and collective creativity: Who's being creative?",
  author    = "Maher, M L",
  journal   = "ICCC",
  publisher = "Citeseer",
  abstract  = "Creativity research has traditionally focused on human
               creativity, and even more specifically, on the psychology of
               individual creative people. In contrast, computational creativity
               research involves the development and evaluation of creativity in
               a computational system. As we study the effect of scaling up from
               the creativity of a computational system and individual people to
               large numbers of diverse computational agents and people, we have
               a new perspective: creativity can ascribed to a computational
               agent, an individual person …",
  year      =  2012
}

@INPROCEEDINGS{Candy2002-ra,
  title     = "Modeling co-creativity in art and technology",
  author    = "Candy, Linda and Edmonds, Ernest",
  booktitle = "Proceedings of the 4th conference on Creativity \& cognition",
  publisher = "Association for Computing Machinery",
  address   = "New York, NY, USA",
  pages     = "134--141",
  abstract  = "Collaborative projects in art and technology provide an
               opportunity to investigate how co-creativity takes place. This
               paper describes some of the characteristics of collaborative work
               that were identified from empirical evidence captured during the
               COSTART project [4]. We examine the way the information was
               analyzed and the results of that exercise. An approach to
               modeling co-creativity based on case study data is described and
               three example models proposed. This work enabled us to consider
               the implications of the different models for supporting
               creativity and their relationship to success factors. We conclude
               that the provision of 'support' for co-creativity in art and
               technology needs to include ongoing collaborative relationships
               that are fostered by organizations dedicated to the co-evolution
               of both art and new technology.",
  series    = "C\&C '02",
  month     =  oct,
  year      =  2002,
  keywords  = "creativity, digital technology, art, modeling, collaboration"
}

@ARTICLE{Abra1994-gk,
  title     = "Collaboration in creative work: An initiative for investigation",
  author    = "Abra, Jock",
  journal   = "Creat. Res. J.",
  publisher = "Routledge",
  volume    =  7,
  number    =  1,
  pages     = "1--20",
  abstract  = "Abstract: Collaborations have produced many great achievements.
               To stimulate the scholarly attention that the phenomenon deserves
               but has not received, this article reviews anecdotal evidence and
               examples of collaboration from different fields and indicates
               various forms it can take. Several creative phenomena are
               reinterpreted in light of collaboration's effects, and hypotheses
               and methods for study are suggested. It is speculated that
               collaborations benefit from partner diversity and require special
               talents of which people differ.",
  month     =  jan,
  year      =  1994
}

@ARTICLE{Wang2020-ng,
  title    = "A State-of-the-Art Review on Image Synthesis With Generative
              Adversarial Networks",
  author   = "Wang, Lei and Chen, Wei and Yang, Wenjia and Bi, Fangming and Yu,
              Fei Richard",
  journal  = "IEEE Access",
  volume   =  8,
  pages    = "63514--63537",
  abstract = "Generative Adversarial Networks (GANs) have achieved impressive
              results in various image synthesis tasks, and are becoming a hot
              topic in computer vision research because of the impressive
              performance they achieved in various applications. In this paper,
              we introduce the recent research on GANs in the field of image
              processing, including image synthesis, image generation, image
              semantic editing, image-to-image translation, image
              super-resolution, image inpainting, and cartoon generation. We
              analyze and summarize the methods used in these applications which
              have improved the generated results. Then, we discuss the
              challenges faced by GANs and introduce some methods to deal with
              these problems. We also preview some likely future research
              directions in the field of GANs, such as video generation, facial
              animation synthesis and 3D face reconstruction. The purpose of
              this review is to provide insights into the research on GANs and
              to present the various applications based on GANs in different
              scenarios.",
  year     =  2020,
  keywords = "Image synthesis;Generative adversarial networks;Training;Face;Task
              analysis;Generators;Generative adversarial networks;image
              synthesis;image-to-image translation;image editing;cartoon
              generation"
}

@ARTICLE{Kingma2013-di,
  title         = "Auto-Encoding Variational Bayes",
  author        = "Kingma, Diederik P and Welling, Max",
  journal       = "arXiv [stat.ML]",
  abstract      = "How can we perform efficient inference and learning in
                   directed probabilistic models, in the presence of continuous
                   latent variables with intractable posterior distributions,
                   and large datasets? We introduce a stochastic variational
                   inference and learning algorithm that scales to large
                   datasets and, under some mild differentiability conditions,
                   even works in the intractable case. Our contributions is
                   two-fold. First, we show that a reparameterization of the
                   variational lower bound yields a lower bound estimator that
                   can be straightforwardly optimized using standard stochastic
                   gradient methods. Second, we show that for i.i.d. datasets
                   with continuous latent variables per datapoint, posterior
                   inference can be made especially efficient by fitting an
                   approximate inference model (also called a recognition model)
                   to the intractable posterior using the proposed lower bound
                   estimator. Theoretical advantages are reflected in
                   experimental results.",
  month         =  dec,
  year          =  2013,
  archivePrefix = "arXiv",
  primaryClass  = "stat.ML"
}

@ARTICLE{Gradim2021-rw,
  title   = "Overview of Generative Processes in the work of Brian Eno",
  author  = "{Gradim} and {Pestana}",
  journal = "11th Workshop on Ubiquitous",
  year    =  2021
}

@ARTICLE{Shneiderman2019-gq,
  title    = "Creativity and collaboration: Revisiting cybernetic serendipity",
  author   = "Shneiderman, Ben",
  journal  = "Proc. Natl. Acad. Sci. U. S. A.",
  volume   =  116,
  number   =  6,
  pages    = "1837--1843",
  month    =  feb,
  year     =  2019,
  keywords = "collaboration; creativity; cybernetic serendipity; disciplinary
              integration",
  language = "en"
}

@MISC{Mccormack_undated-bg,
  title        = "Art, emergence, and the computational sublime",
  author       = "Mccormack, Jon and Dorin, Alan",
  abstract     = "This paper looks at some critical and technical issues of
                  relevance to generative art. In particular, it examines the
                  concept of emergence, looking at its historical origins and
                  salient issues surrounding its classification and meaning for
                  developing generative art. These issues include the hierarchy
                  of levels associated with emergence, recognition and ontology
                  of patterns, prediction and determinism. Each of these are
                  then related to attempts to create emergent phenomena with
                  computers for artistic purposes. Several methodologies for
                  developing emergent generative art are discussed including
                  what is termed in the paper ``the computational sublime''.
                  This definition is considered in relation to historical and
                  contemporary definitions of the sublime and is posited as a
                  way for artists to suggest their work is more than the sum of
                  its parts.",
  howpublished = "\url{https://users.monash.edu/~jonmc/research/Papers/art-2it.pdf}",
  note         = "Accessed: 2022-7-7"
}

@BOOK{McCormack_undated-dv,
  title  = "Impossible Nature: the art of Jon {McComarck}",
  author = "McCormack, Jon"
}

@INCOLLECTION{Bown2012-gg,
  title     = "Generative and Adaptive Creativity: A Unified Approach to
               Creativity in Nature, Humans and Machines",
  author    = "Bown, Oliver",
  editor    = "McCormack, Jon and d'Inverno, Mark",
  booktitle = "Computers and Creativity",
  publisher = "Springer Berlin Heidelberg",
  address   = "Berlin, Heidelberg",
  pages     = "361--381",
  abstract  = "Computational creativity is not limited to the study of
               human-like creativity and forces us to think about creativity as
               a general process that can be applied wherever new things come
               into existence. In this chapter I propose that in order to unify
               various forms of creativity it is necessary to consider a
               distinction between two types of creativity: generative
               creativity, in which things are created as the result of a
               process regardless of their value, and adaptive creativity, in
               which things are created as adaptive responses by a system to its
               situation. Whilst individual human creativity is typically of the
               adaptive form, collectively humans are engaged in processes of
               generative creativity as well as adaptive creativity. It is
               helpful to understand human creative behaviour as part of a
               social process involving these two aspects, and this is relevant
               to understanding how manmade artefacts can act as creative agents
               in social networks.",
  year      =  2012
}

@ARTICLE{Dorin2012-kh,
  title     = "A framework for understanding generative art",
  author    = "Dorin, Alan and McCabe, Jonathan and McCormack, Jon and Monro,
               Gordon and Whitelaw, Mitchell",
  journal   = "Digital Creativity",
  publisher = "Routledge",
  volume    =  23,
  number    = "3-4",
  pages     = "239--259",
  abstract  = "In this article we argue that a framework for the description,
               analysis and comparison of generative artworks is needed.
               Existing ideas from kinetic art and other domains in which
               process description is prominent are shown to be inadequate.
               Therefore, we propose a new framework that meets this need and
               facilitates the long-term aim of constructing a comprehensive
               taxonomy of generative art. Our framework is divided into four
               major components: a description of a work's entities; its
               processes and their environmental interactions; and the outcomes
               experienced by the work's audience. We describe a set of diverse
               generative artworks in terms of our framework, demonstrating how
               it can be applied in practice to compare and contrast them.",
  month     =  dec,
  year      =  2012
}

@INCOLLECTION{Turing1950-zz,
  title     = "Computing Machinery and Intelligence",
  author    = "Turing, Alan M",
  editor    = "Epstein, Robert and Roberts, Gary and Beber, Grace",
  booktitle = "Parsing the Turing Test: Philosophical and Methodological Issues
               in the Quest for the Thinking Computer",
  publisher = "Springer Netherlands",
  address   = "Dordrecht",
  pages     = "23--65",
  abstract  = "I propose to consider the question, “Can machines think?”♣ This
               should begin with definitions of the meaning of the terms
               “machine” and “think”. The definitions might be framed so as to
               reflect so far as possible the normal use of the words, but this
               attitude is dangerous. If the meaning of the words “machine” and
               “think” are to be found by examining how they are commonly used
               it is difficult to escape the conclusion that the meaning and the
               answer to the question, “Can machines think?” is to be sought in
               a statistical survey such as a Gallup poll.",
  year      =  1950
}

@ARTICLE{Dou2021-dw,
  title         = "Is {GPT}-3 Text Indistinguishable from Human Text? Scarecrow:
                   A Framework for Scrutinizing Machine Text",
  author        = "Dou, Yao and Forbes, Maxwell and Koncel-Kedziorski, Rik and
                   Smith, Noah A and Choi, Yejin",
  journal       = "arXiv [cs.CL]",
  abstract      = "Modern neural language models can produce remarkably fluent
                   and grammatical text. So much, in fact, that recent work by
                   Clark et al. (2021) has reported that conventional
                   crowdsourcing can no longer reliably distinguish between
                   machine-authored (GPT-3) and human-authored writing. As
                   errors in machine generations become ever subtler and harder
                   to spot, it poses a new challenge to the research community
                   for robust machine text evaluation. We propose a new
                   framework called Scarecrow for scrutinizing machine text via
                   crowd annotation. To support the broad range of real machine
                   errors that can be identified by laypeople, the ten error
                   categories of Scarecrow -- such as redundancy, commonsense
                   errors, and incoherence -- are identified through several
                   rounds of crowd annotation experiments without a predefined
                   ontology. We then use Scarecrow to collect over 41k error
                   spans in human-written and machine-generated paragraphs of
                   English language news text. We isolate factors for detailed
                   analysis, including parameter count, training data, and
                   various decoding-time configurations. Our approach
                   successfully quantifies measurable gaps between human
                   authored text and generations from models of several sizes,
                   including fourteen configurations of GPT-3. In addition, our
                   analysis unveils new insights, with detailed rationales
                   provided by laypeople, e.g., that the commonsense
                   capabilities have been improving with larger models while
                   math capabilities have not, and that the choices of simple
                   decoding hyperparameters can make remarkable differences on
                   the perceived quality of machine text. We release our
                   training material, annotation toolkit and dataset at
                   https://yao-dou.github.io/scarecrow/.",
  month         =  jul,
  year          =  2021,
  archivePrefix = "arXiv",
  primaryClass  = "cs.CL"
}

@ARTICLE{Csikszentmihalyi1992-ah,
  title    = "The measurement of flow in everyday life: toward a theory of
              emergent motivation",
  author   = "Csikszentmihalyi, M and Rathunde, K",
  journal  = "Nebr. Symp. Motiv.",
  volume   =  40,
  pages    = "57--97",
  year     =  1992,
  language = "en"
}

@ARTICLE{Yudkowsky2016-wf,
  title     = "The {AI} alignment problem: why it is hard, and where to start",
  author    = "{Yudkowsky}",
  journal   = "Symbolic Systems Distinguished Speaker",
  publisher = "intelligence.org",
  abstract  = "… This is where we are on most of the AI alignment problems, like
               if I ask you, “How do you build a friendly AI ?” What stops you
               is not that you don’t have enough computing power. What …",
  year      =  2016
}

@ARTICLE{Linardatos2020-uq,
  title    = "Explainable {AI}: A Review of Machine Learning Interpretability
              Methods",
  author   = "Linardatos, Pantelis and Papastefanopoulos, Vasilis and
              Kotsiantis, Sotiris",
  journal  = "Entropy",
  volume   =  23,
  number   =  1,
  abstract = "Recent advances in artificial intelligence (AI) have led to its
              widespread industrial adoption, with machine learning systems
              demonstrating superhuman performance in a significant number of
              tasks. However, this surge in performance, has often been achieved
              through increased model complexity, turning such systems into
              ``black box'' approaches and causing uncertainty regarding the way
              they operate and, ultimately, the way that they come to decisions.
              This ambiguity has made it problematic for machine learning
              systems to be adopted in sensitive yet critical domains, where
              their value could be immense, such as healthcare. As a result,
              scientific interest in the field of Explainable Artificial
              Intelligence (XAI), a field that is concerned with the development
              of new methods that explain and interpret machine learning models,
              has been tremendously reignited over recent years. This study
              focuses on machine learning interpretability methods; more
              specifically, a literature review and taxonomy of these methods
              are presented, as well as links to their programming
              implementations, in the hope that this survey would serve as a
              reference point for both theorists and practitioners.",
  month    =  dec,
  year     =  2020,
  keywords = "black-box; explainability; fairness; interpretability; machine
              learning; sensitivity; xai",
  language = "en"
}

@ARTICLE{Langlotz2019-hh,
  title    = "Will Artificial Intelligence Replace Radiologists?",
  author   = "Langlotz, Curtis P",
  journal  = "Radiol Artif Intell",
  volume   =  1,
  number   =  3,
  pages    = "e190058",
  month    =  may,
  year     =  2019,
  language = "en"
}

@ARTICLE{Schon1987-fy,
  title     = "The reflective practitioner: How professionals think in action",
  author    = "Schon, Donald A",
  journal   = "Adm. Sci. Q.",
  publisher = "JSTOR",
  volume    =  32,
  number    =  4,
  pages     =  614,
  month     =  dec,
  year      =  1987
}

@ARTICLE{Fallman2008-ch,
  title     = "The Interaction Design Research Triangle of Design Practice,
               Design Studies, and Design Exploration",
  author    = "Fallman, Daniel",
  journal   = "Design Issues",
  publisher = "The MIT Press",
  volume    =  24,
  number    =  3,
  pages     = "4--18",
  year      =  2008
}

@ARTICLE{Thoppilan2022-jf,
  title         = "{LaMDA}: Language Models for Dialog Applications",
  author        = "Thoppilan, Romal and De Freitas, Daniel and Hall, Jamie and
                   Shazeer, Noam and Kulshreshtha, Apoorv and Cheng, Heng-Tze
                   and Jin, Alicia and Bos, Taylor and Baker, Leslie and Du, Yu
                   and Li, Yaguang and Lee, Hongrae and Zheng, Huaixiu Steven
                   and Ghafouri, Amin and Menegali, Marcelo and Huang, Yanping
                   and Krikun, Maxim and Lepikhin, Dmitry and Qin, James and
                   Chen, Dehao and Xu, Yuanzhong and Chen, Zhifeng and Roberts,
                   Adam and Bosma, Maarten and Zhao, Vincent and Zhou, Yanqi and
                   Chang, Chung-Ching and Krivokon, Igor and Rusch, Will and
                   Pickett, Marc and Srinivasan, Pranesh and Man, Laichee and
                   Meier-Hellstern, Kathleen and Morris, Meredith Ringel and
                   Doshi, Tulsee and Santos, Renelito Delos and Duke, Toju and
                   Soraker, Johnny and Zevenbergen, Ben and Prabhakaran,
                   Vinodkumar and Diaz, Mark and Hutchinson, Ben and Olson,
                   Kristen and Molina, Alejandra and Hoffman-John, Erin and Lee,
                   Josh and Aroyo, Lora and Rajakumar, Ravi and Butryna, Alena
                   and Lamm, Matthew and Kuzmina, Viktoriya and Fenton, Joe and
                   Cohen, Aaron and Bernstein, Rachel and Kurzweil, Ray and
                   Aguera-Arcas, Blaise and Cui, Claire and Croak, Marian and
                   Chi, Ed and Le, Quoc",
  journal       = "arXiv [cs.CL]",
  abstract      = "We present LaMDA: Language Models for Dialog Applications.
                   LaMDA is a family of Transformer-based neural language models
                   specialized for dialog, which have up to 137B parameters and
                   are pre-trained on 1.56T words of public dialog data and web
                   text. While model scaling alone can improve quality, it shows
                   less improvements on safety and factual grounding. We
                   demonstrate that fine-tuning with annotated data and enabling
                   the model to consult external knowledge sources can lead to
                   significant improvements towards the two key challenges of
                   safety and factual grounding. The first challenge, safety,
                   involves ensuring that the model's responses are consistent
                   with a set of human values, such as preventing harmful
                   suggestions and unfair bias. We quantify safety using a
                   metric based on an illustrative set of human values, and we
                   find that filtering candidate responses using a LaMDA
                   classifier fine-tuned with a small amount of
                   crowdworker-annotated data offers a promising approach to
                   improving model safety. The second challenge, factual
                   grounding, involves enabling the model to consult external
                   knowledge sources, such as an information retrieval system, a
                   language translator, and a calculator. We quantify factuality
                   using a groundedness metric, and we find that our approach
                   enables the model to generate responses grounded in known
                   sources, rather than responses that merely sound plausible.
                   Finally, we explore the use of LaMDA in the domains of
                   education and content recommendations, and analyze their
                   helpfulness and role consistency.",
  month         =  jan,
  year          =  2022,
  archivePrefix = "arXiv",
  primaryClass  = "cs.CL"
}

@ARTICLE{McNamara2012-dx,
  title     = "Six rules for practice-led research",
  author    = "McNamara, Andrew",
  journal   = "TEXT: Journal of Writing and Writing Programs",
  publisher = "The Australian Association of Writing Programs",
  volume    =  2012,
  number    = "S14",
  pages     = "1--15",
  abstract  = "Recent experience of practice-led postgraduate supervision has
               prompted me to conclude that the practice-led research method, as
               it is currently construed, produces good outcomes, especially in
               permitting practitioners in the creative arts, design and media
               into the research framework, but at the same time it also
               generates certain recurring difficulties. What are these
               difficulties? Practice-led candidates tend to rely on a narrow
               range of formulations with the result that they assume: (i) the
               innovative nature of practice-led research; (ii) that its novelty
               is based in opposition to other research methods; (iii) that
               practice is intrinsically research, often leading to tautological
               formulations; (iv) the hyper-self-reflexive nature of
               practice-led research. This set of guidelines was composed in
               order to circumvent the shortcomings that result from these
               recurring formulations. My belief is that, if these shortcomings
               are avoided, there is nothing to prevent practice-led from
               further developing as a research inquiry and thus achieving
               rewarding and successful research outcomes. Originally composed
               for the purposes of postgraduate supervision, these six rules are
               presented here in the context of a wider analysis of the
               emergence of practice-led research and its current conditions of
               possibility as a research method.",
  year      =  2012
}

@ARTICLE{Hutchings2020-bv,
  title     = "Design considerations for real-time collaboration with creative
               artificial intelligence",
  author    = "Hutchings, P and Gifford, T and Yee-King, M and Llano, M T and
               {others}",
  journal   = "Organised",
  publisher = "cambridge.org",
  abstract  = "Machines incorporating techniques from artificial intelligence
               and machine learning can work with human users on a
               moment-to-moment, real-time basis to generate creative outcomes,
               …",
  year      =  2020
}

@ARTICLE{Pease_undated-jx,
  title   = "On the Machine Condition and its Creative Expression",
  author  = "{Pease} and {Guckelsberger} and {McCormack} and {Llano}",
  journal = "Int. Commun. Chin. Cult."
}

@ARTICLE{Henriksen2018-wa,
  title   = "A Cybernetic Perspective on Design and Creativity: a Conversation
             with Dr. Paul Pangaro",
  author  = "Henriksen, Danah and Mishra, Punya and Warr, Melissa and {The
             Deep-Play Research Group}",
  journal = "TechTrends",
  volume  =  62,
  number  =  1,
  pages   = "6--10",
  month   =  jan,
  year    =  2018
}


@MISC{Dell-Acqua2022-dy,
  title        = "Falling asleep at the wheel: Human/{AI} collaboration in a
                  field experiment on {HR} recruiters",
  author       = "Dell'Acqua, Fabrizio",
  month        =  jan,
  year         =  2022,
  howpublished = "\url{https://anacanhoto.com/wp-content/uploads/2024/08/554ee-fallingasleepatthewheel-fabriziodellacqua.pdf}",
  note         = "Accessed: 2025-4-25"
}

@INPROCEEDINGS{Mirowski2023-oz,
  title     = "Co-writing screenplays and theatre scripts with language models:
               Evaluation by industry professionals",
  author    = "Mirowski, Piotr and Mathewson, Kory W and Pittman, Jaylen and
               Evans, Richard",
  booktitle = "Proceedings of the 2023 CHI Conference on Human Factors in
               Computing Systems",
  publisher = "ACM",
  address   = "New York, NY, USA",
  volume    =  2021,
  pages     = "1--34",
  month     =  apr,
  year      =  2023,
  language  = "en"
}

@INPROCEEDINGS{Deterding2017-wh,
  title     = "Mixed-Initiative Creative Interfaces",
  author    = "Deterding, Sebastian and Hook, Jonathan and Fiebrink, Rebecca and
               Gillies, Marco and Gow, Jeremy and Akten, Memo and Smith, Gillian
               and Liapis, Antonios and Compton, Kate",
  booktitle = "Proceedings of the 2017 CHI Conference Extended Abstracts on
               Human Factors in Computing Systems",
  publisher = "ACM",
  address   = "New York, NY, USA",
  abstract  = "Enabled by artificial intelligence techniques, we are witnessing
               the rise of a new paradigm of computational creativity support:
               mixed-initiative creative interfaces put human and computer in a
               tight interactive loop where each suggests, produces, evaluates,
               modifies, and selects creative outputs in response to the other.
               This paradigm could broaden and amplify creative capacity for
               all, but has so far remained mostly confined to artificial
               intelligence for game content generation, and faces many unsolved
               interaction design challenges. This workshop therefore convenes
               CHI and game researchers to advance mixed-initiative approaches
               to creativity support.",
  month     =  may,
  year      =  2017,
  language  = "en"
}

@ARTICLE{Kent1998-tf,
  title    = "Building dialogic relationships through the world wide web",
  author   = "Kent, Michael L and Taylor, Maureen",
  journal  = "Public Relat. Rev.",
  volume   =  24,
  number   =  3,
  pages    = "321--334",
  abstract = "This article provides a theory-based, strategic framework to
              facilitate relationship building with publics through the World
              Wide Web. Although many essays on the Web have appeared in
              professional and technical periodicals, most treatments of the Web
              have lacked theoretical frameworks. Strategic communication on the
              World Wide Web can benefit from a consideration of dialogic
              communication. This article offers dialogic communication as a
              theoretical framework to guide relationship building between
              organizations and publics. Five strategies are provided for
              communication professionals use to create dialogic relationships
              with Internet publics.",
  month    =  sep,
  year     =  1998
}

@ARTICLE{Neelakantan2022-rx,
  title         = "Text and Code Embeddings by Contrastive Pre-Training",
  author        = "Neelakantan, Arvind and Xu, Tao and Puri, Raul and Radford,
                   Alec and Han, Jesse Michael and Tworek, Jerry and Yuan,
                   Qiming and Tezak, Nikolas and Kim, Jong Wook and Hallacy,
                   Chris and Heidecke, Johannes and Shyam, Pranav and Power,
                   Boris and Nekoul, Tyna Eloundou and Sastry, Girish and
                   Krueger, Gretchen and Schnurr, David and Such, Felipe
                   Petroski and Hsu, Kenny and Thompson, Madeleine and Khan,
                   Tabarak and Sherbakov, Toki and Jang, Joanne and Welinder,
                   Peter and Weng, Lilian",
  journal       = "arXiv [cs.CL]",
  abstract      = "Text embeddings are useful features in many applications such
                   as semantic search and computing text similarity. Previous
                   work typically trains models customized for different use
                   cases, varying in dataset choice, training objective and
                   model architecture. In this work, we show that contrastive
                   pre-training on unsupervised data at scale leads to high
                   quality vector representations of text and code. The same
                   unsupervised text embeddings that achieve new
                   state-of-the-art results in linear-probe classification also
                   display impressive semantic search capabilities and sometimes
                   even perform competitively with fine-tuned models. On
                   linear-probe classification accuracy averaging over 7 tasks,
                   our best unsupervised model achieves a relative improvement
                   of 4\% and 1.8\% over previous best unsupervised and
                   supervised text embedding models respectively. The same text
                   embeddings when evaluated on large-scale semantic search
                   attains a relative improvement of 23.4\%, 14.7\%, and 10.6\%
                   over previous best unsupervised methods on MSMARCO, Natural
                   Questions and TriviaQA benchmarks, respectively. Similarly to
                   text embeddings, we train code embedding models on (text,
                   code) pairs, obtaining a 20.8\% relative improvement over
                   prior best work on code search.",
  month         =  jan,
  year          =  2022,
  archivePrefix = "arXiv",
  primaryClass  = "cs.CL"
}

@MISC{noauthor_undated-sl,
  title = "{Ross\_2021\_Psychopolitical}-Anaphylaxis.pdf"
}

@ARTICLE{Li2023-jv,
  title         = "Making {AI} Less ``Thirsty'': Uncovering and Addressing the
                   Secret Water Footprint of {AI} Models",
  author        = "Li, Pengfei and Yang, Jianyi and Islam, Mohammad A and Ren,
                   Shaolei",
  journal       = "arXiv [cs.LG]",
  abstract      = "The growing carbon footprint of artificial intelligence (AI)
                   models, especially large ones such as GPT-3, has been
                   undergoing public scrutiny. Unfortunately, however, the
                   equally important and enormous water (withdrawal and
                   consumption) footprint of AI models has remained under the
                   radar. For example, training GPT-3 in Microsoft's
                   state-of-the-art U.S. data centers can directly evaporate
                   700,000 liters of clean freshwater, but such information has
                   been kept a secret. More critically, the global AI demand may
                   be accountable for 4.2 -- 6.6 billion cubic meters of water
                   withdrawal in 2027, which is more than the total annual water
                   withdrawal of 4 -- 6 Denmark or half of the United Kingdom.
                   This is very concerning, as freshwater scarcity has become
                   one of the most pressing challenges shared by all of us in
                   the wake of the rapidly growing population, depleting water
                   resources, and aging water infrastructures. To respond to the
                   global water challenges, AI models can, and also must, take
                   social responsibility and lead by example by addressing their
                   own water footprint. In this paper, we provide a principled
                   methodology to estimate the water footprint of AI models, and
                   also discuss the unique spatial-temporal diversities of AI
                   models' runtime water efficiency. Finally, we highlight the
                   necessity of holistically addressing water footprint along
                   with carbon footprint to enable truly sustainable AI.",
  month         =  apr,
  year          =  2023,
  archivePrefix = "arXiv",
  primaryClass  = "cs.LG"
}

@ARTICLE{Floridi2020-qc,
  title     = "{GPT}-3: Its nature, scope, limits, and consequences",
  author    = "Floridi, Luciano and Chiriatti, Massimo",
  journal   = "Minds Mach.",
  publisher = "Springer Science and Business Media LLC",
  volume    =  30,
  number    =  4,
  pages     = "681--694",
  abstract  = "AbstractIn this commentary, we discuss the nature of reversible
               and irreversible questions, that is, questions that may enable
               one to identify the nature of the source of their answers. We
               then introduce GPT-3, a third-generation, autoregressive language
               model that uses deep learning to produce human-like texts, and
               use the previous distinction to analyse it. We expand the
               analysis to present three tests based on mathematical, semantic
               (that is, the Turing Test), and ethical questions and show that
               GPT-3 is not designed to pass any of them. This is a reminder
               that GPT-3 does not do what it is not supposed to do, and that
               any interpretation of GPT-3 as the beginning of the emergence of
               a general form of artificial intelligence is merely uninformed
               science fiction. We conclude by outlining some of the significant
               consequences of the industrialisation of automatic and cheap
               production of good, semantic artefacts.",
  month     =  dec,
  year      =  2020,
  language  = "en"
}

@ARTICLE{Perez-y-Perez2004-cm,
  title     = "Three computer-based models of storytelling: {BRUTUS}, {MINSTREL}
               and {MEXICA}",
  author    = "Pérez y Pérez, Rafael and Sharples, Mike",
  journal   = "Knowl. Based Syst.",
  publisher = "Elsevier BV",
  volume    =  17,
  number    =  1,
  pages     = "15--29",
  abstract  = "This paper attempts to establish criteria to analyse and evaluate
               computer models of creativity in writing. The paper provides a
               brief review of the antecedents of automatic story-generation and
               offers a proposal for the analysis and evaluation of computer
               models of creativity in writing. It reviews three major projects
               to develop computer-based storywriters published between 1993 and
               2000 and analyses their approach, similarities, differences and
               contributions. It compares the three approaches and discusses
               implications for the modelling of creativity in writing and the
               design of future story generation systems.",
  month     =  jan,
  year      =  2004,
  language  = "en"
}

@ARTICLE{Yang2022-vb,
  title         = "{Re3}: Generating Longer Stories With Recursive Reprompting
                   and Revision",
  author        = "Yang, Kevin and Tian, Yuandong and Peng, Nanyun and Klein,
                   Dan",
  journal       = "arXiv [cs.CL]",
  abstract      = "We consider the problem of automatically generating longer
                   stories of over two thousand words. Compared to prior work on
                   shorter stories, long-range plot coherence and relevance are
                   more central challenges here. We propose the Recursive
                   Reprompting and Revision framework (Re3) to address these
                   challenges by (a) prompting a general-purpose language model
                   to construct a structured overarching plan, and (b)
                   generating story passages by repeatedly injecting contextual
                   information from both the plan and current story state into a
                   language model prompt. We then revise by (c) reranking
                   different continuations for plot coherence and premise
                   relevance, and finally (d) editing the best continuation for
                   factual consistency. Compared to similar-length stories
                   generated directly from the same base model, human evaluators
                   judged substantially more of Re3's stories as having a
                   coherent overarching plot (by 14\% absolute increase), and
                   relevant to the given initial premise (by 20\%).",
  month         =  oct,
  year          =  2022,
  archivePrefix = "arXiv",
  primaryClass  = "cs.CL"
}

@MISC{noauthor_undated-ao,
  title = "2307.11760.pdf"
}

@ARTICLE{Neelakantan2022-dn,
  title         = "Text and Code Embeddings by Contrastive Pre-Training",
  author        = "Neelakantan, Arvind and Xu, Tao and Puri, Raul and Radford,
                   Alec and Han, Jesse Michael and Tworek, Jerry and Yuan,
                   Qiming and Tezak, Nikolas and Kim, Jong Wook and Hallacy,
                   Chris and Heidecke, Johannes and Shyam, Pranav and Power,
                   Boris and Nekoul, Tyna Eloundou and Sastry, Girish and
                   Krueger, Gretchen and Schnurr, David and Such, Felipe
                   Petroski and Hsu, Kenny and Thompson, Madeleine and Khan,
                   Tabarak and Sherbakov, Toki and Jang, Joanne and Welinder,
                   Peter and Weng, Lilian",
  journal       = "arXiv [cs.CL]",
  abstract      = "Text embeddings are useful features in many applications such
                   as semantic search and computing text similarity. Previous
                   work typically trains models customized for different use
                   cases, varying in dataset choice, training objective and
                   model architecture. In this work, we show that contrastive
                   pre-training on unsupervised data at scale leads to high
                   quality vector representations of text and code. The same
                   unsupervised text embeddings that achieve new
                   state-of-the-art results in linear-probe classification also
                   display impressive semantic search capabilities and sometimes
                   even perform competitively with fine-tuned models. On
                   linear-probe classification accuracy averaging over 7 tasks,
                   our best unsupervised model achieves a relative improvement
                   of 4\% and 1.8\% over previous best unsupervised and
                   supervised text embedding models respectively. The same text
                   embeddings when evaluated on large-scale semantic search
                   attains a relative improvement of 23.4\%, 14.7\%, and 10.6\%
                   over previous best unsupervised methods on MSMARCO, Natural
                   Questions and TriviaQA benchmarks, respectively. Similarly to
                   text embeddings, we train code embedding models on (text,
                   code) pairs, obtaining a 20.8\% relative improvement over
                   prior best work on code search.",
  month         =  jan,
  year          =  2022,
  archivePrefix = "arXiv",
  primaryClass  = "cs.CL"
}

@ARTICLE{Hermann2003-zi,
  title     = "Broadcasting auditory weather reports-a pilot project",
  author    = "Hermann, T and Drees, J M and Ritter, H",
  publisher = "smartech.gatech.edu",
  abstract  = "This paper reports on a pilot project between our research
               department and and a local radio station, investigating the use
               of sonification to render and present auditory weather forecasts.
               The sonifications include auditory markers for certain relevant
               time points, expected weather events like thunder, snow or fog
               and several auditory streams to summarize the temporal weather
               changes during the day. To our knowledge, this is the first
               utilization of sonification in a regular radio program. We
               introduce the sonification concept …",
  year      =  2003
}

@ARTICLE{Kalonaris2022-ug,
  title         = "Tokyo Kion-On: Query-Based Generative Sonification of
                   Atmospheric Data",
  author        = "Kalonaris, Stefano",
  journal       = "arXiv [cs.SD]",
  abstract      = "Amid growing environmental concerns, interactive displays of
                   data constitute an important tool for exploring and
                   understanding the impact of climate change on the planet's
                   ecosystemic integrity. This paper presents Tokyo kion-on, a
                   query-based sonification model of Tokyo's air temperature
                   from 1876 to 2021. The system uses a recurrent neural network
                   architecture known as LSTM with attention trained on a small
                   dataset of Japanese melodies and conditioned upon said
                   atmospheric data. After describing the model's
                   implementation, a brief comparative illustration of the
                   musical results is presented, along with a discussion on how
                   the exposed hyper-parameters can promote active and
                   non-linear exploration of the data.",
  month         =  aug,
  year          =  2022,
  archivePrefix = "arXiv",
  primaryClass  = "cs.SD"
}

@ARTICLE{Flowers2001-xa,
  title   = "Sonification of daily weather records: Issues of perception,
             attention and memory in design choices",
  author  = "Flowers, John H and Whitwer, Laura E and Grafel, Douglas C and
             Kotan, Cheryl A",
  journal = "Faculty Publications, Department of Psychology",
  pages   =  432,
  year    =  2001
}

@ARTICLE{Quinn2001-qb,
  title     = "Research set to music: The climate symphony and other
               sonifications of ice core, radar, {DNA}, seismic and solar wind
               data",
  author    = "Quinn, M",
  publisher = "smartech.gatech.edu",
  abstract  = "… the Office of Polar Programs and was warmly received. This
               paper describes the Climate Symphony portion of the … The script
               for the Climate Symphony performance was developed in …",
  year      =  2001
}

@INPROCEEDINGS{Polli2004-nu,
  title       = "Atmospherics/weather works: A multi-channel storm sonification
                 project",
  author      = "Polli, Andrea",
  institution = "Georgia Institute of Technology",
  year        =  2004
}

@INPROCEEDINGS{Krol2022-ec,
  title     = "Towards the Generation of Musical Explanations with {GPT}-3",
  author    = "Krol, Stephen James and Llano, Maria Teresa and McCormack, Jon",
  booktitle = "Artificial Intelligence in Music, Sound, Art and Design: 11th
               International Conference, EvoMUSART 2022, Held as Part of EvoStar
               2022, Madrid, Spain, April 20–22, 2022, Proceedings",
  publisher = "Springer-Verlag",
  address   = "Berlin, Heidelberg",
  pages     = "131--147",
  abstract  = "Open AI’s language model, GPT-3, has shown great potential for
               many NLP tasks, with applications in many different domains. In
               this work we carry out a first study on GPT-3’s capability to
               communicate musical decisions through textual explanations when
               prompted with a textual representation of a piece of music.
               Enabling a dialogue in human-AI music partnerships is an
               important step towards more engaging and creative human-AI
               interactions. Our results show that GPT-3 lacks the necessary
               intelligence to really understand musical decisions. A major
               barrier to reach a better performance is the lack of data that
               includes explanations of the creative process carried out by
               artists for musical pieces. We believe such a resource would aid
               the understanding and collaboration with AI music systems.",
  month     =  apr,
  year      =  2022,
  keywords  = "Music, Explainability, GPT3"
}

@ARTICLE{Wei2022-bm,
  title         = "Chain of Thought Prompting Elicits Reasoning in Large
                   Language Models",
  author        = "Wei, Jason and Wang, Xuezhi and Schuurmans, Dale and Bosma,
                   Maarten and Ichter, Brian and Xia, Fei and Chi, Ed and Le,
                   Quoc and Zhou, Denny",
  journal       = "arXiv [cs.CL]",
  abstract      = "We explore how generating a chain of thought -- a series of
                   intermediate reasoning steps -- significantly improves the
                   ability of large language models to perform complex
                   reasoning. In particular, we show how such reasoning
                   abilities emerge naturally in sufficiently large language
                   models via a simple method called chain of thought prompting,
                   where a few chain of thought demonstrations are provided as
                   exemplars in prompting. Experiments on three large language
                   models show that chain of thought prompting improves
                   performance on a range of arithmetic, commonsense, and
                   symbolic reasoning tasks. The empirical gains can be
                   striking. For instance, prompting a 540B-parameter language
                   model with just eight chain of thought exemplars achieves
                   state of the art accuracy on the GSM8K benchmark of math word
                   problems, surpassing even finetuned GPT-3 with a verifier.",
  month         =  jan,
  year          =  2022,
  archivePrefix = "arXiv",
  primaryClass  = "cs.CL"
}

@ARTICLE{Ramesh2021-xb,
  title         = "Zero-Shot Text-to-Image Generation",
  author        = "Ramesh, Aditya and Pavlov, Mikhail and Goh, Gabriel and Gray,
                   Scott and Voss, Chelsea and Radford, Alec and Chen, Mark and
                   Sutskever, Ilya",
  journal       = "arXiv [cs.CV]",
  abstract      = "Text-to-image generation has traditionally focused on finding
                   better modeling assumptions for training on a fixed dataset.
                   These assumptions might involve complex architectures,
                   auxiliary losses, or side information such as object part
                   labels or segmentation masks supplied during training. We
                   describe a simple approach for this task based on a
                   transformer that autoregressively models the text and image
                   tokens as a single stream of data. With sufficient data and
                   scale, our approach is competitive with previous
                   domain-specific models when evaluated in a zero-shot fashion.",
  month         =  feb,
  year          =  2021,
  archivePrefix = "arXiv",
  primaryClass  = "cs.CV"
}

@ARTICLE{Hutter2005-fe,
  title     = "Universal artificial intelligence: Sequential decisions based on
               algorithmic probability",
  author    = "Hutter, Marcus",
  publisher = "Springer",
  abstract  = "Personal motivation. The dream of creating artificial devices
               that reach or outperform human inteUigence is an old one. It is
               also one of the dreams of my youth, which have never left me.
               What makes this challenge so interesting? A solution would have
               enormous implications on our society, and there are reasons to
               believe that the AI problem can be solved in my expected
               lifetime. So, it's worth sticking to it for a lifetime, even if
               it takes 30 years or so to reap the benefits. The AI problem. The
               science of artificial intelligence (AI) may be defined as the
               construction of intelligent systems and their analysis. A natural
               definition of a system is anything that has an input and an
               output stream. Intelligence is more complicated. It can have many
               faces like creativity, solving prob lems, pattern recognition,
               classification, learning, induction, deduction, build ing
               analogies, optimization, surviving in an environment, language
               processing, and knowledge. A formal definition incorporating
               every aspect of intelligence, however, seems difficult. Most, if
               not all known facets of intelligence can be formulated as goal
               driven or, more precisely, as maximizing some utility func tion.
               It is, therefore, sufficient to study goal-driven AI; eg the
               (biological) goal of animals and humans is to survive and spread.
               The goal of AI systems should be to be useful to humans.",
  year      =  2005
}

@ARTICLE{Pascanu2012-tl,
  title         = "On the difficulty of training Recurrent Neural Networks",
  author        = "Pascanu, Razvan and Mikolov, Tomas and Bengio, Yoshua",
  journal       = "arXiv [cs.LG]",
  abstract      = "There are two widely known issues with properly training
                   Recurrent Neural Networks, the vanishing and the exploding
                   gradient problems detailed in Bengio et al. (1994). In this
                   paper we attempt to improve the understanding of the
                   underlying issues by exploring these problems from an
                   analytical, a geometric and a dynamical systems perspective.
                   Our analysis is used to justify a simple yet effective
                   solution. We propose a gradient norm clipping strategy to
                   deal with exploding gradients and a soft constraint for the
                   vanishing gradients problem. We validate empirically our
                   hypothesis and proposed solutions in the experimental
                   section.",
  month         =  nov,
  year          =  2012,
  archivePrefix = "arXiv",
  primaryClass  = "cs.LG"
}

@ARTICLE{Graves2013-yv,
  title         = "Generating sequences with recurrent neural networks",
  author        = "Graves, Alex",
  journal       = "arXiv [cs.NE]",
  abstract      = "This paper shows how Long Short-term Memory recurrent neural
                   networks can be used to generate complex sequences with
                   long-range structure, simply by predicting one data point at
                   a time. The approach is demonstrated for text (where the data
                   are discrete) and online handwriting (where the data are
                   real-valued). It is then extended to handwriting synthesis by
                   allowing the network to condition its predictions on a text
                   sequence. The resulting system is able to generate highly
                   realistic cursive handwriting in a wide variety of styles.",
  month         =  aug,
  year          =  2013,
  archivePrefix = "arXiv",
  primaryClass  = "cs.NE"
}

@ARTICLE{Sutskever2014-jq,
  title         = "Sequence to sequence learning with Neural Networks",
  author        = "Sutskever, Ilya and Vinyals, Oriol and Le, Quoc V",
  journal       = "arXiv [cs.CL]",
  abstract      = "Deep Neural Networks (DNNs) are powerful models that have
                   achieved excellent performance on difficult learning tasks.
                   Although DNNs work well whenever large labeled training sets
                   are available, they cannot be used to map sequences to
                   sequences. In this paper, we present a general end-to-end
                   approach to sequence learning that makes minimal assumptions
                   on the sequence structure. Our method uses a multilayered
                   Long Short-Term Memory (LSTM) to map the input sequence to a
                   vector of a fixed dimensionality, and then another deep LSTM
                   to decode the target sequence from the vector. Our main
                   result is that on an English to French translation task from
                   the WMT'14 dataset, the translations produced by the LSTM
                   achieve a BLEU score of 34.8 on the entire test set, where
                   the LSTM's BLEU score was penalized on out-of-vocabulary
                   words. Additionally, the LSTM did not have difficulty on long
                   sentences. For comparison, a phrase-based SMT system achieves
                   a BLEU score of 33.3 on the same dataset. When we used the
                   LSTM to rerank the 1000 hypotheses produced by the
                   aforementioned SMT system, its BLEU score increases to 36.5,
                   which is close to the previous best result on this task. The
                   LSTM also learned sensible phrase and sentence
                   representations that are sensitive to word order and are
                   relatively invariant to the active and the passive voice.
                   Finally, we found that reversing the order of the words in
                   all source sentences (but not target sentences) improved the
                   LSTM's performance markedly, because doing so introduced many
                   short term dependencies between the source and the target
                   sentence which made the optimization problem easier.",
  month         =  sep,
  year          =  2014,
  archivePrefix = "arXiv",
  primaryClass  = "cs.CL"
}

@ARTICLE{Bahdanau2014-nh,
  title         = "Neural machine translation by jointly learning to align and
                   translate",
  author        = "Bahdanau, Dzmitry and Cho, Kyunghyun and Bengio, Yoshua",
  journal       = "arXiv [cs.CL]",
  abstract      = "Neural machine translation is a recently proposed approach to
                   machine translation. Unlike the traditional statistical
                   machine translation, the neural machine translation aims at
                   building a single neural network that can be jointly tuned to
                   maximize the translation performance. The models proposed
                   recently for neural machine translation often belong to a
                   family of encoder-decoders and consists of an encoder that
                   encodes a source sentence into a fixed-length vector from
                   which a decoder generates a translation. In this paper, we
                   conjecture that the use of a fixed-length vector is a
                   bottleneck in improving the performance of this basic
                   encoder-decoder architecture, and propose to extend this by
                   allowing a model to automatically (soft-)search for parts of
                   a source sentence that are relevant to predicting a target
                   word, without having to form these parts as a hard segment
                   explicitly. With this new approach, we achieve a translation
                   performance comparable to the existing state-of-the-art
                   phrase-based system on the task of English-to-French
                   translation. Furthermore, qualitative analysis reveals that
                   the (soft-)alignments found by the model agree well with our
                   intuition.",
  month         =  sep,
  year          =  2014,
  archivePrefix = "arXiv",
  primaryClass  = "cs.CL"
}

@ARTICLE{Radford2018-fm,
  title    = "Improving Language Understanding by Generative Pre-Training",
  author   = "Radford, Alec and Narasimhan, Karthik",
  abstract = "The general task-agnostic model outperforms discriminatively
              trained models that use architectures speciﬁcally crafted for each
              task, improving upon the state of the art in 9 out of the 12 tasks
              studied. Natural language understanding comprises a wide range of
              diverse tasks such as textual entailment, question answering,
              semantic similarity assessment, and document classiﬁcation.
              Although large unlabeled text corpora are abundant, labeled data
              for learning these speciﬁc tasks is scarce, making it challenging
              for discriminatively trained models to perform adequately. We
              demonstrate that large gains on these tasks can be realized by
              generative pre-training of a language model on a diverse corpus of
              unlabeled text, followed by discriminative ﬁne-tuning on each
              speciﬁc task. In contrast to previous approaches, we make use of
              task-aware input transformations during ﬁne-tuning to achieve
              effective transfer while requiring minimal changes to the model
              architecture. We demonstrate the effectiveness of our approach on
              a wide range of benchmarks for natural language understanding. Our
              general task-agnostic model outperforms discriminatively trained
              models that use architectures speciﬁcally crafted for each task,
              signiﬁcantly improving upon the state of the art in 9 out of the
              12 tasks studied. For instance, we achieve absolute improvements
              of 8.9\% on commonsense reasoning (Stories Cloze Test), 5.7\% on
              question answering (RACE), and 1.5\% on textual entailment
              (MultiNLI).",
  year     =  2018,
  language = "en"
}

@ARTICLE{Gemini-Team2023-ux,
  title         = "Gemini: A family of highly capable multimodal models",
  author        = "{Gemini Team} and Anil, Rohan and Borgeaud, Sebastian and
                   Alayrac, Jean-Baptiste and Yu, Jiahui and Soricut, Radu and
                   Schalkwyk, Johan and Dai, Andrew M and Hauth, Anja and
                   Millican, Katie and Silver, David and Johnson, Melvin and
                   Antonoglou, Ioannis and Schrittwieser, Julian and Glaese,
                   Amelia and Chen, Jilin and Pitler, Emily and Lillicrap,
                   Timothy and Lazaridou, Angeliki and Firat, Orhan and Molloy,
                   James and Isard, Michael and Barham, Paul R and Hennigan, Tom
                   and Lee, Benjamin and Viola, Fabio and Reynolds, Malcolm and
                   Xu, Yuanzhong and Doherty, Ryan and Collins, Eli and Meyer,
                   Clemens and Rutherford, Eliza and Moreira, Erica and Ayoub,
                   Kareem and Goel, Megha and Krawczyk, Jack and Du, Cosmo and
                   Chi, Ed and Cheng, Heng-Tze and Ni, Eric and Shah, Purvi and
                   Kane, Patrick and Chan, Betty and Faruqui, Manaal and
                   Severyn, Aliaksei and Lin, Hanzhao and Li, Yaguang and Cheng,
                   Yong and Ittycheriah, Abe and Mahdieh, Mahdis and Chen, Mia
                   and Sun, Pei and Tran, Dustin and Bagri, Sumit and
                   Lakshminarayanan, Balaji and Liu, Jeremiah and Orban, Andras
                   and Güra, Fabian and Zhou, Hao and Song, Xinying and Boffy,
                   Aurelien and Ganapathy, Harish and Zheng, Steven and Choe,
                   Hyunjeong and Weisz, Ágoston and Zhu, Tao and Lu, Yifeng and
                   Gopal, Siddharth and Kahn, Jarrod and Kula, Maciej and
                   Pitman, Jeff and Shah, Rushin and Taropa, Emanuel and Merey,
                   Majd Al and Baeuml, Martin and Chen, Zhifeng and Shafey,
                   Laurent El and Zhang, Yujing and Sercinoglu, Olcan and
                   Tucker, George and Piqueras, Enrique and Krikun, Maxim and
                   Barr, Iain and Savinov, Nikolay and Danihelka, Ivo and
                   Roelofs, Becca and White, Anaïs and Andreassen, Anders and
                   von Glehn, Tamara and Yagati, Lakshman and Kazemi, Mehran and
                   Gonzalez, Lucas and Khalman, Misha and Sygnowski, Jakub and
                   Frechette, Alexandre and Smith, Charlotte and Culp, Laura and
                   Proleev, Lev and Luan, Yi and Chen, Xi and Lottes, James and
                   Schucher, Nathan and Lebron, Federico and Rrustemi, Alban and
                   Clay, Natalie and Crone, Phil and Kocisky, Tomas and Zhao,
                   Jeffrey and Perz, Bartek and Yu, Dian and Howard, Heidi and
                   Bloniarz, Adam and Rae, Jack W and Lu, Han and Sifre, Laurent
                   and Maggioni, Marcello and Alcober, Fred and Garrette, Dan
                   and Barnes, Megan and Thakoor, Shantanu and Austin, Jacob and
                   Barth-Maron, Gabriel and Wong, William and Joshi, Rishabh and
                   Chaabouni, Rahma and Fatiha, Deeni and Ahuja, Arun and Tomar,
                   Gaurav Singh and Senter, Evan and Chadwick, Martin and
                   Kornakov, Ilya and Attaluri, Nithya and Iturrate, Iñaki and
                   Liu, Ruibo and Li, Yunxuan and Cogan, Sarah and Chen, Jeremy
                   and Jia, Chao and Gu, Chenjie and Zhang, Qiao and Grimstad,
                   Jordan and Hartman, Ale Jakse and Garcia, Xavier and Pillai,
                   Thanumalayan Sankaranarayana and Devlin, Jacob and Laskin,
                   Michael and Casas, Diego de Las and Valter, Dasha and Tao,
                   Connie and Blanco, Lorenzo and Badia, Adrià Puigdomènech and
                   Reitter, David and Chen, Mianna and Brennan, Jenny and
                   Rivera, Clara and Brin, Sergey and Iqbal, Shariq and Surita,
                   Gabriela and Labanowski, Jane and Rao, Abhi and Winkler,
                   Stephanie and Parisotto, Emilio and Gu, Yiming and Olszewska,
                   Kate and Addanki, Ravi and Miech, Antoine and Louis, Annie
                   and Teplyashin, Denis and Brown, Geoff and Catt, Elliot and
                   Balaguer, Jan and Xiang, Jackie and Wang, Pidong and Ashwood,
                   Zoe and Briukhov, Anton and Webson, Albert and Ganapathy,
                   Sanjay and Sanghavi, Smit and Kannan, Ajay and Chang,
                   Ming-Wei and Stjerngren, Axel and Djolonga, Josip and Sun,
                   Yuting and Bapna, Ankur and Aitchison, Matthew and Pejman,
                   Pedram and Michalewski, Henryk and Yu, Tianhe and Wang, Cindy
                   and Love, Juliette and Ahn, Junwhan and Bloxwich, Dawn and
                   Han, Kehang and Humphreys, Peter and Sellam, Thibault and
                   Bradbury, James and Godbole, Varun and Samangooei, Sina and
                   Damoc, Bogdan and Kaskasoli, Alex and Arnold, Sébastien M R
                   and Vasudevan, Vijay and Agrawal, Shubham and Riesa, Jason
                   and Lepikhin, Dmitry and Tanburn, Richard and Srinivasan,
                   Srivatsan and Lim, Hyeontaek and Hodkinson, Sarah and Shyam,
                   Pranav and Ferret, Johan and Hand, Steven and Garg, Ankush
                   and Paine, Tom Le and Li, Jian and Li, Yujia and Giang, Minh
                   and Neitz, Alexander and Abbas, Zaheer and York, Sarah and
                   Reid, Machel and Cole, Elizabeth and Chowdhery, Aakanksha and
                   Das, Dipanjan and Rogozińska, Dominika and Nikolaev, Vitaliy
                   and Sprechmann, Pablo and Nado, Zachary and Zilka, Lukas and
                   Prost, Flavien and He, Luheng and Monteiro, Marianne and
                   Mishra, Gaurav and Welty, Chris and Newlan, Josh and Jia,
                   Dawei and Allamanis, Miltiadis and Hu, Clara Huiyi and de
                   Liedekerke, Raoul and Gilmer, Justin and Saroufim, Carl and
                   Rijhwani, Shruti and Hou, Shaobo and Shrivastava, Disha and
                   Baddepudi, Anirudh and Goldin, Alex and Ozturel, Adnan and
                   Cassirer, Albin and Xu, Yunhan and Sohn, Daniel and Sachan,
                   Devendra and Amplayo, Reinald Kim and Swanson, Craig and
                   Petrova, Dessie and Narayan, Shashi and Guez, Arthur and
                   Brahma, Siddhartha and Landon, Jessica and Patel, Miteyan and
                   Zhao, Ruizhe and Villela, Kevin and Wang, Luyu and Jia,
                   Wenhao and Rahtz, Matthew and Giménez, Mai and Yeung, Legg
                   and Keeling, James and Georgiev, Petko and Mincu, Diana and
                   Wu, Boxi and Haykal, Salem and Saputro, Rachel and
                   Vodrahalli, Kiran and Qin, James and Cankara, Zeynep and
                   Sharma, Abhanshu and Fernando, Nick and Hawkins, Will and
                   Neyshabur, Behnam and Kim, Solomon and Hutter, Adrian and
                   Agrawal, Priyanka and Castro-Ros, Alex and van den Driessche,
                   George and Wang, Tao and Yang, Fan and Chang, Shuo-Yiin and
                   Komarek, Paul and McIlroy, Ross and Lučić, Mario and Zhang,
                   Guodong and Farhan, Wael and Sharman, Michael and Natsev,
                   Paul and Michel, Paul and Bansal, Yamini and Qiao, Siyuan and
                   Cao, Kris and Shakeri, Siamak and Butterfield, Christina and
                   Chung, Justin and Rubenstein, Paul Kishan and Agrawal,
                   Shivani and Mensch, Arthur and Soparkar, Kedar and Lenc,
                   Karel and Chung, Timothy and Pope, Aedan and Maggiore, Loren
                   and Kay, Jackie and Jhakra, Priya and Wang, Shibo and Maynez,
                   Joshua and Phuong, Mary and Tobin, Taylor and Tacchetti,
                   Andrea and Trebacz, Maja and Robinson, Kevin and Katariya,
                   Yash and Riedel, Sebastian and Bailey, Paige and Xiao, Kefan
                   and Ghelani, Nimesh and Aroyo, Lora and Slone, Ambrose and
                   Houlsby, Neil and Xiong, Xuehan and Yang, Zhen and
                   Gribovskaya, Elena and Adler, Jonas and Wirth, Mateo and Lee,
                   Lisa and Li, Music and Kagohara, Thais and Pavagadhi, Jay and
                   Bridgers, Sophie and Bortsova, Anna and Ghemawat, Sanjay and
                   Ahmed, Zafarali and Liu, Tianqi and Powell, Richard and
                   Bolina, Vijay and Iinuma, Mariko and Zablotskaia, Polina and
                   Besley, James and Chung, Da-Woon and Dozat, Timothy and
                   Comanescu, Ramona and Si, Xiance and Greer, Jeremy and Su,
                   Guolong and Polacek, Martin and Kaufman, Raphaël Lopez and
                   Tokumine, Simon and Hu, Hexiang and Buchatskaya, Elena and
                   Miao, Yingjie and Elhawaty, Mohamed and Siddhant, Aditya and
                   Tomasev, Nenad and Xing, Jinwei and Greer, Christina and
                   Miller, Helen and Ashraf, Shereen and Roy, Aurko and Zhang,
                   Zizhao and Ma, Ada and Filos, Angelos and Besta, Milos and
                   Blevins, Rory and Klimenko, Ted and Yeh, Chih-Kuan and
                   Changpinyo, Soravit and Mu, Jiaqi and Chang, Oscar and
                   Pajarskas, Mantas and Muir, Carrie and Cohen, Vered and Lan,
                   Charline Le and Haridasan, Krishna and Marathe, Amit and
                   Hansen, Steven and Douglas, Sholto and Samuel, Rajkumar and
                   Wang, Mingqiu and Austin, Sophia and Lan, Chang and Jiang,
                   Jiepu and Chiu, Justin and Lorenzo, Jaime Alonso and Sjösund,
                   Lars Lowe and Cevey, Sébastien and Gleicher, Zach and
                   Avrahami, Thi and Boral, Anudhyan and Srinivasan, Hansa and
                   Selo, Vittorio and May, Rhys and Aisopos, Konstantinos and
                   Hussenot, Léonard and Soares, Livio Baldini and Baumli, Kate
                   and Chang, Michael B and Recasens, Adrià and Caine, Ben and
                   Pritzel, Alexander and Pavetic, Filip and Pardo, Fabio and
                   Gergely, Anita and Frye, Justin and Ramasesh, Vinay and
                   Horgan, Dan and Badola, Kartikeya and Kassner, Nora and Roy,
                   Subhrajit and Dyer, Ethan and Campos, Víctor Campos and
                   Tomala, Alex and Tang, Yunhao and Badawy, Dalia El and White,
                   Elspeth and Mustafa, Basil and Lang, Oran and Jindal,
                   Abhishek and Vikram, Sharad and Gong, Zhitao and Caelles,
                   Sergi and Hemsley, Ross and Thornton, Gregory and Feng,
                   Fangxiaoyu and Stokowiec, Wojciech and Zheng, Ce and Thacker,
                   Phoebe and Ünlü, Çağlar and Zhang, Zhishuai and Saleh,
                   Mohammad and Svensson, James and Bileschi, Max and Patil,
                   Piyush and Anand, Ankesh and Ring, Roman and Tsihlas,
                   Katerina and Vezer, Arpi and Selvi, Marco and Shevlane, Toby
                   and Rodriguez, Mikel and Kwiatkowski, Tom and Daruki, Samira
                   and Rong, Keran and Dafoe, Allan and FitzGerald, Nicholas and
                   Gu-Lemberg, Keren and Khan, Mina and Hendricks, Lisa Anne and
                   Pellat, Marie and Feinberg, Vladimir and Cobon-Kerr, James
                   and Sainath, Tara and Rauh, Maribeth and Hashemi, Sayed Hadi
                   and Ives, Richard and Hasson, Yana and Noland, Eric and Cao,
                   Yuan and Byrd, Nathan and Hou, Le and Wang, Qingze and
                   Sottiaux, Thibault and Paganini, Michela and Lespiau,
                   Jean-Baptiste and Moufarek, Alexandre and Hassan, Samer and
                   Shivakumar, Kaushik and van Amersfoort, Joost and Mandhane,
                   Amol and Joshi, Pratik and Goyal, Anirudh and Tung, Matthew
                   and Brock, Andrew and Sheahan, Hannah and Misra, Vedant and
                   Li, Cheng and Rakićević, Nemanja and Dehghani, Mostafa and
                   Liu, Fangyu and Mittal, Sid and Oh, Junhyuk and Noury, Seb
                   and Sezener, Eren and Huot, Fantine and Lamm, Matthew and De
                   Cao, Nicola and Chen, Charlie and Mudgal, Sidharth and
                   Stella, Romina and Brooks, Kevin and Vasudevan, Gautam and
                   Liu, Chenxi and Chain, Mainak and Melinkeri, Nivedita and
                   Cohen, Aaron and Wang, Venus and Seymore, Kristie and Zubkov,
                   Sergey and Goel, Rahul and Yue, Summer and Krishnakumaran,
                   Sai and Albert, Brian and Hurley, Nate and Sano, Motoki and
                   Mohananey, Anhad and Joughin, Jonah and Filonov, Egor and
                   Kępa, Tomasz and Eldawy, Yomna and Lim, Jiawern and Rishi,
                   Rahul and Badiezadegan, Shirin and Bos, Taylor and Chang,
                   Jerry and Jain, Sanil and Padmanabhan, Sri Gayatri Sundara
                   and Puttagunta, Subha and Krishna, Kalpesh and Baker, Leslie
                   and Kalb, Norbert and Bedapudi, Vamsi and Kurzrok, Adam and
                   Lei, Shuntong and Yu, Anthony and Litvin, Oren and Zhou,
                   Xiang and Wu, Zhichun and Sobell, Sam and Siciliano, Andrea
                   and Papir, Alan and Neale, Robby and Bragagnolo, Jonas and
                   Toor, Tej and Chen, Tina and Anklin, Valentin and Wang,
                   Feiran and Feng, Richie and Gholami, Milad and Ling, Kevin
                   and Liu, Lijuan and Walter, Jules and Moghaddam, Hamid and
                   Kishore, Arun and Adamek, Jakub and Mercado, Tyler and
                   Mallinson, Jonathan and Wandekar, Siddhinita and Cagle,
                   Stephen and Ofek, Eran and Garrido, Guillermo and Lombriser,
                   Clemens and Mukha, Maksim and Sun, Botu and Mohammad,
                   Hafeezul Rahman and Matak, Josip and Qian, Yadi and Peswani,
                   Vikas and Janus, Pawel and Yuan, Quan and Schelin, Leif and
                   David, Oana and Garg, Ankur and He, Yifan and Duzhyi, Oleksii
                   and Älgmyr, Anton and Lottaz, Timothée and Li, Qi and Yadav,
                   Vikas and Xu, Luyao and Chinien, Alex and Shivanna, Rakesh
                   and Chuklin, Aleksandr and Li, Josie and Spadine, Carrie and
                   Wolfe, Travis and Mohamed, Kareem and Das, Subhabrata and
                   Dai, Zihang and He, Kyle and von Dincklage, Daniel and
                   Upadhyay, Shyam and Maurya, Akanksha and Chi, Luyan and
                   Krause, Sebastian and Salama, Khalid and Rabinovitch, Pam G
                   and M, Pavan Kumar Reddy and Selvan, Aarush and Dektiarev,
                   Mikhail and Ghiasi, Golnaz and Guven, Erdem and Gupta,
                   Himanshu and Liu, Boyi and Sharma, Deepak and Shtacher, Idan
                   Heimlich and Paul, Shachi and Akerlund, Oscar and Aubet,
                   François-Xavier and Huang, Terry and Zhu, Chen and Zhu, Eric
                   and Teixeira, Elico and Fritze, Matthew and Bertolini,
                   Francesco and Marinescu, Liana-Eleonora and Bölle, Martin and
                   Paulus, Dominik and Gupta, Khyatti and Latkar, Tejasi and
                   Chang, Max and Sanders, Jason and Wilson, Roopa and Wu,
                   Xuewei and Tan, Yi-Xuan and Thiet, Lam Nguyen and Doshi,
                   Tulsee and Lall, Sid and Mishra, Swaroop and Chen, Wanming
                   and Luong, Thang and Benjamin, Seth and Lee, Jasmine and
                   Andrejczuk, Ewa and Rabiej, Dominik and Ranjan, Vipul and
                   Styrc, Krzysztof and Yin, Pengcheng and Simon, Jon and
                   Harriott, Malcolm Rose and Bansal, Mudit and Robsky, Alexei
                   and Bacon, Geoff and Greene, David and Mirylenka, Daniil and
                   Zhou, Chen and Sarvana, Obaid and Goyal, Abhimanyu and
                   Andermatt, Samuel and Siegler, Patrick and Horn, Ben and
                   Israel, Assaf and Pongetti, Francesco and Chen, Chih-Wei
                   ``louis and Selvatici, Marco and Silva, Pedro and Wang,
                   Kathie and Tolins, Jackson and Guu, Kelvin and Yogev, Roey
                   and Cai, Xiaochen and Agostini, Alessandro and Shah, Maulik
                   and Nguyen, Hung and Donnaile, Noah Ó and Pereira, Sébastien
                   and Friso, Linda and Stambler, Adam and Kurzrok, Adam and
                   Kuang, Chenkai and Romanikhin, Yan and Geller, Mark and Yan,
                   Z J and Jang, Kane and Lee, Cheng-Chun and Fica, Wojciech and
                   Malmi, Eric and Tan, Qijun and Banica, Dan and Balle, Daniel
                   and Pham, Ryan and Huang, Yanping and Avram, Diana and Shi,
                   Hongzhi and Singh, Jasjot and Hidey, Chris and Ahuja,
                   Niharika and Saxena, Pranab and Dooley, Dan and Potharaju,
                   Srividya Pranavi and O'Neill, Eileen and Gokulchandran, Anand
                   and Foley, Ryan and Zhao, Kai and Dusenberry, Mike and Liu,
                   Yuan and Mehta, Pulkit and Kotikalapudi, Ragha and
                   Safranek-Shrader, Chalence and Goodman, Andrew and Kessinger,
                   Joshua and Globen, Eran and Kolhar, Prateek and Gorgolewski,
                   Chris and Ibrahim, Ali and Song, Yang and Eichenbaum, Ali and
                   Brovelli, Thomas and Potluri, Sahitya and Lahoti, Preethi and
                   Baetu, Cip and Ghorbani, Ali and Chen, Charles and Crawford,
                   Andy and Pal, Shalini and Sridhar, Mukund and Gurita, Petru
                   and Mujika, Asier and Petrovski, Igor and Cedoz, Pierre-Louis
                   and Li, Chenmei and Chen, Shiyuan and Santo, Niccolò Dal and
                   Goyal, Siddharth and Punjabi, Jitesh and Kappaganthu, Karthik
                   and Kwak, Chester and Lv, Pallavi and Velury, Sarmishta and
                   Choudhury, Himadri and Hall, Jamie and Shah, Premal and
                   Figueira, Ricardo and Thomas, Matt and Lu, Minjie and Zhou,
                   Ting and Kumar, Chintu and Jurdi, Thomas and Chikkerur,
                   Sharat and Ma, Yenai and Yu, Adams and Kwak, Soo and Ähdel,
                   Victor and Rajayogam, Sujeevan and Choma, Travis and Liu, Fei
                   and Barua, Aditya and Ji, Colin and Park, Ji Ho and
                   Hellendoorn, Vincent and Bailey, Alex and Bilal, Taylan and
                   Zhou, Huanjie and Khatir, Mehrdad and Sutton, Charles and
                   Rzadkowski, Wojciech and Macintosh, Fiona and Shagin,
                   Konstantin and Medina, Paul and Liang, Chen and Zhou, Jinjing
                   and Shah, Pararth and Bi, Yingying and Dankovics, Attila and
                   Banga, Shipra and Lehmann, Sabine and Bredesen, Marissa and
                   Lin, Zifan and Hoffmann, John Eric and Lai, Jonathan and
                   Chung, Raynald and Yang, Kai and Balani, Nihal and
                   Bražinskas, Arthur and Sozanschi, Andrei and Hayes, Matthew
                   and Alcalde, Héctor Fernández and Makarov, Peter and Chen,
                   Will and Stella, Antonio and Snijders, Liselotte and Mandl,
                   Michael and Kärrman, Ante and Nowak, Paweł and Wu, Xinyi and
                   Dyck, Alex and Vaidyanathan, Krishnan and R, Raghavender and
                   Mallet, Jessica and Rudominer, Mitch and Johnston, Eric and
                   Mittal, Sushil and Udathu, Akhil and Christensen, Janara and
                   Verma, Vishal and Irving, Zach and Santucci, Andreas and
                   Elsayed, Gamaleldin and Davoodi, Elnaz and Georgiev, Marin
                   and Tenney, Ian and Hua, Nan and Cideron, Geoffrey and
                   Leurent, Edouard and Alnahlawi, Mahmoud and Georgescu, Ionut
                   and Wei, Nan and Zheng, Ivy and Scandinaro, Dylan and Jiang,
                   Heinrich and Snoek, Jasper and Sundararajan, Mukund and Wang,
                   Xuezhi and Ontiveros, Zack and Karo, Itay and Cole, Jeremy
                   and Rajashekhar, Vinu and Tumeh, Lara and Ben-David, Eyal and
                   Jain, Rishub and Uesato, Jonathan and Datta, Romina and
                   Bunyan, Oskar and Wu, Shimu and Zhang, John and Stanczyk,
                   Piotr and Zhang, Ye and Steiner, David and Naskar, Subhajit
                   and Azzam, Michael and Johnson, Matthew and Paszke, Adam and
                   Chiu, Chung-Cheng and Elias, Jaume Sanchez and Mohiuddin,
                   Afroz and Muhammad, Faizan and Miao, Jin and Lee, Andrew and
                   Vieillard, Nino and Park, Jane and Zhang, Jiageng and
                   Stanway, Jeff and Garmon, Drew and Karmarkar, Abhijit and
                   Dong, Zhe and Lee, Jong and Kumar, Aviral and Zhou, Luowei
                   and Evens, Jonathan and Isaac, William and Irving, Geoffrey
                   and Loper, Edward and Fink, Michael and Arkatkar, Isha and
                   Chen, Nanxin and Shafran, Izhak and Petrychenko, Ivan and
                   Chen, Zhe and Jia, Johnson and Levskaya, Anselm and Zhu,
                   Zhenkai and Grabowski, Peter and Mao, Yu and Magni, Alberto
                   and Yao, Kaisheng and Snaider, Javier and Casagrande, Norman
                   and Palmer, Evan and Suganthan, Paul and Castaño, Alfonso and
                   Giannoumis, Irene and Kim, Wooyeol and Rybiński, Mikołaj and
                   Sreevatsa, Ashwin and Prendki, Jennifer and Soergel, David
                   and Goedeckemeyer, Adrian and Gierke, Willi and Jafari,
                   Mohsen and Gaba, Meenu and Wiesner, Jeremy and Wright, Diana
                   Gage and Wei, Yawen and Vashisht, Harsha and Kulizhskaya,
                   Yana and Hoover, Jay and Le, Maigo and Li, Lu and Iwuanyanwu,
                   Chimezie and Liu, Lu and Ramirez, Kevin and Khorlin, Andrey
                   and Cui, Albert and Lin, Tian and Wu, Marcus and Aguilar,
                   Ricardo and Pallo, Keith and Chakladar, Abhishek and Perng,
                   Ginger and Abellan, Elena Allica and Zhang, Mingyang and
                   Dasgupta, Ishita and Kushman, Nate and Penchev, Ivo and
                   Repina, Alena and Wu, Xihui and van der Weide, Tom and
                   Ponnapalli, Priya and Kaplan, Caroline and Simsa, Jiri and
                   Li, Shuangfeng and Dousse, Olivier and Yang, Fan and Piper,
                   Jeff and Ie, Nathan and Pasumarthi, Rama and Lintz, Nathan
                   and Vijayakumar, Anitha and Andor, Daniel and Valenzuela,
                   Pedro and Lui, Minnie and Paduraru, Cosmin and Peng, Daiyi
                   and Lee, Katherine and Zhang, Shuyuan and Greene, Somer and
                   Nguyen, Duc Dung and Kurylowicz, Paula and Hardin, Cassidy
                   and Dixon, Lucas and Janzer, Lili and Choo, Kiam and Feng,
                   Ziqiang and Zhang, Biao and Singhal, Achintya and Du, Dayou
                   and McKinnon, Dan and Antropova, Natasha and Bolukbasi, Tolga
                   and Keller, Orgad and Reid, David and Finchelstein, Daniel
                   and Raad, Maria Abi and Crocker, Remi and Hawkins, Peter and
                   Dadashi, Robert and Gaffney, Colin and Franko, Ken and
                   Bulanova, Anna and Leblond, Rémi and Chung, Shirley and
                   Askham, Harry and Cobo, Luis C and Xu, Kelvin and Fischer,
                   Felix and Xu, Jun and Sorokin, Christina and Alberti, Chris
                   and Lin, Chu-Cheng and Evans, Colin and Dimitriev, Alek and
                   Forbes, Hannah and Banarse, Dylan and Tung, Zora and
                   Omernick, Mark and Bishop, Colton and Sterneck, Rachel and
                   Jain, Rohan and Xia, Jiawei and Amid, Ehsan and Piccinno,
                   Francesco and Wang, Xingyu and Banzal, Praseem and Mankowitz,
                   Daniel J and Polozov, Alex and Krakovna, Victoria and Brown,
                   Sasha and Bateni, Mohammadhossein and Duan, Dennis and
                   Firoiu, Vlad and Thotakuri, Meghana and Natan, Tom and Geist,
                   Matthieu and Girgin, Ser Tan and Li, Hui and Ye, Jiayu and
                   Roval, Ofir and Tojo, Reiko and Kwong, Michael and Lee-Thorp,
                   James and Yew, Christopher and Sinopalnikov, Danila and
                   Ramos, Sabela and Mellor, John and Sharma, Abhishek and Wu,
                   Kathy and Miller, David and Sonnerat, Nicolas and Vnukov,
                   Denis and Greig, Rory and Beattie, Jennifer and Caveness,
                   Emily and Bai, Libin and Eisenschlos, Julian and Korchemniy,
                   Alex and Tsai, Tomy and Jasarevic, Mimi and Kong, Weize and
                   Dao, Phuong and Zheng, Zeyu and Liu, Frederick and Yang, Fan
                   and Zhu, Rui and Teh, Tian Huey and Sanmiya, Jason and
                   Gladchenko, Evgeny and Trdin, Nejc and Toyama, Daniel and
                   Rosen, Evan and Tavakkol, Sasan and Xue, Linting and Elkind,
                   Chen and Woodman, Oliver and Carpenter, John and
                   Papamakarios, George and Kemp, Rupert and Kafle, Sushant and
                   Grunina, Tanya and Sinha, Rishika and Talbert, Alice and Wu,
                   Diane and Owusu-Afriyie, Denese and Du, Cosmo and Thornton,
                   Chloe and Pont-Tuset, Jordi and Narayana, Pradyumna and Li,
                   Jing and Fatehi, Saaber and Wieting, John and Ajmeri, Omar
                   and Uria, Benigno and Ko, Yeongil and Knight, Laura and
                   Héliou, Amélie and Niu, Ning and Gu, Shane and Pang, Chenxi
                   and Li, Yeqing and Levine, Nir and Stolovich, Ariel and
                   Santamaria-Fernandez, Rebeca and Goenka, Sonam and Yustalim,
                   Wenny and Strudel, Robin and Elqursh, Ali and Deck, Charlie
                   and Lee, Hyo and Li, Zonglin and Levin, Kyle and Hoffmann,
                   Raphael and Holtmann-Rice, Dan and Bachem, Olivier and Arora,
                   Sho and Koh, Christy and Yeganeh, Soheil Hassas and Põder,
                   Siim and Tariq, Mukarram and Sun, Yanhua and Ionita, Lucian
                   and Seyedhosseini, Mojtaba and Tafti, Pouya and Liu, Zhiyu
                   and Gulati, Anmol and Liu, Jasmine and Ye, Xinyu and
                   Chrzaszcz, Bart and Wang, Lily and Sethi, Nikhil and Li,
                   Tianrun and Brown, Ben and Singh, Shreya and Fan, Wei and
                   Parisi, Aaron and Stanton, Joe and Koverkathu, Vinod and
                   Choquette-Choo, Christopher A and Li, Yunjie and Lu, T J and
                   Ittycheriah, Abe and Shroff, Prakash and Varadarajan, Mani
                   and Bahargam, Sanaz and Willoughby, Rob and Gaddy, David and
                   Desjardins, Guillaume and Cornero, Marco and Robenek, Brona
                   and Mittal, Bhavishya and Albrecht, Ben and Shenoy, Ashish
                   and Moiseev, Fedor and Jacobsson, Henrik and Ghaffarkhah,
                   Alireza and Rivière, Morgane and Walton, Alanna and Crepy,
                   Clément and Parrish, Alicia and Zhou, Zongwei and Farabet,
                   Clement and Radebaugh, Carey and Srinivasan, Praveen and van
                   der Salm, Claudia and Fidjeland, Andreas and Scellato,
                   Salvatore and Latorre-Chimoto, Eri and Klimczak-Plucińska,
                   Hanna and Bridson, David and de Cesare, Dario and Hudson, Tom
                   and Mendolicchio, Piermaria and Walker, Lexi and Morris, Alex
                   and Mauger, Matthew and Guseynov, Alexey and Reid, Alison and
                   Odoom, Seth and Loher, Lucia and Cotruta, Victor and
                   Yenugula, Madhavi and Grewe, Dominik and Petrushkina,
                   Anastasia and Duerig, Tom and Sanchez, Antonio and Yadlowsky,
                   Steve and Shen, Amy and Globerson, Amir and Webb, Lynette and
                   Dua, Sahil and Li, Dong and Bhupatiraju, Surya and Hurt, Dan
                   and Qureshi, Haroon and Agarwal, Ananth and Shani, Tomer and
                   Eyal, Matan and Khare, Anuj and Belle, Shreyas Rammohan and
                   Wang, Lei and Tekur, Chetan and Kale, Mihir Sanjay and Wei,
                   Jinliang and Sang, Ruoxin and Saeta, Brennan and Liechty,
                   Tyler and Sun, Yi and Zhao, Yao and Lee, Stephan and Nayak,
                   Pandu and Fritz, Doug and Vuyyuru, Manish Reddy and
                   Aslanides, John and Vyas, Nidhi and Wicke, Martin and Ma,
                   Xiao and Eltyshev, Evgenii and Martin, Nina and Cate, Hardie
                   and Manyika, James and Amiri, Keyvan and Kim, Yelin and
                   Xiong, Xi and Kang, Kai and Luisier, Florian and Tripuraneni,
                   Nilesh and Madras, David and Guo, Mandy and Waters, Austin
                   and Wang, Oliver and Ainslie, Joshua and Baldridge, Jason and
                   Zhang, Han and Pruthi, Garima and Bauer, Jakob and Yang, Feng
                   and Mansour, Riham and Gelman, Jason and Xu, Yang and
                   Polovets, George and Liu, Ji and Cai, Honglong and Chen,
                   Warren and Sheng, Xianghai and Xue, Emily and Ozair, Sherjil
                   and Angermueller, Christof and Li, Xiaowei and Sinha, Anoop
                   and Wang, Weiren and Wiesinger, Julia and Koukoumidis,
                   Emmanouil and Tian, Yuan and Iyer, Anand and Gurumurthy,
                   Madhu and Goldenson, Mark and Shah, Parashar and Blake, M K
                   and Yu, Hongkun and Urbanowicz, Anthony and Palomaki,
                   Jennimaria and Fernando, Chrisantha and Durden, Ken and
                   Mehta, Harsh and Momchev, Nikola and Rahimtoroghi, Elahe and
                   Georgaki, Maria and Raul, Amit and Ruder, Sebastian and
                   Redshaw, Morgan and Lee, Jinhyuk and Zhou, Denny and Jalan,
                   Komal and Li, Dinghua and Hechtman, Blake and Schuh, Parker
                   and Nasr, Milad and Milan, Kieran and Mikulik, Vladimir and
                   Franco, Juliana and Green, Tim and Nguyen, Nam and Kelley,
                   Joe and Mahendru, Aroma and Hu, Andrea and Howland, Joshua
                   and Vargas, Ben and Hui, Jeffrey and Bansal, Kshitij and Rao,
                   Vikram and Ghiya, Rakesh and Wang, Emma and Ye, Ke and Sarr,
                   Jean Michel and Preston, Melanie Moranski and Elish,
                   Madeleine and Li, Steve and Kaku, Aakash and Gupta, Jigar and
                   Pasupat, Ice and Juan, Da-Cheng and Someswar, Milan and M.,
                   Tejvi and Chen, Xinyun and Amini, Aida and Fabrikant, Alex
                   and Chu, Eric and Dong, Xuanyi and Muthal, Amruta and
                   Buthpitiya, Senaka and Jauhari, Sarthak and Hua, Nan and
                   Khandelwal, Urvashi and Hitron, Ayal and Ren, Jie and
                   Rinaldi, Larissa and Drath, Shahar and Dabush, Avigail and
                   Jiang, Nan-Jiang and Godhia, Harshal and Sachs, Uli and Chen,
                   Anthony and Fan, Yicheng and Taitelbaum, Hagai and Noga, Hila
                   and Dai, Zhuyun and Wang, James and Liang, Chen and Hamer,
                   Jenny and Ferng, Chun-Sung and Elkind, Chenel and Atias,
                   Aviel and Lee, Paulina and Listík, Vít and Carlen, Mathias
                   and van de Kerkhof, Jan and Pikus, Marcin and Zaher,
                   Krunoslav and Müller, Paul and Zykova, Sasha and Stefanec,
                   Richard and Gatsko, Vitaly and Hirnschall, Christoph and
                   Sethi, Ashwin and Xu, Xingyu Federico and Ahuja, Chetan and
                   Tsai, Beth and Stefanoiu, Anca and Feng, Bo and Dhandhania,
                   Keshav and Katyal, Manish and Gupta, Akshay and Parulekar,
                   Atharva and Pitta, Divya and Zhao, Jing and Bhatia, Vivaan
                   and Bhavnani, Yashodha and Alhadlaq, Omar and Li, Xiaolin and
                   Danenberg, Peter and Tu, Dennis and Pine, Alex and Filippova,
                   Vera and Ghosh, Abhipso and Limonchik, Ben and Urala,
                   Bhargava and Lanka, Chaitanya Krishna and Clive, Derik and
                   Sun, Yi and Li, Edward and Wu, Hao and Hongtongsak, Kevin and
                   Li, Ianna and Thakkar, Kalind and Omarov, Kuanysh and
                   Majmundar, Kushal and Alverson, Michael and Kucharski,
                   Michael and Patel, Mohak and Jain, Mudit and Zabelin, Maksim
                   and Pelagatti, Paolo and Kohli, Rohan and Kumar, Saurabh and
                   Kim, Joseph and Sankar, Swetha and Shah, Vineet and
                   Ramachandruni, Lakshmi and Zeng, Xiangkai and Bariach, Ben
                   and Weidinger, Laura and Vu, Tu and Andreev, Alek and He,
                   Antoine and Hui, Kevin and Kashem, Sheleem and Subramanya,
                   Amar and Hsiao, Sissie and Hassabis, Demis and Kavukcuoglu,
                   Koray and Sadovsky, Adam and Le, Quoc and Strohman, Trevor
                   and Wu, Yonghui and Petrov, Slav and Dean, Jeffrey and
                   Vinyals, Oriol",
  journal       = "arXiv [cs.CL]",
  abstract      = "This report introduces a new family of multimodal models,
                   Gemini, that exhibit remarkable capabilities across image,
                   audio, video, and text understanding. The Gemini family
                   consists of Ultra, Pro, and Nano sizes, suitable for
                   applications ranging from complex reasoning tasks to
                   on-device memory-constrained use-cases. Evaluation on a broad
                   range of benchmarks shows that our most-capable Gemini Ultra
                   model advances the state of the art in 30 of 32 of these
                   benchmarks - notably being the first model to achieve
                   human-expert performance on the well-studied exam benchmark
                   MMLU, and improving the state of the art in every one of the
                   20 multimodal benchmarks we examined. We believe that the new
                   capabilities of the Gemini family in cross-modal reasoning
                   and language understanding will enable a wide variety of use
                   cases. We discuss our approach toward post-training and
                   deploying Gemini models responsibly to users through services
                   including Gemini, Gemini Advanced, Google AI Studio, and
                   Cloud Vertex AI.",
  month         =  dec,
  year          =  2023,
  archivePrefix = "arXiv",
  primaryClass  = "cs.CL"
}

@MISC{Ianigro2022-wg,
  title     = "Plecto: Investigating the musical affordances of Continuous Time
               Recurrent Neural Networks",
  author    = "Ianigro, Steffan",
  publisher = "UNSW Sydney",
  abstract  = "``Plecto: Investigating the musical affordances of Continuous
               Time Recurrent Neural Networks'' is a practice-based research
               project that investigates how continuous time recurrent neural
               networks (CTRNNs) can be applied to the problem of achieving
               gestural control in improvised electronic music. One of the
               challenges of improvising using computers is manipulating
               different compositional layers during a performance while
               maintaining granular and expressive control. Artists turn to
               concepts such as artificial life to solve this problem and pursue
               software agents with complex, responsive and organic qualities
               that lead to the perception of lifelikeness. Guided by this
               theme, I propose a design for a low frequency oscillator (LFO),
               called Plecto, for use within existing composition workflows that
               harnesses the idiosyncratic behaviours of CTRNNs as a gestural
               agent within improvised electronic music performances. CTRNNs
               have been used in studies of biological modelling such as animal
               locomotion, and also of minimally cognitive behaviours such as
               basic object perception. Their ability to produce lifelike
               abstract forms makes them well suited as a source of gestural
               control. Oliver Bown and Sebastian Lexer have applied CTRNNs to
               musical event generation, using evolutionary algorithms (EA) to
               search for different CTRNN behaviours. I have extended this
               approach, using a novelty search (NS) variant for the open-ended
               discovery of CTRNN configurations, each exhibiting novel
               behaviours that can be applied to different musical problems.
               Through a series of computational studies, I have explored the
               lifelike qualities of CTRNNs best suited for gestural control and
               a novelty search algorithm design for their discovery. An
               iterative design process was also undertaken, establishing clear
               design principles adopted to build a usable representation of the
               CTRNN algorithm within an LFO device built for the Ableton Live
               environment. Evaluation of the tool was conducted through a user
               survey and practice-based case studies that incorporate the
               device into my own improvised electronic music workflow as a
               gestural agent. The primary outcomes of this research are a suite
               of software that can be adopted by the broader community of
               practitioners and a series of compositions reflecting the impacts
               of the CTRNN algorithm on my creative process.",
  year      =  2022
}

@ARTICLE{Bilda2008-hx,
  title    = "Designing for creative engagement",
  author   = "Bilda, Zafer and Edmonds, Ernest and Candy, Linda",
  journal  = "Design Studies",
  volume   =  29,
  number   =  6,
  pages    = "525--540",
  abstract = "This paper addresses the problem of understanding creative
              engagement with interactive systems. A model of engagement is
              proposed which represents modalities and phases of interactive
              experiences. The model was derived from empirical studies of
              audience interaction with art systems. The aim is to provide a
              means of facilitating communication between participants in the
              interaction design process. The intention is to help improve
              collaboration between participants through examining,
              understanding and agreeing on the set of concepts and modalities
              on interactive experience. The ongoing research involves refining
              and developing the model into a more general-purpose instrument.",
  month    =  nov,
  year     =  2008,
  keywords = "interaction design; user behaviour; evaluation; engagement;
              modelling"
}

@ARTICLE{Edmonds2006-or,
  title     = "On creative engagement",
  author    = "Edmonds, Ernest and Muller, Lizzie and Connell, Matthew",
  journal   = "Visual Communication",
  publisher = "SAGE Publications",
  volume    =  5,
  number    =  3,
  pages     = "307--322",
  abstract  = "This article is concerned with the design of interactive art
               systems intended for display in public locations. It reviews
               approaches to interactive art systems and discusses the issue of
               creative engagement with them by the active audience. An approach
               to elaborating a model of creative engagement is described and
               exploratory work on its refinement is reported.",
  month     =  oct,
  year      =  2006
}

@INPROCEEDINGS{Candy2020-ym,
  title     = "Creating with the Digital: Tool, Medium, Mediator, Partner",
  author    = "Candy, Linda",
  booktitle = "Interactivity, Game Creation, Design, Learning, and Innovation",
  publisher = "Springer International Publishing",
  pages     = "13--28",
  abstract  = "This chapter is about the different kinds of relationships that
               creative practitioners have with digital technologies in the
               making of artworks. Four types of creative process are described
               in which the role of the digital is differentiated as tool,
               medium, mediator and partner. In many cases, the digital
               technology performs more than one role: practitioners are using
               ready-made tools for making interactive works and at the same
               time writing algorithms to create digital partners with whom they
               perform. In this kind of creative practice, the technology is
               often the material of the creative works as well as the means by
               which they are made. It can enable a wide range of aesthetic
               qualities as well as facilitate different kinds of experience for
               both creators and audiences. This is a journey that many artists
               are taking in the 21st century contemporary digital arts world.
               The discussion is illustrated by the works of creative
               practitioners for whom digital technology is integral to the way
               they work.",
  year      =  2020
}

@ARTICLE{Shneiderman2006-di,
  title     = "Creativity support tools: Report from a {U}.s. national science
               foundation sponsored workshop",
  author    = "Shneiderman, Ben and Fischer, Gerhard and Czerwinski, Mary and
               Resnick, Mitch and Myers, Brad and Candy, Linda and Edmonds,
               Ernest and Eisenberg, Mike and Giaccardi, Elisa and Hewett, Tom
               and Jennings, Pamela and Kules, Bill and Nakakoji, Kumiyo and
               Nunamaker, Jay and Pausch, Randy and Selker, Ted and Sylvan,
               Elisabeth and Terry, Michael",
  journal   = "Int. J. Hum. Comput. Interact.",
  publisher = "Informa UK Limited",
  volume    =  20,
  number    =  2,
  pages     = "61--77",
  month     =  may,
  year      =  2006,
  language  = "en"
}

@INPROCEEDINGS{Lin2020-ji,
  title     = "It is your turn: Collaborative ideation with a co-creative robot
               through sketch",
  author    = "Lin, Yuyu and Guo, Jiahao and Chen, Yang and Yao, Cheng and Ying,
               Fangtian",
  booktitle = "Proceedings of the 2020 CHI Conference on Human Factors in
               Computing Systems",
  publisher = "ACM",
  address   = "New York, NY, USA",
  month     =  apr,
  year      =  2020
}

@ARTICLE{Ippolito2022-mf,
  title     = "Creative writing with an {AI}-powered writing assistant:
               Perspectives from professional writers",
  author    = "Ippolito, Daphne and Yuan, Ann and Coenen, Andy and Burnam,
               Sehmon",
  journal   = "arXiv.org",
  publisher = "arXiv",
  abstract  = "Recent developments in natural language generation (NLG) using
               neural language models have brought us closer than ever to the
               goal of building AI-powered creative writing tools. However, most
               prior work on human-AI collaboration in the creative writing
               domain has evaluated new systems with amateur writers, typically
               in contrived user studies of limited scope. In this work, we
               commissioned 13 professional, published writers from a diverse
               set of creative writing backgrounds to craft stories using
               Wordcraft, a text editor with built-in AI-powered writing
               assistance tools. Using interviews and participant journals, we
               discuss the potential of NLG to have significant impact in the
               creative writing domain--especially with respect to
               brainstorming, generation of story details, world-building, and
               research assistance. Experienced writers, more so than amateurs,
               typically have well-developed systems and methodologies for
               writing, as well as distinctive voices and target audiences. Our
               work highlights the challenges in building for these writers; NLG
               technologies struggle to preserve style and authorial voice, and
               they lack deep understanding of story contents. In order for
               AI-powered writing assistants to realize their full potential, it
               is essential that they take into account the diverse goals and
               expertise of human writers.",
  year      =  2022,
  language  = "en"
}

@INPROCEEDINGS{Yuan2022-kb,
  title     = "Wordcraft: Story Writing With Large Language Models",
  author    = "Yuan, Ann and Coenen, Andy and Reif, Emily and Ippolito, Daphne",
  booktitle = "Proceedings of the 27th International Conference on Intelligent
               User Interfaces",
  publisher = "Association for Computing Machinery",
  address   = "New York, NY, USA",
  pages     = "841--852",
  abstract  = "The latest generation of large neural language models such as
               GPT-3 have achieved new levels of performance on benchmarks for
               language understanding and generation. These models have even
               demonstrated an ability to perform arbitrary tasks without
               explicit training. In this work, we sought to learn how people
               might use such models in the process of creative writing. We
               built Wordcraft, a text editor in which users collaborate with a
               generative language model to write a story. We evaluated
               Wordcraft with a user study in which participants wrote short
               stories with and without the tool. Our results show that large
               language models enable novel co-writing experiences. For example,
               the language model is able to engage in open-ended conversation
               about the story, respond to writers’ custom requests expressed in
               natural language (such as ”rewrite this text to be more
               Dickensian”), and generate suggestions that serve to unblock
               writers in the creative process. Based on these results, we
               discuss design implications for future human-AI co-writing
               systems.",
  series    = "IUI '22",
  month     =  mar,
  year      =  2022,
  keywords  = "NLP"
}

@ARTICLE{Vinchon2023-gh,
  title     = "Artificial intelligence \& creativity: A manifesto for
               collaboration",
  author    = "Vinchon, Florent and Lubart, Todd and Bartolotta, Sabrina and
               Gironnay, Valentin and Botella, Marion and Bourgeois-Bougrine,
               Samira and Burkhardt, Jean-Marie and Bonnardel, Nathalie and
               Corazza, Giovanni Emanuele and Glăveanu, Vlad and Hanchett
               Hanson, Michael and Ivcevic, Zorana and Karwowski, Maciej and
               Kaufman, James C and Okada, Takeshi and Reiter-Palmon, Roni and
               Gaggioli, Andrea",
  journal   = "J. Creat. Behav.",
  publisher = "Wiley",
  volume    =  57,
  number    =  4,
  pages     = "472--484",
  abstract  = "ABSTRACTWith the advent of artificial intelligence (AI), the
               field of creativity faces new opportunities and challenges. This
               manifesto explores several scenarios of human–machine
               collaboration on creative tasks and proposes “fundamental laws of
               generative AI” to reinforce the responsible and ethical use of AI
               in the creativity field. Four scenarios are proposed and
               discussed: “Co‐Cre‐AI‐tion,” “Organic,” “Plagiarism 3.0,” and
               “Shut down,” each illustrating different possible futures based
               on the collaboration between humans and machines. In addition, we
               have incorporated an AI‐generated manifesto that also highlights
               important themes, ranging from accessibility and ethics to
               cultural sensitivity. The fundamental laws proposed aim to
               prevent AIs from generating harmful content and competing
               directly with humans. Creating labels and laws are also
               highlighted to ensure responsible use of AIs. The positive future
               of creativity and AI lies in a harmonious collaboration that can
               benefit everyone, potentially leading to a new level of creative
               productivity respecting ethical considerations and human values
               during the creative process.",
  month     =  dec,
  year      =  2023,
  language  = "en"
}

@INPROCEEDINGS{Palani2021-jd,
  title     = "{CoNotate}: Suggesting queries based on notes promotes knowledge
               discovery",
  author    = "Palani, Srishti and Ding, Zijian and Nguyen, Austin and Chuang,
               Andrew and MacNeil, Stephen and Dow, Steven P",
  booktitle = "Proceedings of the 2021 CHI Conference on Human Factors in
               Computing Systems",
  publisher = "ACM",
  address   = "New York, NY, USA",
  pages     = "1--14",
  month     =  may,
  year      =  2021
}

@ARTICLE{Eloundou2023-et,
  title         = "{GPTs} are {GPTs}: An Early Look at the Labor Market Impact
                   Potential of Large Language Models",
  author        = "Eloundou, Tyna and Manning, Sam and Mishkin, Pamela and Rock,
                   Daniel",
  journal       = "arXiv [econ.GN]",
  abstract      = "We investigate the potential implications of Generative
                   Pre-trained Transformer (GPT) models and related technologies
                   on the U.S. labor market. Using a new rubric, we assess
                   occupations based on their correspondence with GPT
                   capabilities, incorporating both human expertise and
                   classifications from GPT-4. Our findings indicate that
                   approximately 80\% of the U.S. workforce could have at least
                   10\% of their work tasks affected by the introduction of
                   GPTs, while around 19\% of workers may see at least 50\% of
                   their tasks impacted. The influence spans all wage levels,
                   with higher-income jobs potentially facing greater exposure.
                   Notably, the impact is not limited to industries with higher
                   recent productivity growth. We conclude that Generative
                   Pre-trained Transformers exhibit characteristics of
                   general-purpose technologies (GPTs), suggesting that as these
                   models could have notable economic, social, and policy
                   implications.",
  month         =  mar,
  year          =  2023,
  archivePrefix = "arXiv",
  primaryClass  = "econ.GN"
}

@ARTICLE{Walker2010-fy,
  title     = "Experiencing flow: Is doing it together better than doing it
               alone?",
  author    = "Walker, Charles J",
  journal   = "J. Posit. Psychol.",
  publisher = "Routledge",
  volume    =  5,
  number    =  1,
  pages     = "3--11",
  abstract  = "A survey study and two experiments were done to test the
               hypothesis that social flow is more enjoyable than solitary flow.
               In the survey study it was found that recalled social flow
               experiences were rated more enjoyable than solitary flow
               experiences. In the first experiment when challenge and skill
               were the same across social and solitary conditions, social flow
               was reported to be more enjoyable than solitary flow. In the
               second experiment when the level of social interdependence was
               manipulated it was found that participants in highly
               interdependent teams reported more joy in flow than individuals
               performing less interdependently. In both experiments, people
               playing simple paddleball games reported and expressed more joy
               performing with others than alone. Taken together, the three
               investigations support the conclusion that doing it together is
               better than doing it alone. Solitary flow, while quite enjoyable,
               is not as enjoyable as social flow.",
  month     =  jan,
  year      =  2010
}

@ARTICLE{Sun2016-wo,
  title    = "Training your brain to be more creative: brain functional and
              structural changes induced by divergent thinking training",
  author   = "Sun, Jiangzhou and Chen, Qunlin and Zhang, Qinglin and Li, Yadan
              and Li, Haijiang and Wei, Dongtao and Yang, Wenjing and Qiu, Jiang",
  journal  = "Hum. Brain Mapp.",
  volume   =  37,
  number   =  10,
  pages    = "3375--3387",
  abstract = "Creativity is commonly defined as the ability to produce something
              both novel and useful. Stimulating creativity has great
              significance for both individual success and social improvement.
              Although increasing creative capacity has been confirmed to be
              possible and effective at the behavioral level, few longitudinal
              studies have examined the extent to which the brain function and
              structure underlying creativity are plastic. A cognitive
              stimulation (20 sessions) method was used in the present study to
              train subjects and to explore the neuroplasticity induced by
              training. The behavioral results revealed that both the
              originality and the fluency of divergent thinking were
              significantly improved by training. Furthermore, functional
              changes induced by training were observed in the dorsal anterior
              cingulate cortex (dACC), dorsal lateral prefrontal cortex (DLPFC),
              and posterior brain regions. Moreover, the gray matter volume
              (GMV) was significantly increased in the dACC after divergent
              thinking training. These results suggest that the enhancement of
              creativity may rely not only on the posterior brain regions that
              are related to the fundamental cognitive processes of creativity
              (e.g., semantic processing, generating novel associations), but
              also on areas that are involved in top-down cognitive control,
              such as the dACC and DLPFC. Hum Brain Mapp 37:3375-3387, 2016. ©
              2016 Wiley Periodicals, Inc.",
  month    =  oct,
  year     =  2016,
  keywords = "DLPFC; dACC; divergent thinking; neural plasticity",
  language = "en"
}

@BOOK{noauthor_undated-my,
  title     = "Artificial Intelligence in Music, Sound, Art and Design",
  publisher = "Springer Nature Switzerland"
}

@ARTICLE{May2019-jg,
  title         = "On Measuring Social Biases in Sentence Encoders",
  author        = "May, Chandler and Wang, Alex and Bordia, Shikha and Bowman,
                   Samuel R and Rudinger, Rachel",
  journal       = "arXiv [cs.CL]",
  abstract      = "The Word Embedding Association Test shows that GloVe and
                   word2vec word embeddings exhibit human-like implicit biases
                   based on gender, race, and other social constructs (Caliskan
                   et al., 2017). Meanwhile, research on learning reusable text
                   representations has begun to explore sentence-level texts,
                   with some sentence encoders seeing enthusiastic adoption.
                   Accordingly, we extend the Word Embedding Association Test to
                   measure bias in sentence encoders. We then test several
                   sentence encoders, including state-of-the-art methods such as
                   ELMo and BERT, for the social biases studied in prior work
                   and two important biases that are difficult or impossible to
                   test at the word level. We observe mixed results including
                   suspicious patterns of sensitivity that suggest the test's
                   assumptions may not hold in general. We conclude by proposing
                   directions for future work on measuring bias in sentence
                   encoders.",
  month         =  mar,
  year          =  2019,
  archivePrefix = "arXiv",
  primaryClass  = "cs.CL"
}

@ARTICLE{Suchman1987-ab,
  title     = "Plans and situated actions: The problem of human-machine
               communication",
  author    = "Suchman, Lucy A",
  journal   = "xii",
  publisher = "Cambridge University Press Plans and situated actions",
  address   = "New York, NY, US",
  volume    =  203,
  abstract  = "``Plans and situated actions'' presents a compelling case for the
               reexamination of current models underlying interface design. Lucy
               Suchman's proposals for a fresh characterization of
               human-computer interaction which also incorporates recent
               insights from the social sciences provides a challenge that
               everyone interested in machine intelligence will need seriously
               to consider. (PsycINFO Database Record (c) 2016 APA, all rights
               reserved)",
  year      =  1987
}

@BOOK{Esposito2022-ml,
  title     = "Artificial Communication: How algorithms produce social
               intelligence",
  author    = "Esposito, Elena",
  publisher = "The MIT Press",
  abstract  = "A proposal that we think about digital technologies such as
               machine learning not in terms of artificial intelligence but as
               artificial communication. Algorithms that work with deep learning
               and big data are getting so much better at doing so many things
               that it makes us uncomfortable. How can a device know what our
               favorite songs are, or what we should write in an email? Have
               machines become too smart? In Artificial Communication, Elena
               Esposito argues that drawing this sort of analogy between
               algorithms and human intelligence is misleading. If machines
               contribute to social intelligence, it will not be because they
               have learned how to think like us but because we have learned how
               to communicate with them. Esposito proposes that we think of
               “smart” machines not in terms of artificial intelligence but in
               terms of artificial communication. To do this, we need a concept
               of communication that can take into account the possibility that
               a communication partner may be not a human being but an
               algorithm—which is not random and is completely controlled,
               although not by the processes of the human mind. Esposito
               investigates this by examining the use of algorithms in different
               areas of social life. She explores the proliferation of lists
               (and lists of lists) online, explaining that the web works on the
               basis of lists to produce further lists; the use of
               visualization; digital profiling and algorithmic
               individualization, which personalize a mass medium with playlists
               and recommendations; and the implications of the “right to be
               forgotten.” Finally, she considers how photographs today seem to
               be used to escape the present rather than to preserve a memory.",
  month     =  may,
  year      =  2022,
  language  = "en"
}

@ARTICLE{Vaccaro2024-ne,
  title     = "When combinations of humans and {AI} are useful: A systematic
               review and meta-analysis",
  author    = "Vaccaro, Michelle and Almaatouq, Abdullah and Malone, Thomas",
  journal   = "Nat. Hum. Behav.",
  publisher = "Nature Publishing Group",
  pages     = "1--11",
  abstract  = "Inspired by the increasing use of artificial intelligence (AI) to
               augment humans, researchers have studied human-AI systems
               involving different tasks, systems and populations. Despite such
               a large body of work, we lack a broad conceptual understanding of
               when combinations of humans and AI are better than either alone.
               Here we addressed this question by conducting a preregistered
               systematic review and meta-analysis of 106 experimental studies
               reporting 370 effect sizes. We searched an interdisciplinary set
               of databases (the Association for Computing Machinery Digital
               Library, the Web of Science and the Association for Information
               Systems eLibrary) for studies published between 1 January 2020
               and 30 June 2023. Each study was required to include an original
               human-participants experiment that evaluated the performance of
               humans alone, AI alone and human-AI combinations. First, we found
               that, on average, human-AI combinations performed significantly
               worse than the best of humans or AI alone (Hedges' g = -0.23;
               95\% confidence interval, -0.39 to -0.07). Second, we found
               performance losses in tasks that involved making decisions and
               significantly greater gains in tasks that involved creating
               content. Finally, when humans outperformed AI alone, we found
               performance gains in the combination, but when AI outperformed
               humans alone, we found losses. Limitations of the evidence
               assessed here include possible publication bias and variations in
               the study designs analysed. Overall, these findings highlight the
               heterogeneity of the effects of human-AI collaboration and point
               to promising avenues for improving human-AI systems.",
  month     =  oct,
  year      =  2024,
  language  = "en"
}

@ARTICLE{Koivisto2023-lw,
  title     = "Best humans still outperform artificial intelligence in a
               creative divergent thinking task",
  author    = "Koivisto, Mika and Grassini, Simone",
  journal   = "Sci. Rep.",
  publisher = "Springer Science and Business Media LLC",
  volume    =  13,
  number    =  1,
  pages     =  13601,
  abstract  = "Creativity has traditionally been considered an ability exclusive
               to human beings. However, the rapid development of artificial
               intelligence (AI) has resulted in generative AI chatbots that can
               produce high-quality artworks, raising questions about the
               differences between human and machine creativity. In this study,
               we compared the creativity of humans (n = 256) with that of three
               current AI chatbots using the alternate uses task (AUT), which is
               the most used divergent thinking task. Participants were asked to
               generate uncommon and creative uses for everyday objects. On
               average, the AI chatbots outperformed human participants. While
               human responses included poor-quality ideas, the chatbots
               generally produced more creative responses. However, the best
               human ideas still matched or exceed those of the chatbots. While
               this study highlights the potential of AI as a tool to enhance
               creativity, it also underscores the unique and complex nature of
               human creativity that may be difficult to fully replicate or
               surpass with AI technology. The study provides insights into the
               relationship between human and machine creativity, which is
               related to important questions about the future of creative work
               in the age of AI.",
  month     =  sep,
  year      =  2023,
  language  = "en"
}

@ARTICLE{Hubert2024-kv,
  title     = "The current state of artificial intelligence generative language
               models is more creative than humans on divergent thinking tasks",
  author    = "Hubert, Kent F and Awa, Kim N and Zabelina, Darya L",
  journal   = "Sci. Rep.",
  publisher = "Springer Science and Business Media LLC",
  volume    =  14,
  number    =  1,
  pages     =  3440,
  abstract  = "The emergence of publicly accessible artificial intelligence (AI)
               large language models such as ChatGPT has given rise to global
               conversations on the implications of AI capabilities. Emergent
               research on AI has challenged the assumption that creative
               potential is a uniquely human trait thus, there seems to be a
               disconnect between human perception versus what AI is objectively
               capable of creating. Here, we aimed to assess the creative
               potential of humans in comparison to AI. In the present study,
               human participants (N = 151) and GPT-4 provided responses for the
               Alternative Uses Task, Consequences Task, and Divergent
               Associations Task. We found that AI was robustly more creative
               along each divergent thinking measurement in comparison to the
               human counterparts. Specifically, when controlling for fluency of
               responses, AI was more original and elaborate. The present
               findings suggest that the current state of AI language models
               demonstrate higher creative potential than human respondents.",
  month     =  feb,
  year      =  2024,
  language  = "en"
}

@ARTICLE{Lee2024-vz,
  title     = "An empirical investigation of the impact of {ChatGPT} on
               creativity",
  author    = "Lee, Byung Cheol and Chung, Jaeyeon Jae",
  journal   = "Nat. Hum. Behav.",
  publisher = "Springer Science and Business Media LLC",
  volume    =  8,
  number    =  10,
  pages     = "1906--1914",
  abstract  = "This paper investigates the potential of ChatGPT for helping
               humans tackle problems that require creativity. Across five
               experiments, we asked participants to use ChatGPT (GPT-3.5) to
               generate creative ideas for various everyday and
               innovation-related problems, including choosing a creative gift
               for a teenager, making a toy, repurposing unused items and
               designing an innovative dining table. We found that using ChatGPT
               increased the creativity of the generated ideas compared with not
               using any technology or using a conventional Web search (Google).
               This effect remained robust regardless of whether the problem
               required consideration of many (versus few) constraints and
               whether it was viewed as requiring empathetic concern.
               Furthermore, ChatGPT was most effective at generating
               incrementally (versus radically) new ideas. Process evidence
               suggests that the positive influence of ChatGPT can be attributed
               to its capability to combine remotely related concepts into a
               cohesive form, leading to a more articulate presentation of
               ideas.",
  month     =  oct,
  year      =  2024,
  language  = "en"
}

@ARTICLE{Aveling2015-nn,
  title     = "A qualitative method for analysing multivoicedness",
  author    = "Aveling, Emma-Louise and Gillespie, Alex and Cornish, Flora",
  journal   = "Qual. Res.",
  publisher = "SAGE Publications",
  volume    =  15,
  number    =  6,
  pages     = "670--687",
  abstract  = "'Multivoicedness' and the 'multivoiced Self' have become
               important theoretical concepts guiding research. Drawing on the
               tradition of dialogism, the Self is conceptualised as being
               constituted by a multiplicity of dynamic, interacting voices.
               Despite the growth in literature and empirical research, there
               remains a paucity of established methodological tools for
               analysing the multivoiced Self using qualitative data. In this
               article, we set out a systematic, practical 'how-to' guide for
               analysing multivoicedness. Using theoretically derived tools, our
               three-step method comprises: identifying the voices of
               I-positions within the Self's talk (or text), identifying the
               voices of 'inner-Others', and examining the dialogue and
               relationships between the different voices. We elaborate each
               step and illustrate our method using examples from a published
               paper in which data were analysed using this method. We conclude
               by offering more general principles for the use of the method and
               discussing potential applications.",
  month     =  dec,
  year      =  2015,
  keywords  = "I-positions; Other; dialogical Self; dialogism; method of
               analysis; multivoicedness; voices",
  language  = "en"
}

@ARTICLE{Scott2004-vn,
  title     = "The effectiveness of creativity training: A quantitative review",
  author    = "Scott, Ginamarie and Leritz, Lyle E and Mumford, Michael D",
  journal   = "Creat. Res. J.",
  publisher = "Routledge",
  volume    =  16,
  number    =  4,
  pages     = "361--388",
  abstract  = "Abstract: Over the course of the last half century, numerous
               training programs intended to develop creativity capacities have
               been proposed. In this study, a quantitative meta?analysis of
               program evaluation efforts was conducted. Based on 70 prior
               studies, it was found that well?designed creativity training
               programs typically induce gains in performance with these effects
               generalizing across criteria, settings, and target populations.
               Moreover, these effects held when internal validity
               considerations were taken into account. An examination of the
               factors contributing to the relative effectiveness of these
               training programs indicated that more successful programs were
               likely to focus on development of cognitive skills and the
               heuristics involved in skill application, using realistic
               exercises appropriate to the domain at hand. The implications of
               these observations for the development of creativity through
               educational and training interventions are discussed along with
               directions for future research.",
  month     =  dec,
  year      =  2004
}



@ARTICLE{Lubart2001-vl,
  title     = "Models of the Creative Process: Past, Present and Future",
  author    = "Lubart, Todd I",
  journal   = "Creat. Res. J.",
  publisher = "Routledge",
  volume    =  13,
  number    = "3-4",
  pages     = "295--308",
  abstract  = "The creative process, one of the key topics discussed in
               Guilford's (1950) address to the American Psychological
               Association and his subsequent work, refers to the sequence of
               thoughts and actions that leads to novel, adaptive productions.
               This article examines conceptions of the creative process that
               have been advocated during the past century. In particular,
               stage-based models of the creative process are discussed and the
               evolution of these models is traced. Empirical research suggests
               that the basic 4-stage model of the creative process may need to
               be revised or replaced. Several key questions about the creative
               process are raised, such as how the creative process differs from
               the noncreative process and how process-related differences may
               lead to different levels of creative performance. New directions
               for future research are identified.",
  month     =  oct,
  year      =  2001
}

@ARTICLE{Davis2017-yz,
  title     = "Quantifying Collaboration with a Co-Creative Drawing Agent",
  author    = "Davis, N and Hsiao, C and Singh, K Y and Lin, B and Magerko, B",
  journal   = "ACM Trans. Interact. Intell. Syst.",
  publisher = "Association for Computing Machinery",
  address   = "New York, NY, USA",
  volume    =  7,
  number    =  4,
  pages     = "1--25",
  abstract  = "This article describes a new technique for quantifying creative
               collaboration and applies it to the user study evaluation of a
               co-creative drawing agent. We present a cognitive framework
               called creative sense-making that provides a new method to
               visualize and quantify the interaction dynamics of creative
               collaboration, for example, the rhythm of interaction, style of
               turn taking, and the manner in which participants are mutually
               making sense of a situation. The creative sense-making framework
               includes a qualitative coding technique, interaction coding
               software, an analysis method, and the cognitive theory behind
               these applications. This framework and analysis method are
               applied to empirical studies of the Drawing Apprentice
               collaborative sketching system to compare human collaboration
               with a co-creative AI agent vs. a Wizard of Oz setup. The
               analysis demonstrates how the proposed technique can be used to
               analyze interaction data using continuous functions (e.g.,
               integrations and moving averages) to measure and evaluate how
               collaborations unfold through time.",
  month     =  dec,
  year      =  2017,
  keywords  = "Creativity, drawing, interaction dynamics, creative agents,
               collaboration, evaluation methods, qualitative coding"
}

@INPROCEEDINGS{Jacobsen2020-sn,
  title     = "Perceived and Measured Task Effectiveness in Human-{AI}
               Collaboration",
  author    = "Jacobsen, Rune Møberg and Bysted, Lukas Bjørn Leer and Johansen,
               Patrick Skov and Papachristos, Eleftherios and Skov, Mikael B",
  booktitle = "Extended Abstracts of the 2020 CHI Conference on Human Factors in
               Computing Systems",
  publisher = "Association for Computing Machinery",
  address   = "New York, NY, USA",
  pages     = "1--9",
  abstract  = "Human-AI Collaboration is emerging all around with the increasing
               utilisation of AI. Few prior studies have investigated the
               perceived effectiveness of users solving tasks with AI. To expand
               on these, we conducted a within-subjects repeated measures study
               involving 35 participants sorting household waste according to
               recyclability both with and without the help of an AI system. Our
               results show that people both sorted more effectively and
               perceived themselves more effective. Furthermore, we document a
               trend where people sorting without suggestions perceived
               themselves more effective than they were, while the opposite was
               true for people when sorting receiving suggestions. Based on our
               results we propose open questions for future research on
               perceived effectiveness when collaborating with AI systems.",
  series    = "CHI EA '20",
  month     =  apr,
  year      =  2020,
  keywords  = "lab study, artificial intelligence, effectiveness, human-ai
               collaboration"
}

@INCOLLECTION{Singer2011-od,
  title     = "A Survey of Quantitative Team Performance Metrics For Human-Robot
               Collaboration",
  author    = "Singer, Sharon and Akin, David",
  booktitle = "41st International Conference on Environmental Systems",
  publisher = "American Institute of Aeronautics and Astronautics",
  series    = "International Conference on Environmental Systems (ICES)",
  month     =  jul,
  year      =  2011
}

@INPROCEEDINGS{Howell-Munson2022-pt,
  title     = "Towards Brain Metrics for Improving Multi-Agent Adaptive
               Human-Robot Collaboration: A Preliminary Study",
  author    = "Howell-Munson, Alicia and Doherty, Emily and Gavriel, Peter and
               Nicolas, Claire and Norton, Adam and Neamtu, Rodica and Yanco,
               Holly and Wu, Yi-Ning and Solovey, Erin T",
  booktitle = "2022 Symposium on Human-Computer Interaction for Work",
  publisher = "Association for Computing Machinery",
  address   = "New York, NY, USA",
  number    = "Article 11",
  pages     = "1--10",
  abstract  = "When humans work closely together, they can pick up subtle cues
               from their team members and adapt their behavior appropriately.
               Humans working closely with robots may also give off cues, but
               the robots cannot detect these signals and therefore cannot
               change behavior. In this paper, we focus on heterogeneous
               multi-human and robot teams. Such scenarios exist frequently in
               search and rescue operations as well as space missions, where
               robots perform tasks that are unsafe or even impossible for
               humans. At the same time, human team members collaborate to make
               important decisions that influence and direct the robots’ work.
               These decisions often have to be made quickly with high levels of
               uncertainty, with simultaneous physical and mental demands on the
               human. In this project, we aim to explore the following
               questions: Can brain data provide insights that could improve
               team performance? Could we use these signals to detect when
               someone is experiencing excessive workload? Could we detect an
               impact on team performance caused by the robot?",
  series    = "CHIWORK 2022",
  month     =  jun,
  year      =  2022,
  keywords  = "teamwork, collaboration, human-robot interaction, fNIRS"
}

@ARTICLE{Sankaran2022-ti,
  title     = "A Modeling Approach for Measuring the Performance of a Human-{AI}
               Collaborative Process",
  author    = "Sankaran, Ganesh and Palomino, Marco A and Knahl, Martin and
               Siestrup, Guido",
  journal   = "NATO Adv. Sci. Inst. Ser. E Appl. Sci.",
  publisher = "Multidisciplinary Digital Publishing Institute",
  volume    =  12,
  number    =  22,
  pages     =  11642,
  abstract  = "Despite the unabated growth of algorithmic decision-making in
               organizations, there is a growing consensus that numerous
               situations will continue to require humans in the loop. However,
               the blending of a formal machine and bounded human rationality
               also amplifies the risk of what is known as local rationality.
               Therefore, it is crucial, especially in a data-abundant
               environment that characterizes algorithmic decision-making, to
               devise means to assess performance holistically. In this paper,
               we propose a simulation-based model to address the current lack
               of research on quantifying algorithmic interventions in a broader
               organizational context. Our approach allows the combining of
               causal modeling and data science algorithms to represent decision
               settings involving a mix of machine and human rationality to
               measure performance. As a testbed, we consider the case of a
               fictitious company trying to improve its forecasting process with
               the help of a machine learning approach. The example demonstrates
               that a myopic assessment obscures problems that only a broader
               framing reveals. It highlights the value of a systems view since
               the effects of the interplay between human and algorithmic
               decisions can be largely unintuitive. Such a simulation-based
               approach can be an effective tool in efforts to delineate roles
               for humans and algorithms in hybrid contexts.",
  month     =  nov,
  year      =  2022,
  language  = "en"
}

@ARTICLE{Freedman2020-pi,
  title         = "Helpfulness as a Key Metric of Human-Robot Collaboration",
  author        = "Freedman, Richard G and Levine, Steven J and Williams, Brian
                   C and Zilberstein, Shlomo",
  journal       = "arXiv [cs.AI]",
  abstract      = "As robotic teammates become more common in society, people
                   will assess the robots' roles in their interactions along
                   many dimensions. One such dimension is effectiveness: people
                   will ask whether their robotic partners are trustworthy and
                   effective collaborators. This begs a crucial question: how
                   can we quantitatively measure the helpfulness of a robotic
                   partner for a given task at hand? This paper seeks to answer
                   this question with regards to the interactive robot's
                   decision making. We describe a clear, concise, and
                   task-oriented metric applicable to many different planning
                   and execution paradigms. The proposed helpfulness metric is
                   fundamental to assessing the benefit that a partner has on a
                   team for a given task. In this paper, we define helpfulness,
                   illustrate it on concrete examples from a variety of domains,
                   discuss its properties and ramifications for planning
                   interactions with humans, and present preliminary results.",
  month         =  oct,
  year          =  2020,
  archivePrefix = "arXiv",
  primaryClass  = "cs.AI"
}

@ARTICLE{Fugener2019-yz,
  title    = "Cognitive challenges in human-{AI} collaboration: Investigating
              the path towards productive delegation",
  author   = "Fügener, Andreas and Grahl, Jörn and Gupta, Alok and Ketter,
              Wolfgang",
  abstract = "We study how humans make decisions when they collaborate with an
              artificial intelligence (AI): each instance of a classification
              task could be classified by themselves or by the AI. Experimental
              results suggest that humans and AI who work together can
              outperform the superior AI when it works alone. However, this only
              occurred when the AI delegated work to humans, not when humans
              delegated work to the AI. The AI profited, even from working with
              low-performing subjects, but humans did not delegate well. This
              bad delegation performance cannot be explained with algorithm
              aversion. On the contrary, subjects tried to follow a provided
              delegation strategy diligently and appeared to appreciate the AI
              support. However, human results suffered due to a lack of
              metaknowledge. They were not able to assess their own capabilities
              correctly, which in turn leads to poor delegation decisions. In
              contrast to reluctance to use AI, lacking metaknowledgeis an
              unconscious trait. It limits fundamentally how well human decision
              makers can collaborate with AI and other algorithms when there is
              no explicit performance feedback. The results have implications
              for the future of work, the design of human-AI collaborative
              environments and education in the digital age.",
  month    =  apr,
  year     =  2019,
  keywords = "Future of Work, Artificial Intelligence, Augemented Decision
              Environments, Deep Learning, Human-AI Collaboration, Machine
              Learning, Intelligent Software Agents"
}

@ARTICLE{Castro2021-gq,
  title    = "Trends of Human-Robot Collaboration in Industry Contexts:
              Handover, Learning, and Metrics",
  author   = "Castro, Afonso and Silva, Filipe and Santos, Vitor",
  journal  = "Sensors",
  volume   =  21,
  number   =  12,
  abstract = "Repetitive industrial tasks can be easily performed by traditional
              robotic systems. However, many other works require cognitive
              knowledge that only humans can provide. Human-Robot Collaboration
              (HRC) emerges as an ideal concept of co-working between a human
              operator and a robot, representing one of the most significant
              subjects for human-life improvement.The ultimate goal is to
              achieve physical interaction, where handing over an object plays a
              crucial role for an effective task accomplishment. Considerable
              research work had been developed in this particular field in
              recent years, where several solutions were already proposed.
              Nonetheless, some particular issues regarding Human-Robot
              Collaboration still hold an open path to truly important research
              improvements. This paper provides a literature overview, defining
              the HRC concept, enumerating the distinct human-robot
              communication channels, and discussing the physical interaction
              that this collaboration entails. Moreover, future challenges for a
              natural and intuitive collaboration are exposed: the machine must
              behave like a human especially in the pre-grasping/grasping phases
              and the handover procedure should be fluent and bidirectional, for
              an articulated function development. These are the focus of the
              near future investigation aiming to shed light on the complex
              combination of predictive and reactive control mechanisms
              promoting coordination and understanding. Following recent
              progress in artificial intelligence, learning exploration stand as
              the key element to allow the generation of coordinated actions and
              their shaping by experience.",
  month    =  jun,
  year     =  2021,
  keywords = "Human-Robot Collaboration; interfaces of communication; object
              handover; physicality; robot cognition",
  language = "en"
}

@INPROCEEDINGS{Wang2023-ve,
  title     = "Primacy Effect of {ChatGPT}",
  author    = "Wang, Yiwei and Cai, Yujun and Chen, Muhao and Liang, Yuxuan and
               Hooi, Bryan",
  editor    = "Bouamor, Houda and Pino, Juan and Bali, Kalika",
  booktitle = "Proceedings of the 2023 Conference on Empirical Methods in
               Natural Language Processing",
  publisher = "Association for Computational Linguistics",
  address   = "Singapore",
  pages     = "108--115",
  abstract  = "Instruction-tuned large language models (LLMs), such as ChatGPT,
               have led to promising zero-shot performance in discriminative
               natural language understanding (NLU) tasks. This involves
               querying the LLM using a prompt containing the question, and the
               candidate labels to choose from. The question-answering
               capabilities of ChatGPT arise from its pre-training on large
               amounts of human-written text, as well as its subsequent
               fine-tuning on human preferences, which motivates us to ask: Does
               ChatGPT also inherit humans' cognitive biases? In this paper, we
               study the primacy effect of ChatGPT: the tendency of selecting
               the labels at earlier positions as the answer. We have two main
               findings: i) ChatGPT's decision is sensitive to the order of
               labels in the prompt; ii) ChatGPT has a clearly higher chance to
               select the labels at earlier positions as the answer. We hope
               that our experiments and analyses provide additional insights
               into building more reliable ChatGPT-based solutions. We release
               the source code at https://github.com/wangywUST/PrimacyEffectGPT.",
  month     =  dec,
  year      =  2023
}

@ARTICLE{Eicher2024-eo,
  title         = "Compensatory Biases Under Cognitive Load: Reducing Selection
                   Bias in Large Language Models",
  author        = "Eicher, J E and Irgolič, R F",
  journal       = "arXiv [cs.CL]",
  abstract      = "Large Language Models (LLMs) like gpt-3.5-turbo and
                   claude-instant-1.2 have become instrumental in interpreting
                   and executing semantic-based tasks. Unfortunately, these
                   models' inherent biases, akin to human cognitive biases,
                   adversely affect their performance. Particularly affected is
                   object selection from lists; a fundamental operation in
                   digital navigation and decision-making. This research
                   critically examines these biases and quantifies the effects
                   on a representative list selection task. To explore these
                   biases, we conducted a series of controlled experiments,
                   manipulating temperature, list length, object identity,
                   object type, prompt complexity, and model. This enabled us to
                   isolate and measure the influence of the biases on selection
                   behavior. Our findings show that bias structure is strongly
                   dependent on the model, with object type modulating the
                   magnitude of the effect. With a strong primacy effect,
                   causing the first objects in a list to be disproprotionately
                   represented in outputs. Furthermore the usage of guard rails,
                   a prompt engineering method of ensuring a response structure,
                   can increase bias and decrease instruction adherence when
                   combined with a selection task. The bias is ablated when the
                   guard rail step is separated from the list sampling step,
                   lowering the complexity of each individual task. The
                   implications of this research are two-fold, practically
                   providing a guide for designing unbiased LLM applications and
                   theoretically suggesting that LLMs experience a form of
                   cognitive load compensated for by increasing bias.",
  month         =  jan,
  year          =  2024,
  archivePrefix = "arXiv",
  primaryClass  = "cs.CL"
}

@INPROCEEDINGS{Ocampo2023-gu,
  title     = "Using {GPT}-3 to Achieve Semantically Relevant Data Sonificiation
               for an Art Installation",
  author    = "Ocampo, Rodolfo and Andres, Josh and Schmidt, Adrian and Pegram,
               Caroline and Shave, Justin and Hill, Charlton and Wright, Brendan
               and Bown, Oliver",
  booktitle = "Artificial Intelligence in Music, Sound, Art and Design",
  publisher = "Springer Nature Switzerland",
  pages     = "212--227",
  abstract  = "Large Language Models such as GPT-3 exhibit generative language
               capabilities with multiple potential applications in creative
               practice. In this paper, we present a method for data
               sonification that employs the GPT-3 model to create semantically
               relevant mappings between artificial intelligence-generated
               natural language descriptions of data, and human-generated
               descriptions of sounds. We implemented this method in a public
               art installation to generate a soundscape based on data from
               different systems. While common sonification approaches rely on
               arbitrary mappings between data values and sonic values, our
               approach explores the use of language models to achieve a mapping
               not via values but via meaning. We find our approach is a useful
               tool for musification practice and demonstrates a new application
               of generative language models in creative new media arts
               practice. We show how different prompts influence data to sound
               mappings, and highlight that matching the embeddings of texts of
               different lengths produces undesired behavior.",
  year      =  2023
}

@ARTICLE{Zhou2024-jk,
  title         = "Self-discover: Large language models self-compose reasoning
                   structures",
  author        = "Zhou, Pei and Pujara, Jay and Ren, Xiang and Chen, Xinyun and
                   Cheng, Heng-Tze and Le, Quoc V and Chi, Ed H and Zhou, Denny
                   and Mishra, Swaroop and Zheng, Huaixiu Steven",
  journal       = "arXiv [cs.AI]",
  abstract      = "We introduce SELF-DISCOVER, a general framework for LLMs to
                   self-discover the task-intrinsic reasoning structures to
                   tackle complex reasoning problems that are challenging for
                   typical prompting methods. Core to the framework is a
                   self-discovery process where LLMs select multiple atomic
                   reasoning modules such as critical thinking and step-by-step
                   thinking, and compose them into an explicit reasoning
                   structure for LLMs to follow during decoding. SELF-DISCOVER
                   substantially improves GPT-4 and PaLM 2's performance on
                   challenging reasoning benchmarks such as BigBench-Hard,
                   grounded agent reasoning, and MATH, by as much as 32\%
                   compared to Chain of Thought (CoT). Furthermore,
                   SELF-DISCOVER outperforms inference-intensive methods such as
                   CoT-Self-Consistency by more than 20\%, while requiring
                   10-40x fewer inference compute. Finally, we show that the
                   self-discovered reasoning structures are universally
                   applicable across model families: from PaLM 2-L to GPT-4, and
                   from GPT-4 to Llama2, and share commonalities with human
                   reasoning patterns.",
  month         =  feb,
  year          =  2024,
  archivePrefix = "arXiv",
  primaryClass  = "cs.AI"
}

@ARTICLE{Doshi2023-dv,
  title     = "Generative artificial intelligence enhances creativity but
               reduces the diversity of novel content",
  author    = "Doshi, Anil Rajnikant and Hauser, Oliver",
  journal   = "SSRN Electron. J.",
  publisher = "Elsevier BV",
  abstract  = "Creativity is core to being human. Generative artificial
               intelligence (GenAI) holds promise for humans to be more creative
               by offering new ideas, or less creati",
  month     =  aug,
  year      =  2023,
  keywords  = "generative artificial intelligence (GenAI), artificial
               intelligence (AI), generative AI, large language models (LLMs),
               creativity, experiment",
  language  = "en"
}

@ARTICLE{Auger2013-qd,
  title     = "Speculative design: crafting the speculation",
  author    = "Auger, James",
  journal   = "Digit. Creat.",
  publisher = "Informa UK Limited",
  volume    =  24,
  number    =  1,
  pages     = "11--35",
  abstract  = "The article positions the author's work as speculative design
               but—like the term design fictions—is open to several
               interpretations. How is the fictional character of such work
               conceptualised and produced? What kinds of speculation are
               involved? The article considers the value of one particular
               approach and argues that speculative design serves two distinct
               purposes: first, to enable us to think about the future; second,
               to critique current practice. Methods are described through case
               studies, either of the author's own projects or projects
               completed by graduates of the design interactions course at the
               Royal College of Art. A key concept is the ‘perceptual
               bridge’—the means by which designs engage their audience. The
               article argues that a vital factor in the success of a
               Speculative Design proposal is the careful management of the
               speculation, specifically what informs the use of technology,
               aesthetics, behaviour, interaction and function of the designed
               artefact.",
  month     =  mar,
  year      =  2013,
  language  = "en"
}

@BOOK{Mitrovic2021-cb,
  title     = "Beyond Speculative Design: Past - Present - Future",
  author    = "Mitrović, Ivica and Auger, James and Hanna, Julian and Helgason,
               Ingi",
  publisher = "SpeculativeEdu",
  abstract  = "The book Beyond Speculative Design: Past - Present - Future
               consists of six main sections. After the introduction, there is a
               brief history of speculation in radically different contexts,
               followed by a broad overview of speculative design practice and
               education. From there we dive into speculative design approaches,
               methods, and tools through a series of detailed case studies
               written by the practitioners themselves. A summary of critical
               views on speculative practice over the past two decades follows,
               and we conclude with a suggestion of future paths and a list of
               guidelines (towards good practice) for both educators and
               speculative designers.We hope that this book will provide
               newcomers with a thorough introduction to the past, present and
               future of speculative design and related approaches. Experienced
               practitioners will have the opportunity to check in and learn
               more about diverse approaches, methods and tools, as well as case
               studies; some of which - due to the radical heterogeneity and
               interdisciplinary of the field - they may not have previously
               been aware of. Educators will find a wealth of guidelines, tools,
               case studies and other sources of inspiration, while students
               will benefit from a comprehensive and multifaceted overview of
               the speculative design landscape, across Europe and beyond. --
               Proporcionat per l'editor.",
  year      =  2021,
  language  = "en"
}

@ARTICLE{Shun-liang_Chao2017-se,
  title     = "The Alchemy of Photography: “Grotesque Realism” and Hybrid Nature
               in Jerry Uelsmann's Photomontages",
  author    = "{Shun-liang Chao}",
  journal   = "Criticism",
  publisher = "Wayne State University Press",
  volume    =  59,
  number    =  2,
  pages     = "301--328",
  year      =  2017
}

@ARTICLE{Albahar_undated-vl,
  title  = "{DEEPFAKES}: {THREATS} {AND} {COUNTERMEASURES} {SYSTEMATIC} {REVIEW}",
  author = "Albahar, Marwan and Almalki, Jameel"
}

@INCOLLECTION{Malafouris2008-xn,
  title     = "At the potter’s wheel : An argument for material agency",
  author    = "Malafouris, Lambros",
  booktitle = "Material Agency",
  publisher = "Springer US",
  address   = "Boston, MA",
  pages     = "19--36",
  year      =  2008
}

@BOOK{noauthor_2023-sv,
  title     = "Proceedings of the 2023 {CHI} Conference on Human Factors in
               Computing Systems",
  publisher = "Association for Computing Machinery",
  address   = "New York, NY, USA",
  month     =  mar,
  year      =  2023
}

@ARTICLE{Masood2023-va,
  title    = "Deepfakes generation and detection: state-of-the-art, open
              challenges, countermeasures, and way forward",
  author   = "Masood, Momina and Nawaz, Mariam and Malik, Khalid Mahmood and
              Javed, Ali and Irtaza, Aun and Malik, Hafiz",
  journal  = "Applied Intelligence",
  volume   =  53,
  number   =  4,
  pages    = "3974--4026",
  abstract = "Easy access to audio-visual content on social media, combined with
              the availability of modern tools such as Tensorflow or Keras, and
              open-source trained models, along with economical computing
              infrastructure, and the rapid evolution of deep-learning (DL)
              methods have heralded a new and frightening trend. Particularly,
              the advent of easily available and ready to use Generative
              Adversarial Networks (GANs), have made it possible to generate
              deepfakes media partially or completely fabricated with the intent
              to deceive to disseminate disinformation and revenge porn, to
              perpetrate financial frauds and other hoaxes, and to disrupt
              government functioning. Existing surveys have mainly focused on
              the detection of deepfake images and videos; this paper provides a
              comprehensive review and detailed analysis of existing tools and
              machine learning (ML) based approaches for deepfake generation,
              and the methodologies used to detect such manipulations in both
              audio and video. For each category of deepfake, we discuss
              information related to manipulation approaches, current public
              datasets, and key standards for the evaluation of the performance
              of deepfake detection techniques, along with their results.
              Additionally, we also discuss open challenges and enumerate future
              directions to guide researchers on issues which need to be
              considered in order to improve the domains of both deepfake
              generation and detection. This work is expected to assist readers
              in understanding how deepfakes are created and detected, along
              with their current limitations and where future research may lead.",
  month    =  feb,
  year     =  2023
}

@ARTICLE{Zavadski2023-ud,
  title         = "{ControlNet}-{XS}: Designing an Efficient and Effective
                   Architecture for Controlling Text-to-Image Diffusion Models",
  author        = "Zavadski, Denis and Feiden, Johann-Friedrich and Rother,
                   Carsten",
  journal       = "arXiv [cs.CV]",
  abstract      = "The field of image synthesis has made tremendous strides
                   forward in the last years. Besides defining the desired
                   output image with text-prompts, an intuitive approach is to
                   additionally use spatial guidance in form of an image, such
                   as a depth map. For this, a recent and highly popular
                   approach is to use a controlling network, such as ControlNet,
                   in combination with a pre-trained image generation model,
                   such as Stable Diffusion. When evaluating the design of
                   existing controlling networks, we observe that they all
                   suffer from the same problem of a delay in information
                   flowing between the generation and controlling process. This,
                   in turn, means that the controlling network must have
                   generative capabilities. In this work we propose a new
                   controlling architecture, called ControlNet-XS, which does
                   not suffer from this problem, and hence can focus on the
                   given task of learning to control. In contrast to ControlNet,
                   our model needs only a fraction of parameters, and hence is
                   about twice as fast during inference and training time.
                   Furthermore, the generated images are of higher quality and
                   the control is of higher fidelity. All code and pre-trained
                   models will be made publicly available.",
  month         =  dec,
  year          =  2023,
  archivePrefix = "arXiv",
  primaryClass  = "cs.CV"
}

@ARTICLE{Talebirad2023-fe,
  title         = "Multi-Agent Collaboration: Harnessing the Power of
                   Intelligent {LLM} Agents",
  author        = "Talebirad, Yashar and Nadiri, Amirhossein",
  journal       = "arXiv [cs.AI]",
  abstract      = "In this paper, we present a novel framework for enhancing the
                   capabilities of large language models (LLMs) by leveraging
                   the power of multi-agent systems. Our framework introduces a
                   collaborative environment where multiple intelligent agent
                   components, each with distinctive attributes and roles, work
                   together to handle complex tasks more efficiently and
                   effectively. We demonstrate the practicality and versatility
                   of our framework through case studies in artificial general
                   intelligence (AGI), specifically focusing on the Auto-GPT and
                   BabyAGI models. We also examine the ``Gorilla'' model, which
                   integrates external APIs into the LLM. Our framework
                   addresses limitations and challenges such as looping issues,
                   security risks, scalability, system evaluation, and ethical
                   considerations. By modeling various domains such as courtroom
                   simulations and software development scenarios, we showcase
                   the potential applications and benefits of our proposed
                   multi-agent system. Our framework provides an avenue for
                   advancing the capabilities and performance of LLMs through
                   collaboration and knowledge exchange among intelligent
                   agents.",
  month         =  jun,
  year          =  2023,
  archivePrefix = "arXiv",
  primaryClass  = "cs.AI"
}

@ARTICLE{Brooks2022-yh,
  title         = "{InstructPix2Pix}: Learning to Follow Image Editing
                   Instructions",
  author        = "Brooks, Tim and Holynski, Aleksander and Efros, Alexei A",
  journal       = "arXiv [cs.CV]",
  abstract      = "We propose a method for editing images from human
                   instructions: given an input image and a written instruction
                   that tells the model what to do, our model follows these
                   instructions to edit the image. To obtain training data for
                   this problem, we combine the knowledge of two large
                   pretrained models -- a language model (GPT-3) and a
                   text-to-image model (Stable Diffusion) -- to generate a large
                   dataset of image editing examples. Our conditional diffusion
                   model, InstructPix2Pix, is trained on our generated data, and
                   generalizes to real images and user-written instructions at
                   inference time. Since it performs edits in the forward pass
                   and does not require per example fine-tuning or inversion,
                   our model edits images quickly, in a matter of seconds. We
                   show compelling editing results for a diverse collection of
                   input images and written instructions.",
  month         =  nov,
  year          =  2022,
  archivePrefix = "arXiv",
  primaryClass  = "cs.CV"
}

@ARTICLE{Zhang2023-by,
  title         = "Adding Conditional Control to Text-to-Image Diffusion Models",
  author        = "Zhang, Lvmin and Rao, Anyi and Agrawala, Maneesh",
  journal       = "arXiv [cs.CV]",
  abstract      = "We present ControlNet, a neural network architecture to add
                   spatial conditioning controls to large, pretrained
                   text-to-image diffusion models. ControlNet locks the
                   production-ready large diffusion models, and reuses their
                   deep and robust encoding layers pretrained with billions of
                   images as a strong backbone to learn a diverse set of
                   conditional controls. The neural architecture is connected
                   with ``zero convolutions'' (zero-initialized convolution
                   layers) that progressively grow the parameters from zero and
                   ensure that no harmful noise could affect the finetuning. We
                   test various conditioning controls, eg, edges, depth,
                   segmentation, human pose, etc, with Stable Diffusion, using
                   single or multiple conditions, with or without prompts. We
                   show that the training of ControlNets is robust with small
                   (1m) datasets. Extensive results show that ControlNet may
                   facilitate wider applications to control image diffusion
                   models.",
  month         =  feb,
  year          =  2023,
  archivePrefix = "arXiv",
  primaryClass  = "cs.CV"
}

@ARTICLE{Abbas2024-sf,
  title     = "Is it harmful or helpful? Examining the causes and consequences
               of generative {AI} usage among university students",
  author    = "Abbas, Muhammad and Jam, Farooq Ahmed and Khan, Tariq Iqbal",
  journal   = "International Journal of Educational Technology in Higher
               Education",
  publisher = "SpringerOpen",
  volume    =  21,
  number    =  1,
  pages     = "1--22",
  abstract  = "While the discussion on generative artificial intelligence, such
               as ChatGPT, is making waves in academia and the popular press,
               there is a need for more insight into the use of ChatGPT among
               students and the potential harmful or beneficial consequences
               associated with its usage. Using samples from two studies, the
               current research examined the causes and consequences of ChatGPT
               usage among university students. Study 1 developed and validated
               an eight-item scale to measure ChatGPT usage by conducting a
               survey among university students (N = 165). Study 2 used a
               three-wave time-lagged design to collect data from university
               students (N = 494) to further validate the scale and test the
               study’s hypotheses. Study 2 also examined the effects of academic
               workload, academic time pressure, sensitivity to rewards, and
               sensitivity to quality on ChatGPT usage. Study 2 further examined
               the effects of ChatGPT usage on students’ levels of
               procrastination, memory loss, and academic performance. Study 1
               provided evidence for the validity and reliability of the ChatGPT
               usage scale. Furthermore, study 2 revealed that when students
               faced higher academic workload and time pressure, they were more
               likely to use ChatGPT. In contrast, students who were sensitive
               to rewards were less likely to use ChatGPT. Not surprisingly, use
               of ChatGPT was likely to develop tendencies for procrastination
               and memory loss and dampen the students’ academic performance.
               Finally, academic workload, time pressure, and sensitivity to
               rewards had indirect effects on students’ outcomes through
               ChatGPT usage.",
  month     =  feb,
  year      =  2024,
  language  = "en"
}

@INPROCEEDINGS{Kim2021-fh,
  title     = "Evaluating the effect of co-creative systems on design ideation",
  author    = "Kim, Jingoog and Maher, M",
  booktitle = "Processings of the 2021 International Conference on Computational
               Creativity (ICCC)",
  publisher = "computationalcreativity.net",
  pages     = "440--443",
  year      =  2021
}

@ARTICLE{Polli2004-bf,
  title    = "Atmospherics/Weatherworks: A Multi-Channel Storm Sonification
              Project",
  author   = "Polli, Andrea",
  journal  = "Int Conf Audit Disp",
  abstract = "Atmospherics/Weather Works is an interdisciplinary project in the
              sonification of storms and other meteorological events generated
              directly from data produced by a highly detailed and physically
              accurate model of weather systems used for research and
              forecasting. This paper discusses the background, conception, and
              execution of a series of sonifications of a historical hurricane
              and winter snowstorm that resulted in several performances, stereo
              recordings, a public multi-channel spatialized sound installation,
              and an online interactive sound listening environment.",
  month    =  jul,
  year     =  2004
}

@ARTICLE{Eicher2024-fv,
  title         = "Compensatory Biases Under Cognitive Load: Reducing Selection
                   Bias in Large Language Models",
  author        = "Eicher, J E and Irgolič, R F",
  journal       = "arXiv [cs.CL]",
  abstract      = "Large Language Models (LLMs) like gpt-3.5-turbo and
                   claude-instant-1.2 have become instrumental in interpreting
                   and executing semantic-based tasks. Unfortunately, these
                   models' inherent biases, akin to human cognitive biases,
                   adversely affect their performance. Particularly affected is
                   object selection from lists; a fundamental operation in
                   digital navigation and decision-making. This research
                   critically examines these biases and quantifies the effects
                   on a representative list selection task. To explore these
                   biases, we conducted a series of controlled experiments,
                   manipulating temperature, list length, object identity,
                   object type, prompt complexity, and model. This enabled us to
                   isolate and measure the influence of the biases on selection
                   behavior. Our findings show that bias structure is strongly
                   dependent on the model, with object type modulating the
                   magnitude of the effect. With a strong primacy effect,
                   causing the first objects in a list to be disproportionately
                   represented in outputs. Furthermore the usage of guard rails,
                   a prompt engineering method of ensuring a response structure,
                   can increase bias and decrease instruction adherence when
                   combined with a selection task. The bias is ablated when the
                   guard rail step is separated from the list sampling step,
                   lowering the complexity of each individual task. The
                   implications of this research are two-fold, practically
                   providing a guide for designing unbiased LLM applications and
                   theoretically suggesting that LLMs experience a form of
                   cognitive load compensated for by increasing bias.",
  month         =  jan,
  year          =  2024,
  archivePrefix = "arXiv",
  primaryClass  = "cs.CL"
}

@BOOK{Cope1992-rl,
  title     = "Computers and Musical Style",
  author    = "Cope, David",
  publisher = "Oxford University Press",
  address   = "London, England",
  series    = "Computer music and digital audio series",
  month     =  jan,
  year      =  1992,
  language  = "en"
}

@INPROCEEDINGS{Amershi2019-wu,
  title     = "Guidelines for Human-{AI} Interaction",
  author    = "Amershi, Saleema and Weld, Dan and Vorvoreanu, Mihaela and
               Fourney, Adam and Nushi, Besmira and Collisson, Penny and Suh,
               Jina and Iqbal, Shamsi and Bennett, Paul N and Inkpen, Kori and
               Teevan, Jaime and Kikin-Gil, Ruth and Horvitz, Eric",
  booktitle = "Proceedings of the 2019 CHI Conference on Human Factors in
               Computing Systems",
  publisher = "Association for Computing Machinery",
  address   = "New York, NY, USA",
  number    = "Paper 3",
  pages     = "1--13",
  abstract  = "Advances in artificial intelligence (AI) frame opportunities and
               challenges for user interface design. Principles for human-AI
               interaction have been discussed in the human-computer interaction
               community for over two decades, but more study and innovation are
               needed in light of advances in AI and the growing uses of AI
               technologies in human-facing applications. We propose 18
               generally applicable design guidelines for human-AI interaction.
               These guidelines are validated through multiple rounds of
               evaluation including a user study with 49 design practitioners
               who tested the guidelines against 20 popular AI-infused products.
               The results verify the relevance of the guidelines over a
               spectrum of interaction scenarios and reveal gaps in our
               knowledge, highlighting opportunities for further research. Based
               on the evaluations, we believe the set of design guidelines can
               serve as a resource to practitioners working on the design of
               applications and features that harness AI technologies, and to
               researchers interested in the further development of human-AI
               interaction design principles.",
  series    = "CHI '19",
  month     =  may,
  year      =  2019,
  keywords  = "ai-infused systems, design guidelines, human-ai interaction"
}

@ARTICLE{Wan2023-he,
  title         = "``it felt like having a second mind'': Investigating
                   human-{AI} co-creativity in prewriting with large language
                   models",
  author        = "Wan, Qian and Hu, Siying and Zhang, Yu and Wang, Piaohong and
                   Wen, Bo and Lu, Zhicong",
  journal       = "arXiv [cs.HC]",
  abstract      = "Prewriting is the process of discovering and developing ideas
                   before a first draft, which requires divergent thinking and
                   often implies unstructured strategies such as diagramming,
                   outlining, free-writing, etc. Although large language models
                   (LLMs) have been demonstrated to be useful for a variety of
                   tasks including creative writing, little is known about how
                   users would collaborate with LLMs to support prewriting. The
                   preferred collaborative role and initiative of LLMs during
                   such a creativity process is also unclear. To investigate
                   human-LLM collaboration patterns and dynamics during
                   prewriting, we conducted a three-session qualitative study
                   with 15 participants in two creative tasks: story writing and
                   slogan writing. The findings indicated that during
                   collaborative prewriting, there appears to be a three-stage
                   iterative Human-AI Co-creativity process that includes
                   Ideation, Illumination, and Implementation stages. This
                   collaborative process champions the human in a dominant role,
                   in addition to mixed and shifting levels of initiative that
                   exist between humans and LLMs. This research also reports on
                   collaboration breakdowns that occur during this process, user
                   perceptions of using existing LLMs during Human-AI
                   Co-creativity, and discusses design implications to support
                   this co-creativity process.",
  month         =  jul,
  year          =  2023,
  archivePrefix = "arXiv",
  primaryClass  = "cs.HC"
}

@INPROCEEDINGS{Haase2023-mz,
  title     = "The Art of Inspiring Creativity: Exploring the Unique Impact of
               {AI}-generated Images",
  author    = "Haase, Jennifer and Djurica, Djordje and Mendling, Jan",
  booktitle = "AMCIS 2023 Proceedings",
  abstract  = "This paper examines whether AI-generated art can serve as a
               source of inspiration to enhance individual creative performance.
               Specifically, the study investigates whether AI-generated art has
               associative potential that can stimulate idea generation and
               enhance individual creativity in terms of originality and the
               number of ideas generated by humans. To address this research
               problem, we focus on DALL-E-2, a generative AI system that can
               create images from textual descriptions. We first provide an
               overview of situational creativity support systems and then
               present the design of an online experiment in which 298
               participants used (artificially generated vs. traditional) art or
               none to ideate. The data shows that art in general, but
               AI-generated especially, has the potential to enhance creative
               performance by stimulating idea generation. We discuss the
               implications of using AI-generated art as a creative support
               tool.",
  year      =  2023
}

@ARTICLE{Lyu2022-ny,
  title     = "Communication in human–AI co-creation: Perceptual analysis of
               paintings generated by text-to-image system",
  author    = "Lyu, Yanru and Wang, Xinxin and Lin, Rungtai and Wu, Jun",
  journal   = "Appl. Sci. (Basel)",
  publisher = "MDPI AG",
  volume    =  12,
  number    =  22,
  pages     =  11312,
  abstract  = "In recent years, art creation using artificial intelligence (AI)
               has started to become a mainstream phenomenon. One of the latest
               applications of AI is to generate visual artwork from natural
               language descriptions where anyone can interact with it to create
               thousands of artistic images with minimal effort, which provokes
               the questions: what is the essence of artistic creation, and who
               can create art in this era? Considering that, in this study, the
               theoretical communication framework was adopted to investigate
               the difference in the interaction with the text-to-image system
               between artists and nonartists. In this experiment, ten artists
               and ten nonartists were invited to co-create with Midjourney.
               Their actions and reflections were recorded, and two sets of
               generated images were collected for the visual question-answering
               task, with a painting created by the artist as a reference
               sample. A total of forty-two subjects with artistic backgrounds
               participated in the evaluated experiment. The results indicated
               differences between the two groups in their creation actions and
               their attitude toward AI, while the technology blurred the
               difference in the perception of the results caused by the
               creator’s artistic experience. In addition, attention should be
               paid to communication on the effectiveness level for a better
               perception of the artistic value.",
  month     =  nov,
  year      =  2022,
  language  = "en"
}

@ARTICLE{Haase2023-vz,
  title         = "Artificial muses: Generative Artificial Intelligence chatbots
                   have risen to human-level creativity",
  author        = "Haase, Jennifer and Hanel, Paul H P",
  journal       = "arXiv [cs.AI]",
  abstract      = "A widespread view is that Artificial Intelligence cannot be
                   creative. We tested this assumption by comparing
                   human-generated ideas with those generated by six Generative
                   Artificial Intelligence (GAI) chatbots: $alpa.\!ai$,
                   $Copy.\!ai$, ChatGPT (versions 3 and 4), $Studio.\!ai$, and
                   YouChat. Humans and a specifically trained AI independently
                   assessed the quality and quantity of ideas. We found no
                   qualitative difference between AI and human-generated
                   creativity, although there are differences in how ideas are
                   generated. Interestingly, 9.4 percent of humans were more
                   creative than the most creative GAI, GPT-4. Our findings
                   suggest that GAIs are valuable assistants in the creative
                   process. Continued research and development of GAI in
                   creative tasks is crucial to fully understand this
                   technology's potential benefits and drawbacks in shaping the
                   future of creativity. Finally, we discuss the question of
                   whether GAIs are capable of being truly creative.",
  month         =  mar,
  year          =  2023,
  archivePrefix = "arXiv",
  primaryClass  = "cs.AI"
}

@ARTICLE{Kantosalo2015-pk,
  title     = "Interaction evaluation for human-computer co-creativity: A case
               study",
  author    = "Kantosalo, Anna and Toivanen, Jukka M and Toivonen, Hannu (tt)",
  journal   = "Int Conf Control Commun Comput India",
  publisher = "tuhat.helsinki.fi",
  pages     = "276--283",
  abstract  = "Interaction design has been suggested as a framework for
               evaluating computational creativity by Bown (2014). Yet few
               practical accounts on using an Interaction Design based
               evaluation strategy in Computational Creativity Contexts have
               been reported in the literature. This study paper describes the
               evaluation process and results of a human-computer co-creative
               poetry writing tool intended for children in a school context. We
               specifically focus on one formative evaluation case utilizing
               Interaction Design evaluation methods, offering a suggestion on
               how to conduct Interaction Design based evaluation in a
               computational creativity context, as well as, report the results
               of the evaluation itself. The evaluation process is considered
               from the perspective of a computational creativity researcher and
               we focus on challenges and benefits of the interaction design
               evaluation approach within a computational creativity project
               context.",
  year      =  2015
}

@ARTICLE{Schaerf2024-gf,
  title         = "Reflections on disentanglement and the latent space",
  author        = "Schaerf, Ludovica",
  journal       = "arXiv [cs.CY]",
  abstract      = "The latent space of image generative models is a
                   multi-dimensional space of compressed hidden visual
                   knowledge. Its entity captivates computer scientists, digital
                   artists, and media scholars alike. Latent space has become an
                   aesthetic category in AI art, inspiring artistic techniques
                   such as the latent space walk, exemplified by the works of
                   Mario Klingemann and others. It is also viewed as cultural
                   snapshots, encoding rich representations of our visual world.
                   This paper proposes a double view of the latent space, as a
                   multi-dimensional archive of culture and as a
                   multi-dimensional space of potentiality. The paper discusses
                   disentanglement as a method to elucidate the double nature of
                   the space and as an interpretative direction to exploit its
                   organization in human terms. The paper compares the role of
                   disentanglement as potentiality to that of conditioning, as
                   imagination, and confronts this interpretation with the
                   philosophy of Deleuzian potentiality and Hume's imagination.
                   Lastly, this paper notes the difference between traditional
                   generative models and recent architectures.",
  month         =  oct,
  year          =  2024,
  archivePrefix = "arXiv",
  primaryClass  = "cs.CY"
}

@ARTICLE{Kim2021-zg,
  title     = "Collaborative Ideation Partner: Design Ideation in Human-{AI}
               Co-creativity",
  author    = "Kim, Jingoog and Maher, M and Siddiqui, Safat",
  journal   = "CHIRA",
  publisher = "scitepress.org",
  pages     = "123--130",
  abstract  = ": AI-based co-creative design systems enable users to collaborate
               with an AI agent on open-ended creative tasks during the design
               process. This paper describes a co-creative system that supports
               design creativity by providing inspiring design solutions in the
               initial idea generation process, based on the visual and
               conceptual similarity to sketches drawn by a designer. The
               interactive experience allows the user to seek inspiration
               collaborating with the AI agent as needed. In this paper, we
               study how the visual and conceptual similarity of the inspiring
               design from the AI partner influences design ideation by
               examining the effect on design ideation during a design task. Our
               findings show that the AI-based stimuli produce ideation outcomes
               with more variety and novelty when compared to random stimuli.",
  year      =  2021
}

@MISC{Schaerf2024-kc,
  title     = "Reflections on disentanglement and the latent space",
  author    = "Schaerf, Ludovica",
  publisher = "s.n.",
  year      =  2024
}

@ARTICLE{Hwang2024-ph,
  title         = "``It was 80\% me, 20\% {AI}'': Seeking Authenticity in
                   Co-Writing with Large Language Models",
  author        = "Hwang, Angel Hsing-Chi and Liao, Q Vera and Blodgett, Su Lin
                   and Olteanu, Alexandra and Trischler, Adam",
  journal       = "arXiv [cs.HC]",
  abstract      = "Given the rising proliferation and diversity of AI writing
                   assistance tools, especially those powered by large language
                   models (LLMs), both writers and readers may have concerns
                   about the impact of these tools on the authenticity of
                   writing work. We examine whether and how writers want to
                   preserve their authentic voice when co-writing with AI tools
                   and whether personalization of AI writing support could help
                   achieve this goal. We conducted semi-structured interviews
                   with 19 professional writers, during which they co-wrote with
                   both personalized and non-personalized AI writing-support
                   tools. We supplemented writers' perspectives with opinions
                   from 30 avid readers about the written work co-produced with
                   AI collected through an online survey. Our findings
                   illuminate conceptions of authenticity in human-AI
                   co-creation, which focus more on the process and experience
                   of constructing creators' authentic selves. While writers
                   reacted positively to personalized AI writing tools, they
                   believed the form of personalization needs to target writers'
                   growth and go beyond the phase of text production. Overall,
                   readers' responses showed less concern about human-AI
                   co-writing. Readers could not distinguish AI-assisted work,
                   personalized or not, from writers' solo-written work and
                   showed positive attitudes toward writers experimenting with
                   new technology for creative writing.",
  month         =  nov,
  year          =  2024,
  archivePrefix = "arXiv",
  primaryClass  = "cs.HC"
}

@ARTICLE{Ritchie2012-nb,
  title    = "A closer look at creativity as search",
  author   = "Ritchie, G",
  journal  = "Int Conf Control Commun Comput India",
  pages    = "41--48",
  abstract = "Several papers by Wiggins (building on ideas by Boden) have
              outlined a view of creative concept generation as a very general
              search process, but that formalisation has not been developed much
              in the past few years. Also, there are some aspects where
              clarification or spelling out of details would be useful. We
              present a re-formulation of the central ideas in Wiggins’s
              framework, with slightly more rigorous statements of the
              definitions and a number of minor extensions. We also explain how
              this framework relates to some hitherto completely separate
              proposals by Ritchie.",
  month    =  may,
  year     =  2012
}


@ARTICLE{Rombach2021-wf,
  title         = "High-resolution image synthesis with latent diffusion models",
  author        = "Rombach, Robin and Blattmann, Andreas and Lorenz, Dominik and
                   Esser, Patrick and Ommer, Björn",
  journal       = "arXiv [cs.CV]",
  abstract      = "By decomposing the image formation process into a sequential
                   application of denoising autoencoders, diffusion models (DMs)
                   achieve state-of-the-art synthesis results on image data and
                   beyond. Additionally, their formulation allows for a guiding
                   mechanism to control the image generation process without
                   retraining. However, since these models typically operate
                   directly in pixel space, optimization of powerful DMs often
                   consumes hundreds of GPU days and inference is expensive due
                   to sequential evaluations. To enable DM training on limited
                   computational resources while retaining their quality and
                   flexibility, we apply them in the latent space of powerful
                   pretrained autoencoders. In contrast to previous work,
                   training diffusion models on such a representation allows for
                   the first time to reach a near-optimal point between
                   complexity reduction and detail preservation, greatly
                   boosting visual fidelity. By introducing cross-attention
                   layers into the model architecture, we turn diffusion models
                   into powerful and flexible generators for general
                   conditioning inputs such as text or bounding boxes and
                   high-resolution synthesis becomes possible in a convolutional
                   manner. Our latent diffusion models (LDMs) achieve a new
                   state of the art for image inpainting and highly competitive
                   performance on various tasks, including unconditional image
                   generation, semantic scene synthesis, and super-resolution,
                   while significantly reducing computational requirements
                   compared to pixel-based DMs. Code is available at
                   https://github.com/CompVis/latent-diffusion .",
  month         =  dec,
  year          =  2021,
  archivePrefix = "arXiv",
  primaryClass  = "cs.CV"
}

@ARTICLE{Ho2020-zj,
  title         = "Denoising Diffusion Probabilistic Models",
  author        = "Ho, Jonathan and Jain, Ajay and Abbeel, Pieter",
  journal       = "arXiv [cs.LG]",
  abstract      = "We present high quality image synthesis results using
                   diffusion probabilistic models, a class of latent variable
                   models inspired by considerations from nonequilibrium
                   thermodynamics. Our best results are obtained by training on
                   a weighted variational bound designed according to a novel
                   connection between diffusion probabilistic models and
                   denoising score matching with Langevin dynamics, and our
                   models naturally admit a progressive lossy decompression
                   scheme that can be interpreted as a generalization of
                   autoregressive decoding. On the unconditional CIFAR10
                   dataset, we obtain an Inception score of 9.46 and a
                   state-of-the-art FID score of 3.17. On 256x256 LSUN, we
                   obtain sample quality similar to ProgressiveGAN. Our
                   implementation is available at
                   https://github.com/hojonathanho/diffusion",
  month         =  jun,
  year          =  2020,
  archivePrefix = "arXiv",
  primaryClass  = "cs.LG"
}

@INPROCEEDINGS{Inie2023-ml,
  title     = "Designing participatory {AI}: Creative professionals’ worries and
               expectations about generative {AI}",
  author    = "Inie, Nanna and Falk, Jeanette and Tanimoto, Steve",
  booktitle = "Extended Abstracts of the 2023 CHI Conference on Human Factors in
               Computing Systems",
  publisher = "ACM",
  address   = "New York, NY, USA",
  month     =  apr,
  year      =  2023,
  language  = "en"
}

@INPROCEEDINGS{Lawton2023-gd,
  title     = "Drawing with reframer: Emergence and control in co-creative {AI}",
  author    = "Lawton, Tomas and Ibarrola, Francisco J and Ventura, Dan and
               Grace, Kazjon",
  booktitle = "Proceedings of the 28th International Conference on Intelligent
               User Interfaces",
  publisher = "ACM",
  address   = "New York, NY, USA",
  month     =  mar,
  year      =  2023,
  language  = "en"
}

@ARTICLE{Colton2011-uy,
  title    = "Computational creativity theory: The {FACE} and {IDEA} descriptive
              models",
  author   = "Colton, S and Charnley, J and Pease, A",
  journal  = "International Conference on Computational Creativity",
  pages    = "90--95",
  abstract = "We introduce computational creativity theory (CCT) as an analogue
              in computational creativity research to computational learning
              theory in machine learning. In its current draft, CCT comprises
              the FACE descriptive model of creative acts as tuples of
              generative acts, and the IDEA descriptive model of the impact such
              creative acts may have. To introduce these, we simplify various
              assumptions about software development, background material given
              to software, how creative acts are performed by computer, and how
              audiences consume the results. We use the two descriptive models
              to perform two comparisons studies, firstly for mathematical
              discovery software, and secondly for visual art generating
              programs. We conclude by discussing possible additions,
              improvements and refinements to CCT.",
  month    =  dec,
  year     =  2011
}

@ARTICLE{Dosovitskiy2020-wh,
  title         = "An image is worth {16x16} words: Transformers for image
                   recognition at scale",
  author        = "Dosovitskiy, Alexey and Beyer, Lucas and Kolesnikov,
                   Alexander and Weissenborn, Dirk and Zhai, Xiaohua and
                   Unterthiner, Thomas and Dehghani, Mostafa and Minderer,
                   Matthias and Heigold, Georg and Gelly, Sylvain and Uszkoreit,
                   Jakob and Houlsby, Neil",
  journal       = "arXiv [cs.CV]",
  abstract      = "While the Transformer architecture has become the de-facto
                   standard for natural language processing tasks, its
                   applications to computer vision remain limited. In vision,
                   attention is either applied in conjunction with convolutional
                   networks, or used to replace certain components of
                   convolutional networks while keeping their overall structure
                   in place. We show that this reliance on CNNs is not necessary
                   and a pure transformer applied directly to sequences of image
                   patches can perform very well on image classification tasks.
                   When pre-trained on large amounts of data and transferred to
                   multiple mid-sized or small image recognition benchmarks
                   (ImageNet, CIFAR-100, VTAB, etc.), Vision Transformer (ViT)
                   attains excellent results compared to state-of-the-art
                   convolutional networks while requiring substantially fewer
                   computational resources to train.",
  month         =  oct,
  year          =  2020,
  archivePrefix = "arXiv",
  primaryClass  = "cs.CV"
}

@INPROCEEDINGS{Ghajargar2022-af,
  title     = "A redhead walks into a bar: Experiences of writing fiction with
               artificial intelligence",
  author    = "Ghajargar, Maliheh and Bardzell, Jeffrey and Lagerkvist, Love",
  booktitle = "Proceedings of the 25th International Academic Mindtrek
               Conference",
  publisher = "ACM",
  address   = "New York, NY, USA",
  month     =  nov,
  year      =  2022
}

@ARTICLE{Crespo2022-ty,
  title     = "Augmenting digital nature: Generative art as a constructive
               feedback loop",
  author    = "Crespo, Sofia and McCormick, Feileacan",
  journal   = "Archit. Des.",
  publisher = "Wiley",
  volume    =  92,
  number    =  3,
  pages     = "54--59",
  month     =  may,
  year      =  2022,
  language  = "en"
}

@INPROCEEDINGS{Tholander2023-rv,
  title     = "Design ideation with {AI} - sketching, thinking and talking with
               generative machine learning models",
  author    = "Tholander, Jakob and Jonsson, Martin",
  booktitle = "Proceedings of the 2023 ACM Designing Interactive Systems
               Conference",
  publisher = "ACM",
  address   = "New York, NY, USA",
  month     =  jul,
  year      =  2023,
  language  = "en"
}

@INPROCEEDINGS{Chang2023-tv,
  title     = "The Prompt Artists",
  author    = "Chang, Minsuk and Druga, Stefania and Fiannaca, Alexander J and
               Vergani, Pedro and Kulkarni, Chinmay and Cai, Carrie J and Terry,
               Michael",
  booktitle = "Creativity and Cognition",
  publisher = "ACM",
  address   = "New York, NY, USA",
  month     =  jun,
  year      =  2023,
  language  = "en"
}

@ARTICLE{Bodker2015-ik,
  title     = "Third-wave {HCI}, 10 years later---participation and sharing",
  author    = "Bødker, Susanne",
  journal   = "Interactions",
  publisher = "Association for Computing Machinery (ACM)",
  volume    =  22,
  number    =  5,
  pages     = "24--31",
  month     =  aug,
  year      =  2015,
  language  = "en"
}

@BOOK{Suchman2006-bs,
  title     = "Human-machine reconfigurations: Plans and situated actions: Plans
               and Situated Actions",
  author    = "Suchman, Lucy",
  publisher = "Harvard University Press",
  address   = "Cambridge",
  year      =  2006
}

@ARTICLE{Schon1992-jt,
  title     = "Designing as reflective conversation with the materials of a
               design situation",
  author    = "Schon, Donald A",
  journal   = "Res. Eng. Des.",
  publisher = "Springer Science and Business Media LLC",
  volume    =  3,
  number    =  3,
  pages     = "131--147",
  abstract  = "What are the prospects for applying the methods of Artificial
               Intelligence to architectural designers' knowing-in-action? David
               Marr (Marr, 1982) has advanced the idea of a computational theory
               of vision, which requires defining the information processing
               tasks carried out in vision. I ask, by analogy: what are the
               information processing tasks carried out in design? In order to
               answer this question, I propose, one ought to study design
               phenomenology. I illustrate several such studies, based on
               observations of a design studio, the performance of a design
               exercise, and the playing of a design game. In order to simulate
               the transactions with a design situation illustrated in these
               studies, the computer would have to carry out processes that
               begin prior to the presentation of what are normally defined as
               “design inputs.” Such processes involve the construction of
               “design worlds,” and they include: the simplest unit of design
               experimentation, the designer's seeing-moving-seeing;
               constructing figures from marks on a page; appreciating design
               qualities; setting design intentions and problems; recognizing
               the unintended consequences of move experiments; storing and
               deploying prototypes; and communicating across divergent design
               worlds. I conclude that the practitioners of Artificial
               Intelligence in design would do better to aim at producing design
               assistants rather than knowledge systems phenomenologically
               equivalent to those of designers.",
  month     =  sep,
  year      =  1992,
  language  = "en"
}

@BOOK{Wiener1948-mb,
  title     = "Cybernetics or control and communication in the animal and the
               machine",
  author    = "Wiener, Norbert",
  publisher = "The MIT Press",
  abstract  = "A classic and influential work that laid the theoretical
               foundations for information theory and a timely text for
               contemporary informations theorists and p",
  year      =  1948,
  language  = "en"
}

@ARTICLE{Hitsuwari2023-tw,
  title     = "Does human–AI collaboration lead to more creative art? Aesthetic
               evaluation of human-made and {AI}-generated haiku poetry",
  author    = "Hitsuwari, Jimpei and Ueda, Yoshiyuki and Yun, Woojin and Nomura,
               Michio",
  journal   = "Comput. Human Behav.",
  publisher = "Elsevier BV",
  volume    =  139,
  number    =  107502,
  pages     =  107502,
  abstract  = "With the development of technology, the quality of AI-generated
               text has improved. This is relevant in the AI art field, where AI
               generates literature…",
  month     =  feb,
  year      =  2023,
  language  = "en"
}

@INCOLLECTION{Bown2018-op,
  title     = "Interaction Design for Metacreative Systems",
  author    = "Bown, Oliver and Brown, Andrew R",
  booktitle = "Human–Computer Interaction Series",
  publisher = "Springer International Publishing",
  address   = "Cham",
  pages     = "67--87",
  year      =  2018
}

@BOOK{Filimowicz2018-mj,
  title     = "New directions in third wave human-computer interaction: Volume 1
               - technologies",
  editor    = "Filimowicz, Michael and Tzankova, Veronika",
  publisher = "Springer International Publishing",
  address   = "Cham, Switzerland",
  edition   =  1,
  series    = "Human-Computer Interaction Series",
  month     =  jul,
  year      =  2018,
  language  = "en"
}

@INPROCEEDINGS{Bodker2006-qg,
  title     = "When second wave {HCI} meets third wave challenges",
  author    = "Bødker, Susanne",
  booktitle = "Proceedings of the 4th Nordic conference on Human-computer
               interaction: changing roles",
  publisher = "ACM",
  address   = "New York, NY, USA",
  abstract  = "This paper surveys the current status of second generation HCI
               theory, faced with the challenges brought to HCI by the so-called
               third wave. In the third wave, the use context and application
               types are broadened, and intermixed, relative to the focus of the
               second wave on work. Technology spreads from the workplace to our
               homes and everyday lives and culture. Using these challenges the
               paper specifically addresses the topics of multiplicity, context,
               boundaries, experience and participation in order to discuss
               where second wave theory and conceptions can still be positioned
               to make a contribution as part of the maturing of our handling of
               the challenges brought on by the third wave.",
  month     =  oct,
  year      =  2006,
  language  = "en"
}

@INPROCEEDINGS{Brown2016-tc,
  title     = "Understanding musical practices as agency networks",
  author    = "Brown, Andrew R",
  booktitle = "Proceedings of the international conference on computational
               creativity",
  pages     = "139--146",
  abstract  = "This position paper proposes that creative practices can be
               usefully understood as agency networks. In particular it looks at
               interactive algorithmic musical practices and the takes a
               distributed view of the influences involved in such music making.
               The elements involved include humans, tools, culture and the
               physical environment that constitute a system or network of
               mutual influences. Such an agency network perspective is intended
               to be useful for the pragmatic tasks of designing new interactive
               music systems and developing new musical practices that utilise
               them. Drawing on previous research into generative music and
               computational creativity, various views on interactive music
               systems are canvassed and an approach to describing these as
               agency networks is developed. It is suggested that new
               human-machine musical practices may arise as a result of adopting
               an agency network perspective and that these, in turn, can drive
               cultural innovations.",
  year      =  2016
}

@ARTICLE{Alkaissi2023-tp,
  title     = "Artificial hallucinations in {ChatGPT}: Implications in
               scientific writing",
  author    = "Alkaissi, Hussam and McFarlane, Samy I",
  journal   = "Cureus",
  publisher = "Springer Science and Business Media LLC",
  volume    =  15,
  number    =  2,
  pages     = "e35179",
  abstract  = "While still in its infancy, ChatGPT (Generative Pretrained
               Transformer), introduced in November 2022, is bound to hugely
               impact many industries, including healthcare, medical education,
               biomedical research, and scientific writing. Implications of
               ChatGPT, that new chatbot introduced by OpenAI on academic
               writing, is largely unknown. In response to the Journal of
               Medical Science (Cureus) Turing Test - call for case reports
               written with the assistance of ChatGPT, we present two cases one
               of homocystinuria-associated osteoporosis, and the other is on
               late-onset Pompe disease (LOPD), a rare metabolic disorder. We
               tested ChatGPT to write about the pathogenesis of these
               conditions. We documented the positive, negative, and rather
               troubling aspects of our newly introduced chatbot's performance.",
  month     =  feb,
  year      =  2023,
  keywords  = "artificial intelligence and education; artificial intelligence
               and writing; artificial intelligence in medicine; chatbot;
               chatgpt",
  language  = "en"
}

@ARTICLE{Kim2023-wt,
  title         = "Repurposing text-generating {AI} into a thought-provoking
                   writing tutor",
  author        = "Kim, Tae Wook and Tan, Quan",
  journal       = "arXiv [cs.HC]",
  abstract      = "Text-generating AI technology has the potential to
                   revolutionize writing education. However, current AI
                   writing-support tools are limited to providing linear
                   feedback to users. In this work, we demonstrate how
                   text-generating AI can be repurposed into a thought-provoking
                   writing tutor with the addition of recursive feedback
                   mechanisms. Concretely, we developed a prototype AI
                   writing-support tool called Scraft that asks Socratic
                   questions to users and encourages critical thinking. To
                   explore how Scraft can aid with writing education, we
                   conducted a preliminary study with 15 students in a
                   university writing class. Participants expressed that
                   Scraft's recursive feedback is helpful for improving their
                   writing skills. However, participants also noted that
                   Scraft's feedback is sometimes factually incorrect and lacks
                   context. We discuss the implications of our findings and
                   future research directions.",
  month         =  apr,
  year          =  2023,
  archivePrefix = "arXiv",
  primaryClass  = "cs.HC"
}

@ARTICLE{Tankelevitch2023-tn,
  title         = "The metacognitive demands and opportunities of generative
                   {AI}",
  author        = "Tankelevitch, Lev and Kewenig, Viktor and Simkute, Auste and
                   Scott, Ava Elizabeth and Sarkar, Advait and Sellen, Abigail
                   and Rintel, Sean",
  journal       = "arXiv [cs.HC]",
  abstract      = "Generative AI (GenAI) systems offer unprecedented
                   opportunities for transforming professional and personal
                   work, yet present challenges around prompting, evaluating and
                   relying on outputs, and optimizing workflows. We argue that
                   metacognition$\unicode{x2013}$the psychological ability to
                   monitor and control one's thoughts and
                   behavior$\unicode{x2013}$offers a valuable lens to understand
                   and design for these usability challenges. Drawing on
                   research in psychology and cognitive science, and recent
                   GenAI user studies, we illustrate how GenAI systems impose
                   metacognitive demands on users, requiring a high degree of
                   metacognitive monitoring and control. We propose these
                   demands could be addressed by integrating metacognitive
                   support strategies into GenAI systems, and by designing GenAI
                   systems to reduce their metacognitive demand by targeting
                   explainability and customizability. Metacognition offers a
                   coherent framework for understanding the usability challenges
                   posed by GenAI, and provides novel research and design
                   directions to advance human-AI interaction.",
  month         =  dec,
  year          =  2023,
  archivePrefix = "arXiv",
  primaryClass  = "cs.HC"
}

@ARTICLE{Lee2022-rj,
  title         = "Evaluating human-language model interaction",
  author        = "Lee, Mina and Srivastava, Megha and Hardy, Amelia and
                   Thickstun, John and Durmus, Esin and Paranjape, Ashwin and
                   Gerard-Ursin, Ines and Li, Xiang Lisa and Ladhak, Faisal and
                   Rong, Frieda and Wang, Rose E and Kwon, Minae and Park, Joon
                   Sung and Cao, Hancheng and Lee, Tony and Bommasani, Rishi and
                   Bernstein, Michael and Liang, Percy",
  journal       = "arXiv [cs.CL]",
  abstract      = "Many real-world applications of language models (LMs), such
                   as writing assistance and code autocomplete, involve human-LM
                   interaction. However, most benchmarks are non-interactive in
                   that a model produces output without human involvement. To
                   evaluate human-LM interaction, we develop a new framework,
                   Human-AI Language-based Interaction Evaluation (HALIE), that
                   defines the components of interactive systems and dimensions
                   to consider when designing evaluation metrics. Compared to
                   standard, non-interactive evaluation, HALIE captures (i) the
                   interactive process, not only the final output; (ii) the
                   first-person subjective experience, not just a third-party
                   assessment; and (iii) notions of preference beyond quality
                   (e.g., enjoyment and ownership). We then design five tasks to
                   cover different forms of interaction: social dialogue,
                   question answering, crossword puzzles, summarization, and
                   metaphor generation. With four state-of-the-art LMs (three
                   variants of OpenAI's GPT-3 and AI21 Labs' Jurassic-1), we
                   find that better non-interactive performance does not always
                   translate to better human-LM interaction. In particular, we
                   highlight three cases where the results from non-interactive
                   and interactive metrics diverge and underscore the importance
                   of human-LM interaction for LM evaluation.",
  month         =  dec,
  year          =  2022,
  archivePrefix = "arXiv",
  primaryClass  = "cs.CL"
}

@ARTICLE{Hardy2021-on,
  title    = "Effective social chatbot strategies for increasing user initiative",
  author   = "Hardy, Amelia and Paranjape, Ashwin and Manning, Christopher D",
  pages    = "99--110",
  abstract = "Many existing chatbots do not effectively support mixed
              initiative, forcing their users to either respond passively or
              lead constantly. We seek to improve this experience by introducing
              new mechanisms to encourage user initiative in social chatbot
              conversations. Since user initiative in this setting is distinct
              from initiative in human-human or task-oriented dialogue, we first
              propose a new definition that accounts for the unique behaviors
              users take in this context. Drawing from linguistics, we propose
              three mechanisms to promote user initiative: back-channeling,
              personal disclosure, and replacing questions with statements. We
              show that simple automatic metrics of utterance length, number of
              noun phrases, and diversity of user responses correlate with human
              judgement of initiative. Finally, we use these metrics to suggest
              that these strategies do result in statistically significant
              increases in user initiative, where frequent, but not excessive,
              back-channeling is the most effective strategy.",
  month    =  jul,
  year     =  2021
}


@ARTICLE{Harkonen2020-eu,
  title         = "{GANSpace}: Discovering Interpretable {GAN} Controls",
  author        = "Härkönen, Erik and Hertzmann, Aaron and Lehtinen, Jaakko and
                   Paris, Sylvain",
  journal       = "arXiv [cs.CV]",
  abstract      = "This paper describes a simple technique to analyze Generative
                   Adversarial Networks (GANs) and create interpretable controls
                   for image synthesis, such as change of viewpoint, aging,
                   lighting, and time of day. We identify important latent
                   directions based on Principal Components Analysis (PCA)
                   applied either in latent space or feature space. Then, we
                   show that a large number of interpretable controls can be
                   defined by layer-wise perturbation along the principal
                   directions. Moreover, we show that BigGAN can be controlled
                   with layer-wise inputs in a StyleGAN-like manner. We show
                   results on different GANs trained on various datasets, and
                   demonstrate good qualitative matches to edit directions found
                   through earlier supervised approaches.",
  month         =  apr,
  year          =  2020,
  archivePrefix = "arXiv",
  primaryClass  = "cs.CV"
}

@INPROCEEDINGS{Ashktorab2021-gx,
  title     = "Effects of communication directionality and {AI} agent
               differences in human-{AI} interaction",
  author    = "Ashktorab, Zahra and Dugan, Casey and Johnson, James and Pan,
               Qian and Zhang, Wei and Kumaravel, Sadhana and Campbell, Murray",
  booktitle = "Proceedings of the 2021 CHI Conference on Human Factors in
               Computing Systems",
  publisher = "ACM",
  address   = "New York, NY, USA",
  month     =  may,
  year      =  2021
}

@ARTICLE{Vesa2023-is,
  title     = "The Relevance of Trust, Communication and Role Clarity to Project
               Performance",
  author    = "Vesa, Siirilä",
  publisher = "theseus.fi",
  abstract  = "The literature review provides a general overview of project
               management and relevant to this thesis: project communication,
               trust, project performance, project success, and role clarity.",
  year      =  2023
}

@ARTICLE{Nixon2017-fg,
  title     = "Clarity, consistency and communication: using enhanced dialogue
               to create a course-based feedback strategy",
  author    = "Nixon, Sarah and Brooman, Simon and Murphy, Becky and Fearon,
               Damien",
  journal   = "Assess. Eval. High. Educ.",
  publisher = "Informa UK Limited",
  volume    =  42,
  number    =  5,
  pages     = "812--822",
  abstract  = "This article examines the outcomes of a study across four
               discipline areas in order to develop course-based assessment
               strategies in closer cooperation with students. Second-year
               students (n = 48) from different disciplines were engaged in two
               phases of activity-orientated workshops. Phase 1 sought their
               perceptions of feedback. Phase 2 saw students design a proposed
               strategy to present to the respective staff teams. We discuss the
               emerging themes which appeared to be very similar amongst this
               diverse cross section of students: a lack of faith in marking
               consistency; the need for clear guidelines and criteria; the
               greater use of positive feedback language; and a close
               association with tutors. The emergence of strategies specific to
               each course is discussed, along with the alignment of the
               outcomes of this approach with pedagogic knowledge. It is
               suggested that enhanced dialogue enabled staff and students to
               develop a common understanding, and gave impetus to improving
               assessment feedback practices. Outcomes recommended here include
               changes to practice such as a team approach to feedback
               development, the content and style of feedback, developing the
               usefulness of feedback for future work and the need for teams to
               periodically revisit staff development in this area.",
  month     =  jul,
  year      =  2017
}

@ARTICLE{Brandmo2021-cf,
  title     = "Group coaching that promotes self-efficacy and role clarity among
               school leaders",
  author    = "Brandmo, Christian and Aas, Marit and Colbjørnsen, Tor and Olsen,
               Rolf",
  journal   = "Scand. J. Educ. Res.",
  publisher = "Informa UK Limited",
  volume    =  65,
  number    =  2,
  pages     = "195--211",
  month     =  feb,
  year      =  2021,
  language  = "en"
}

@ARTICLE{Radhakrishnan2018-nv,
  title     = "A role analysis exercise to minimize role ambiguity and promote
               role clarity in instructional design teams",
  author    = "Radhakrishnan, V",
  publisher = "jscholarship.library.jhu.edu",
  year      =  2018
}

@ARTICLE{Ribeiro2016-xb,
  title         = "``why should {I} trust you?'': Explaining the predictions of
                   any classifier",
  author        = "Ribeiro, Marco Tulio and Singh, Sameer and Guestrin, Carlos",
  journal       = "arXiv [cs.LG]",
  abstract      = "Despite widespread adoption, machine learning models remain
                   mostly black boxes. Understanding the reasons behind
                   predictions is, however, quite important in assessing trust,
                   which is fundamental if one plans to take action based on a
                   prediction, or when choosing whether to deploy a new model.
                   Such understanding also provides insights into the model,
                   which can be used to transform an untrustworthy model or
                   prediction into a trustworthy one. In this work, we propose
                   LIME, a novel explanation technique that explains the
                   predictions of any classifier in an interpretable and
                   faithful manner, by learning an interpretable model locally
                   around the prediction. We also propose a method to explain
                   models by presenting representative individual predictions
                   and their explanations in a non-redundant way, framing the
                   task as a submodular optimization problem. We demonstrate the
                   flexibility of these methods by explaining different models
                   for text (e.g. random forests) and image classification (e.g.
                   neural networks). We show the utility of explanations via
                   novel experiments, both simulated and with human subjects, on
                   various scenarios that require trust: deciding if one should
                   trust a prediction, choosing between models, improving an
                   untrustworthy classifier, and identifying why a classifier
                   should not be trusted.",
  month         =  feb,
  year          =  2016,
  archivePrefix = "arXiv",
  primaryClass  = "cs.LG"
}

@ARTICLE{Doshi-Velez2017-qv,
  title         = "Towards A rigorous science of interpretable machine learning",
  author        = "Doshi-Velez, Finale and Kim, Been",
  journal       = "arXiv [stat.ML]",
  abstract      = "As machine learning systems become ubiquitous, there has been
                   a surge of interest in interpretable machine learning:
                   systems that provide explanation for their outputs. These
                   explanations are often used to qualitatively assess other
                   criteria such as safety or non-discrimination. However,
                   despite the interest in interpretability, there is very
                   little consensus on what interpretable machine learning is
                   and how it should be measured. In this position paper, we
                   first define interpretability and describe when
                   interpretability is needed (and when it is not). Next, we
                   suggest a taxonomy for rigorous evaluation and expose open
                   questions towards a more rigorous science of interpretable
                   machine learning.",
  month         =  feb,
  year          =  2017,
  archivePrefix = "arXiv",
  primaryClass  = "stat.ML"
}

@ARTICLE{Li2024-al,
  title         = "{WF}-{VAE}: Enhancing video {VAE} by wavelet-driven energy
                   flow for latent video diffusion model",
  author        = "Li, Zongjian and Lin, Bin and Ye, Yang and Chen, Liuhan and
                   Cheng, Xinhua and Yuan, Shenghai and Yuan, Li",
  journal       = "arXiv [cs.CV]",
  abstract      = "Video Variational Autoencoder (VAE) encodes videos into a
                   low-dimensional latent space, becoming a key component of
                   most Latent Video Diffusion Models (LVDMs) to reduce model
                   training costs. However, as the resolution and duration of
                   generated videos increase, the encoding cost of Video VAEs
                   becomes a limiting bottleneck in training LVDMs. Moreover,
                   the block-wise inference method adopted by most LVDMs can
                   lead to discontinuities of latent space when processing
                   long-duration videos. The key to addressing the computational
                   bottleneck lies in decomposing videos into distinct
                   components and efficiently encoding the critical information.
                   Wavelet transform can decompose videos into multiple
                   frequency-domain components and improve the efficiency
                   significantly, we thus propose Wavelet Flow VAE (WF-VAE), an
                   autoencoder that leverages multi-level wavelet transform to
                   facilitate low-frequency energy flow into latent
                   representation. Furthermore, we introduce a method called
                   Causal Cache, which maintains the integrity of latent space
                   during block-wise inference. Compared to state-of-the-art
                   video VAEs, WF-VAE demonstrates superior performance in both
                   PSNR and LPIPS metrics, achieving 2x higher throughput and 4x
                   lower memory consumption while maintaining competitive
                   reconstruction quality. Our code and models are available at
                   https://github.com/PKU-YuanGroup/WF-VAE.",
  month         =  nov,
  year          =  2024,
  archivePrefix = "arXiv",
  primaryClass  = "cs.CV"
}

@INPROCEEDINGS{Grace2015-uc,
  title     = "Specific curiosity as a cause and consequence of transformational
               creativity",
  author    = "Grace, Kazjon and Maher, M",
  booktitle = "Proceedings of the International Conference on Computational
               Creativity",
  pages     = "260--267",
  abstract  = "This paper describes a framework by which creative systems can
               intentionally exhibit transformational creativity. Intentions are
               derived from surprising events in a process based on specific
               curiosity. We argue that autonomy of intent is achieved when a
               creative system directs its generative processes based on
               knowledge learnt from within its creative domain, and develop a
               framework to elaborate this behaviour. The framework describes
               ways that transformation of the creative domain can arise: from
               learning, from a serendipitous situation, and as a result of
               intentional exploration. Examples of each of these kinds of
               transformation are then illustrated through examples in the
               domain of recipes.",
  year      =  2015
}

@ARTICLE{Runco2025-bu,
  title     = "Updating the standard definition of creativity to account for the
               artificial creativity of {AI}",
  author    = "Runco, Mark A",
  journal   = "Creat. Res. J.",
  publisher = "Informa UK Limited",
  volume    =  37,
  number    =  1,
  pages     = "1--5",
  month     =  jan,
  year      =  2025,
  language  = "en"
}

@ARTICLE{Calderwood2020-gg,
  title    = "How novelists use generative language models: An exploratory user
              study",
  author   = "Calderwood, Alex and Qiu, Vivian and Gero, K and Chilton, Lydia B",
  abstract = "Generative language models are garnering interest as creative
              tools. We present a user study to explore how fiction writers use
              generative language models during their writing process. We had
              four professional novelists complete various writing tasks while
              having access to a generative language model that either finishes
              their sentence or generates the next paragraph of text. We report
              the primary ways that novelists interact with these models,
              including: to generate ideas for describing scenes and characters,
              to create antagonistic suggestions that force them to hone their
              descriptive language, and as a constraint tool for challenging
              their writing practice. We identify six criteria for evaluating
              creative writing assistants, and propose design guidelines for
              future co-writing tools.",
  year     =  2020
}

@ARTICLE{Weisz2023-ee,
  title         = "Toward general design principles for generative {AI}
                   applications",
  author        = "Weisz, Justin D and Muller, Michael and He, Jessica and
                   Houde, Stephanie",
  journal       = "arXiv [cs.HC]",
  abstract      = "Generative AI technologies are growing in power, utility, and
                   use. As generative technologies are being incorporated into
                   mainstream applications, there is a need for guidance on how
                   to design those applications to foster productive and safe
                   use. Based on recent research on human-AI co-creation within
                   the HCI and AI communities, we present a set of seven
                   principles for the design of generative AI applications.
                   These principles are grounded in an environment of generative
                   variability. Six principles are focused on designing for
                   characteristics of generative AI: multiple outcomes \&
                   imperfection; exploration \& control; and mental models \&
                   explanations. In addition, we urge designers to design
                   against potential harms that may be caused by a generative
                   model's hazardous output, misuse, or potential for human
                   displacement. We anticipate these principles to usefully
                   inform design decisions made in the creation of novel
                   human-AI applications, and we invite the community to apply,
                   revise, and extend these principles to their own work.",
  month         =  jan,
  year          =  2023,
  archivePrefix = "arXiv",
  primaryClass  = "cs.HC"
}

@ARTICLE{Rezwana2022-gg,
  title     = "Designing creative {AI} partners with {COFI}: A framework for
               modeling interaction in human-{AI} co-creative systems",
  author    = "Rezwana, Jeba and Maher, Mary Lou",
  journal   = "ACM Trans. Comput. Hum. Interact.",
  publisher = "Association for Computing Machinery (ACM)",
  abstract  = "Human-AI co-creativity involves both humans and AI collaborating
               on a shared creative product as partners. In a creative
               collaboration, interaction dynamics, such as turn-taking,
               contribution type, and communication, are the driving forces of
               the co-creative process. Therefore the interaction model is a
               critical and essential component for effective co-creative
               systems. There is relatively little research about interaction
               design in the co-creativity field, which is reflected in a lack
               of focus on interaction design in many existing co-creative
               systems. The primary focus of co-creativity research has been on
               the abilities of the AI. This paper focuses on the importance of
               interaction design in co-creative systems with the development of
               the Co-Creative Framework for Interaction design (COFI) that
               describes the broad scope of possibilities for interaction design
               in co-creative systems. Researchers can use COFI for modeling
               interaction in co-creative systems by exploring alternatives in
               this design space of interaction. COFI can also be beneficial
               while investigating and interpreting the interaction design of
               existing co-creative systems. We coded a dataset of existing 92
               co-creative systems using COFI and analyzed the data to show how
               COFI provides a basis to categorize the interaction models of
               existing co-creative systems. We identify opportunities to shift
               the focus of interaction models in co-creativity to enable more
               communication between the user and AI leading to human-AI
               partnerships.",
  month     =  feb,
  year      =  2022,
  language  = "en"
}

@ARTICLE{Hollan2000-bj,
  title     = "Distributed cognition: toward a new foundation for human-computer
               interaction research",
  author    = "Hollan, James and Hutchins, Edwin and Kirsh, David",
  journal   = "ACM Trans. Comput. Hum. Interact.",
  publisher = "Association for Computing Machinery (ACM)",
  volume    =  7,
  number    =  2,
  pages     = "174--196",
  abstract  = "We are quickly passing through the historical moment when people
               work in front of a single computer, dominated by a small CRT and
               focused on tasks involving only local information. Networked
               computers are becoming ubiquitous and are playing increasingly
               significant roles in our lives and in the basic infrastructures
               of science, business, and social interaction. For human-computer
               interaction to advance in the new millennium we need to better
               understand the emerging dynamic of interaction in which the focus
               task is no longer confined to the desktop but reaches into a
               complex networked world of information and computer-mediated
               interactions. We think the theory of distributed cognition has a
               special role to play in understanding interactions between people
               and technologies, for its focus has always been on whole
               environments: what we really do in them and how we coordinate our
               activity in them. Distributed cognition provides a radical
               reorientation of how to think about designing and supporting
               human-computer interaction. As a theory it is specifically
               tailored to understanding interactions among people and
               technologies. In this article we propose distributed cognition as
               a new foundation for human-computer interaction, sketch an
               integrated research framework, and use selections from our
               earlier work to suggest how this framework can provide new
               opportunities in the design of digital work materials.",
  month     =  jun,
  year      =  2000,
  language  = "en"
}

@BOOK{Norman1994-kz,
  title     = "Things that make us smart: Defending human attributes in the age
               of the machine",
  author    = "Norman, Donald",
  publisher = "Addison-Wesley Longman Publishing Co., Inc.",
  address   = "75 Arlington Street, Suite 300 Boston, MA United States",
  volume    =  10,
  pages     =  77,
  year      =  1994,
  language  = "en"
}

@ARTICLE{Zwir2022-gf,
  title     = "Evolution of genetic networks for human creativity",
  author    = "Zwir, I and Del-Val, C and Hintsanen, M and Cloninger, K M and
               Romero-Zaliz, R and Mesa, A and Arnedo, J and Salas, R and
               Poblete, G F and Raitoharju, E and Raitakari, O and
               Keltikangas-Järvinen, L and de Erausquin, G A and Tattersall, I
               and Lehtimäki, T and Cloninger, C R",
  journal   = "Mol. Psychiatry",
  publisher = "Springer Science and Business Media LLC",
  volume    =  27,
  number    =  1,
  pages     = "354--376",
  abstract  = "The genetic basis for the emergence of creativity in modern
               humans remains a mystery despite sequencing the genomes of
               chimpanzees and Neanderthals, our closest hominid relatives.
               Data-driven methods allowed us to uncover networks of genes
               distinguishing the three major systems of modern human
               personality and adaptability: emotional reactivity, self-control,
               and self-awareness. Now we have identified which of these genes
               are present in chimpanzees and Neanderthals. We replicated our
               findings in separate analyses of three high-coverage genomes of
               Neanderthals. We found that Neanderthals had nearly the same
               genes for emotional reactivity as chimpanzees, and they were
               intermediate between modern humans and chimpanzees in their
               numbers of genes for both self-control and self-awareness. 95\%
               of the 267 genes we found only in modern humans were not
               protein-coding, including many long-non-coding RNAs in the
               self-awareness network. These genes may have arisen by positive
               selection for the characteristics of human well-being and
               behavioral modernity, including creativity, prosocial behavior,
               and healthy longevity. The genes that cluster in association with
               those found only in modern humans are over-expressed in brain
               regions involved in human self-awareness and creativity,
               including late-myelinating and phylogenetically recent regions of
               neocortex for autobiographical memory in frontal, parietal, and
               temporal regions, as well as related components of
               cortico-thalamo-ponto-cerebellar-cortical and
               cortico-striato-cortical loops. We conclude that modern humans
               have more than 200 unique non-protein-coding genes regulating
               co-expression of many more protein-coding genes in coordinated
               networks that underlie their capacities for self-awareness,
               creativity, prosocial behavior, and healthy longevity, which are
               not found in chimpanzees or Neanderthals.",
  month     =  jan,
  year      =  2022,
  language  = "en"
}

@ARTICLE{Abel2025-ty,
  title   = "{AI} Bias for Creative Writing: Subjective Assessment Versus
             Willingness to Pay",
  author  = "Abel, M and Johnson, R",
  journal = "Institute of Labor Economics Discussion Paper Series",
  year    =  2025
}

@ARTICLE{Mamykina2002-lm,
  title     = "Collaborative creativity",
  author    = "Mamykina, Lena and Candy, Linda and Edmonds, Ernest",
  journal   = "Commun. ACM",
  publisher = "Association for Computing Machinery (ACM)",
  volume    =  45,
  number    =  10,
  pages     = "96--99",
  month     =  oct,
  year      =  2002,
  language  = "en"
}

@INPROCEEDINGS{Aragon2011-mv,
  title     = "Collaborative creativity: a complex systems model with
               distributed affect",
  author    = "Aragon, Cecilia R and Williams, Alison",
  booktitle = "Proceedings of the SIGCHI Conference on Human Factors in
               Computing Systems",
  publisher = "ACM",
  address   = "New York, NY, USA",
  month     =  may,
  year      =  2011
}

@ARTICLE{Gerlich2025-as,
  title     = "{AI} tools in society: Impacts on cognitive offloading and the
               future of critical thinking",
  author    = "Gerlich, Michael",
  journal   = "Societies (Basel)",
  publisher = "MDPI AG",
  volume    =  15,
  number    =  1,
  pages     =  6,
  abstract  = "The proliferation of artificial intelligence (AI) tools has
               transformed numerous aspects of daily life, yet its impact on
               critical thinking remains underexplored. This study investigates
               the relationship between AI tool usage and critical thinking
               skills, focusing on cognitive offloading as a mediating factor.
               Utilising a mixed-method approach, we conducted surveys and
               in-depth interviews with 666 participants across diverse age
               groups and educational backgrounds. Quantitative data were
               analysed using ANOVA and correlation analysis, while qualitative
               insights were obtained through thematic analysis of interview
               transcripts. The findings revealed a significant negative
               correlation between frequent AI tool usage and critical thinking
               abilities, mediated by increased cognitive offloading. Younger
               participants exhibited higher dependence on AI tools and lower
               critical thinking scores compared to older participants.
               Furthermore, higher educational attainment was associated with
               better critical thinking skills, regardless of AI usage. These
               results highlight the potential cognitive costs of AI tool
               reliance, emphasising the need for educational strategies that
               promote critical engagement with AI technologies. This study
               contributes to the growing discourse on AI’s cognitive
               implications, offering practical recommendations for mitigating
               its adverse effects on critical thinking. The findings underscore
               the importance of fostering critical thinking in an AI-driven
               world, making this research essential reading for educators,
               policymakers, and technologists.",
  month     =  jan,
  year      =  2025,
  language  = "en"
}

@ARTICLE{Lin2023-zq,
  title         = "An ontology of co-creative {AI} systems",
  author        = "Lin, Zhiyu and Riedl, Mark",
  journal       = "arXiv [cs.AI]",
  abstract      = "The term co-creativity has been used to describe a wide
                   variety of human-AI assemblages in which human and AI are
                   both involved in a creative endeavor. In order to assist with
                   disambiguating research efforts, we present an ontology of
                   co-creative systems, focusing on how responsibilities are
                   divided between human and AI system and the information
                   exchanged between them. We extend Lubart's original ontology
                   of creativity support tools with three new categories
                   emphasizing artificial intelligence:
                   computer-as-subcontractor, computer-as-critic, and
                   computer-as-teammate, some of which have sub-categorizations.",
  month         =  oct,
  year          =  2023,
  archivePrefix = "arXiv",
  primaryClass  = "cs.AI"
}

@BOOK{Pope2005-za,
  title     = "Creativity: Theory, History, Practice",
  author    = "Pope, Rob",
  publisher = "Routledge",
  year      =  2005
}

@MISC{Manual_undated-jk,
  title  = "By {E}. Paul Torrance",
  author = "Manual, Interpretive"
}

@MISC{noauthor_undated-ka,
  title = "{ICCC\_author\_kit\_2022\_\_2\_}.pdf"
}

@ARTICLE{Colton2011-vl,
  title    = "Computational creativity theory: The {FACE} and {IDEA} descriptive
              models",
  author   = "Colton, S and Charnley, J and Pease, A",
  journal  = "Int Conf Control Commun Comput India",
  pages    = "90--95",
  abstract = "We introduce computational creativity theory (CCT) as an analogue
              in computational creativity research to computational learning
              theory in machine learning. In its current draft, CCT comprises
              the FACE descriptive model of creative acts as tuples of
              generative acts, and the IDEA descriptive model of the impact such
              creative acts may have. To introduce these, we simplify various
              assumptions about software development, background material given
              to software, how creative acts are performed by computer, and how
              audiences consume the results. We use the two descriptive models
              to perform two comparisons studies, firstly for mathematical
              discovery software, and secondly for visual art generating
              programs. We conclude by discussing possible additions,
              improvements and refinements to CCT.",
  month    =  dec,
  year     =  2011
}

@ARTICLE{Ritchie2007-jy,
  title     = "Some empirical criteria for attributing creativity to a computer
               program",
  author    = "Ritchie, Graeme",
  journal   = "Minds Mach. (Dordr.)",
  publisher = "Springer Science and Business Media LLC",
  volume    =  17,
  number    =  1,
  pages     = "67--99",
  abstract  = "Over recent decades there has been a growing interest in the
               question of whether computer programs are capable of genuinely
               creative activity. Although this notion can be explored as a
               purely philosophical debate, an alternative perspective is to
               consider what aspects of the behaviour of a program might be
               noted or measured in order to arrive at an empirically supported
               judgement that creativity has occurred. We sketch out, in general
               abstract terms, what goes on when a potentially creative program
               is constructed and run, and list some of the relationships (for
               example, between input and output) which might contribute to a
               decision about creativity. Specifically, we list a number of
               criteria which might indicate interesting properties of a
               program’s behaviour, from the perspective of possible creativity.
               We go on to review some ways in which these criteria have been
               applied to actual implementations, and some possible improvements
               to this way of assessing creativity.",
  month     =  jul,
  year      =  2007,
  language  = "en"
}

@ARTICLE{Moruzzi2021-gy,
  title     = "Measuring creativity: an account of natural and artificial
               creativity",
  author    = "Moruzzi, Caterina",
  journal   = "Eur. J. Philos. Sci.",
  publisher = "Springer Science and Business Media LLC",
  volume    =  11,
  number    =  1,
  pages     =  1,
  abstract  = "AbstractDespite the recent upsurge of interest in the
               investigation of creativity, the question of how to measure
               creativity is arguably underdiscussed. The aim of this paper is
               to address this gap, proposing a multidimensional account of
               creativity which identifies problem-solving, evaluation, and
               naivety as measurable features that are common among creative
               processes. The benefits that result from the adoption of this
               model are twofold: integrating discussions on creativity in
               various domains and offering the tools to assess creativity
               across systems of different kinds. By situating creativity within
               this framework, I aim to contribute to a non-anthropocentric,
               more comprehensive understanding of the notion, and to debates on
               natural and artificial creativity.",
  month     =  mar,
  year      =  2021,
  language  = "en"
}

@ARTICLE{Moruzzi2020-mw,
  title    = "Artificial creativity and general intelligence",
  author   = "Moruzzi, Caterina",
  journal  = "Journal of Science and Technology of the Arts",
  volume   =  12,
  number   =  3,
  pages    = "84--99",
  abstract = "It is hard to deny that the notions of creativity and intelligence
              are inherently connected. But what does this correlation amount
              to? Is creativity a necessary desideratum of intelligence? On the
              other hand, does the fact of being intelligent necessarily imply
              being creative as well? The aim of this paper is to explore these
              questions and to contribute to the discussion regarding the
              connections between the notions of creativity and intelligence. In
              order to do so, I draw on the results obtained from a study on the
              public perceptions and attitudes in relation to the use of AI in
              the creative sector conducted at the University of Nottingham.
              Through this discussion I aim to test the hypothesis that the key
              features of creativity correspond to aspects that are essential
              for the realization of Artificial General Intelligence, e.g.
              flexibility, domain knowledge, and common-sense. After having
              illustrated the parallels between the two concepts, I contend that
              while creativity is a crucial component of general intelligence,
              the constituents needed to build an AGI may not be sufficient to
              design creative artificial systems. I close the paper by
              tentatively suggesting how the motivations behind the discontent
              expressed by the participants against creative AI can be explained
              through the uncanny valley phenomenon.",
  month    =  dec,
  year     =  2020
}

@ARTICLE{El-Assady2022-qc,
  title     = "Which biases and reasoning pitfalls do explanations trigger?
               Decomposing communication processes in human–AI interaction",
  author    = "El-Assady, Mennatallah and Moruzzi, Caterina",
  journal   = "IEEE Comput. Graph. Appl.",
  publisher = "IEEE",
  volume    =  42,
  number    =  6,
  pages     = "11--23",
  abstract  = "Collaborative human–AI problem-solving and decision making rely
               on effective communications between both agents. Such
               communication processes comprise explanations and interactions
               between a sender and a receiver. Investigating these dynamics is
               crucial to avoid miscommunication problems. Hence, in this
               article, we propose a communication dynamics model, examining the
               impact of the sender’s explanation intention and strategy on the
               receiver’s perception of explanation effects. We further present
               potential biases and reasoning pitfalls with the aim of
               contributing to the design of hybrid intelligence systems.
               Finally, we propose six desiderata for human-centered explainable
               AI and discuss future research opportunities.",
  month     =  sep,
  year      =  2022
}

@ARTICLE{Moruzzi2022-gp,
  title     = "Creative agents: Rethinking agency and creativity in human and
               artificial systems",
  author    = "Moruzzi, Caterina",
  journal   = "J. Aesthet. Phenomenol.",
  publisher = "Informa UK Limited",
  volume    =  9,
  number    =  2,
  pages     = "245--268",
  month     =  jul,
  year      =  2022,
  language  = "en"
}

@INPROCEEDINGS{Moruzzi2024-cq,
  title     = "A user-centered framework for human-{AI} co-creativity",
  author    = "Moruzzi, Caterina and Margarido, Solange",
  booktitle = "Extended Abstracts of the CHI Conference on Human Factors in
               Computing Systems",
  publisher = "ACM",
  address   = "New York, NY, USA",
  pages     = "1--9",
  month     =  may,
  year      =  2024
}

@ARTICLE{Bengio2003-xn,
  title    = "A neural probabilistic language model",
  author   = "Bengio, Yoshua and Ducharme, Réjean and Vincent, Pascal and
              Janvin, Christian",
  journal  = "J. Mach. Learn. Res.",
  volume   =  3,
  pages    = "932--938",
  abstract = "A goal of statistical language modeling is to learn the joint
              probability function of sequences of words. This is intrinsically
              difficult because of the curse of dimensionality: we propose to
              fight it with its own weapons. In the proposed approach one learns
              simultaneously (1) a distributed representation for each word
              (i.e. a similarity between words) along with (2) the probability
              function for word sequences, expressed with these representations.
              Generalization is obtained because a sequence of words that has
              never been seen before gets high probability if it is made of
              words that are similar to words forming an already seen sentence.
              We report on experiments using neural networks for the probability
              function, showing on two text corpora that the proposed approach
              very significantly improves on a state-of-the-art trigram model.",
  month    =  mar,
  year     =  2003
}

@ARTICLE{DeepSeek-AI2025-ai,
  title         = "{DeepSeek}-{R1}: Incentivizing Reasoning Capability in {LLMs}
                   via Reinforcement Learning",
  author        = "{DeepSeek-AI} and Guo, Daya and Yang, Dejian and Zhang,
                   Haowei and Song, Junxiao and Zhang, Ruoyu and Xu, Runxin and
                   Zhu, Qihao and Ma, Shirong and Wang, Peiyi and Bi, Xiao and
                   Zhang, Xiaokang and Yu, Xingkai and Wu, Yu and Wu, Z F and
                   Gou, Zhibin and Shao, Zhihong and Li, Zhuoshu and Gao, Ziyi
                   and Liu, Aixin and Xue, Bing and Wang, Bingxuan and Wu,
                   Bochao and Feng, Bei and Lu, Chengda and Zhao, Chenggang and
                   Deng, Chengqi and Zhang, Chenyu and Ruan, Chong and Dai,
                   Damai and Chen, Deli and Ji, Dongjie and Li, Erhang and Lin,
                   Fangyun and Dai, Fucong and Luo, Fuli and Hao, Guangbo and
                   Chen, Guanting and Li, Guowei and Zhang, H and Bao, Han and
                   Xu, Hanwei and Wang, Haocheng and Ding, Honghui and Xin,
                   Huajian and Gao, Huazuo and Qu, Hui and Li, Hui and Guo,
                   Jianzhong and Li, Jiashi and Wang, Jiawei and Chen, Jingchang
                   and Yuan, Jingyang and Qiu, Junjie and Li, Junlong and Cai, J
                   L and Ni, Jiaqi and Liang, Jian and Chen, Jin and Dong, Kai
                   and Hu, Kai and Gao, Kaige and Guan, Kang and Huang, Kexin
                   and Yu, Kuai and Wang, Lean and Zhang, Lecong and Zhao, Liang
                   and Wang, Litong and Zhang, Liyue and Xu, Lei and Xia, Leyi
                   and Zhang, Mingchuan and Zhang, Minghua and Tang, Minghui and
                   Li, Meng and Wang, Miaojun and Li, Mingming and Tian, Ning
                   and Huang, Panpan and Zhang, Peng and Wang, Qiancheng and
                   Chen, Qinyu and Du, Qiushi and Ge, Ruiqi and Zhang, Ruisong
                   and Pan, Ruizhe and Wang, Runji and Chen, R J and Jin, R L
                   and Chen, Ruyi and Lu, Shanghao and Zhou, Shangyan and Chen,
                   Shanhuang and Ye, Shengfeng and Wang, Shiyu and Yu, Shuiping
                   and Zhou, Shunfeng and Pan, Shuting and Li, S S and Zhou,
                   Shuang and Wu, Shaoqing and Ye, Shengfeng and Yun, Tao and
                   Pei, Tian and Sun, Tianyu and Wang, T and Zeng, Wangding and
                   Zhao, Wanjia and Liu, Wen and Liang, Wenfeng and Gao, Wenjun
                   and Yu, Wenqin and Zhang, Wentao and Xiao, W L and An, Wei
                   and Liu, Xiaodong and Wang, Xiaohan and Chen, Xiaokang and
                   Nie, Xiaotao and Cheng, Xin and Liu, Xin and Xie, Xin and
                   Liu, Xingchao and Yang, Xinyu and Li, Xinyuan and Su,
                   Xuecheng and Lin, Xuheng and Li, X Q and Jin, Xiangyue and
                   Shen, Xiaojin and Chen, Xiaosha and Sun, Xiaowen and Wang,
                   Xiaoxiang and Song, Xinnan and Zhou, Xinyi and Wang, Xianzu
                   and Shan, Xinxia and Li, Y K and Wang, Y Q and Wei, Y X and
                   Zhang, Yang and Xu, Yanhong and Li, Yao and Zhao, Yao and
                   Sun, Yaofeng and Wang, Yaohui and Yu, Yi and Zhang, Yichao
                   and Shi, Yifan and Xiong, Yiliang and He, Ying and Piao,
                   Yishi and Wang, Yisong and Tan, Yixuan and Ma, Yiyang and
                   Liu, Yiyuan and Guo, Yongqiang and Ou, Yuan and Wang, Yuduan
                   and Gong, Yue and Zou, Yuheng and He, Yujia and Xiong, Yunfan
                   and Luo, Yuxiang and You, Yuxiang and Liu, Yuxuan and Zhou,
                   Yuyang and Zhu, Y X and Xu, Yanhong and Huang, Yanping and
                   Li, Yaohui and Zheng, Yi and Zhu, Yuchen and Ma, Yunxian and
                   Tang, Ying and Zha, Yukun and Yan, Yuting and Ren, Z Z and
                   Ren, Zehui and Sha, Zhangli and Fu, Zhe and Xu, Zhean and
                   Xie, Zhenda and Zhang, Zhengyan and Hao, Zhewen and Ma,
                   Zhicheng and Yan, Zhigang and Wu, Zhiyu and Gu, Zihui and
                   Zhu, Zijia and Liu, Zijun and Li, Zilin and Xie, Ziwei and
                   Song, Ziyang and Pan, Zizheng and Huang, Zhen and Xu, Zhipeng
                   and Zhang, Zhongyu and Zhang, Zhen",
  journal       = "arXiv [cs.CL]",
  abstract      = "We introduce our first-generation reasoning models,
                   DeepSeek-R1-Zero and DeepSeek-R1. DeepSeek-R1-Zero, a model
                   trained via large-scale reinforcement learning (RL) without
                   supervised fine-tuning (SFT) as a preliminary step,
                   demonstrates remarkable reasoning capabilities. Through RL,
                   DeepSeek-R1-Zero naturally emerges with numerous powerful and
                   intriguing reasoning behaviors. However, it encounters
                   challenges such as poor readability, and language mixing. To
                   address these issues and further enhance reasoning
                   performance, we introduce DeepSeek-R1, which incorporates
                   multi-stage training and cold-start data before RL.
                   DeepSeek-R1 achieves performance comparable to OpenAI-o1-1217
                   on reasoning tasks. To support the research community, we
                   open-source DeepSeek-R1-Zero, DeepSeek-R1, and six dense
                   models (1.5B, 7B, 8B, 14B, 32B, 70B) distilled from
                   DeepSeek-R1 based on Qwen and Llama.",
  month         =  jan,
  year          =  2025,
  archivePrefix = "arXiv",
  primaryClass  = "cs.CL"
}

@ARTICLE{OpenAI2023-lt,
  title         = "{GPT}-4 Technical Report",
  author        = "{OpenAI} and Achiam, Josh and Adler, Steven and Agarwal,
                   Sandhini and Ahmad, Lama and Akkaya, Ilge and Aleman,
                   Florencia Leoni and Almeida, Diogo and Altenschmidt, Janko
                   and Altman, Sam and Anadkat, Shyamal and Avila, Red and
                   Babuschkin, Igor and Balaji, Suchir and Balcom, Valerie and
                   Baltescu, Paul and Bao, Haiming and Bavarian, Mohammad and
                   Belgum, Jeff and Bello, Irwan and Berdine, Jake and
                   Bernadett-Shapiro, Gabriel and Berner, Christopher and
                   Bogdonoff, Lenny and Boiko, Oleg and Boyd, Madelaine and
                   Brakman, Anna-Luisa and Brockman, Greg and Brooks, Tim and
                   Brundage, Miles and Button, Kevin and Cai, Trevor and
                   Campbell, Rosie and Cann, Andrew and Carey, Brittany and
                   Carlson, Chelsea and Carmichael, Rory and Chan, Brooke and
                   Chang, Che and Chantzis, Fotis and Chen, Derek and Chen,
                   Sully and Chen, Ruby and Chen, Jason and Chen, Mark and
                   Chess, Ben and Cho, Chester and Chu, Casey and Chung, Hyung
                   Won and Cummings, Dave and Currier, Jeremiah and Dai, Yunxing
                   and Decareaux, Cory and Degry, Thomas and Deutsch, Noah and
                   Deville, Damien and Dhar, Arka and Dohan, David and Dowling,
                   Steve and Dunning, Sheila and Ecoffet, Adrien and Eleti, Atty
                   and Eloundou, Tyna and Farhi, David and Fedus, Liam and
                   Felix, Niko and Fishman, Simón Posada and Forte, Juston and
                   Fulford, Isabella and Gao, Leo and Georges, Elie and Gibson,
                   Christian and Goel, Vik and Gogineni, Tarun and Goh, Gabriel
                   and Gontijo-Lopes, Rapha and Gordon, Jonathan and Grafstein,
                   Morgan and Gray, Scott and Greene, Ryan and Gross, Joshua and
                   Gu, Shixiang Shane and Guo, Yufei and Hallacy, Chris and Han,
                   Jesse and Harris, Jeff and He, Yuchen and Heaton, Mike and
                   Heidecke, Johannes and Hesse, Chris and Hickey, Alan and
                   Hickey, Wade and Hoeschele, Peter and Houghton, Brandon and
                   Hsu, Kenny and Hu, Shengli and Hu, Xin and Huizinga, Joost
                   and Jain, Shantanu and Jain, Shawn and Jang, Joanne and
                   Jiang, Angela and Jiang, Roger and Jin, Haozhun and Jin,
                   Denny and Jomoto, Shino and Jonn, Billie and Jun, Heewoo and
                   Kaftan, Tomer and Kaiser, Łukasz and Kamali, Ali and
                   Kanitscheider, Ingmar and Keskar, Nitish Shirish and Khan,
                   Tabarak and Kilpatrick, Logan and Kim, Jong Wook and Kim,
                   Christina and Kim, Yongjik and Kirchner, Jan Hendrik and
                   Kiros, Jamie and Knight, Matt and Kokotajlo, Daniel and
                   Kondraciuk, Łukasz and Kondrich, Andrew and Konstantinidis,
                   Aris and Kosic, Kyle and Krueger, Gretchen and Kuo, Vishal
                   and Lampe, Michael and Lan, Ikai and Lee, Teddy and Leike,
                   Jan and Leung, Jade and Levy, Daniel and Li, Chak Ming and
                   Lim, Rachel and Lin, Molly and Lin, Stephanie and Litwin,
                   Mateusz and Lopez, Theresa and Lowe, Ryan and Lue, Patricia
                   and Makanju, Anna and Malfacini, Kim and Manning, Sam and
                   Markov, Todor and Markovski, Yaniv and Martin, Bianca and
                   Mayer, Katie and Mayne, Andrew and McGrew, Bob and McKinney,
                   Scott Mayer and McLeavey, Christine and McMillan, Paul and
                   McNeil, Jake and Medina, David and Mehta, Aalok and Menick,
                   Jacob and Metz, Luke and Mishchenko, Andrey and Mishkin,
                   Pamela and Monaco, Vinnie and Morikawa, Evan and Mossing,
                   Daniel and Mu, Tong and Murati, Mira and Murk, Oleg and Mély,
                   David and Nair, Ashvin and Nakano, Reiichiro and Nayak,
                   Rajeev and Neelakantan, Arvind and Ngo, Richard and Noh,
                   Hyeonwoo and Ouyang, Long and O'Keefe, Cullen and Pachocki,
                   Jakub and Paino, Alex and Palermo, Joe and Pantuliano, Ashley
                   and Parascandolo, Giambattista and Parish, Joel and
                   Parparita, Emy and Passos, Alex and Pavlov, Mikhail and Peng,
                   Andrew and Perelman, Adam and Peres, Filipe de Avila Belbute
                   and Petrov, Michael and Pinto, Henrique Ponde de Oliveira and
                   {Michael} and {Pokorny} and Pokrass, Michelle and Pong,
                   Vitchyr H and Powell, Tolly and Power, Alethea and Power,
                   Boris and Proehl, Elizabeth and Puri, Raul and Radford, Alec
                   and Rae, Jack and Ramesh, Aditya and Raymond, Cameron and
                   Real, Francis and Rimbach, Kendra and Ross, Carl and Rotsted,
                   Bob and Roussez, Henri and Ryder, Nick and Saltarelli, Mario
                   and Sanders, Ted and Santurkar, Shibani and Sastry, Girish
                   and Schmidt, Heather and Schnurr, David and Schulman, John
                   and Selsam, Daniel and Sheppard, Kyla and Sherbakov, Toki and
                   Shieh, Jessica and Shoker, Sarah and Shyam, Pranav and Sidor,
                   Szymon and Sigler, Eric and Simens, Maddie and Sitkin, Jordan
                   and Slama, Katarina and Sohl, Ian and Sokolowsky, Benjamin
                   and Song, Yang and Staudacher, Natalie and Such, Felipe
                   Petroski and Summers, Natalie and Sutskever, Ilya and Tang,
                   Jie and Tezak, Nikolas and Thompson, Madeleine B and Tillet,
                   Phil and Tootoonchian, Amin and Tseng, Elizabeth and Tuggle,
                   Preston and Turley, Nick and Tworek, Jerry and Uribe, Juan
                   Felipe Cerón and Vallone, Andrea and Vijayvergiya, Arun and
                   Voss, Chelsea and Wainwright, Carroll and Wang, Justin Jay
                   and Wang, Alvin and Wang, Ben and Ward, Jonathan and Wei,
                   Jason and Weinmann, C J and Welihinda, Akila and Welinder,
                   Peter and Weng, Jiayi and Weng, Lilian and Wiethoff, Matt and
                   Willner, Dave and Winter, Clemens and Wolrich, Samuel and
                   Wong, Hannah and Workman, Lauren and Wu, Sherwin and Wu, Jeff
                   and Wu, Michael and Xiao, Kai and Xu, Tao and Yoo, Sarah and
                   Yu, Kevin and Yuan, Qiming and Zaremba, Wojciech and Zellers,
                   Rowan and Zhang, Chong and Zhang, Marvin and Zhao, Shengjia
                   and Zheng, Tianhao and Zhuang, Juntang and Zhuk, William and
                   Zoph, Barret",
  journal       = "arXiv [cs.CL]",
  abstract      = "We report the development of GPT-4, a large-scale, multimodal
                   model which can accept image and text inputs and produce text
                   outputs. While less capable than humans in many real-world
                   scenarios, GPT-4 exhibits human-level performance on various
                   professional and academic benchmarks, including passing a
                   simulated bar exam with a score around the top 10\% of test
                   takers. GPT-4 is a Transformer-based model pre-trained to
                   predict the next token in a document. The post-training
                   alignment process results in improved performance on measures
                   of factuality and adherence to desired behavior. A core
                   component of this project was developing infrastructure and
                   optimization methods that behave predictably across a wide
                   range of scales. This allowed us to accurately predict some
                   aspects of GPT-4's performance based on models trained with
                   no more than 1/1,000th the compute of GPT-4.",
  month         =  mar,
  year          =  2023,
  archivePrefix = "arXiv",
  primaryClass  = "cs.CL"
}

@ARTICLE{Gemini-Team2024-wk,
  title         = "Gemini 1.5: Unlocking multimodal understanding across
                   millions of tokens of context",
  author        = "{Gemini Team}",
  journal       = "arXiv [cs.CL]",
  abstract      = "In this report, we introduce the Gemini 1.5 family of models,
                   representing the next generation of highly compute-efficient
                   multimodal models capable of recalling and reasoning over
                   fine-grained information from millions of tokens of context,
                   including multiple long documents and hours of video and
                   audio. The family includes two new models: (1) an updated
                   Gemini 1.5 Pro, which exceeds the February version on the
                   great majority of capabilities and benchmarks; (2) Gemini 1.5
                   Flash, a more lightweight variant designed for efficiency
                   with minimal regression in quality. Gemini 1.5 models achieve
                   near-perfect recall on long-context retrieval tasks across
                   modalities, improve the state-of-the-art in long-document QA,
                   long-video QA and long-context ASR, and match or surpass
                   Gemini 1.0 Ultra's state-of-the-art performance across a
                   broad set of benchmarks. Studying the limits of Gemini 1.5's
                   long-context ability, we find continued improvement in
                   next-token prediction and near-perfect retrieval (>99\%) up
                   to at least 10M tokens, a generational leap over existing
                   models such as Claude 3.0 (200k) and GPT-4 Turbo (128k).
                   Finally, we highlight real-world use cases, such as Gemini
                   1.5 collaborating with professionals on completing their
                   tasks achieving 26 to 75\% time savings across 10 different
                   job categories, as well as surprising new capabilities of
                   large language models at the frontier; when given a grammar
                   manual for Kalamang, a language with fewer than 200 speakers
                   worldwide, the model learns to translate English to Kalamang
                   at a similar level to a person who learned from the same
                   content.",
  month         =  mar,
  year          =  2024,
  archivePrefix = "arXiv",
  primaryClass  = "cs.CL"
}

@ARTICLE{Polyak2024-lh,
  title         = "Movie Gen: A cast of media foundation models",
  author        = "Polyak, Adam and Zohar, Amit and Brown, Andrew and Tjandra,
                   Andros and Sinha, Animesh and Lee, Ann and Vyas, Apoorv and
                   Shi, Bowen and Ma, Chih-Yao and Chuang, Ching-Yao and Yan,
                   David and Choudhary, Dhruv and Wang, Dingkang and Sethi, Geet
                   and Pang, Guan and Ma, Haoyu and Misra, Ishan and Hou, Ji and
                   Wang, Jialiang and Jagadeesh, Kiran and Li, Kunpeng and
                   Zhang, Luxin and Singh, Mannat and Williamson, Mary and Le,
                   Matt and Yu, Matthew and Singh, Mitesh Kumar and Zhang,
                   Peizhao and Vajda, Peter and Duval, Quentin and Girdhar,
                   Rohit and Sumbaly, Roshan and Rambhatla, Sai Saketh and Tsai,
                   Sam and Azadi, Samaneh and Datta, Samyak and Chen, Sanyuan
                   and Bell, Sean and Ramaswamy, Sharadh and Sheynin, Shelly and
                   Bhattacharya, Siddharth and Motwani, Simran and Xu, Tao and
                   Li, Tianhe and Hou, Tingbo and Hsu, Wei-Ning and Yin, Xi and
                   Dai, Xiaoliang and Taigman, Yaniv and Luo, Yaqiao and Liu,
                   Yen-Cheng and Wu, Yi-Chiao and Zhao, Yue and Kirstain, Yuval
                   and He, Zecheng and He, Zijian and Pumarola, Albert and
                   Thabet, Ali and Sanakoyeu, Artsiom and Mallya, Arun and Guo,
                   Baishan and Araya, Boris and Kerr, Breena and Wood, Carleigh
                   and Liu, Ce and Peng, Cen and Vengertsev, Dimitry and
                   Schonfeld, Edgar and Blanchard, Elliot and Juefei-Xu, Felix
                   and Nord, Fraylie and Liang, Jeff and Hoffman, John and
                   Kohler, Jonas and Fire, Kaolin and Sivakumar, Karthik and
                   Chen, Lawrence and Yu, Licheng and Gao, Luya and
                   Georgopoulos, Markos and Moritz, Rashel and Sampson, Sara K
                   and Li, Shikai and Parmeggiani, Simone and Fine, Steve and
                   Fowler, Tara and Petrovic, Vladan and Du, Yuming",
  journal       = "arXiv [cs.CV]",
  abstract      = "We present Movie Gen, a cast of foundation models that
                   generates high-quality, 1080p HD videos with different aspect
                   ratios and synchronized audio. We also show additional
                   capabilities such as precise instruction-based video editing
                   and generation of personalized videos based on a user's
                   image. Our models set a new state-of-the-art on multiple
                   tasks: text-to-video synthesis, video personalization, video
                   editing, video-to-audio generation, and text-to-audio
                   generation. Our largest video generation model is a 30B
                   parameter transformer trained with a maximum context length
                   of 73K video tokens, corresponding to a generated video of 16
                   seconds at 16 frames-per-second. We show multiple technical
                   innovations and simplifications on the architecture, latent
                   spaces, training objectives and recipes, data curation,
                   evaluation protocols, parallelization techniques, and
                   inference optimizations that allow us to reap the benefits of
                   scaling pre-training data, model size, and training compute
                   for training large scale media generation models. We hope
                   this paper helps the research community to accelerate
                   progress and innovation in media generation models. All
                   videos from this paper are available at
                   https://go.fb.me/MovieGenResearchVideos.",
  month         =  oct,
  year          =  2024,
  archivePrefix = "arXiv",
  primaryClass  = "cs.CV"
}

@ARTICLE{Patel2023-fg,
  title     = "{ChatGPT}: the future of discharge summaries?",
  author    = "Patel, Sajan B and Lam, Kyle",
  journal   = "Lancet Digit. Health",
  publisher = "Elsevier BV",
  volume    =  5,
  number    =  3,
  pages     = "e107--e108",
  month     =  mar,
  year      =  2023,
  language  = "en"
}

@ARTICLE{Parasuraman2010-me,
  title     = "Complacency and bias in human use of automation: an attentional
               integration",
  author    = "Parasuraman, Raja and Manzey, Dietrich H",
  journal   = "Hum. Factors",
  publisher = "SAGE Publications",
  volume    =  52,
  number    =  3,
  pages     = "381--410",
  abstract  = "OBJECTIVE: Our aim was to review empirical studies of complacency
               and bias in human interaction with automated and decision support
               systems and provide an integrated theoretical model for their
               explanation. BACKGROUND: Automation-related complacency and
               automation bias have typically been considered separately and
               independently. METHODS: Studies on complacency and automation
               bias were analyzed with respect to the cognitive processes
               involved. RESULTS: Automation complacency occurs under conditions
               of multiple-task load, when manual tasks compete with the
               automated task for the operator's attention. Automation
               complacency is found in both naive and expert participants and
               cannot be overcome with simple practice. Automation bias results
               in making both omission and commission errors when decision aids
               are imperfect. Automation bias occurs in both naive and expert
               participants, cannot be prevented by training or instructions,
               and can affect decision making in individuals as well as in
               teams. While automation bias has been conceived of as a special
               case of decision bias, our analysis suggests that it also depends
               on attentional processes similar to those involved in
               automation-related complacency. CONCLUSION: Complacency and
               automation bias represent different manifestations of overlapping
               automation-induced phenomena, with attention playing a central
               role. An integrated model of complacency and automation bias
               shows that they result from the dynamic interaction of personal,
               situational, and automation-related characteristics. APPLICATION:
               The integrated model and attentional synthesis provides a
               heuristic framework for further research on complacency and
               automation bias and design options for mitigating such effects in
               automated and decision support systems.",
  month     =  jun,
  year      =  2010,
  language  = "en"
}

@ARTICLE{Jordanous2016-xb,
  title     = "Four {PPPPerspectives} on computational creativity in theory and
               in practice",
  author    = "Jordanous, Anna",
  journal   = "Conn. Sci.",
  publisher = "Informa UK Limited",
  volume    =  28,
  number    =  2,
  pages     = "194--216",
  abstract  = "Computational creativity is the modelling, simulating or
               replicating of creativity computationally. In examining and
               learning from these “creative systems”, from what perspective
               should the creativity of a system be considered? Are we
               interested in the creativity of the system's output? Or of its
               creative processes? Features of the system? Or how it operates
               within its environment? Traditionally computational creativity
               has focused more on creative systems' products or processes,
               though this focus has widened recently. Creativity research
               offers the Four Ps of creativity: Person/Producer, Product,
               Process and Press/Environment. This paper presents the Four Ps,
               explaining each in the context of creativity research and how it
               relates to computational creativity. To illustrate the usefulness
               of the Four Ps in taking broader perspectives on creativity in
               its computational treatment, the concepts of novelty and value
               are explored using the Four Ps, highlighting aspects of novelty
               and value that may otherwise be overlooked. Analysis of recent
               research in computational creativity finds that although each of
               the Four Ps appears in the body of computational creativity work,
               individual pieces of work often do not acknowledge all Four Ps,
               missing opportunities to widen their work's relevance. We can
               see, though, that high-status computational creativity papers do
               typically address all Four Ps. This paper argues that the broader
               views of creativity afforded by the Four Ps is vital in guiding
               us towards more comprehensively useful computational
               investigations of creativity.",
  month     =  apr,
  year      =  2016,
  language  = "en"
}

@UNPUBLISHED{McCarthy1955-ls,
  title    = "A proposal for the Dartmouth summer research project on artificial
              intelligence",
  author   = "McCarthy, John and Minsky, M and Rochester, N and Shannon, C",
  volume   =  27,
  pages    = "12--14",
  abstract = "The 1956 Dartmouth summer research project on artificial
              intelligence was initiated by this August 31, 1955 proposal,
              authored by John McCarthy, Marvin Minsky, Nathaniel Rochester, and
              Claude Shannon. The original typescript consisted of 17 pages plus
              a title page. Copies of the typescript are housed in the archives
              at Dartmouth College and Stanford University. The first 5 papers
              state the proposal, and the remaining pages give qualifications
              and interests of the four who proposed the study. In the interest
              of brevity, this article reproduces only the proposal itself,
              along with the short autobiographical statements of the proposers.",
  year     =  1955
}

@ARTICLE{Shneiderman2020-ue,
  title     = "Human-centered artificial intelligence: Three fresh ideas",
  author    = "Shneiderman, Ben",
  journal   = "AIS Trans. Hum.-Comput. Interact.",
  publisher = "Association for Information Systems",
  volume    =  12,
  number    =  3,
  pages     = "109--124",
  abstract  = "Human-Centered AI (HCAI) is a promising direction for designing
               AI systems that support human self-efficacy, promote creativity,
               clarify responsibility, and facilitate social participation.
               These human aspirations also encourage consideration of privacy,
               security, environmental protection, social justice, and human
               rights. This commentary reverses the current emphasis on
               algorithms and AI methods, by putting humans at the center of
               systems design thinking, in effect, a second Copernican
               Revolution. It offers three ideas: (1) a two-dimensional HCAI
               framework, which shows how it is possible to have both high
               levels of human control AND high levels of automation, (2) a
               shift from emulating humans to empowering people with a plea to
               shift language, imagery, and metaphors away from portrayals of
               intelligent autonomous teammates towards descriptions of powerful
               tool-like appliances and tele-operated devices, and (3) a
               three-level governance structure that describes how software
               engineering teams can develop more reliable systems, how managers
               can emphasize a safety culture across an organization, and how
               industry-wide certification can promote trustworthy HCAI systems.
               These ideas will be challenged by some, refined by others,
               extended to accommodate new technologies, and validated with
               quantitative and qualitative research. They offer a reframe -- a
               chance to restart design discussions for products and services --
               which could bring greater benefits to individuals, families,
               communities, businesses, and society.",
  year      =  2020
}

@ARTICLE{Glickman2024-zh,
  title     = "How human–AI feedback loops alter human perceptual, emotional and
               social judgements",
  author    = "Glickman, Moshe and Sharot, Tali",
  journal   = "Nat. Hum. Behav.",
  publisher = "Springer Science and Business Media LLC",
  pages     = "1--15",
  abstract  = "AbstractArtificial intelligence (AI) technologies are rapidly
               advancing, enhancing human capabilities across various fields
               spanning from finance to medicine. Despite their numerous
               advantages, AI systems can exhibit biased judgements in domains
               ranging from perception to emotion. Here, in a series of
               experiments (n = 1,401 participants), we reveal a feedback loop
               where human–AI interactions alter processes underlying human
               perceptual, emotional and social judgements, subsequently
               amplifying biases in humans. This amplification is significantly
               greater than that observed in interactions between humans, due to
               both the tendency of AI systems to amplify biases and the way
               humans perceive AI systems. Participants are often unaware of the
               extent of the AI’s influence, rendering them more susceptible to
               it. These findings uncover a mechanism wherein AI systems amplify
               biases, which are further internalized by humans, triggering a
               snowball effect where small errors in judgement escalate into
               much larger ones.",
  month     =  dec,
  year      =  2024,
  language  = "en"
}

@ARTICLE{Bower2021-uh,
  title     = "Perceptions of {AI} engaging in human expression",
  author    = "Bower, Alexander H and Steyvers, Mark",
  journal   = "Sci. Rep.",
  publisher = "Springer Science and Business Media LLC",
  volume    =  11,
  number    =  1,
  pages     = "1--7",
  abstract  = "AbstractThough humans should defer to the superior judgement of
               AI in an increasing number of domains, certain biases prevent us
               from doing so. Understanding when and why these biases occur is a
               central challenge for human-computer interaction. One proposed
               source of such bias is task subjectivity. We test this hypothesis
               by having both real and purported AI engage in one of the most
               subjective expressions possible: Humor. Across two experiments,
               we address the following: Will people rate jokes as less funny if
               they believe an AI created them? When asked to rate jokes and
               guess their likeliest source, participants evaluate jokes that
               they attribute to humans as the funniest and those to AI as the
               least funny. However, when these same jokes are explicitly framed
               as either human or AI-created, there is no such difference in
               ratings. Our findings demonstrate that user attitudes toward AI
               are more malleable than once thought—even when they (seemingly)
               attempt the most fundamental of human expressions.",
  month     =  oct,
  year      =  2021,
  language  = "en"
}

@ARTICLE{Gottweis2025-kc,
  title   = "Towards an {AI} co-scientist",
  author  = "Gottweis, Juraj and Weng, Wei-Hung and Daryin, Alexander and Tu,
             Tao and Palepu, Anil and Sirkovic, Petar and Myaskovsky, Artiom and
             Weissenberger, Felix and Rong, Keran and Tanno, Ryutaro and Saab,
             Khaled and Popovici, Dan and Blum, Jacob and Zhang, Fan and Chou,
             Katherine and Hassidim, Avinatan and Gokturk, Burak and Vahdat,
             Amin and Kohli, Pushmeet and Matias, Yossi and Carroll, Andrew and
             Kulkarni, Kavita and Tomasev, Nenad and Dhillon, Vikram and
             Vaishnav, Eeshit Dhaval and Lee, Byron and Costa, Tiago R D and
             Penadés, José R and Peltz, Gary and Xu, Yunhan and Pawlosky,
             Annalisa and Karthikesalingam, Alan and Natarajan, Vivek",
  journal = "Google Research Blog",
  month   =  feb,
  year    =  2025
}

@INPROCEEDINGS{Hornbaek2017-wg,
  title     = "What Is Interaction?",
  author    = "Hornbæk, Kasper and Oulasvirta, Antti",
  booktitle = "Proceedings of the 2017 CHI Conference on Human Factors in
               Computing Systems",
  publisher = "ACM",
  address   = "New York, NY, USA",
  month     =  may,
  year      =  2017
}

@ARTICLE{Amershi2014-xa,
  title     = "Power to the people: The role of humans in interactive machine
               learning",
  author    = "Amershi, Saleema and Cakmak, Maya and Knox, W Bradley and
               Kulesza, Todd",
  journal   = "AI Mag.",
  publisher = "Wiley",
  volume    =  35,
  number    =  4,
  pages     = "105--120",
  abstract  = "Systems that can learn interactively from their end‐users are
               quickly becoming widespread. Until recently, this progress has
               been fueled mostly by advances in machine learning; however, more
               and more researchers are realizing the importance of studying
               users of these systems. In this article we promote this approach
               and demonstrate how it can result in better user experiences and
               more effective learning systems. We present a number of case
               studies that demonstrate how interactivity results in a tight
               coupling between the system and the user, exemplify ways in which
               some existing systems fail to account for the user, and explore
               new ways for learning systems to interact with their users. After
               giving a glimpse of the progress that has been made thus far, we
               discuss some of the challenges we face in moving the field
               forward.",
  month     =  dec,
  year      =  2014,
  language  = "en"
}

@BOOK{Finke1992-kh,
  title     = "Creative Cognition: Theory, research, and applications",
  author    = "Finke, Ronald A and Ward, Thomas B and Smith, Steven M",
  publisher = "The MIT Press",
  abstract  = "Creative Cognition combines original experiments with existing
               work in cognitive psychology to provide the first explicit
               account of the cognitive processes and structures that contribute
               to creative thinking and discovery. Creative Cognition combines
               original experiments with existing work in cognitive psychology
               to provide the first explicit account of the cognitive processes
               and structures that contribute to creative thinking and
               discovery. In separate chapters, the authors take up
               visualization, concept formation, categorization, memory
               retrieval, and problem solving. They describe novel experimental
               methods for studying creative cognitive processes under
               controlled laboratory conditions, along with techniques that can
               be used to generate many different types of inventions and
               concepts. Unlike traditional approaches, Creative Cognition
               considers creativity as a product of numerous cognitive
               processes, each of which helps to set the stage for insight and
               discovery. It identifies many of these processes as well as
               general principles of creative cognition that can be applied
               across a variety of different domains, with examples in
               artificial intelligence, engineering design, product development,
               architecture, education, and the visual arts. Following a summary
               of previous approaches to creativity, the authors present a
               theoretical model of the creative process. They review research
               involving an innovative imagery recombination technique,
               developed by Finke, that clearly demonstrates that creative
               inventions can be induced in the laboratory. They then describe
               experiments in category learning that support the provocative
               claim that the factors constraining category formation similarly
               constrain imagination and illustrate the role of various memory
               processes and other strategies in creative problem solving.
               Bradford Books imprint",
  month     =  oct,
  year      =  1992,
  language  = "en"
}

@INPROCEEDINGS{Weisz2024-io,
  title     = "Design Principles for Generative {AI} Applications",
  author    = "Weisz, Justin D and He, Jessica and Muller, Michael and Hoefer,
               Gabriela and Miles, Rachel and Geyer, Werner",
  booktitle = "Proceedings of the CHI Conference on Human Factors in Computing
               Systems",
  publisher = "ACM",
  address   = "New York, NY, USA",
  volume    =  10,
  pages     = "1--22",
  month     =  may,
  year      =  2024
}

@ARTICLE{Blanchard2024-jz,
  title    = "Developing symbiotic virtuosity: {AI}-augmented musical
              instruments and their use in live music performances",
  author   = "Blanchard, Lancelot and Naseck, Perry and Egozy, Eran and
              Paradiso, Joseph A",
  abstract = "Recent advancements in generative AI have led to the development
              of powerful models capable of generating full-length,
              professional-sounding music from brief text prompts. These models
              have also sparked concerns among artists who feel their creative
              roles are being overshadowed. To address this issue, we propose
              the development of AI-augmented instruments, defined as generative
              AI systems embedded within musical instruments, that provide
              artists with extensive control and responsiveness to real-time
              musical inputs while harnessing the capability of powerful AI
              models. Through a thorough definition of virtuosity, we explore
              how these AI-augmented instruments can exhibit virtuosic
              qualities, serve as collaborative partners, and enable artists to
              attain a new form of virtuosity, which we call ‘symbiotic
              virtuosity.’ Furthermore, we present a set of guidelines for
              effectively communicating the AI’s capabilities to live audiences.
              To exemplify our reflections, we delve into our collaboration with
              Grammy-winning keyboardist Jordan Rudess, which resulted in a
              pioneering AI–human co-created demonstrative performance that was
              held at the MIT Media Lab in April 2024.",
  month    =  sep,
  year     =  2024
}

@ARTICLE{Lee2025-dw,
  title     = "The impact of Generative {AI} on critical thinking: Self-reported
               reductions in cognitive effort and confidence effects from a
               survey of knowledge workers",
  author    = "Lee, Hank",
  journal   = "CHI Conference on Human Factors in Computing Systems (CHI '25),
               April 26-May 01, 2025, Yokohama, Japan",
  publisher = "Association for Computing Machinery",
  volume    =  1,
  number    =  1,
  abstract  = "The rise of Generative AI (GenAI) in knowledge workflows raises
               questions about its impact on critical thinking skills and
               practices. We survey 319 knowledge workers to investigate 1) when
               and how they perceive the enaction of critical thinking when
               using GenAI, and 2) when and why GenAI affects their effort to do
               so. Participants shared 936 first-hand examples of using GenAI in
               work tasks. Quantitatively, when considering both task-and
               user-specific factors, a user’s task-specific self-confidence and
               confidence in GenAI are predictive of whether critical thinking
               is enacted and the effort of doing so in GenAI-assisted tasks.
               Specifically, higher confidence in GenAI is associated with less
               critical thinking, while higher self-confidence is associated
               with more critical thinking. Qualitatively, GenAI shifts the
               nature of critical thinking toward information verification,
               response integration, and task stewardship. Our insights reveal
               new design challenges and opportunities for developing GenAI
               tools for knowledge work.",
  year      =  2025
}

@ARTICLE{Guckelsberger2017-nk,
  title     = "Addressing the ``why?'' in computational creativity: A
               non-anthropocentric, minimal model of intentional creative agency",
  author    = "Guckelsberger, C and Salge, Christoph and Colton, S",
  journal   = "Int Conf Control Commun Comput India",
  publisher = "research.monash.edu",
  pages     = "128--135",
  abstract  = "Generally, computational creativity (CC) systems cannot explain
               why they are being creative, without ultimately referring back to
               the values and goals of their designer. Answering the why? would
               allow for the attribution of intentional agency, and likely lead
               to a stronger perception of creativity. Enactive artificial
               intelligence, a framework inspired by autopoietic enactive
               cognitive science, equips us with the necessary conditions for a
               value function to reflect a system's own intrinsic goals. We
               translate the framework's general claims to CC and ground a
               system's creative activity intrinsically in the maintenance of
               its identity. We relate to candidate computational principles to
               realise enactive artificial agents, thus laying the foundations
               for a minimal, non-anthropocentric model of intentional creative
               agency. We discuss first implications for the design and
               evaluation of CC, and address why human-level intentional
               creative agency is so hard to achieve. We ultimately propose a
               new research direction in CC, where intentional creative agency
               is addressed bottom up.",
  month     =  apr,
  year      =  2017
}

@ARTICLE{Colton2008-fh,
  title     = "Creativity versus the perception of creativity in computational
               systems",
  author    = "Colton, S",
  journal   = "AAAI spring symposium: creative intelligent systems",
  publisher = "cdn.aaai.org",
  pages     = "14--20",
  abstract  = "We add to the discussion of how to assess the creativity of
               programs which generate artefacts such as poems, theorems,
               paintings, melodies, etc. To do so, we first review some existing
               frameworks for assessing artefact generation programs. Then,
               drawing on our experience of building both a mathematical
               discovery system and an automated painter, we argue that it is
               not appropriate to base the assessment of a system on its output
               alone, and that the way it produces artefacts also needs to be
               taken into account. We suggest a simple framework within which
               the behaviour of a program can be categorised and described which
               may add to the perception of creativity in the system.",
  month     =  sep,
  year      =  2008
}

@INCOLLECTION{Boden2009-vo,
  title     = "Conceptual spaces",
  author    = "Boden, Margaret A",
  booktitle = "Milieus of Creativity",
  publisher = "Springer Netherlands",
  address   = "Dordrecht",
  pages     = "235--243",
  year      =  2009,
  language  = "en"
}

@INCOLLECTION{Wiggins2019-yj,
  title     = "A framework for description, analysis and comparison of creative
               systems",
  author    = "Wiggins, Geraint A",
  booktitle = "Computational Synthesis and Creative Systems",
  publisher = "Springer International Publishing",
  address   = "Cham",
  pages     = "21--47",
  abstract  = "Abstract I summarise and attempt to clarify some concepts
               presented in and arising from Margaret Boden’s descriptive
               hierarchy of creativity (Boden, M. A., The Creative Mind: Myths
               and Mechanisms, 2nd Ed., Routledge, London, 2004), by formalising
               the ideas she proposes. The aim is to move towards a model which
               allows detailed comparison, and hence better understanding, of
               systems, whether artificial, natural or hybrid, which exhibit
               behaviour which would be called ‘creative’ in humans. The
               framework paves the way for the description of naturalistic,
               multi-agent creative artificial intelligence systems, which
               create in a societal context. I demonstrate some simple reasoning
               about creative behaviour based on the new framework, to show how
               it might be useful for the analysis and study of creative
               systems. In particular, I identify some crucial properties of
               creative systems, in terms of the framework components, some of
               which may usefully be proven a priori of a given system. Finally,
               I exemplify the use of the framework by broadly describing the
               development of art music from the 10th to the 20th century in
               these more formal terms.",
  year      =  2019,
  language  = "en"
}

@ARTICLE{Kumar2024-yf,
  title         = "Human creativity in the age of {LLMs}: Randomized experiments
                   on divergent and convergent thinking",
  author        = "Kumar, Harsh and Vincentius, Jonathan and Jordan, Ewan and
                   Anderson, Ashton",
  journal       = "arXiv [cs.HC]",
  abstract      = "Large language models are transforming the creative process
                   by offering unprecedented capabilities to algorithmically
                   generate ideas. While these tools can enhance human
                   creativity when people co-create with them, it's unclear how
                   this will impact unassisted human creativity. We conducted
                   two large pre-registered parallel experiments involving 1,100
                   participants attempting tasks targeting the two core
                   components of creativity, divergent and convergent thinking.
                   We compare the effects of two forms of large language model
                   (LLM) assistance -- a standard LLM providing direct answers
                   and a coach-like LLM offering guidance -- with a control
                   group receiving no AI assistance, and focus particularly on
                   how all groups perform in a final, unassisted stage. Our
                   findings reveal that while LLM assistance can provide
                   short-term boosts in creativity during assisted tasks, it may
                   inadvertently hinder independent creative performance when
                   users work without assistance, raising concerns about the
                   long-term impact on human creativity and cognition.",
  month         =  sep,
  year          =  2024,
  archivePrefix = "arXiv",
  primaryClass  = "cs.HC"
}

@ARTICLE{Bai2022-ec,
  title         = "Training a helpful and harmless assistant with reinforcement
                   learning from human feedback",
  author        = "Bai, Yuntao and Jones, Andy and Ndousse, Kamal and Askell,
                   Amanda and Chen, Anna and DasSarma, Nova and Drain, Dawn and
                   Fort, Stanislav and Ganguli, Deep and Henighan, Tom and
                   Joseph, Nicholas and Kadavath, Saurav and Kernion, Jackson
                   and Conerly, Tom and El-Showk, Sheer and Elhage, Nelson and
                   Hatfield-Dodds, Zac and Hernandez, Danny and Hume, Tristan
                   and Johnston, Scott and Kravec, Shauna and Lovitt, Liane and
                   Nanda, Neel and Olsson, Catherine and Amodei, Dario and
                   Brown, Tom and Clark, Jack and McCandlish, Sam and Olah,
                   Chris and Mann, Ben and Kaplan, Jared",
  journal       = "arXiv [cs.CL]",
  abstract      = "We apply preference modeling and reinforcement learning from
                   human feedback (RLHF) to finetune language models to act as
                   helpful and harmless assistants. We find this alignment
                   training improves performance on almost all NLP evaluations,
                   and is fully compatible with training for specialized skills
                   such as python coding and summarization. We explore an
                   iterated online mode of training, where preference models and
                   RL policies are updated on a weekly cadence with fresh human
                   feedback data, efficiently improving our datasets and models.
                   Finally, we investigate the robustness of RLHF training, and
                   identify a roughly linear relation between the RL reward and
                   the square root of the KL divergence between the policy and
                   its initialization. Alongside our main results, we perform
                   peripheral analyses on calibration, competing objectives, and
                   the use of OOD detection, compare our models with human
                   writers, and provide samples from our models using prompts
                   appearing in recent related work.",
  month         =  apr,
  year          =  2022,
  archivePrefix = "arXiv",
  primaryClass  = "cs.CL"
}

@INPROCEEDINGS{Kantosalo2016-qb,
  title     = "Modes for creative human-computer collaboration: Alternating and
               task-divided co-creativity",
  author    = "Kantosalo, Anna and Toivonen, Hannu",
  booktitle = "Proceedings of the 2016 International Conference on Computational
               Creativity",
  pages     = "77--84",
  abstract  = "The analysis of human-computer co-creative systems in current
               literature is focused on a human perspective, highlighting the
               beneﬁts of co-creative systems for human users. This study paper
               examines different styles of human-computer co-creation from a
               more computational perspective, presenting new concepts for
               analysis of computational agents in human-computer co-creation.
               Our perspective is based on Wiggins’ formalization of creativity
               as a search. We formalize for co-creative scenarios involving an
               alternating, iterative approach to co-creation, which we call
               alternating co-creativity and brieﬂy discuss its non-alternating
               counterpart, task-divided co-creativity. With focus on
               alternating co-creativity, we analyze the co-creative process and
               discuss new modes and roles for the creative agents within it.
               Finally, we illustrate our theoretical ﬁndings in the context of
               current co-creative systems and discuss their relation to the
               roles and expectations presented in current literature.",
  year      =  2016
}

@BOOK{M2023-ia,
  title     = "Deep learning: Foundations and concepts",
  author    = "M., Christopher and {Hugh}",
  publisher = "Springer International Publishing",
  address   = "Cham, Switzerland",
  edition   =  2024,
  month     =  nov,
  year      =  2023,
  language  = "en"
}

@ARTICLE{Simonton2012-bv,
  title     = "Taking the {U}.s. patent office criteria seriously: A
               quantitative three-criterion creativity definition and its
               implications",
  author    = "Simonton, Dean Keith",
  journal   = "Creat. Res. J.",
  publisher = "Informa UK Limited",
  volume    =  24,
  number    = "2-3",
  pages     = "97--106",
  abstract  = "Although creativity has recently attracted considerable
               theoretical and empirical research, researchers have yet to reach
               a consensus on how best to define the phenomenon. To help
               establish a consensus, a definition is proposed that is based on
               the three criteria used by the United States Patent Office to
               evaluate applications for patent protection. The modified version
               uses the criteria of novelty, utility, and surprise. Moreover,
               creativity assessments based on these three criteria are
               quantitative and multiplicative rather than qualitative or
               additive. This three-criterion definition then leads to four
               implications regarding (a) the limitations to domain-specific
               expertise, (b) the varieties of comparable creativities, (c) the
               contrast between subjective and objective evaluations, and (d)
               the place of blind variation and selective retention in the
               creative process. These implications prove that adding the third
               criterion has critical consequences for understanding the
               phenomenon. Creativity is not only treated with superior
               sophistication, but also paradoxes that appear using the most
               common two-criterion definition readily disappear when the third
               criterion is included in the analysis. Hence, the conceptual
               differences between two- and three-criterion definitions are not
               trivial.",
  month     =  apr,
  year      =  2012,
  language  = "en"
}

@ARTICLE{Runco2012-np,
  title     = "Divergent thinking as an indicator of creative potential",
  author    = "Runco, Mark A and Acar, Selcuk",
  journal   = "Creat. Res. J.",
  publisher = "Informa UK Limited",
  volume    =  24,
  number    =  1,
  pages     = "66--75",
  abstract  = "Divergent thinking (DT) tests are very often used in creativity
               studies. Certainly DT does not guarantee actual creative
               achievement, but tests of DT are reliable and reasonably valid
               predictors of certain performance criteria. The validity of DT is
               described as reasonable because validity is not an all-or-nothing
               attribute, but is, instead, a matter of degree. Also, validity
               only makes sense relative to particular criteria. The criteria
               strongly associated with DT are detailed in this article. It also
               summarizes the uses and limitations of DT, conceptually and
               psychometrically. After the psychometric evidence is reviewed,
               alternative tests and scoring procedures are described, including
               several that have only recently been published. Throughout this
               article related processes, such as problem finding and evaluative
               thinking, are linked to DT.",
  month     =  jan,
  year      =  2012,
  language  = "en"
}

@ARTICLE{Simon1967-nr,
  title     = "Understanding Creativity",
  author    = "Simon, H A",
  journal   = "Creativity: Its educational implications",
  publisher = "iiif.library.cmu.edu",
  year      =  1967
}

@INCOLLECTION{Colton2002-nx,
  title     = "The {HR} program for theorem generation",
  author    = "Colton, Simon",
  booktitle = "Automated Deduction—CADE-18",
  publisher = "Springer Berlin Heidelberg",
  address   = "Berlin, Heidelberg",
  pages     = "285--289",
  series    = "Lecture notes in computer science",
  year      =  2002
}

@ARTICLE{Bengio2012-lt,
  title         = "Representation learning: A review and new perspectives",
  author        = "Bengio, Yoshua and Courville, Aaron and Vincent, Pascal",
  journal       = "arXiv [cs.LG]",
  abstract      = "The success of machine learning algorithms generally depends
                   on data representation, and we hypothesize that this is
                   because different representations can entangle and hide more
                   or less the different explanatory factors of variation behind
                   the data. Although specific domain knowledge can be used to
                   help design representations, learning with generic priors can
                   also be used, and the quest for AI is motivating the design
                   of more powerful representation-learning algorithms
                   implementing such priors. This paper reviews recent work in
                   the area of unsupervised feature learning and deep learning,
                   covering advances in probabilistic models, auto-encoders,
                   manifold learning, and deep networks. This motivates
                   longer-term unanswered questions about the appropriate
                   objectives for learning good representations, for computing
                   representations (i.e., inference), and the geometrical
                   connections between representation learning, density
                   estimation and manifold learning.",
  month         =  jun,
  year          =  2012,
  archivePrefix = "arXiv",
  primaryClass  = "cs.LG"
}

@ARTICLE{Radford2015-hw,
  title         = "Unsupervised representation learning with deep convolutional
                   generative adversarial networks",
  author        = "Radford, Alec and Metz, Luke and Chintala, Soumith",
  journal       = "arXiv [cs.LG]",
  abstract      = "In recent years, supervised learning with convolutional
                   networks (CNNs) has seen huge adoption in computer vision
                   applications. Comparatively, unsupervised learning with CNNs
                   has received less attention. In this work we hope to help
                   bridge the gap between the success of CNNs for supervised
                   learning and unsupervised learning. We introduce a class of
                   CNNs called deep convolutional generative adversarial
                   networks (DCGANs), that have certain architectural
                   constraints, and demonstrate that they are a strong candidate
                   for unsupervised learning. Training on various image
                   datasets, we show convincing evidence that our deep
                   convolutional adversarial pair learns a hierarchy of
                   representations from object parts to scenes in both the
                   generator and discriminator. Additionally, we use the learned
                   features for novel tasks - demonstrating their applicability
                   as general image representations.",
  month         =  nov,
  year          =  2015,
  archivePrefix = "arXiv",
  primaryClass  = "cs.LG"
}

@ARTICLE{Liang2025-wc,
  title         = "The widespread adoption of large language model-assisted
                   writing across society",
  author        = "Liang, Weixin and Zhang, Yaohui and Codreanu, Mihai and Wang,
                   Jiayu and Cao, Hancheng and Zou, James",
  journal       = "arXiv [cs.CL]",
  abstract      = "The recent advances in large language models (LLMs) attracted
                   significant public and policymaker interest in its adoption
                   patterns. In this paper, we systematically analyze
                   LLM-assisted writing across four domains-consumer complaints,
                   corporate communications, job postings, and international
                   organization press releases-from January 2022 to September
                   2024. Our dataset includes 687,241 consumer complaints,
                   537,413 corporate press releases, 304.3 million job postings,
                   and 15,919 United Nations (UN) press releases. Using a robust
                   population-level statistical framework, we find that LLM
                   usage surged following the release of ChatGPT in November
                   2022. By late 2024, roughly 18\% of financial consumer
                   complaint text appears to be LLM-assisted, with adoption
                   patterns spread broadly across regions and slightly higher in
                   urban areas. For corporate press releases, up to 24\% of the
                   text is attributable to LLMs. In job postings, LLM-assisted
                   writing accounts for just below 10\% in small firms, and is
                   even more common among younger firms. UN press releases also
                   reflect this trend, with nearly 14\% of content being
                   generated or modified by LLMs. Although adoption climbed
                   rapidly post-ChatGPT, growth appears to have stabilized by
                   2024, reflecting either saturation in LLM adoption or
                   increasing subtlety of more advanced models. Our study shows
                   the emergence of a new reality in which firms, consumers and
                   even international organizations substantially rely on
                   generative AI for communications.",
  month         =  feb,
  year          =  2025,
  archivePrefix = "arXiv",
  primaryClass  = "cs.CL"
}

@ARTICLE{Colton1999-et,
  title   = "Artificial intelligence and scientific creativity",
  author  = "Colton, S and Steel, G",
  journal = "Artificial Intelligence and the Study of Behaviour Quarterly",
  volume  =  102,
  year    =  1999
}

@BOOK{Sharples2022-hq,
  title     = "Story machines: How computers have become creative writers: How
               computers have become creative writers",
  author    = "Sharples, Mike and Pérez y Pérez, Rafael",
  publisher = "Routledge",
  address   = "London, England",
  month     =  jul,
  year      =  2022,
  language  = "en"
}

@INPROCEEDINGS{Sarkar2023-ee,
  title     = "Exploring perspectives on the impact of artificial intelligence
               on the creativity of knowledge work: Beyond mechanised plagiarism
               and stochastic parrots",
  author    = "Sarkar, Advait",
  booktitle = "Proceedings of the 2nd Annual Meeting of the Symposium on
               Human-Computer Interaction for Work",
  publisher = "ACM",
  address   = "New York, NY, USA",
  month     =  jun,
  year      =  2023,
  language  = "en"
}

@ARTICLE{Meehan1977-rs,
  title     = "{TALE}-{SPIN}, an interactive program that writes stories",
  author    = "Meehan, J",
  journal   = "Int Jt Conf Artif Intell",
  publisher = "ijcai.org",
  pages     = "91--98",
  month     =  aug,
  year      =  1977
}

@ARTICLE{Peebles2022-gk,
  title         = "Scalable diffusion models with transformers",
  author        = "Peebles, William and Xie, Saining",
  journal       = "arXiv [cs.CV]",
  abstract      = "We explore a new class of diffusion models based on the
                   transformer architecture. We train latent diffusion models of
                   images, replacing the commonly-used U-Net backbone with a
                   transformer that operates on latent patches. We analyze the
                   scalability of our Diffusion Transformers (DiTs) through the
                   lens of forward pass complexity as measured by Gflops. We
                   find that DiTs with higher Gflops -- through increased
                   transformer depth/width or increased number of input tokens
                   -- consistently have lower FID. In addition to possessing
                   good scalability properties, our largest DiT-XL/2 models
                   outperform all prior diffusion models on the
                   class-conditional ImageNet 512x512 and 256x256 benchmarks,
                   achieving a state-of-the-art FID of 2.27 on the latter.",
  month         =  dec,
  year          =  2022,
  archivePrefix = "arXiv",
  primaryClass  = "cs.CV"
}

@ARTICLE{Wu2025-or,
  title         = "One does not simply meme alone: Evaluating co-creativity
                   between {LLMs} and humans in the generation of humor",
  author        = "Wu, Zhikun and Weber, Thomas and Müller, Florian",
  journal       = "arXiv [cs.HC]",
  abstract      = "Collaboration has been shown to enhance creativity, leading
                   to more innovative and effective outcomes. While previous
                   research has explored the abilities of Large Language Models
                   (LLMs) to serve as co-creative partners in tasks like writing
                   poetry or creating narratives, the collaborative potential of
                   LLMs in humor-rich and culturally nuanced domains remains an
                   open question. To address this gap, we conducted a user study
                   to explore the potential of LLMs in co-creating memes - a
                   humor-driven and culturally specific form of creative
                   expression. We conducted a user study with three groups of 50
                   participants each: a human-only group creating memes without
                   AI assistance, a human-AI collaboration group interacting
                   with a state-of-the-art LLM model, and an AI-only group where
                   the LLM autonomously generated memes. We assessed the quality
                   of the generated memes through crowdsourcing, with each meme
                   rated on creativity, humor, and shareability. Our results
                   showed that LLM assistance increased the number of ideas
                   generated and reduced the effort participants felt. However,
                   it did not improve the quality of the memes when humans
                   collaborated with LLM. Interestingly, memes created entirely
                   by AI performed better than both human-only and human-AI
                   collaborative memes in all areas on average. However, when
                   looking at the top-performing memes, human-created ones were
                   better in humor, while human-AI collaborations stood out in
                   creativity and shareability. These findings highlight the
                   complexities of human-AI collaboration in creative tasks.
                   While AI can boost productivity and create content that
                   appeals to a broad audience, human creativity remains crucial
                   for content that connects on a deeper level.",
  month         =  jan,
  year          =  2025,
  archivePrefix = "arXiv",
  primaryClass  = "cs.HC"
}

@INCOLLECTION{Riedl2006-bl,
  title     = "Failing believably: Toward drama management with autonomous
               actors in interactive narratives",
  author    = "Riedl, Mark O and Stern, Andrew",
  booktitle = "Technologies for Interactive Digital Storytelling and
               Entertainment",
  publisher = "Springer Berlin Heidelberg",
  address   = "Berlin, Heidelberg",
  pages     = "195--206",
  series    = "Lecture notes in computer science",
  year      =  2006
}

@ARTICLE{Riedl2006-jc,
  title     = "From linear story generation to branching story graphs",
  author    = "Riedl, Mark O and Young, R Michael",
  journal   = "IEEE Comput. Graph. Appl.",
  publisher = "Institute of Electrical and Electronics Engineers (IEEE)",
  volume    =  26,
  number    =  3,
  pages     = "23--31",
  month     =  may,
  year      =  2006,
  language  = "en"
}

@INCOLLECTION{Riedl2006-xy,
  title     = "Believable agents and intelligent story adaptation for
               interactive storytelling",
  author    = "Riedl, Mark O and Stern, Andrew",
  booktitle = "Technologies for Interactive Digital Storytelling and
               Entertainment",
  publisher = "Springer Berlin Heidelberg",
  address   = "Berlin, Heidelberg",
  pages     = "1--12",
  series    = "Lecture notes in computer science",
  year      =  2006
}

@ARTICLE{Riedl2006-sg,
  title     = "Believable Agents and Intelligent Scenario Direction for Social
               and Cultural Leadership Training",
  author    = "Riedl, Mark O and Stern, A",
  publisher = "sites.cc.gatech.edu",
  year      =  2006
}

@INCOLLECTION{Riedl2008-nf,
  title     = "Story planning with vignettes: Toward overcoming the content
               production bottleneck",
  author    = "Riedl, Mark O and Sugandh, Neha",
  booktitle = "Interactive Storytelling",
  publisher = "Springer Berlin Heidelberg",
  address   = "Berlin, Heidelberg",
  pages     = "168--179",
  series    = "Lecture notes in computer science",
  year      =  2008
}

@BOOK{Russell2016-oe,
  title     = "Artificial intelligence: A modern approach, global edition",
  author    = "Russell, Stuart and Norvig, Peter",
  publisher = "Pearson Education",
  address   = "London, England",
  edition   =  3,
  month     =  apr,
  year      =  2016
}

@ARTICLE{Riedl2012-na,
  title     = "Interactive Narrative: An Intelligent Systems Approach",
  author    = "Riedl, Mark O and Bulitko, V",
  journal   = "AI Mag.",
  publisher = "ojs.aaai.org",
  volume    =  34,
  pages     = "67--77",
  abstract  = "Interactive narrative is a form of digital interactive experience
               in which users create or influence a dramatic storyline through
               their actions. The goal of an interactive narrative system is to
               immerse the user in a virtual world such that he or she believes
               that they are an integral part of an unfolding story and that
               their actions can significantly alter the direction and/or
               outcome of the story.In this article we review the ways in which
               artificial intelligence can be brought to bear on the creation of
               interactive narrative systems. We lay out the landscape of about
               20 years of interactive narrative research and explore the
               successes as well as open research questions pertaining to the
               novel use of computational narrative intelligence in the pursuit
               of entertainment, education, and training.",
  month     =  dec,
  year      =  2012
}

@ARTICLE{Montfort2023-pb,
  title    = "Computational Models for Understanding Narrative",
  author   = "Montfort, Nicholas and Perez, Perez Y",
  abstract = "We describe how the computational modeling of narrative serves as
              a method of inquiry and helps to further humanistic understanding
              in this domain. Our focus is on our own systems, MEXICA and
              Curveship. Each of these two computational narrative systems is a
              working representation of aspects of the human processes of
              creative writing or narrating, and can be used to explore these
              processes and learn more about them. We describe some specific
              insights gained regarding the connection between characters’
              emotional relationships and conflicts, collaboration between
              writers, elements of narrative theory, expressions of surprise,
              and how referring expressions are important to literary style. We
              conclude by considering how models of story and narrative are not
              the same as large language models (LLMs) and we should not expect
              either type of system to do the work of the other.",
  year     =  2023
}

@INPROCEEDINGS{Guzdial2019-cv,
  title     = "Friend, collaborator, student, manager: How design of an
               {AI}-driven game level editor affects creators",
  author    = "Guzdial, Matthew and Liao, Nicholas and Chen, Jonathan and Chen,
               Shao-Yu and Shah, Shukan and Shah, Vishwa and Reno, Joshua and
               Smith, Gillian and Riedl, Mark O",
  booktitle = "Proceedings of the 2019 CHI Conference on Human Factors in
               Computing Systems",
  publisher = "ACM",
  address   = "New York, NY, USA",
  pages     = "1--13",
  month     =  may,
  year      =  2019
}

@ARTICLE{LeCun2015-cv,
  title     = "Deep learning",
  author    = "LeCun, Yann and Bengio, Yoshua and Hinton, Geoffrey",
  journal   = "Nature",
  publisher = "Springer Science and Business Media LLC",
  volume    =  521,
  number    =  7553,
  pages     = "436--444",
  abstract  = "Deep learning allows computational models that are composed of
               multiple processing layers to learn representations of data with
               multiple levels of abstraction. These methods have dramatically
               improved the state-of-the-art in speech recognition, visual
               object recognition, object detection and many other domains such
               as drug discovery and genomics. Deep learning discovers intricate
               structure in large data sets by using the backpropagation
               algorithm to indicate how a machine should change its internal
               parameters that are used to compute the representation in each
               layer from the representation in the previous layer. Deep
               convolutional nets have brought about breakthroughs in processing
               images, video, speech and audio, whereas recurrent nets have
               shone light on sequential data such as text and speech.",
  month     =  may,
  year      =  2015,
  language  = "en"
}

@ARTICLE{LeCun2015-zb,
  title     = "Deep learning",
  author    = "LeCun, Yann and Bengio, Yoshua and Hinton, Geoffrey",
  journal   = "Nature",
  publisher = "Springer Science and Business Media LLC",
  volume    =  521,
  number    =  7553,
  pages     = "436--444",
  abstract  = "Deep learning allows computational models that are composed of
               multiple processing layers to learn representations of data with
               multiple levels of abstraction. These methods have dramatically
               improved the state-of-the-art in speech recognition, visual
               object recognition, object detection and many other domains such
               as drug discovery and genomics. Deep learning discovers intricate
               structure in large data sets by using the backpropagation
               algorithm to indicate how a machine should change its internal
               parameters that are used to compute the representation in each
               layer from the representation in the previous layer. Deep
               convolutional nets have brought about breakthroughs in processing
               images, video, speech and audio, whereas recurrent nets have
               shone light on sequential data such as text and speech.",
  month     =  may,
  year      =  2015,
  language  = "en"
}

@INPROCEEDINGS{Devlin2019-zt,
  title     = "{BERT}: Pre-training of Deep Bidirectional Transformers for
               Language Understanding",
  author    = "Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova,
               Kristina",
  booktitle = "Proceedings of the 2019 Conference of the North",
  publisher = "Association for Computational Linguistics",
  address   = "Stroudsburg, PA, USA",
  pages     = "4171--4186",
  abstract  = "Jacob Devlin, Ming-Wei Chang, Kenton Lee, Kristina Toutanova.
               Proceedings of the 2019 Conference of the North American Chapter
               of the Association for Computational Linguistics: Human Language
               Technologies, Volume 1 (Long and Short Papers). 2019.",
  year      =  2019
}

@ARTICLE{Jakesch2023-ks,
  title         = "Co-writing with opinionated language models affects users'
                   views",
  author        = "Jakesch, Maurice and Bhat, Advait and Buschek, Daniel and
                   Zalmanson, Lior and Naaman, Mor",
  journal       = "arXiv [cs.HC]",
  abstract      = "If large language models like GPT-3 preferably produce a
                   particular point of view, they may influence people's
                   opinions on an unknown scale. This study investigates whether
                   a language-model-powered writing assistant that generates
                   some opinions more often than others impacts what users write
                   - and what they think. In an online experiment, we asked
                   participants (N=1,506) to write a post discussing whether
                   social media is good for society. Treatment group
                   participants used a language-model-powered writing assistant
                   configured to argue that social media is good or bad for
                   society. Participants then completed a social media attitude
                   survey, and independent judges (N=500) evaluated the opinions
                   expressed in their writing. Using the opinionated language
                   model affected the opinions expressed in participants'
                   writing and shifted their opinions in the subsequent attitude
                   survey. We discuss the wider implications of our results and
                   argue that the opinions built into AI language technologies
                   need to be monitored and engineered more carefully.",
  month         =  feb,
  year          =  2023,
  archivePrefix = "arXiv",
  primaryClass  = "cs.HC"
}

@ARTICLE{DellAcqua2023-og,
  title     = "Navigating the jagged technological frontier: Field experimental
               evidence of the effects of {AI} on knowledge worker productivity
               and quality",
  author    = "Dell'Acqua, Fabrizio and McFowland, Edward and Mollick, Ethan R
               and Lifshitz-Assaf, Hila and Kellogg, Katherine and Rajendran,
               Saran and Krayer, Lisa and Candelon, François and Lakhani, Karim
               R",
  journal   = "SSRN Electron. J.",
  publisher = "Elsevier BV",
  year      =  2023,
  language  = "en"
}

@INPROCEEDINGS{Davis2024-ml,
  title     = "Fashioning creative expertise with generative {AI}: Graphical
               interfaces for design space exploration better support ideation
               than text prompts",
  author    = "Davis, Richard Lee and Wambsganss, Thiemo and Jiang, Wei and Kim,
               Kevin Gonyop and Käser, Tanja and Dillenbourg, Pierre",
  booktitle = "Proceedings of the CHI Conference on Human Factors in Computing
               Systems",
  publisher = "ACM",
  address   = "New York, NY, USA",
  volume    =  33,
  pages     = "1--26",
  month     =  may,
  year      =  2024,
  language  = "en"
}

@INPROCEEDINGS{Guzdial2019-pf,
  title     = "Friend, collaborator, student, manager: How design of an
               {AI}-driven game level editor affects creators",
  author    = "Guzdial, Matthew and Liao, Nicholas and Chen, Jonathan and Chen,
               Shao-Yu and Shah, Shukan and Shah, Vishwa and Reno, Joshua and
               Smith, Gillian and Riedl, Mark O",
  booktitle = "Proceedings of the 2019 CHI Conference on Human Factors in
               Computing Systems",
  publisher = "ACM",
  address   = "New York, NY, USA",
  month     =  may,
  year      =  2019,
  language  = "en"
}

@ARTICLE{Ding2024-ja,
  title         = "Towards intent-based user interfaces: Charting the design
                   space of intent-{AI} interactions across task types",
  author        = "Ding, Zijian",
  journal       = "arXiv [cs.HC]",
  abstract      = "Technological advances continue to redefine the dynamics of
                   human-machine interactions, particularly in task execution.
                   This proposal responds to the advancements in Generative AI
                   by outlining a research plan that probes intent-AI
                   interaction across a diverse set of tasks: fixed-scope
                   content curation task, atomic creative tasks, and complex and
                   interdependent tasks. This exploration aims to inform and
                   contribute to the development of Intent-based User Interface
                   (IUI). The study is structured in three phases: examining
                   fixed-scope tasks through news headline generation, exploring
                   atomic creative tasks via analogy generation, and delving
                   into complex tasks through exploratory visual data analysis.
                   Future work will focus on improving IUIs to better provide
                   suggestions to encourage experienced users to express broad
                   and exploratory intents, and detailed and structured guidance
                   for novice users to iterate on analysis intents for high
                   quality outputs.",
  month         =  apr,
  year          =  2024,
  archivePrefix = "arXiv",
  primaryClass  = "cs.HC"
}

@ARTICLE{Berger-Tal2014-cu,
  title     = "The exploration-exploitation dilemma: a multidisciplinary
               framework",
  author    = "Berger-Tal, Oded and Nathan, Jonathan and Meron, Ehud and Saltz,
               David",
  journal   = "PLoS One",
  publisher = "Public Library of Science (PLoS)",
  volume    =  9,
  number    =  4,
  pages     = "e95693",
  abstract  = "The trade-off between the need to obtain new knowledge and the
               need to use that knowledge to improve performance is one of the
               most basic trade-offs in nature, and optimal performance usually
               requires some balance between exploratory and exploitative
               behaviors. Researchers in many disciplines have been searching
               for the optimal solution to this dilemma. Here we present a novel
               model in which the exploration strategy itself is dynamic and
               varies with time in order to optimize a definite goal, such as
               the acquisition of energy, money, or prestige. Our model produced
               four very distinct phases: Knowledge establishment, Knowledge
               accumulation, Knowledge maintenance, and Knowledge exploitation,
               giving rise to a multidisciplinary framework that applies equally
               to humans, animals, and organizations. The framework can be used
               to explain a multitude of phenomena in various disciplines, such
               as the movement of animals in novel landscapes, the most
               efficient resource allocation for a start-up company, or the
               effects of old age on knowledge acquisition in humans.",
  month     =  apr,
  year      =  2014,
  language  = "en"
}

@ARTICLE{Turpin2023-ow,
  title         = "Language Models don't always say what they think: Unfaithful
                   explanations in chain-of-thought prompting",
  author        = "Turpin, Miles and Michael, Julian and Perez, Ethan and
                   Bowman, Samuel R",
  journal       = "arXiv [cs.CL]",
  abstract      = "Large Language Models (LLMs) can achieve strong performance
                   on many tasks by producing step-by-step reasoning before
                   giving a final output, often referred to as chain-of-thought
                   reasoning (CoT). It is tempting to interpret these CoT
                   explanations as the LLM's process for solving a task. This
                   level of transparency into LLMs' predictions would yield
                   significant safety benefits. However, we find that CoT
                   explanations can systematically misrepresent the true reason
                   for a model's prediction. We demonstrate that CoT
                   explanations can be heavily influenced by adding biasing
                   features to model inputs--e.g., by reordering the
                   multiple-choice options in a few-shot prompt to make the
                   answer always ``(A)''--which models systematically fail to
                   mention in their explanations. When we bias models toward
                   incorrect answers, they frequently generate CoT explanations
                   rationalizing those answers. This causes accuracy to drop by
                   as much as 36\% on a suite of 13 tasks from BIG-Bench Hard,
                   when testing with GPT-3.5 from OpenAI and Claude 1.0 from
                   Anthropic. On a social-bias task, model explanations justify
                   giving answers in line with stereotypes without mentioning
                   the influence of these social biases. Our findings indicate
                   that CoT explanations can be plausible yet misleading, which
                   risks increasing our trust in LLMs without guaranteeing their
                   safety. Building more transparent and explainable systems
                   will require either improving CoT faithfulness through
                   targeted efforts or abandoning CoT in favor of alternative
                   methods.",
  month         =  may,
  year          =  2023,
  archivePrefix = "arXiv",
  primaryClass  = "cs.CL"
}

@ARTICLE{Raisch2021-nw,
  title     = "Artificial intelligence and management: The
               automation–augmentation paradox",
  author    = "Raisch, Sebastian and Krakowski, Sebastian",
  journal   = "Acad. Manage. Rev.",
  publisher = "Academy of Management",
  volume    =  46,
  number    =  1,
  pages     = "192--210",
  month     =  jan,
  year      =  2021,
  language  = "en"
}


@ARTICLE{Hosanagar2024-rf,
  title         = "Designing human and generative {AI} collaboration",
  author        = "Hosanagar, Kartik and Ahn, Daehwan",
  journal       = "arXiv [cs.HC]",
  abstract      = "We examined the effectiveness of various human-AI
                   collaboration designs on creative work. Through a human
                   subjects experiment set in the context of creative writing,
                   we found that while AI assistance improved productivity
                   across all models, collaboration design significantly
                   influenced output quality, user satisfaction, and content
                   characteristics. Models incorporating human creative input
                   delivered higher content interestingness and overall quality
                   as well as greater task performer satisfaction compared to
                   conditions where humans were limited to confirming AI's
                   output. Increased AI involvement encouraged creators to
                   explore beyond personal experience but also led to lower
                   aggregate diversity in stories and genres among participants.
                   However, this effect was mitigated through human
                   participation in early creative tasks. These findings
                   underscore the importance of preserving the human creative
                   role to ensure quality, satisfaction, and creative diversity
                   in human-AI collaboration.",
  month         =  dec,
  year          =  2024,
  archivePrefix = "arXiv",
  primaryClass  = "cs.HC"
}

@ARTICLE{Sharma2023-or,
  title         = "Towards understanding sycophancy in language models",
  author        = "Sharma, Mrinank and Tong, Meg and Korbak, Tomasz and
                   Duvenaud, David and Askell, Amanda and Bowman, Samuel R and
                   Cheng, Newton and Durmus, Esin and Hatfield-Dodds, Zac and
                   Johnston, Scott R and Kravec, Shauna and Maxwell, Timothy and
                   McCandlish, Sam and Ndousse, Kamal and Rausch, Oliver and
                   Schiefer, Nicholas and Yan, Da and Zhang, Miranda and Perez,
                   Ethan",
  journal       = "arXiv [cs.CL]",
  abstract      = "Human feedback is commonly utilized to finetune AI
                   assistants. But human feedback may also encourage model
                   responses that match user beliefs over truthful ones, a
                   behaviour known as sycophancy. We investigate the prevalence
                   of sycophancy in models whose finetuning procedure made use
                   of human feedback, and the potential role of human preference
                   judgments in such behavior. We first demonstrate that five
                   state-of-the-art AI assistants consistently exhibit
                   sycophancy across four varied free-form text-generation
                   tasks. To understand if human preferences drive this broadly
                   observed behavior, we analyze existing human preference data.
                   We find that when a response matches a user's views, it is
                   more likely to be preferred. Moreover, both humans and
                   preference models (PMs) prefer convincingly-written
                   sycophantic responses over correct ones a non-negligible
                   fraction of the time. Optimizing model outputs against PMs
                   also sometimes sacrifices truthfulness in favor of
                   sycophancy. Overall, our results indicate that sycophancy is
                   a general behavior of state-of-the-art AI assistants, likely
                   driven in part by human preference judgments favoring
                   sycophantic responses.",
  month         =  oct,
  year          =  2023,
  archivePrefix = "arXiv",
  primaryClass  = "cs.CL"
}
