\chapter[Conclusion]{Conclusion}\label{c:conclusion}

To begin this conclusion, I would like to briefly summarise the research so far. In Chapter 1, I argued that generative AI opens the possibility for human-AI co-creativity. While there are design principles for guiding interaction between human and computers in multiple scenarios, no such principles exist yet for the case of human-AI co-creativity.

As a general starting point, I argued that dialogic interaction offers a promising approach. While prevailing modes of interaction centre around command-execute paradigms, co-creativity with increasingly capable systems, with varying levels of intelligence and generative power, call for a computer-in-dialogue approach: one where humans and AI engage in iterative cycles of mutual influence and understanding. Particularly, I sought to investigate how interaction design can enable roles assumed by humans and AI that are co-creative, and understand how different interaction design decisions influence the roles assumed.

With this, I defined, in Chapter 1, the core aim of this thesis as to investigate and enable human-AI co-creativity, maintaining human agency while effectively leveraging the creative potential of this technology.

The following three research questions were proposed to guide this enquiry:

\begin{quote}
\textbf{Sub-Questions:}
\begin{itemize}
    \item \emph{R1: How does interaction design influence the role that humans and AI play in creative production?}
    \item \emph{R2: What is the potential of modelling dialogue in interaction design to enable effective human–AI co-creativity?}
    \item \emph{R3: Which interaction design principles can guide the development of effective co-creative systems?}
\end{itemize}
\end{quote}

I examined this question through a mix of approaches. These included a thorough review of the literature and practice, which developed at a rapid pace as a response to rapidly changing technology throughout this thesis. I then engaged in a practice-based research approach through case studies, and through prototype-led user studies. With this, I investigated human-AI co-creativity from a practical perspective -- my own creative practice in collaboration with others -- and from an interaction design research perspective, testing interaction design approaches with users from a qualitative and quantitative perspective.

In Chapter 3, I laid the theoretical foundations that guided my inquiry from the perspective of dialogic interaction: I defined dialogic co-creativity as a human-computer interaction concept, comprising of six elements: iterative interaction, bidirectional communication, a shared collaborative space, context-awareness, mutual influence and mutual understanding. Importantly, I established as a core component of dialogue is that it can happen both \textit{about} the creation (discussing goals, providing feedback) and \textit{through} the creation (writing words, playing notes, drawing lines). The subsequent research was navigated with these components as a navigational lens, investigating how each one can be implemented, and how it contributes to the effectiveness of co-creativity.

In the same Chapter 3, I presented an early exploration of the role of dialogue and dialogic capabilities of language model systems, exploring the role and capacity of these systems to engage in bidirectional communication. Notably, this experiment was conducted before the launch of ChatGPT, which has made conversational interaction the default.

In Chapter 4, I noted that while bidirectional interaction in chat-interfaces enables a more dialogic interaction than linear prompting systems, they are still limited in affording interaction both through and about the interaction: instead, the interface biases the user to merely provide instructions and feedback rather than engage at the writing level. Based on this, I developed a prototype implementing a \textbf{shared collaborative space} in addition to a chat window. With this, humans and AI could both converse about the writing, and edit it collaboratively. I found that this interface led to higher levels of active involvement and ownership at the writing level, though questions remain about how to implement these collaborative interfaces to effectively manage contributions.

In Chapter 5, I turned my attention to professional creative practice, investigating the challenges of leveraging generative AI image systems in real-world scenarios. I collaborated with the Australian Financial Review to produce visual materials for one of their issues, including the cover of the magazine and the cover of the weekly paper. Throughout this exploration, I found the main challenges for the usability of these tools are their inability to afford iterative workflows, maintaining consistency of subjects, objects, and scenes, and the difficulty in steering them.

In Chapter 6, I turned to my own creative practice, and described two case studies that involve the collaborative production of two new media installations leveraging large language models to drive the generation of real-time audiovisual soundscapes from environmental data. With this, I explored the possibilities of generative AI to assume novel roles in creative practice, affording new creative operations. In particular, serving as a semantic translation bridge between complex environments and generative artworks. Throughout this case study, similar challenges related to iteration and control were revealed.

In this conclusion, I provide an in depth discussion to answer the research questions. As the reader may be aware, the field of generative AI, and how people interact with them in creative activities changed rapidly through the period of this thesis (late 2021 to early 2025). This was both an opportunity and challenge for my research. By combining original research with an analysis of these developments in practice and the emerging literature, I believe a clear argument emerges.

In the rest of this conclusion, I will discuss in depth how this argument unfolds. First, I will provide the core argument extracted from this research. I will then discusses how interaction design influences the roles humans and AI play (R1). Following this, I present the interaction design principles for human-AI co-creativity (R3), informed by my framework of dialogic co-creativity (R2).


\section{Core argument}

This thesis argues that prevailing modes of interaction with generative AI in creative activities induce a clear role distribution: Humans operate within the \textit{intentional space}, where creative goals, visions, and high-level decisions reside, while AI takes on roles in the \textit{action space}, where artefact-level operations such as drawing, writing words, or playing notes occur.

I argue this role distribution presents challenges to maintaining human agency through what I term as \textbf{severed creative agency}: a disconnect between creative intentions and action. This severing emerges from two main sources. First, a difficulty in steering generative systems through linear prompt-response interaction. Second, it emerges from a lack of involvement by the user at the action level: they become instructors and directors outsourcing creative production rather than active co-creators.

I argue that a dialogic interaction paradigm offers potential to arrive at more co-creative role distributions by enabling an iterative mutual adaptation and understanding, where humans and AI interact iteratively both through and about the creation.

To operationalise this, I combine the findings from my research studies, with emerging literature and with observations from practice, to provide a set of design principles that can inform the development of co-creative systems:

The principles are provided below for clarity, and the discussion that derives them is presented below.


\section{How Interaction Design Influences Roles and Agency}

At the beginning of this thesis, I introduced a fundamental distinction: interaction in co-creativity can occur both \textit{about} the creation and \textit{through} the creation. Prompt-response interaction paradigms, which are currently prevalent, primarily afford interaction \textit{about} the artifact rather than \textit{through} it. Building upon this initial distinction, I argue that we can understand creativity as a dynamic process of navigating two distinct yet interconnected spaces: the \textbf{intention space} and the \textbf{action space}.

The \textbf{intention space} encompasses the acts and stances \textit{about} the artifact, such as establishing goals, expressing taste, making decisions, providing directions, and formulating the overall intention to express. Conversely, the \textbf{action space} involves potential operations \textit{on} and \textit{through} the artifact itself, like writing words, playing notes, or drawing lines. In both individual and collaborative creative processes, humans iteratively move between these two spaces.

For example, \cite{Csikszentmihalyi1997-ui} describes a self-reinforcing feedback loop between actions and evaluations. He posits that a clear feedback signal about how actions contribute to a goal is crucial for achieving \textbf{flow}, which he observes among creative professionals when their actions and awareness of those actions virtually merge. Similarly, Schön \cite{Schon1987-fy} introduces the concept of \textbf{reflection-in-action}, where professionals, including creatives, continuously reshape their understanding of a situation (intention) and their actions within it (action) throughout the process. Schön \cite{Schon1992-jt} further suggests that in practice, the distinction between thinking and doing collapses into an iterative, embodied dialogue, akin to a "conversation with the materials," where the artifact "talks back," and the practitioner listens and responds. This highlights that the creative act is fundamentally a reciprocal shaping between action and intention.

\begin{figure}[H]
 \centering
\includegraphics[width=1\linewidth]{intention action spaces.png}
 \caption{The distinction between the intention space (goals, vision, decisions) and the action space (artefact-level operations).}
 \label{fig:intention-action-spaces}
\end{figure}

\subsection{The Emergence of Severed Creative Agency}

Throughout my research, and supported by emerging literature, I have observed a consistent pattern in human-AI interaction: humans predominantly take actions \textit{about} the artifact, while AI largely takes actions \textit{through} the artifact. This leads to a distinct \textbf{role distribution}, directly addressing my first research question (R1): humans increasingly assume roles primarily situated in the \textbf{intention space}, while AI occupies roles within the \textbf{action space}.

This separation of roles is evident in how users describe their involvement. For instance, in Chapter 4, participants articulated their experiences in ways that clearly reflect this dynamic:

\begin{quote}
"I was the curator of the story—I picked the pieces I liked and left the rest."

"I gave it the idea, and it just took it from there, writing almost everything."

"I gave it the skeleton of the story, and Vorges fleshed it out, almost like giving the recipe and having it cook the dish."

"I asked it to write a paragraph about a dystopian future, and it did everything from there."

"I started with a basic introduction, and Vorges expanded it into a complete narrative."

"Vorges wrote 90\% of the story based on my prompts. I just tweaked it a bit."
\end{quote}

These statements frame the role of the user as that of a curator, director or conceptualiser and the AI as an executor. This observation is corroborated by broader findings in the field. Palani et al. \cite{Palani2024-on}, in their comprehensive review of emerging roles in human-generative AI interaction, found that users increasingly adopt roles at the "Project" level, while AI assumes roles at the "Artifact" level. They noted, "Users saw themselves as ideators and project managers with a larger creative vision orchestrating information context and tasks across multiple GenAI models instead of traditional workers executing each task."

Similarly, in a study with musicians using generative AI tools, Suh et al. \cite{Suh2021-cj} described a shift in human roles from "composers" to "producers," "advisors," or "museum curators." One participant articulated this shift by stating, "When AI was present, our roles were more of choosing the ones that sound best and not necessarily building on top of it or creating something of ourselves," while another noted, "I felt like it was the composer and we were the listeners giving feedback and choosing."

This phenomenon is further exemplified by what AI researcher Andrej Karpathy termed \textbf{"vibe-coding"}—a practice where users prompt an AI to write code with minimal involvement in reading or understanding it:

\begin{quote}
"There's a new kind of coding I call "vibe coding", where you fully give in to the vibes, embrace exponentials, and forget that the code even exists. It's possible because the LLMs (e.g. Cursor Composer w Sonnet) are getting too good. Also I just talk to Composer with SuperWhisper so I barely even touch the keyboard. I ask for the dumbest things like "decrease the padding on the sidebar by half" because I'm too lazy to find it. I "Accept All" always, I don't read the diffs anymore. When I get error messages I just copy paste them in with no comment, usually that fixes it. The code grows beyond my usual comprehension, I'd have to really read through it for a while. Sometimes the LLMs can't fix a bug so I just work around it or ask for random changes until it goes away. It's not too bad for throwaway weekend projects, but still quite amusing. I'm building a project or webapp, but it's not really coding - I just see stuff, say stuff, run stuff, and copy paste stuff, and it mostly works."
\end{quote}
As \cite{Weisz2024-io} aptly summarises, "Generative AI technologies have introduced a new paradigm of human-computer interaction, what Nielsen refers to as "intent-based outcome specification". In this paradigm, users specify what they want, often using natural language, but not how it should be produced."

This emergent role distribution, where humans operate primarily in the intention space and AI in the action space, creates what I term \textbf{severed creative agency}. This refers to a fundamental disconnect between a human's creative intentions and their ability to translate those intentions into action within the co-creative process. This disjunction poses significant challenges to maintaining human involvement and ownership, a problem that the subsequent sections of this thesis will address.

Agency, in its standard definition, is characterised by intentional action. It involves a dual constraint: an actor with an intention but unable to act accordingly lacks full agency. Conversely, a person compelled to act in a certain way without the corresponding intention also has limited agency. Therefore, if interaction with generative systems consistently disconnects intention from action, it inherently limits the creative agency of users.

Below, I will discuss how this severance occurs and propose interaction design strategies to address it.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.75\linewidth]{roles.png}
    \caption{The distribution of roles in typical human-AI creative interaction, with the human operating at the intention level and the AI at the action level.}
    \label{fig:roles-in-spaces}
\end{figure}

\subsubsection{Challenges in Translating Intention into Action: Difficulty in Steering Generative Outputs}

A primary cause of severed creative agency stems from the difficulty in steering generative AI systems. This is a well-known problem, and one that my own case studies illuminate. For instance, in Chapter 5, I discussed how the main limitation faced when employing generative AI image tools in a professional creative scenario was effectively controlling them. This was particularly evident in achieving stylistic and structural consistency, which is crucial for refining images iteratively towards a convergent goal. Similarly, in Chapter 6, when leveraging a large language model to drive a generative soundscape for a new media installation, I outlined how the unpredictability of outputs and the challenge in controlling them represented a significant limitation.

These practical challenges are echoed in broader research. \cite{Palani2024-on}, in the study discussed earlier, identified "Aligning and Assessing Stochastic Model Outputs With Intent" and "Articulating creative goals" as two major limitations for the adoption of AI in creative activities. For example, one of their participants remarked:
\begin{quote}
"I was prescriptive in my prompt, and I thought I nailed it. But the model never did, and it still doesn't. That drives me crazy and keeps me surprised, delighted, and sometimes annoyed."
\end{quote}
Another user described the challenge of articulation: "at times, I didn't have the vocabulary to ask the model to help me. I think your background knowledge matters: someone with an art history background knows how to prompt a specific style, unlike someone who doesn't." This difficulty is compounded when attempting to articulate tacit knowledge, such as nuanced style and expertise, within a prompt-based paradigm.

This inherent unpredictability is a notable characteristic of generative AI systems, which \cite{Weisz2024-io} terms "generative variability." While this can, on one hand, introduce surprise and delight, it can also lead to significant annoyance and frustration. As I will discuss, balancing this variability is a core task for interaction design in co-creative systems.

Weisz argues that "With generative AI applications, users will need to develop a new set of skills to work with (not against) generative variability by learning how to create specifications that result in artifacts that match their desired intent." However, from an interaction design perspective, the burden of deducing these skills should not rest solely on the user. Instead, effective interaction design can actively help users navigate the generative variability inherent in these systems, enabling more fluid translation from intention to action.

\subsubsection{Source of Severed Creative Agency 2: A Lack of Involvement in the Creative Process}

While the difficulty in steering generative AI systems represents one major source of severed creative agency, a second, equally critical factor emerges from the user's lack of involvement at the action level of the creative process. When human users predominantly assume directive and intentional roles, outsourcing the actual "doing" to the AI, they experience a disconnect that impacts enjoyment, ownership, and even skill development. This disengagement directly contributes to the severing of creative intent from action, ultimately undermining human-AI co-creativity.

Consider the experience of a participant in my Chapter 4 study who used a chat-only interface (Vorges) for writing:

\begin{quote}
"[it] made me feel like I was cheating somehow. It does not feel like my work, even though I gave all the ideas. Also, I believe there is satisfaction in putting a lot of effort/dedication/patience into something. Vorges made everything so simple, fast, and easy that it felt artificial and no real satisfaction came as a result."
\end{quote}

Another participant, using the same interface, described their experience this way:

\begin{quote}
"I find them to be very interesting, and useful tools in getting a job done quickly, but at the cost of losing a sense of individuality."
\end{quote}

Brian Eno's reflections on using generative tools echo these sentiments:

\begin{quote}
"In my own experience as an artist, experimenting with AI has mixed results. I've used several "songwriting" AIs and similar "picture-making" AIs. I'm intrigued and bored at the same time: I find it quickly becomes quite tedious. I have a sort of inner dissatisfaction when I play with it, a little like the feeling I get from eating a lot of confectionery when I'm hungry. I suspect this is because the joy of art isn't only the pleasure of an end result but also the experience of going through the process of having made it. When you go out for a walk it isn't just (or even primarily) for the pleasure of reaching a destination, but for the process of doing the walking." \cite{Eno2024-rj}
\end{quote}

However, a lack of involvement goes beyond subjective feelings; it can lead to an erosion of skills, limiting the confidence and ability of practitioners to translate their intentions into outputs, and in turn, diminishing their creative agency. A growing body of literature indicates that over-reliance on large language models (LLMs) for writing can result in skill loss \cite{Heersmink2024-mk, Rafner2021-tm}. Gerlich \cite{Gerlich2025-as} found a link between over-reliance on AI for writing tasks and a loss of critical thinking skills. More recently, a study by Lee et al. \cite{Lee2025-dw} found that generative AI use among knowledge workers was associated with less cognitive effort and reduced self-confidence. This is particularly concerning for creative agency, as creative self-efficacy, defined as confidence in one's creative ability, is a crucial determinant of creative achievement \cite{Tierney2002-xp}.

In a recent preliminary study by Kosmyna et al. \cite{Kosmyna2025-cm} conducted at MIT, researchers explored the neurological effects of engaging in a creative task using Electroencephalography (EEG). They compared participants using no tools, using web search, and using ChatGPT. The study found that participants using an LLM via a chat interface showed significantly lower levels of brain connectivity and brain activity patterns signaling under-engagement with the task. They also struggled to quote their own work and reported lower levels of ownership of the essay.

Involvement and immersion are crucial aspects of the creative process \cite{Amabile1996-pt, Csikszentmihalyi1997-ui} and are important dimensions for analysis and design in co-creative systems \cite{Davis2016-te, Cherry2014-ty, Rezwana2022-ui, Clark2018-yf, Lawton2023-gd, Yuan2022-kb, Li2024-yh, Kantosalo2015-pk, Resnick2005-fs}. While generative AI offers new possibilities for creating more powerful and useful co-creative systems, paradoxically, their capability can lead them to automate most aspects of the process by providing a path of least resistance. However, research also demonstrates that these effects are largely mediated by interaction design \cite{Kim2023-wt, Essel2024-qc}.

Balancing this is what I suggest is the \textbf{fundamental tension in human-AI co-creativity}.

Generative AI, as discussed above, has the potential to speed up workflows, serve as a safety net, and lead into new creative directions. On the other side, it can lead to users becoming less involved, losing valuable skills, and a sense of satisfaction, individuality, and authenticity in their work.

Others have discussed the need to balance automation and human agency \cite{Moruzzi2024-cq}:
\begin{quote}
    "In this scenario, there is a pressing need to examine the terms of the balance between automation and agency in H-AI interaction to continue reaping the benefits of increased efficiency resulting from the automatization of repetitive and burdensome tasks, preserving at the same time the sense of agency, control, and responsibility of users."
\end{quote}

Having discussed how a role distribution with users at the intentional level and AI at the action level severs creative agency by making it difficult to steer the creation and limiting user involvement, the following sections will outline interaction design principles aimed at addressing these challenges.

\section{Interaction Design Principles for Human-AI Co-Creativity}

While not claiming to be absolute or comprehensive, these design principles are derived from my research, relevant literature, and practical experience. They serve as an initial framework for establishing principles specifically aimed at fostering human-AI co-creativity from the perspective of dialogic interaction.

The following nine principles are organized to address the challenges of severed creative agency through different aspects of interaction design:

\begin{enumerate}
    \item \textbf{Leverage Generative Variability as a Feature for Serendipity and New Creative Directions}
    \item \textbf{Leverage the Unique Characteristics of Generative AI}
    \item \textbf{Enable Users to Train and Fine-tune Models in Their Own Style}
    \item \textbf{Enable Multimodal Expressive Inputs Beyond Text}
    \item \textbf{Enable Iteration that Preserves the User's Journey}
    \item \textbf{Provide Collaborative Spaces Separate from Conversational Spaces}
    \item \textbf{Manage Conflicts of Territory in Shared Collaborative Spaces}
    \item \textbf{Design for Process and Involvement, Not Only Outcome}
    \item \textbf{Make Creative Primitives Visible and Allow Users to Act as Workflow Orchestrators}
\end{enumerate}

\subsection{Principle 1: Leverage Generative Variability as a Feature for Serendipity and New Creative Directions}

While \cite{Weisz2024-io} propose that users need to develop skills to work with generative variability, they also offer interaction design guidelines to help users manage it, such as leveraging multiple outputs, visualizing the user journey, enabling annotation, and drawing attention to differences between outputs. While useful, these strategies primarily focus on \textit{mitigating} generative variability, as their guidelines are aimed at general uses of generative AI across multiple fields. I argue that in the context of co-creativity, generative AI variability does not always need to be mitigated; instead, it can be strategically leveraged as a feature rather than a bug.

A crucial way generative variability can become a feature is by introducing surprise and serendipity. Multiple studies consistently show that the introduction of surprise and serendipity is often referred to as a positive attribute of co-creative interaction with generative systems \cite{Lawton2023-tb, Chiou2023-vr, Louie2020-aq, Moruzzi2022-gp, Park2024-gw, Koch2020-gx}.

This aligns with observations from my own research. For example, one participant in my study remarked:

\begin{quote}
"Vorges is like a creative collaborator or editor with ADHD - not always on point and occasionally disordered, but with no shortage of ideas."
\end{quote}

When describing the value of using the co-writing prototype in Chapter 4, multiple participants stated that its primary value lay in making them feel creative and expanding their perspectives. Many described the usefulness in shifting their perspective and generating new ideas:

\begin{quote}
"Vorges is like the smart academic friend that I go to for creative blocks - they are well versed in history and have a perfect memory from which to shower me with excellent resources and historical references for further exploration of my ideas."
\end{quote}

Sloan \cite{Sloan2016-fj} when describing his experience using an LLM-based co-author, described: "it's like writing with a deranged but very well-read parrot on your shoulder."

So, while the value of generative AI in inducing surprise and serendipity is well recognised, how can we design interactions that effectively leverage them? One promising alternative lies in \textbf{exploration-based interfaces}. For instance, a study by \cite{Davis2024-ml} demonstrated that a multimodal interface allowing 2D exploration of the latent space of fashion designs enabled better ideation than prompt-based text-to-image interfaces, such as the Stable Diffusion tool they tested against. They concluded that "text-only prompts in existing models restrict creative exploration, especially for novices." Their interface implemented various exploratory interactions, with central components being a latent-space exploration panel allowing users to move through designs along semantically meaningful directions (e.g., sleeve length or pattern) and a style-mixing panel for blending designs. This iterative process of exploration and remixing better afforded ideation than the request-execute interactions found in more modern text-to-image systems. 

In a study testing an ideation tool to support human-computer partnerships, \cite{Koch2020-gx} tested an interface called ImageCascade, which showed designers a slow stream of images, related to the task or not, and found this interface was useful in introducing serendipity and perspective shifts in a creative process by providing a space for divergent exploration, compared to prompt-only text-to-image interfaces.

This aligns with broader understandings of creativity as a process of exploration \cite{Boden1998-yn, Wiggins2019-yj}. Given that the \textit{latent space} encoded in generative AI models can be understood as a space of potentiality \cite{Schaerf2024-gf}, generative AI systems may enable a more direct implementation of this process through interfaces that embody this metaphor. Therefore, \textbf{exploratory interfaces, as opposed to purely request-based interfaces}, can be highly effective in leveraging generative variability to induce shifts in perspective, particularly during ideation and divergent creative phases. 


\subsection{Principle 2: Leverage the Unique Characteristics of Generative AI}

Another way to address the challenge of generative variability, particularly in divergent creative stages, is by \textbf{leaning into the unique characteristics of the generative AI medium itself}. As Brian Eno puts it:

\begin{quote}
    Whatever you now find weird, ugly, uncomfortable and nasty about a new medium will surely become its signature. CD distortion, the jitteriness of digital video, the crap sound of 8-bit - all of these will be cherished and emulated as soon as they can be avoided \cite{Eno2007-fl}.
\end{quote}

For generative artificial intelligence, this means recognizing that its unique features, particularly its capacity for unexpected and occasionally "weird" outputs, can become valuable. My own participants offered similar perspectives:

\begin{quote}
"I also love its figurative language and descriptions because of how they kinda just don't make sense. I left that in on purpose because I love the idea of a curious nose and a perpetually second-hand jacket."
\end{quote}

This sentiment is echoed in the literature. Sloan \cite{Sloan2016-fj}, reflecting on his creative process with a generative language model, noted that: "The goal is not to make the resulting text "better"; it's to make it different—weirder, with effects maybe not available by other means." Similarly, Samuel, discussing her experience with language models and citing Du Sautoy, argues that art often enhances our perception by "making the familiar strange." She posits that AI can be an incredible tool for writers precisely because:

\begin{quote}
"it's great at defamiliarizing our world. The human-ish language it generates can startle us into seeing things anew, so we can in turn jolt readers awake through that sense of -ish."
\end{quote}

In my case study with the AFR magazine (Chapter 5), this was precisely our intention: to use the AI system to create "impossible photography"—images that were uncanny and slightly unreal, possessing the distinctive "fuzzy texture" of AI-generated visuals. As the editorial team described:

\begin{quote}
"They are both uncanny and yet slightly unreal. All have the distinctive fuzzy texture of AI images, as if they were drawn. Our prompts were very minimal and the output hints at the way AI is learning 21st-century human culture."
\end{quote}

Akin to how photography spurred impressionism to explore what the human eye sees rather than what the lens captures, generative AI can likewise allow users to induce perspective shifts, contributing to the circularity in human-AI mutual influence. Its "weirdness" and strange artifacts offer a unique lens to understand what \textit{we are seeing} by \textit{seeing what the algorithm sees}. 

In my Chapter 6 data sonificiation examples leveraging an LLM, we largely engage the AI by exploiting and eliciting unique, uncanny language, offering an affective. The creative intention, partly, was to induce the audience to perceive the surrounding context anew through the algorithm's unique lens.

\subsection{Principle 3: Enable Users to Train and Fine-tune Models in Their Own Style}

While the previous section highlighted the role of generative variability and its potential to introduce serendipity, effective co-creative systems must also provide users with a complementary degree of control. 

One strategy for enhancing user control over generative outputs involves enabling the training and fine-tuning of models. As demonstrated in Chapter 6, an iterative approach to model training was crucial for achieving desired visual outcomes in a professional creative context. By iteratively training models on curated datasets, evaluating outputs, and refining the data, we were able to steer the generative process towards specific likenesses and visual intentions. This iterative training process enhanced control, allowing for a more precise alignment with the editorial team's vision, as they noted in an article covering the process \cite{Drummond2023-bh}, "The fact that you can train Stable Diffusion – by limiting or controlling the inputs it draws upon – makes it better [at consistently generating what we intended]".

Furthermore, combining this training with an image-to-image workflow provided additional control over structure and composition. The distinction between a specialised, user-trained model (Stable Diffusion) and a generalist model (Midjourney) highlighted the value of tailoring models to specific creative needs.

Similar practices are observed in other creative domains. Sloan's work training LLM-based co-creators offers a illustrative example \cite{Sloan2016-fj}. 

\begin{quote}
So, a large part of the work (and fun) of applying the deep learning scenesters' hard-won technical triumphs to weird/fun objectives is tracking down non-standard, non-boring datasets. For me, decisions about the collection and processing of the text corpus have been more consequential than decisions about the RNN's design and subsequent training.
\end{quote}

Enabling users to train their own models or fine-tune existing ones is becoming a more widespread practice that is proving effective in practice. Tools like Leonardo AI's LoRA training \footnote{More *https://www.leonardo.ai} and Exactly.ai\footnote{https://www.exactly.ai} allow users to generate content in their unique style and have been a core feature driving their adoptipn. In the case of Exactly.ai, users can train models on their own work, and monetise them based on third-party usage while retaining copyright of the outputs.

From the perspective of dialogic interaction, this process can be understood as contributing to mutual understanding, by helping the user understand better how the model works. Particularly through multiple rounds of dataset curation and training, users can form a more robust mental model of the latent space of the model; it's space of possibilities.

\subsection{Principle 4: Enable Multimodal Expressive Inputs Beyond Text}

Another way to provide controls beyond text is by allowing users to express intentions by \textit{showing, not only telling}. Earlier, I discussed how it is difficult to articulate tacit knowledge such as style and expertise in text-only interfaces. This is often recognised as a limitation of generative AI. For example, a study by Park et al. \cite{Park2024-gw} titled "We are visual thinkers, not verbal thinkers!" analysing how designers use generative AI tools found that their main struggles was to express visual things verbally.

Multimodal inputs offer a promising approach such approach. For example, in Chapter 5 I described how we leveraged image reference to drive the outputs, as shown in Figure  \ref{fig:ai_generation_workflow}.

\begin{figure}[htbp]
    \centering

    % First subfigure - Control network workflow
    \begin{subfigure}[b]{\textwidth}
        \centering
        \includegraphics[width=0.9\textwidth]{controlnetworkflow.png}
        \caption{Workflow used to extract characteristics of an image used as reference. The reference image was generated in a software that better aligned with the aesthetic intent.}
        \label{fig:controlnetworkflow}
    \end{subfigure}


    % Second subfigure - Input/Output comparison
    \begin{subfigure}[b]{\textwidth}
        \centering
        \includegraphics[width=0.9\textwidth]{inputoutput.png}
        \caption{Using a generated image as reference allowed us to achieve the desired result.}
        \label{fig:inputoutput}
    \end{subfigure}

    \caption{AI image generation workflow showing the process of extracting visual characteristics from reference images and applying them to generate target subjects with desired aesthetic qualities.}
    \label{fig:ai_generation_workflow}
\end{figure}

However, creatives often do not work with a single specific reference; they are often targeting a more general aesthetic. For example, designers often curate moodboards that seek to capture a general intention as a starting point. Interfaces that accommodate this process can be effective. In a study by Peng et al. \cite{Peng2024-tr}, the authors described an interface that allows designers to curate mood-boards consisting of colour palettes, images, and text, and use it to drive generation. This interface, they found, allowed designers "explore and express themselves more effectively" than text-to-image tools.

\begin{figure}
    \centering
    \includegraphics[width=1\linewidth]{designprompt.png}
    \caption{DesignPrompt: a moodboard tool by \cite{Peng2024-tr} allowing designers to search images, compose multimodal prompts with images, colors, semantics, and text, and "finely tune their intentions."}
    \label{fig:enter-label}
\end{figure}

The most effective dialogic interfaces may be hybrid ones, combining text and conversation with multimodal inputs, allowing users to switch between expressing ideas through language and by showing examples. This mirrors how humans collaborate in creative tasks; for example, when musicians can't articulate an idea, they simply play it.

\subsection{Principle 5: Enable Iteration that Preserves the User's Journey}

A key component of creative processes it iteration. However, generative variability and a lack of precise control often makes this process notably difficult. In a study with creatives using generative AI tools Park et al. found one of the core limitations they highlighted was support for the iterative nature of creative processes \cite{Park2024-gw}. The same limitiation was identified in my own research. 

As an illustrative example, consider Figure \ref{albo_series}, from Chapter 5. We were satisfied with one of the initial outputs, shown on the left, but wished to make a minor modification: for the subject to be smiling. Despite a seemingly small change (a single word addition to the prompt with identical settings) the resulting image changed significantly. While the general scene and subject's position were retained, a suit jacket was unexpectedly added, and the overall contrast of the image shifted. 

\begin{figure}[H]
    \centering
    \includegraphics[width=1\linewidth]{alboexperiments.png}
    \caption{Screen-grab from my experiments log from the AFR case study, fixing some parameters while varying others. This example illustrates the difficulty of iterating with generative models. The intention was to change the facial expression of the subject, adding a single word to the prompt while using ControlNets to condition the generation. However, clothing was added, and the brightness and contrast of the image changed as well.}
    \label{fig:albo_series}
\end{figure}


Effective iterative refinement is partly a challenge at the model level, but interaction design can help users better understand how inputs map to outputs. Emerging communities of practice are already addressing this through the creation of guides to navigate latent spaces, primarily by systematically documenting input-output relationships in controlled experiments \cite{Smith2022-dm}. In my own research, particularly in case studies 5 and 6, I maintained detailed research journals to track how specific prompts related to their respective outputs; Chapter 6 further elaborates on these experiments.

\begin{figure}[H]
\centering
\includegraphics[width=0.8\linewidth]{linus.png}
\caption{Linus Lee's experimental interface for exploring creative possibilities.}
\label{fig:linus}
\end{figure}

This journaling practice emerged primarily due to the system's limited capability to afford this type of interaction history keeping. Several authors have argues for the need for this. Various design approaches exist to achieve this, such as tree-like visual interfaces that clearly depict branching paths of inputs and outputs, thereby preserving extensive generative histories. This approach aligns closely with Resnick et al.'s recommendations in their "Design Principles for Tools to Support Creative Thinking" \cite{Resnick2005-fs} of rich history keeping. Figure \ref{fig:linus} presents a prototype embodying this principle. Similarly, Weisz et al. propose design principles for generative AI applications, including: visualising the user’s journey, supporting curation and annotation and highlighting differences or variations across outputs.

From a dialogic perspective, systematic record-keeping directly supports the development of robust mental models of the system, contributing to user's understanding of the model's behaviour.

\begin{figure}[H]
\centering
\includegraphics[width=0.8\linewidth]{latentspacemanip.png}
\caption{Prototype by Michael Feldstein for intuitive latent space manipulation.}
\label{fig:feldstein}
\end{figure}

In the context of language generation and co-writing, chat-only interfaces can also restrict users' capacity to iterate effectively by not enabling a space to edit the text. Users frequently express frustration with linear message streams. One participant described their frustration with ChatGPT, noting the process "feels somewhat random and not as iterative." Another participant elaborated:

\begin{quote}
"ChatGPT will always rewrite the entire passage to change just one paragraph, and it is harder to work on one text as input as I often need to scroll back up to see it or continually copy and paste it."
\end{quote}

A third participant highlighted:

\begin{quote}
"I've felt frustrated because it's gone in the wrong direction and then requires a lot of input from me to put it on the track that I have in my head."
\end{quote}


In the next section, I detail how I investigated the potential of an interfaces that implements both a collaborative space and space for conversation to address this. 

\subsection{Principle 6: Provide Collaborative Spaces Separate from Conversational Spaces}

Conversational dialogic interfaces have become the predominant form of interaction with large language models, highlighting both the value of dialogic interaction in practice and its challenges related to co-creativity. My research found that these interfaces tend to position users in a directive, requesting role, effectively outsourcing the writing process. This positioning leads to a lack of involvement, particularly when users engage with chat-only interfaces without a space for stateful collaboration through the writing itself.

Recall the participant's statement highlighted at the beggining of this conclusion:

\begin{quote}
"[it] made me feel like I was cheating somehow. It does not feel like my work, even though I gave all the ideas. Also, I believe there is satisfaction in putting a lot of effort/dedication/patience into something. Vorges made everything so simple, fast, and easy that it felt artificial and no real satisfaction came as a result."
\end{quote}

To address these challenges, this thesis found promise in separating collaborative spaces from conversational spaces, enabling users and AI to collaborate in the action space, interacting \textit{through} the creation and not only \textit{about} the creation. The interface is shown in figure \ref{fig:shared-editor}. As discussed in Chapter 4, this approach led to users reporting that the AI did most of the work less frequently. They also reported higher levels of involvement and agency:


\begin{figure}[H]
    \centering
    \includegraphics[width=1\linewidth]{sharededitor.png}
    \caption{The shared editor prototype, combining a chat with a direct manipulation space.}
    \label{fig:shared-editor}
\end{figure}

\begin{quote}
"I really-really enjoyed writing this. I even had a deep moment of reflection, my writing was nostalgic and sad, but I was able to use AI to steer it in the right direction, it gave me confidence that I was also writing with correct grammar and spelling, English is not my first language and while I am proficient, I can still use proofreading to ensure good quality, this tool helped me with it." (P4 Common AI)
\end{quote}

Others shared similar perspectives:

\begin{quote}
P9 shared: "I liked how my original ideas were still retained, and AI was used to complement my intentions. It forced me to put in some effort and do the majority of the work."

P22 emphasized: "It adds an element of working together, which I think is the moral problem with current AI tools—they often seem like they're doing all the work."
\end{quote}

Participants reported increased agency: P18 said, "It was much better than ChatGPT. I enjoyed how it gave me a lot more agency." P12 remarked, "I really enjoyed it; it still let me have autonomy."

A participant highlighted the limitations of ChatGPT, comparing it with an AI co-writer integrated within a text editor:

\begin{quote}
P5 said: "It can just be a bit clunky having a separate document to then copy, paste, and edit in [in ChatGPT]. This made it super seamless being in the one program."
\end{quote}

While participants generally reported greater involvement when using a shared collaborative space, a recurring theme was their need for improved visibility into the AI's edits and how these changes impacted their own work.

\begin{quote}
Participant 11: "When you ask the AI to check your grammar (as I did), it would be good if it told me what suggestions it had made, so I can double check its work easier."

Another participant commented: "I am unsure as what parts of the text are being edited, in the end I am not quite sure which parts were mine and which ones were edited by AI."

"Once the tool has made revisions to the original text, maybe it can highlight the key changes that have been made... otherwise I need to slowly read through and identify the changes myself."
\end{quote}
Participants also highlighted a significant limitation:
\begin{quote}
The one limitation I would say is that if you don't like what the AI has integrated you need to manually remove it from the only source of text you have (the one you are sharing with the AI). Whereas in an AI chatbox, usually you would parse through the original text copy into the chat, and the chat would then spit out a new copy, makes it a bit easier to edit/cut out any additions you don't like.
\end{quote}

These challenges in collaborative spaces are described by Buschek et al. \cite{Buschek2021-ks} as "conflicts of territory" in their "Nine Potential Pitfalls when Designing Human-AI Co-Creative Systems." These conflicts arise in co-creative spaces when the AI destructively edits user-generated content, or when the user's changes to AI-generated text are subsequently reverted by the AI. To mitigate this, Buschek et al. suggest tracking user edits to protect them and highlighting AI-introduced changes.

\subsubsection{Cursor: an example of managing contributions effectively}
An excellent example of a tool that successfully integrates a collaborative shared space with a conversational interface is Cursor. Cursor's value largely stems from its ability to share a coding space with the user. When the AI offers suggestions or contributions, it presents them as diffs that users can accept or reject. This also allows users to revert changes and maintain version control, much like traditional coding environments.

Naturally, incorporating such features adds complexity to the design of co-creative tools. In the second prototype developed for Chapter 4, this was precisely the focus: managing how the AI introduced edits into the text. While the prototype did not fully implement highlights, the intention was to enable the AI to make direct, single-word edits without rewriting entire sections. This approach aimed to prevent the AI from inadvertently altering text the user had already revised. To achieve this, a protocol was created, allowing the AI to target specific edits within a single text.

\subsection{Making capabilities visible}

When users possess a clear understanding of what the system can and cannot do (its visible creative primitives) they can engage with it more effectively and meta-cognitively discern which actions to delegate to the system and which to undertake themselves. In my literature review, I outlined how the effectiveness of human-AI interaction hinged largely on the user's ability to grasp the system's underlying mechanisms: visibility. In my Chapter 4 co-writing studies, a similar qualitative observation emerged: users expressed a benefit from having more clarity about the kinds of things they could do with chatbots for co-creation, and from having direct ways of triggering certain operations (e.g., providing feedback, generating text, providing suggestions). This points towards the need for a direct manipulation GUI that explicitly triggers creative actions, aligning with Weisz and Nielsen's call for intention-oriented, action-oriented, or outcome-oriented interfaces. In co-creative and generative systems, the 'primitives' are not static objects but dynamic processes and actions. Consequently, making these creative primitives transparent and actionable is of significant importance for fostering truly effective and deeply involved human-AI interaction.

\subsection{Involvement and paths of least resistance}

It is important to clarify that while shared collaborative spaces might increase user involvement, this doesn't mean users are completely hands-on. In my studies, participants using either the shared space (chat + shared editor) or the chat-only interface both largely agreed that the AI did most of the work.

The key difference was the degree of agreement. Participants using the shared text editor showed less agreement with that statement compared to those using the chat-only interface. However, in both scenarios, the general sentiment was that the AI handled the bulk of the work; it was just significantly less pronounced in the shared space. As Figure \ref{fig:graphsharedspaces} illustrates, while chat-only interfaces saw higher agreement with the statement "AI did most of the work," agreement was still high across both interfaces. In essence, even with greater involvement in the collaborative editor interface, users still perceived the AI as doing most of the heavy lifting. This is an instance of what I described earlier as the fundamental tension in human-AI Co-Creativity.

\begin{figure}
\centering
\includegraphics[width=1\linewidth]{graphsharedspaces.png}
\caption{Agreement levels with the statement "AI did most of the work" across chat-only and chat + shared editor interfaces.}
\label{fig:graphsharedspaces}
\end{figure}

A similar phenomenon can be observed with tools like Cursor. Even though Cursor is integrated directly into a shared coding environment and carefully manages conflicts of territory through features like diffs, accepts, and rejects, its AI's ability to handle coding often leads users to outsource much of the work. The "vibe coding" reference I mentioned earlier, made by Andrej Karpathy, specifically referred to using Cursor. This suggests that even when using a deeply integrated tool like Cursor, users may still primarily operate at an intentional level (deciding what should be done) rather than at an action level (actively performing the coding tasks).

\section{A final discussion on emerging roles: is it involvement at higher level of abstraction?}

While throughout this conclusion I characterised a lack of involvement in human-AI co-creation as inherently negative, it could be argued that users engaging in intentional roles allows them to focus on more conceptual aspects of the creative process, and with this, augment their creative agency. As one participant in my writing study described about interacting with Vorges, the AI co-writer: "I like it a lot. I think that it allowed me to focus on the ideas, the plot and the characters even more because Vorges focused on the writing."

This perspective aligns with a crucial role in co-creativity, such as that of a producer who is meaningfully and productively involved by simply providing nudges to musicians, as famed producers Brian Eno and Rick Rubin have been described doing. In fact, producer Rick Rubin explicitly argued that this is precisely the benefit of using generative AI in creative processes. In contrast, for Brian Eno, when discussing engagement with generative AI, argues that focusing only on giving instructions is alienating from in the process itself. However, in his own creative practice with non-AI generative art, Eno describes himself as a gardener, "planting seeds" and letting it grow. 

Can one be considered meaningfully involved when acting primarily at the intentional level? The answer may lie in the nature and dynamic of the involvement, regardless of weather it predominantly occurs in the intentional space (planning, conceptualising) or the action space (direct execution). If the user engages in a one-off linear command-execute creation, we may consider them uninvolved. However, if they engage in an iterative cycle of mutual influence and understanding with the system, we may consider them more involved, even if their involvement occurred only at the intentional level, for example, by providing prompts. 

An illustrative example is Jason Allen's \textit{Théâtre D'opéra Spatial}, which won first place at a digital art fair but generated controversy when it was revealed to be AI-generated. The US Copyright Office denied copyright, arguing it was unclear how much was Allen's work and how much was AI \cite{US-Copyright-Office-Review-Board2023-nw}. Allen argued he was highly involved in the process, iterating hundreds of prompts over many hours and even using digital design software further refine the image. For him, the image was generated by him no different from how other artists use digital software. In this case, prompting may be considered not only \textit{intention} but \textit{action}, simply at a higher level of abstraction.  Indeed, prompting is emerging as a creative practice in its own right, with engaged communities developing idiosyncratic approaches to it, using generative models as the creative medium \cite{Chang2023-tv, Smith2022-dm}.

It can be further argued that the process Jason Allen engaged in was to a degree, dialogic, as it involved mutual influence and understanding, enagaging in a "conversation with the material" as Schön describes. A similar thing can be said about the process of curating datasets and training and prompting generative models described in Chapter 6. In contrast, users engaging with conversational interfaces may engage in less dialogic interaction, even if it appears dialogic by virtue of involving a conversation. For example, some participants in my Chapter 4 co-writing study who engaged with a conversational AI system, described it as doing "everything", simply providing a request and having it generate the rest. Notably, little iterative interaction was reported. 

A core element for dialogic interaction, then, is that the iterative building of mutual influence and understanding towards the production of something imbued with a strong intention, whatever the means. 

\subsection{Creative Primitives and Users Operating at a Higher Level of Abstraction}

The shift in role distribution described throughout can be understood as the tendency to "move up" levels of abstraction when computational primitives at lower levels are automated. Carter and Nielsen \cite{Carter2017-xj} argue that the value of generative artificial intelligence in augmenting human intellect lies in providing new cognitive primitives, much like a calculator automates the laboriousness of long division so that humans operate with "long division" as a basic unit. Extending this, I argue that generative artificial intelligence may be understood, at least partly, as providing a set of new \textit{creative primitives}.

When the user is deeply involved at this higher level of abstraction operating on this primitives, their intentional space can \textit{transforms into a new action space}. My Chapter 6 example illustrates this: prompting the language model to translate incoming data into actions can be understood through the lens of operating on new creative primitives. Translating data into sound is the creative unit I operated with. I can composed this unit with other units in the installation to driving visuals and generative text. This positioned me in the role of workflow orchestrator, building and connecting generative and non generative nodes as creative primitives. As Palani described, from an extensive survey and systematic review, this is increasingly the role identified for creative practitioners engaging with generative models: that of orchestrator and builder of generative workflow \cite{Palani2024-on}s. 

Increasingly, tools are building interactions and interfaces that specifically accommodate this type of role, moving beyond linear prompts or conversational interfaces. For example, ComfyUI is a popular open-source system that allows users to build complex workflows of different generative tools, with users developing personal and idiosyncratic approaches to combining the input-output of diverse generative systems across modalities as creative primitives. Tools like Flora enable similar operations for less technically and coding proficient advanced users, providing a comparable workflow-building interface targeted at designers and artists. Similarly, Leonardo.ai's workflow building tool and blueprints seek to provide compositional workflow-building tools that give more control and involvement to the user beyond simpler prompt interfaces.


\section{Contribution and Future Directions}
This thesis argued that the current paradigm of human-AI interaction often leads to \textit{severed agency}. The primary contribution is the development of \textit{dialogic design} as a framework to counteract this by more closely aligning intention and action through the principles organised under the dimensions of \textbf{Iteration}, \textbf{Communication}, \textbf{Collaboration}, and \textbf{Integration}. The design principles derived from this research offer concrete guidance for building effective co-creative tools that maintain human agency and allow people to leverage the potential of generative AI.

