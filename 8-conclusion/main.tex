\chapter[Conclusion]{Conclusion}\label{c:conclusion}

The core aim of this thesis was to examine how to enable co-creativity between humans and generative artificial intelligence. Specifically, the following core research question was posed.

\begin{quote}
\textbf{Core Research Question:} How can we design generative AI systems that
act as effective co-creators, maintaining human agency while effectively leveraging the creative potential of this technology?  
\end{quote}



This aim was broken down into the following sub-questions:

\begin{quote}
\textbf{Sub-Questions:}
\begin{itemize}
    \item \emph{R1: How does interaction design influence the role that humans and AI play in creative production?}
    \item \emph{R2: What is the potential of modelling dialogue in interaction design to enable effective human–AI co-creativity?}
    \item \emph{R3: Which interaction design principles can guide the development of effective co-creative systems?}
\end{itemize}
\end{quote}

I examined these questions through a mixed-methodology approach, developing and testing prototypes with users from a design research perspective, and engaging in creative practice through collaborations with teams working on real-world creative productions. This chapter begins by presenting the core argument of the thesis. 

It then develops this argument by addressing the research sub-questions, starting with an analysis of how interaction design shapes the roles, agency, and effectiveness of human-AI interaction. Following this, I explore the potential of dialogic interaction to enhance co-creativity, culminating in a final section that synthesises these findings into a set of actionable design principles.

\section{Core argument}

This thesis argues that prevailing modes of interaction with generative AI in creative activities often diminish user creative agency through what I term \textbf{severed creative agency}: a fundamental disconnect between a user's creative intentions and the actions performed by the AI. 

This severing emerges from a significant shift in role distribution. Humans increasingly operate within the \textit{intentional space}, where creative goals, visions, and high-level decisions reside, while AI systems take on roles in the \textit{action space}, where concrete artefact-level operations such as drawing, writing words, or playing notes occur. While assuming primarily intentional roles, severed creative agency arises for two reasons: First, a difficulty in steering generative AI. Second, from a lack of involvement at the action level.

Dialogic co-creativity is a promising approach to address this by more closely \textbf{aligning intention and action}, contributing to increased agency and effectiveness of interactions. Dialogic co-creativity involves designing iterative interactions that promote \textbf{mutual adaptation and understanding} where humans and AI interact not only \textit{about} the creative process (intentional level) but also \textit{through} the creative process itself (action level). 

As the core contribution of this thesis, I articulated a set of design principles that operationalise dialogic co-creativity, offering concrete guidance for the development of co-creative AI systems. 

These principles are: 

\begin{tcolorbox}[colback=gray!5, colframe=gray!60!black, title=\textbf{Design Principles for Human–AI Co-Creativity}, sharp corners=south, fonttitle=\bfseries]
\begin{itemize}
    \item \textbf{Serendipity:} leveraging generative variability and randomness in generative AI to induce perspective shifts and adaptation of creative directions.
    \item \textbf{Personalisation:} allowing users to build a shared understanding of the generative system through training, fine-tuning and style ownership.
    \item \textbf{Expressiveness:} enabling more expressive control of tacit and ineffable creative intentions through multimodal interfaces.
    \item \textbf{Iteration:} enabling iterative creative workflows that allow for refinement and creative journey tracing.
    \item \textbf{Collaboration:} providing dedicated spaces for collaboration both through and about the creation.
\end{itemize}
\end{tcolorbox}

In the next sections I will develop this argument and discuss the derivation of the principles along a set of practical guidelines for their implementation.

\section{How Interaction Design Influences Roles and Agency}

We can understand creativity as a process of moving between two distinct but interconnected spaces: the intention space and the action space. In the \textit{intentional space} reside goals, taste, decisions, directions, and the intention to express. In the \textit{action space} are the concrete creative acts: writing words, playing notes, or drawing lines: the actions performed at the artefact level. This distinction is found across the literature and I argue it is core to understanding the shifting of roles between humans and AI in creative activities.

For example, \cite{Csikszentmihalyi1997-ui} describes a feedback between actions and evaluations. He posits that a clear signal of how actions contribute to a goal is crucial for achieving \textbf{flow}, where \textit{actions} and \textit{awareness of actions} merge. Similarly, Schön \cite{Schon1992-jt} introduces the concept of \textbf{reflection-in-action}, where creatives continuously reshape their understanding of a situation (intention) and their actions within it (action) throughout the process. He suggest that the distinction between thinking and doing collapses into an iterative dialogue; a "conversation with the materials". Computational creativity commonly describes the process as involving both making and evaluation as core components \cite{Colton2011-vl}. My dialogic co-creativity framework described in Chapter 3 makes a central distinction between interaction about the creation (intentions) and through the creation (actions). 

\begin{figure}[H]
 \centering
\includegraphics[width=1\linewidth]{intention action spaces.png}
 \caption{The distinction between the intention space (goals, vision, decisions) and the action space (artefact-level operations).}
 \label{fig:intention-action-spaces}
\end{figure}


The research in this thesis, alongside emerging literature, shows that when interacting
with AI, humans largely assume roles in the intentional space while the AI assumes roles
in the action space. In Chapter 4, I discussed how participants often described their roles in these terms, when interacting with a chat-based AI:

\begin{quote}
"I was the curator of the story—I picked the pieces I liked and left the rest."

"I gave it the idea, and it just took it from there, writing almost everything."

"I gave it the skeleton of the story, and Vorges fleshed it out, almost like giving the recipe and having it cook the dish."

"I asked it to write a paragraph about a dystopian future, and it did everything from there."

"I started with a basic introduction, and Vorges expanded it into a complete narrative."

"Vorges wrote 90\% of the story based on my prompts. I just tweaked it a bit."
\end{quote}

These statements frame the role of the user as that of a curator, director or conceptualiser and the AI as an executor. This observation is corroborated by broader findings in the field. Palani et al. \cite{Palani2024-on}, in their comprehensive review of emerging roles in human-generative AI interaction, found that users increasingly adopt roles at the "Project" level, while AI assumes roles at the "Artifact" level. 


People tended to describe their roles specifically as director, editor, or curator. This echoes
similar findings in the literature. In a systematic review of emerging roles and workflows,
Palani et al. \cite{Palani2024-on} found that users increasingly assume roles at
the "Project" level while AI assumes roles at the "Artifact" level. They noted:

\begin{quote}
    "Users saw themselves as ideators and project managers with a larger creative vision orchestrating information context and tasks across multiple GenAI models instead of traditional workers executing each task."
\end{quote}

Similarly, in a study with musicians using generative AI tools, Suh et al. \cite{Suh2021-cj} described a shift in human roles from "composers" to "producers," "advisors," or "museum curators." One participant articulated this shift by stating: "When AI was present, our roles were more of choosing the ones that sound best and not necessarily building on top of it or creating something of ourselves," while another noted, "I felt like it was the composer and we were the listeners giving feedback and choosing."

These findings in the literature align with practice. The emerging practice of \textit{vibe-coding} was described by AI researcher Andrej Karpathy as prompting an AI to write code, barely being involved in reading or
understanding it:

\begin{quote}
"[I] forget that the code even exists. [...] I barely even touch the keyboard.
[...] The code grows beyond my usual comprehension [...] It's not too bad for
throwaway weekend projects, but still quite amusing. I'm building a project
or webapp, but it's not really coding"
\end{quote}



As Weisz et al. \cite{Weisz2024-io} argue, "Generative AI technologies have introduced a new paradigm of human-computer interaction, what Nielsen refers to as 'intent-based outcome specification'. In this paradigm, users specify what they want, often using natural language, but not how it should be produced."

\subsection{The emergence of severed agency}

A shifting of roles where humans move into the intentional space and AI assumes roles
in the action space introduces a fundamental tension: a disconnect between intention and
action. If we accept the standard definition of agency as intentional action \cite{Schlosser2019-jk}, it is clear how this may affect human creative agency.

Where does the disconnect emerge from? Two sources: first, a difficulty in steering generative AI (the steering problem) and second, a lack of involvement at the action level (the involvement problem). I discuss each one in detail below. 

\subsubsection{The steering problem}

Chapter 5 argued that the main limitation we faced when employing generative AI image tools in a professional creative scenario for the production of magazine visuals was effectively controlling them. In particular, achieving a specific style needed to align with the magazine's identity, controlling the structure of images and maintaining consistency of subject/objects. 

In Chapter 6, when leveraging a large language model to drive a generative soundscape for a new media installation, I outlined how the unpredictability of outputs and the tendency for the model to inexplicably fixate on a small subset of them represented a significant challenge.

In Chapter 4, many of my participants offer an illustrative account. For example, one participant claimed (when describing his experience using ChatGPT to write):

\begin{quote}
    "I've felt frustrated because it's gone in the wrong direction and then requires a lot of input from me to put it on the track that I have in my head"
\end{quote}

Another complained that the interaction "feels somewhat random and not as iterative."

These practical challenges are identified in the literature. \cite{Palani2024-on}, in the study discussed earlier, identified "Aligning and Assessing Stochastic Model Outputs With Intent" and "Articulating creative goals" as two major limitations for the adoption of AI in creative activities. For example, one of their participants remarked:
\begin{quote}
"I was prescriptive in my prompt, and I thought I nailed it. But the model never did, and it still doesn't. That drives me crazy and keeps me surprised, delighted, and sometimes annoyed."
\end{quote}
Another user described the challenge of articulation: "at times, I didn't have the vocabulary to ask the model to help me. I think your background knowledge matters: someone with an art history background knows how to prompt a specific style, unlike someone who doesn't." This difficulty is compounded when attempting to articulate tacit knowledge, such as nuanced style and expertise, within a prompt-based paradigm.

This inherent unpredictability is a notable characteristic of generative AI systems, which \cite{Weisz2024-io} terms "generative variability." While this can, on one hand, introduce surprise and delight, it can also lead to significant annoyance and frustration. As I will discuss, balancing this variability is a core task for interaction design in co-creative systems.

Weisz argues that "With generative AI applications, users will need to develop a new set of skills to work with (not against) generative variability by learning how to create specifications that result in artifacts that match their desired intent." However, from an interaction design perspective, the burden of deducing these skills should not rest solely on the user. Instead, effective interaction design can actively help users navigate the generative variability inherent in these systems, enabling more fluid translation from intention to action.

\subsubsection{The involvement problem}

A second factor contributing to severed creative agency emerges from the user's lack of involvement at the action level of the creative process. When users predominantly assume directive and intentional roles, outsourcing the act-of-doing to the AI, they experience a disconnect that impacts enjoyment, ownership, and contributes to skill erosion. 

Consider the experience of a participant in my Chapter 4 study who used a chat-only interface (Vorges) for writing:

\begin{quote}
"[it] made me feel like I was cheating somehow. It does not feel like my work, even though I gave all the ideas. Also, I believe there is satisfaction in putting a lot of effort/dedication/patience into something. Vorges made everything so simple, fast, and easy that it felt artificial and no real satisfaction came as a result."
\end{quote}

Another participant using the same interface provided a similar account:

\begin{quote}
"I find them to be very interesting, and useful tools in getting a job done quickly, but at the cost of losing a sense of individuality."
\end{quote}

Brian Eno's reflections on using generative tools echo these sentiments:

\begin{quote}
"In my own experience as an artist, experimenting with AI has mixed results. I've used several "songwriting" AIs and similar "picture-making" AIs. I'm intrigued and bored at the same time: I find it quickly becomes quite tedious. I have a sort of inner dissatisfaction when I play with it, a little like the feeling I get from eating a lot of confectionery when I'm hungry. I suspect this is because the joy of art isn't only the pleasure of an end result but also the experience of going through the process of having made it. When you go out for a walk it isn't just (or even primarily) for the pleasure of reaching a destination, but for the process of doing the walking." \cite{Eno2024-rj}
\end{quote}

However, a lack of involvement goes beyond subjective feelings; it can lead to an erosion of skills, limiting the confidence and ability of practitioners to translate their intentions into outputs, and in turn, diminishing their creative agency. A growing body of literature indicates that over-reliance on large language models (LLMs) for writing can result in skill loss \cite{Heersmink2024-mk, Rafner2021-tm}. Gerlich et al. \cite{Gerlich2025-as} found a link between level of usage of AI for writing tasks and a loss of critical thinking skills. More recently, a study by Lee et al. \cite{Lee2025-dw} found that generative AI use among knowledge workers was associated with less cognitive effort and reduced self-confidence. This is particularly impactful for creative agency, as creative self-efficacy, defined as confidence in one's creative ability, is a crucial determinant of creative achievement \cite{Tierney2002-xp}.

In a more recent study by Kosmyna et al. \cite{Kosmyna2025-cm} conducted at MIT, researchers explored the neurological effects of engaging in a creative task using AI by measuring brain activity using Electroencephalography (EEG). They found that, compared to participants using no tools or using web search, those using ChatGPT showed significantly lower levels of brain connectivity and engagement with the task. The participants reported lower levels of ownership of the writing and struggled to quote their own work more than participants in the other groups.

Involvement and immersion are crucial aspects of the creative process \cite{Amabile1996-pt, Csikszentmihalyi1997-ui} and are important dimensions for analysis and design in co-creative systems \cite{Davis2016-te, Cherry2014-ty, Rezwana2022-ui, Clark2018-yf, Lawton2023-gd, Yuan2022-kb, Li2024-yh, Kantosalo2015-pk, Resnick2005-fs}. While emerging capabilities of generative AI offer new possibilities for creating more capable co-creative systems, paradoxically, these same capabilities can provide a path of least resistance towards a type of \textit{creative automation} that negatively impacts human creativity through reduced involvement. 

Balancing this is what I suggest is the \textbf{fundamental tension in human-AI co-creativity}, a trade-off increasingly recognised in the literature \cite{Moruzzi2024-cq}.

In the following section, I discuss how specific strategies from the perspective of interaction design can contribute to this. 

\section{Interaction Design Principles for Human-AI Co-Creativity}

In this section, I outline how each design principle was derived and propose specific guidelines for their practical application. These principles are not intended to be prescriptive or exhaustive, as the scope of this thesis does not allow for that. Rather, they serve as a starting point to address the current lack of guidance for designing human-AI co-creativity. Generative AI capabilities are evolving quickly, and the literature is working to keep pace, exploring how humans can effectively engage with these tools. At the same time, new tools and usage patterns are emerging in practice. By drawing on these developments, alongside my original research and theoretical framing of human-AI co-creativity, I propose five design principles. These may evolve over time, and more may be added. My aim is for them to seed an empirically and practically grounded discussion on how to design more effective co-creative systems.

\begin{tcolorbox}[colback=orange!5,colframe=orange!75!black,title=\textbf{Principle 1: Serendipity}]
\textbf{Description:} Leverage generative variability as a feature to induce surprise and unexpected creative directions.

\textbf{Guidelines:}
\begin{itemize}
\item Provide exploratory interfaces for navigating latent spaces and discovering unexpected outputs
\item Lean into the unique characteristics and "weirdness" of the generative AI medium
\end{itemize}
\end{tcolorbox}


\begin{tcolorbox}[colback=purple!5,colframe=purple!75!black,title=\textbf{Principle 2: Personalisation}]
\textbf{Description:} Enable users to personalise and own their creative style through model training and fine-tuning.

\textbf{Guidelines:}
\begin{itemize}
\item Allow users to train or fine-tune models on their own datasets
\item Support iterative model training processes for dataset curation and refinement
\end{itemize}
\end{tcolorbox}


\begin{tcolorbox}[colback=red!5,colframe=red!75!black,title=\textbf{Principle 3: Expressiveness}]
\textbf{Description:} Enable users to control generation through multiple expressive modalities beyond text.

\textbf{Guidelines:}
\begin{itemize}
\item Enable multimodal inputs for expressive control (images, audio, gestures)
\item Provide expressive interfaces such as moodboards and visual references
\end{itemize}
\end{tcolorbox}

\begin{tcolorbox}[colback=green!5,colframe=green!75!black,title=\textbf{Principle 4: Iteration}]
\textbf{Description:} Support the iterative nature of creative processes through systematic exploration and preservation of creative journeys.

\textbf{Guidelines:}
\begin{itemize}
\item Support iterative workflows that allow incremental changes while maintaining control
\item Provide rich histories and stateful user journeys that preserve creative decisions
\end{itemize}
\end{tcolorbox}

\begin{tcolorbox}[colback=blue!5,colframe=blue!75!black,title=\textbf{Principle 5: Collaboration}]
\textbf{Description:} Enable collaboration both through and about the creation by providing dedicated spaces where humans and AI work together as co-creators.

\textbf{Guidelines:}
\begin{itemize}
\item Provide dedicated collaborative spaces separate from conversation spaces
\item Manage conflicts of territory through edit tracking and highlighting
\item Make clear what the AI can and cannot do by exposing creative primitives
\end{itemize}
\end{tcolorbox}


\subsection{Principle of Serendipity}

Earlier I discussed how severed agency partly emerges from \textit{the steering problem}. Weisz et al \cite{Weisz2024-io} argue that designing generative AI applications largely involves managing generative variability, and propose a set of guidelines to do so. While useful, these strategies focus on \textit{mitigation}. Indeed, this may be necessary in general applications of generative AI. However, in the case of co-creativity, I argue that generative variability can be leveraged as a feature rather than a bug.

Generative variability can become a feature by introducing surprise and serendipity, which are central to creativity \cite{Simon1967-nr, Lubart2001-vl, Grace2015-uc, Moruzzi2022-gp}. Multiple studies show that enabling this is a specific strength of generative AI systems \cite{Lawton2023-tb, Park2024-gw, Koch2020-gx}.

This aligns with observations from my own research. For example, one participant in my study from Chapter 4 remarked:

\begin{quote}
"Vorges is like a creative collaborator or editor with ADHD - not always on point and occasionally disordered, but with no shortage of ideas."
\end{quote}

When describing the value of using the co-writing prototype in Chapter 4, multiple participants stated that its primary value resides in making them feel creative and expanding their perspectives. Many described the usefulness in shifting their perspective and generating new ideas:

\begin{quote}
"Vorges is like the smart academic friend that I go to for creative blocks - they are well versed in history and have a perfect memory from which to shower me with excellent resources and historical references for further exploration of my ideas."
\end{quote}

Similar perspectives are strongly echoed in practice. Creative lead and art director Lucas Crespo writes: 

\begin{quote}
Creative work isn't only about precision. It's about discovery, exploration, and happy accidents that lead to breakthroughs. The more you can induce the feeling of serendipity in a creative tool, the more it keeps me prompting and pushing it to its limits.

As AI advances, I worry we'll optimize too heavily for accuracy at the expense of serendipity. We'll build tools that give us exactly what we ask for, rather than what we didn't know we needed.

The best creative tools should feel like collaborators, not calculators. They should surprise, challenge, and push us in new directions. Working with them should feel more like jamming with a slightly unpredictable bandmate. It's the difference between following a map and exploring without one. 
\end{quote} \cite{Crespo2025-wr}

From the perspective of dialogic co-creativity, inducing serendipity through generative variability may be understood as contributing to mutual influence. Mutual influence and adaptation is not only about the user steering the system (human-to-AI influence). It is also about the AI inducing shifts in perspective and new creative directions (AI-to-human influence). 

\subsubsection{Exploratory interfaces for discovery}

How can we design interactions that promote serendipity? One promising alternative lies in \textbf{exploration-based interfaces}. For instance, a study by \cite{Davis2024-ml} demonstrated that a multimodal interface allowing 2-D exploration of the latent space of fashion designs enabled better ideation than prompt-based text-to-image interfaces, such as the Stable Diffusion tool they tested against. They concluded that "text-only prompts in existing models restrict creative exploration, especially for novices." Their interface allowed users to explore the latent-space of designs along semantically meaningful directions (e.g., sleeve length or pattern) and a style-mixing panel for blending designs. The study found that this interface was reported to be more conducive to ideation than the request-execute interactions found in modern text-to-image systems. 

A study by Koch et al. \cite{Koch2020-gx} testing an ideation tool to support human-computer partnerships evaluated an interface that showed a consistent stream of images, related to the task or not. They found this interface was effective at introducing serendipity and perspective shifts in a creative process by providing a space for divergent exploration.

In practice, Leonardo.ai's Flow State provides an interface that automatically generates prompt variations, enabling guided exploration of possibilities by navigating a stream of images. 

Creativity is often described as a process of exploration \cite{Boden1998-yn, Wiggins2019-yj}. As such, users do not know necessarily what they want to find in advance: they discover it as they explore. However, prompt and request-based interfaces require users to explicitly state it. Generative AI models encode latent spaces of creative possibilities. Interfaces can make their navigation more explicit. If creativity is an exploration of a conceptual space, co-creativity between humans and AI can be a co-exploration of a latent space.  

\subsubsection{Lean into the medium}

Another way to address the challenge of generative variability, particularly in divergent creative stages, is by \textbf{leaning into the unique characteristics of the generative AI medium itself}. As Brian Eno puts it:

\begin{quote}
Whatever you now find weird, ugly, uncomfortable and nasty about a new medium will surely become its signature. CD distortion, the jitteriness of digital video, the crap sound of 8-bit - all of these will be cherished and emulated as soon as they can be avoided \cite{Eno2007-fl}.
\end{quote}

As such, highlighting rather than hiding the weirdness and uniqueness of the output may be creatively useful. As one participant in my study in Chapter 4 highlighted:

\begin{quote}
"I also love its figurative language and descriptions because of how they kinda just don't make sense. I left that in on purpose because I love the idea of a curious nose and a perpetually second-hand jacket."
\end{quote}

This sentiment is echoed in the literature. Sloan \cite{Sloan2016-fj}, reflecting on his creative process with a generative language model, noted that: "The goal is not to make the resulting text "better"; it's to make it different—weirder, with effects maybe not available by other means." Similarly, Samuel, discussing her experience with language models and citing Du Sautoy \cite{Samuel2019-gc}, argues that art often enhances our perception by "making the familiar strange." She posits that AI can be an incredible tool for writers precisely because:

\begin{quote}
"it's great at defamiliarizing our world. The human-ish language it generates can startle us into seeing things anew, so we can in turn jolt readers awake through that sense of -ish."
\end{quote}

In my case study with the AFR magazine (Chapter 5), this was precisely our intention: to use the AI system to create "impossible photography". As the editorial team described \cite{Drummond2023-av}:

\begin{quote}
"They are both uncanny and yet slightly unreal. All have the distinctive fuzzy texture of AI images, as if they were drawn. Our prompts were very minimal and the output hints at the way AI is learning 21st-century human culture."
\end{quote}

Akin to how photography spurred impressionism to explore what the human eye sees rather than what the lens captures, generative AI can offer a unique lens to reframe what \textit{we are seeing} by \textit{seeing what the algorithm sees}. As such, rather than seeking exact realism, or perfect adherence, the strength may be in deviating from the norm. 

In my Chapter 6 data sonification examples leveraging an LLM, we largely engage the AI by exploiting and eliciting unique, uncanny language, offering an affective quality. The creative intention, partly, was to induce the audience to perceive the surrounding context anew through the algorithm's unique lens.

Lastly, Crespo's practical account of his usage of generative AI tool MidJourney for creative direction provides a valuable account. He describes that "embracing AI's imperfections led to breakthrough creative work" and further: 

\begin{quote}
Prompting Midjourney isn't deterministic, with a straightforward input-output. It's probabilistic and rewards discovery. It requires patience and curiosity. You can't send one prompt and await perfection. 
[...]
Take Every's visual style—the final direction wasn't something I planned for; it was something Midjourney and I were able to discover together.
\end{quote} \cite{Crespo2022-ty}


\subsection{Principle of Personalisation}

 As discussed in Chapter 6, an iterative approach to model training was crucial for achieving our desired visual outcomes. By iteratively training models on curated datasets, evaluating outputs, and refining the data, we were able to steer the generative process towards specific likenesses and visual intentions. This iterative training process enhanced control, allowing for a more precise alignment with the editorial team's vision. As they noted in an article covering the process \cite{Drummond2023-bh}, "The fact that you can train Stable Diffusion – by limiting or controlling the inputs it draws upon – makes it better [at consistently generating what we intended]".

Furthermore, combining this training with an image-to-image workflow provided additional control over structure and composition. The distinction between a specialised, user-trained model (Stable Diffusion) and a generalist model to generate references (Midjourney) highlighted the value of training models to specific creative needs.

Training models with custom datasets can be an integral part of a human-AI co-creative process. As the author Robin Sloan described when building and using a generative AI co-creator for writing: \cite{Sloan2016-fj}. 

\begin{quote}
So, a large part of the work (and fun) of applying the deep learning scenesters' hard-won technical triumphs to weird/fun objectives is tracking down non-standard, non-boring datasets. For me, decisions about the collection and processing of the text corpus have been more consequential than decisions about the RNN's design and subsequent training.
\end{quote}

Enabling users to train their own models or fine-tune existing ones is becoming a more widespread practice that is proving effective in practice. Training "LoRA" models \footnote{https://www.leonardo.ai} and Exactly.ai\footnote{https://www.exactly.ai} allow users to generate content in their unique style and have been a core feature driving their adoption. In the case of Exactly.ai, users can train models on their own work, and monetise them based on third-party usage while retaining copyright of the outputs.

From the perspective of dialogic interaction, this process can be understood as contributing to mutual understanding, by helping the user understand better how the model works. Particularly through multiple rounds of dataset curation and training, users can form a more robust mental model of the latent space of the model; its space of possibilities.

\subsection{Principle of Expressiveness}

Another strategy for enhancing user control is by allowing users to express intentions by \textit{showing, not only telling}. Earlier, I discussed how it is difficult to articulate tacit knowledge such as style and expertise in text-only interfaces. This is often recognised as a limitation of generative AI. For example, a study by Park et al. \cite{Park2024-gw} titled "We are visual thinkers, not verbal thinkers!" analysing how designers use generative AI tools found that one of their main struggles was to convey visual intentions through text.

Multimodal inputs offer promise for more expressive interaction. For example, in Chapter 5 I described how we leveraged image references to drive more granular control of the outputs, as shown in Figure  \ref{fig:ai_generation_workflow}. Doing this exclusively with language would have been impossible. 

\begin{figure}[htbp]
    \centering

    % First subfigure - Control network workflow
    \begin{subfigure}[b]{\textwidth}
        \centering
        \includegraphics[width=0.9\textwidth]{controlnetworkflow.png}
        \caption{Workflow used to extract characteristics of an image used as reference. The reference image was generated in a software that better aligned with the aesthetic intent and then used to drive the generation of another model trained on the character's likeness.}
        \label{fig:controlnetworkflow}
    \end{subfigure}


    % Second subfigure - Input/Output comparison
    \begin{subfigure}[b]{\textwidth}
        \centering
        \includegraphics[width=0.9\textwidth]{inputoutput.png}
        \caption{Using a generated image as reference allowed us to achieve the desired result.}
        \label{fig:inputoutput}
    \end{subfigure}

    \caption{AI image generation workflow showing the process of extracting visual characteristics from reference images and applying them to generate target subjects with desired aesthetic qualities.}
    \label{fig:ai_generation_workflow}
\end{figure}

However, creatives often do not work with a single specific reference; they are often targeting a more general aesthetic. For example, designers often curate moodboards that seek to capture a general intention as a starting point. Interfaces that accommodate this process can be effective. In a study by Peng et al. \cite{Peng2024-tr}, the authors described an interface that allows designers to curate mood-boards consisting of colour palettes, images, and text, and use it to drive generation. This interface, they found, allowed designers "explore and express themselves more effectively" than text-to-image tools.

\begin{figure}
    \centering
    \includegraphics[width=1\linewidth]{designprompt.png}
    \caption{DesignPrompt: a moodboard tool by \cite{Peng2024-tr} allowing designers to search images, compose multimodal prompts with images, colors, semantics, and text, and "finely tune their intentions."}
    \label{fig:enter-label}
\end{figure}

The most effective dialogic interfaces may be hybrid ones, combining text and conversation with multimodal inputs, allowing users to switch between expressing ideas through language and by showing examples. This mirrors how humans collaborate in creative tasks; for example, when musicians can't articulate an idea, they simply play it.


\subsection{Principle of Iteration}

A key component of creative processes is iteration.  As an illustrative example, consider Figure \ref{fig:albo_series}, from the case study in Chapter 5. We were satisfied with one of the initial outputs, shown on the left, but wished to make a minor modification: for the subject to be smiling. Despite a seemingly small change which involved a single word addition to the prompt, the resulting image changed significantly. While the general scene and subject's position were retained, a suit jacket was unexpectedly added, and the overall contrast of the image shifted. 

\begin{figure}[H]
    \centering
    \includegraphics[width=1\linewidth]{alboexperiments.png}
    \caption{Screen-grab from my experiments log from the AFR case study, fixing some parameters while varying others. This example illustrates the difficulty of iterating with generative models. The intention was to change the facial expression of the subject, adding a single word to the prompt while using ControlNets to condition the generation. However, clothing was added, and the brightness and contrast of the image changed as well.}
    \label{fig:albo_series}
\end{figure}

Indeed, this lack of support for the iterative nature of creative processes is often cited by professional creatives as a core limitation. It stems partly from generative variability, and the model's inherent capabilities, but it can also be addressed from the perspective of interaction design. In particular, interaction design can help maintain rich histories so that at least practitioners can better form a mental model of how inputs map to outputs. 

In their "Design Principles for Tools to Support Creative Thinking", Resnick et al \cite{Resnick2005-fs} include the need for rich-history keeping. Similarly, in their Design Principles for Generative AI Applications, Weisz et al. \cite{Weisz2024-io} propose guidelines to manage generative variability that can serve as useful strategies to enable more iterative workflows. Specifically: visualising the user's journey, supporting curation and annotation and highlighting differences or variations across outputs.

Emerging communities of practice are already addressing this through the creation of guides to navigate latent spaces, primarily by systematically documenting input-output relationships in controlled experiments \cite{Smith2022-dm}. In my own research, particularly in case studies 5 and 6, I maintained detailed research journals to track how specific prompts related to their respective outputs; Chapter 6 further elaborates on these experiments.

So while there is a clear need for interfaces that help users move through the process in an iterative, journey-keeping manner, interfaces in generative AI applications remain significantly limited in affording this. For example, my journaling practice emerged primarily as a response to the systems' lack of such an interface. In the case of the image generation case study in Chapter 5, the systems I used merely generate galleries of images that make it difficult to track different paths throughout the journey. In the case of my Chapter 6 case studies, I engaged in trial-and-error to understand how different prompts to the language model led to different outputs. Similarly, the interface was limited in affording an iterative and branching exploration.

How could these interfaces look? Consider, for example Lee's experimental interface for language generation, which allows the user to visualise alternative paths based on modifying and weighing attributes in the generated text. 

\begin{figure}[H]
    \centering
    \includegraphics[width=1\linewidth]{linuslee.png}
    \caption{Lee's experimental prototype of an interface that allows user to change and weight attributes to generate variations}
    \label{fig:linusleebranching}
\end{figure}


Contrast this with the type of linear and sequential interface afforded by the prevalent mode of interaction with LLM-powered chatbots. These interfaces enable sequential iteration, but it may be difficult to go back and explore a different direction if needed (a recommended principle by Resnick et al \cite{Resnick2005-fs}).  When describing their interactions with ChatGPT to write, participants from the user studies in Chapter 4 provide useful illustrations. One participant expressed:

\begin{quote}
"I've felt frustrated because it's gone in the wrong direction and then requires a lot of input from me to put it on the track that I have in my head."
\end{quote}

Another simply notes that the process "feels somewhat random and not as iterative", while another elaborated:

\begin{quote}
"ChatGPT will always rewrite the entire passage to change just one paragraph, and it is harder to work on one text as input as I often need to scroll back up to see it or continually copy and paste it."
\end{quote}

Beyond branching interfaces that maintain rich histories, an alternative for more iterative co-creation is interfaces that provide a stateful space for collaboration, separate from the conversational space. In such a space, users and AI can collaboratively edit, go back to previous versions. Users can refine outputs from the AI and vice-versa. In the next section, I discuss the advantages and challenges of such an interface, which I developed and explored as part of a prototype tested in Chapter 4. 

\subsection{Principle of Collaboration}

In the previous section I discussed the need for interfaces and interactions that afford iterative processes. One such interface is that of collaborative shared spaces, separate from the conversational space, that allows users to iteratively collaborate on a creation with the AI. In the case of my research, this involved an exploration in the context of co-creative writing. 

However, beyond the potential for more iterative process, an important advantage of such an interface is that it can increase the level of involvement of the user in the writing level. As I discussed in my Chapter 4, conversational interfaces have become the predominant form of interaction with large language models since the launch of ChatGPT. 

This, on one hand, provided support to a central hypothesis of this thesis: that dialogic, back-and-forth communication with a generative AI can contribute to a co-creative interaction. Indeed, this hypothesis was posed before the launch of ChatGPT and the subsequent proliferation of such interfaces as the dominant form of interaction. 

However, on the other hand, the adoption of these interfaces as the dominant mode illustrates the many challenges of interaction with generative AI systems exclusively through conversational interfaces. Specifically: such interfaces primarily afford the user to assume intentional roles, providing requests, feedback and other instructions, while the AI does the actual writing. Simply, this is partly due to a lack of a dedicated collaborative space. As such, the user becomes less involved in the process, and to a degree, alienated from it, describing their interaction with a chat-based system.

\begin{quote}
"[it] made me feel like I was cheating somehow. It does not feel like my work, even though I gave all the ideas. Also, I believe there is satisfaction in putting a lot of effort/dedication/patience into something. Vorges made everything so simple, fast, and easy that it felt artificial and no real satisfaction came as a result."
\end{quote}

\begin{figure}[H]
    \centering
    \includegraphics[width=1\linewidth]{sharededitor.png}
    \caption{The shared editor prototype, combining a chat with a direct manipulation space.}
    \label{fig:shared-editor}
\end{figure}

To address these challenges, I developed a prototype that implemented both a conversational chat-interface and an integrated collaborative editor, shown in figure \ref{fig:shared-editor}. This interface better supported users having a dialogue both \textit{through} the creation and \textit{about} the creation. As a result, they described more balanced roles, and they engaged more in the action space rather than acting primarily in the intentional space. Moreover, it led to higher reported levels of ownership, involvement and agency, as illustrated by some of the participant statements provided below.

\begin{quote}
"I really-really enjoyed writing this. I even had a deep moment of reflection, my writing was nostalgic and sad, but I was able to use AI to steer it in the right direction, it gave me confidence that I was also writing with correct grammar and spelling, English is not my first language and while I am proficient, I can still use proofreading to ensure good quality, this tool helped me with it." (P4 Common AI)
\end{quote}

Others shared similar perspectives:

\begin{quote}
 "I liked how my original ideas were still retained, and AI was used to complement my intentions. It forced me to put in some effort and do the majority of the work."
\end{quote}

\begin{quote}
    "It adds an element of working together, which I think is the moral problem with current AI tools—they often seem like they're doing all the work."
\end{quote}

\begin{quote}
    "It was much better than ChatGPT. I enjoyed how it gave me a lot more agency." 
\end{quote}

\begin{quote}
    "I really enjoyed it; it still let me have autonomy."
\end{quote}

When comparing the experience with that of using ChatGPT, one participant stated:

\begin{quote}
"It can just be a bit clunky having a separate document to then copy, paste, and edit in [in ChatGPT]. This made it super seamless being in the one program."
\end{quote}


\subsubsection{The need for visibility of contributions}

While participants generally reported greater involvement when using a shared collaborative space, a recurring theme was their need for improved visibility into the AI's edits and how these changes impacted their own work.

One participant stated:
\begin{quote}
 "When you ask the AI to check your grammar (as I did), it would be good if it told me what suggestions it had made, so I can double check its work easier."
\end{quote}

Another participant commented:
\begin{quote}
    "I am unsure as what parts of the text are being edited, in the end I am not quite sure which parts were mine and which ones were edited by AI."
\end{quote}

While a third one highlighted: 

\begin{quote}
"Once the tool has made revisions to the original text, maybe it can highlight the key changes that have been made... otherwise I need to slowly read through and identify the changes myself."
\end{quote}

Related to the need for managing contributions, one participant in fact found it easier to use chat-based interfaces:
\begin{quote}
[...] in an AI chatbox, usually you would parse through the original text copy into the chat, and the chat would then spit out a new copy, makes it a bit easier to edit/cut out any additions you don't like.
\end{quote}

This challenge of managing contributions in shared collaborative spaces is described by Buschek et al. \cite{Buschek2021-ks} as "conflicts of territory" in their "Nine Potential Pitfalls when Designing Human-AI Co-Creative Systems." To mitigate this, Buschek et al. suggest tracking user edits to protect them and highlighting AI-introduced changes, precisely as the participants quotes above suggested.

\subsubsection{Cursor: an example of managing contributions effectively}

How can interfaces that manage contributions effectively be implemented? A valuable example is Cursor \footnote{https://https://www.cursor.com/}. Cursor is a relatively recently launched tool which integrates both a conversational interface with a shared collaborative space. It is positioned as a collaborative programmer, embedded directly into a coding editor (a fork of VS Code). A critical functionality in Cursor is that it can make targeted edits to the code and highlight the changes it has made, and it provides users the ability to accept, reject and backtrack to previous versions. 

Naturally, incorporating such features adds complexity to the design of co-creative tools. In the second prototype developed for Chapter 4, this was precisely the focus: managing how the AI introduced edits into the text. While the prototype did not implement edit highlights, the intention was to enable the AI to make direct, single-word edits without rewriting entire sections. This approach aimed to prevent the AI from inadvertently altering text the user had already revised. To achieve this, a protocol was created, allowing the AI to target specific edits within a single text.

\subsubsection{Make clear what the collaborator can and cannot do}

A last consideration worth discussing related to the implementation of hybrid interfaces implementing a chat and a shared collaborative space. Such interfaces may result in confusion for the user, as it is not clear exactly what the AI collaborator can and cannot do within the collaborative space. In my Chapter 4 co-writing studies, users expressed a need for better visibility of what sort of operations the AI could do. They highlighted potential for drop-down menu's with options, pre-written prompts, and triggering of specific actions with GUI elements. They also highlighted the need for better clarity regarding when a response would appear in the chat and when it would become a contribution in the editor. 

These observations highlight a point I discussed within my literature review: how clear visibility of the capabilities and limitations of the generative AI system is crucial for effective use of them. Moreover, addressing this through interfaces that make these affordances visible is consistent with established usability principles \cite{Nielsen1994-df}. In the more recent context of generative AI, it means implementing the intention-oriented, action-oriented, outcome-oriented interfaces \cite{Weisz2024-io, Schaad2025-ca} which focus on tightly packaging generative actions that users operate with. 


\section{A final consideration on the shifting of roles}

While throughout this conclusion I characterised a lack of involvement in the action space as undesirable from a creative agency perspective, it could be argued that users engaging in intentional roles allows them to \textbf{focus on more conceptual aspects of the creative process}, and with this, \textbf{augment their creative agency}. It could also be interpreted as leveraging generative AI to fill a skill gap to reach \textbf{optimal point between challenge and skill} that Csikszentmihalyi describes as necessary for \textbf{creative flow} \cite{Csikszentmihalyi1997-ui}. As one participant in my writing study described about interacting with Vorges, the AI co-writer: "I like it a lot. I think that it allowed me to focus on the ideas, the plot and the characters even more because Vorges focused on the writing."

Moreover, it can be argued that users focusing on higher level tasks is akin to a producer who is meaningfully and productively involved by simply providing nudges to musicians, as famed producers Brian Eno and Rick Rubin have been described doing. In fact, when describing his thoughts on the future of AI and creativity, Rick Rubin explicitly argued for this perspective \cite{Rubin2025-sc}. In contrast, Brian Eno argues that focusing only on giving instructions to the AI system is alienating from the process itself and the derived satisfaction. However, in his own creative practice with non-AI generative art, Eno describes himself as a gardener, who plants seeds for generative art to work \cite{Eno2007-fl}. 

How can this differing perspectives from two prolific creative professionals engaging primarily at the intention levels in their creative practice be reconciled? I argue the answer lies in the process. More specifically in the dynamic of the involvement, regardless of whether it predominantly occurs in the intentional space (planning, conceptualising) or the action space (direct execution). The key is that they engage in an iterative process, rather than a one-off generation request. In other words, in a dialogic interaction where there is an iterative formation of understanding and influence between human and the generative AI system. 

An illustrative example is Jason Allen's \textit{Théâtre D'opéra Spatial}. Allen submitted an image generated with MidJourney to a digital art competition, and won first place. When it was revealed that the artwork was generated with a generative AI software, controversy and claims of plagiarism argued this was not his creation. However, he claimed his process involved dozens of hours iterating over hundreds of prompts, as well as a final step of image editing in traditional software. 

Later on, the US Copyright Office rejected his application for copyright over the piece, arguing it was unclear how much was Allen's work and how much "was AI" \cite{US-Copyright-Office-Review-Board2023-nw}. I argue the copyright office view fails to recognise that the process of iterating over the prompts was itself the process of creation, and it is not significantly different than other images generated with procedural software means (as other submissions in the competition were). 

Indeed, prompting is emerging as a creative practice in its own right, with engaged communities developing idiosyncratic approaches to it \cite{Chang2023-tv, Smith2022-dm}. Prompting, or the expression of an intention, can be understood as an action at a higher level of abstraction. With this framing, the shift in role distribution described throughout can be understood as the tendency to "move up" levels of abstraction when computational primitives at lower levels are automated. This has been the case, for example, with programming languages. In the context of generative AI, Carter and Nielsen \cite{Carter2017-xj} argue that its potential value in augmenting human intellect lies in providing new cognitive primitives at increasingly higher levels of abstraction, much like a calculator automates the laboriousness of long division so that humans operate with "long division" as a basic unit. Extending this, I argue that generative artificial intelligence may be understood, at least partly, as providing a set of new \textit{creative primitives}.

Creative involvement, therefore, may mean operating fluidly with these creative primitives. The role of the interaction designer largely becomes making these creative primitives visible and operational. 

\section{Closing Remarks and Future Directions}

This thesis found that current interaction design paradigms primarily afford users to engage in intentional roles, directing and requesting work from the AI, while the AI assumes roles in the action space. This division contributes to what I term severed agency, a disconnect between intention and action in creative activities. This disconnection stems from difficulties in steering and a lack of user involvement at the action level.

Throughout this research, I examined the potential of dialogic interaction for designing more effective human-AI co-creative systems. I developed a framework for dialogic co-creativity, a novel contribution to HCI literature, which was shaped within the context of an Australian Research Council project focused on exploring dialogic creative AI.

At the beginning of this research, current forms of generative AI were in early stages. Interaction often involved running a model to generate unconditioned outputs. However, almost in parallel with the development of this thesis, interaction with generative AI in practice gradually began to shift towards more dialogic forms. Text-based prompt interfaces allowed for more natural language control. The launch of ChatGPT marked a pivotal point. Today, interaction with generative AI is increasingly converging towards conversational interfaces. 

On one hand, this transition validated part of our original hypothesis: that dialogic interaction could support richer human-AI creative collaboration. On the other hand, it made, at times, this research appear trivial. 

But as usage progressed, the limitations of these interfaces became more visible. Among them: chat-based systems still privilege a linear, directive interaction model where humans engage about but not through a co-creative process. As such, they primarily automate rather than co-create. 

A growing body of research highlights the consequences. Increased usage of chatbot as such can lead to cognitive skill degradation, which can be observed both psychologically and neurologically. Moreover, enjoyment, ownership and feelings of agency in the creative process can be diminished. 

As such, the other elements of dialogic interaction beyond conversation offered alternatives. Dialogic co-creativity involves interaction through and about the artefact. It requires an iterative formation of understanding, and a mutual adaptation throughout the creative process.

This calls for new interfaces and new modes of interaction. I implemented one such alternative detailed in Chapter 4: a hybrid prototype in 2023 that integrated a chat window with a collaborative text editor with the objective of facilitating interaction through and about the writing process; dedicated spaces for communication and collaboration.  This interface showed users were more involved in the creative process, reported more agency and ownership of the work, 

Important limitations were also highlighted. Even in this hybrid setting, users in general still agreed that AI did most of the work. Compared to the chat-only interface this was tested against, they simply agreed with this less. This specific observation warrants further research. One possibility is that this outcome reflects the fundamental tension in human-AI co-creativity. By providing a path of least resistance, AI may naturally encourage automation of creative tasks.

Yet from both my research and practice, I believe this does not tell whole story. In these studies, users were incentivised to participate. They were not writing for the intrinsic pleasure of the activity. This would point towards the idea that different interactions may be needed for different contexts, use cases, and users. 

These will likely go beyond the current local optimal of conversational and request-based interfaces. As I argued above, they will involve interactions that support serendipity, personalisation, expressiveness, iteration and collaboration.

The outcomes of this research offer an invitation to interaction designers, developers, artists, and creatives to imagine new forms of interaction with emerging computational intelligences beyond the current paradigm. 

These works aimed not to replace human roles but to expand them, allowing the AI to adopt unfamiliar and productive positions in the creative process. Even if challenges in control and iteration remained, new media practices suggest that leaning into the constraints and character of the medium often yields the most interesting results.

Of course, requirements shift across contexts. Commercial creative practices may demand more control and predictability, as was the case in Chapter 5, where magazine visuals needed to align with a specific intent. In such contexts, the balance between control and randomness, between steering and surprise, will differ. 

The breadth of case studies explored in this thesis suggests the elusiveness of overarching single best way for designing co-creative systems. Context matters, user and use case matters. Outlining the specifics offers a rich opportunity for future research. 

As AI becomes embedded in everyday life, designing effective co-creative systems will become increasingly crucial. The principles and frameworks developed in this thesis offer both theoretical understanding and practical guidance for creating systems that maintain human agency while leveraging the creative potential of generative AI. The journey from severed agency to effective co-creativity will represent a fundamental reimagining of how humans and machines interact. As artificial intelligence grows in capability, addressing this will become one of the defining challenges of our time.
