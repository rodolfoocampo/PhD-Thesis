\chapter[Conclusion]{Conclusion}\label{c:conclusion}

To begin this conclusion, I would like to briefly summarise the research so far. In Chapter 1, I argued that generative AI opens the possibility for human-AI co-creativity. While there are design principles for guiding interaction between humans and computers in multiple scenarios, no such principles exist yet for the case of human-AI co-creativity.

As a general starting point, I argued that dialogic interaction offers a promising approach. While prevailing modes of interaction centre around command-execute paradigms, co-creativity with generative AI systems calls for a computer-in-dialogue approach: one where humans and AI engage in iterative cycles of mutual influence and understanding. Particularly, I sought to investigate how interaction design can enable roles assumed by humans and AI that are co-creative, and understand how different interaction design decisions influence the roles assumed.

With this, I defined, in Chapter 1, the core aim of this thesis as to investigate and enable human-AI co-creativity, maintaining human agency while effectively leveraging the creative potential of this technology.

The following three research questions were proposed to guide this enquiry:

\begin{quote}
\textbf{Sub-Questions:}
\begin{itemize}
    \item \emph{R1: How does interaction design influence the role that humans and AI play in creative production?}
    \item \emph{R2: What is the potential of modelling dialogue in interaction design to enable effective humanâ€“AI co-creativity?}
    \item \emph{R3: Which interaction design principles can guide the development of effective co-creative systems?}
\end{itemize}
\end{quote}

I examined these questions through a mix of approaches. These included a thorough review of the literature and practice, which developed at a rapid pace as a response to rapidly changing technology throughout this thesis. I then engaged in a practice-based research approach through case studies, and through prototype-led user studies. With this, I investigated human-AI co-creativity from a practical perspective -- my own creative practice in collaboration with others -- and from an interaction design research perspective, testing interaction design approaches with users from a qualitative and quantitative perspective.

In Chapter 3, I laid the theoretical foundations that guided my inquiry from the perspective of dialogic interaction: I defined dialogic co-creativity as a human-computer interaction concept, comprising six elements: iterative interaction, bidirectional communication, a shared collaborative space, context-awareness, mutual influence and mutual understanding. Importantly, I established that a core component of dialogue is that it can happen both \textit{about} the creation (discussing goals, providing feedback) and \textit{through} the creation (writing words, playing notes, drawing lines). The subsequent research was traversed with these components as a navigational lens, investigating how each one can be implemented, and how it contributes to the effectiveness of co-creativity.

In the same Chapter 3, I presented an early exploration of the role of dialogue and dialogic capabilities of language model systems, exploring the role and capacity of these systems to engage in bidirectional communication. Notably, this experiment was conducted before the launch of ChatGPT, which has made conversational interaction the default.

In Chapter 4, I noted that while bidirectional interaction in chat interfaces enables a more dialogic interaction than linear prompting systems, they are still limited in affording interaction both through and about the creation: instead, the interface biases the user to merely provide instructions and feedback rather than engage at the writing level. Based on this, I developed a prototype implementing a \textbf{shared collaborative space} in addition to a chat window. With this, humans and AI could both converse about the writing, and edit it collaboratively. I found that this interface led to higher levels of active involvement and ownership at the writing level, though questions remain about how to implement these collaborative interfaces to effectively manage contributions.

In Chapter 5, I turned my attention to professional creative practice, investigating the challenges of leveraging generative AI image systems in real-world scenarios. I collaborated with the Australian Financial Review to produce visual materials for one of their issues, including the cover of the magazine and the cover of the weekly paper. Throughout this exploration, I found the main challenges for the usability of these tools are their inability to afford iterative workflows, maintaining consistency of subjects, objects, and scenes, and the difficulty in steering them.

In Chapter 6, I turned to my own creative practice, and described two case studies that involve the collaborative production of two new media installations leveraging large language models to drive the generation of real-time audiovisual soundscapes from environmental data. With this, I explored the possibilities of generative AI to assume novel roles in creative practice, affording new creative operations. In particular, serving as a semantic translation bridge between complex environments and generative artworks. Throughout this case study, similar challenges related to iteration and control were revealed.

In this conclusion, I provide an in-depth discussion to answer the research questions. As the reader may be aware, the field of generative AI, and how people interact with them in creative activities has changed rapidly through the period of this thesis (late 2021 to early 2025). This was both an opportunity and challenge for my research. By combining original research with an analysis of these developments in practice and the emerging literature, I believe a clear argument emerges.

In the rest of this conclusion, I will discuss in depth how this argument unfolds. First, I will provide the core argument extracted from this research. I will then discuss how interaction design influences the roles humans and AI play (R1). Following this, I present the interaction design principles for human-AI co-creativity (R3), informed by my framework of dialogic co-creativity (R2).


\section{Core argument}

This thesis argues that prevailing modes of interaction with generative AI in creative activities induce a clear role distribution: Humans operate within the \textit{intentional space}, where creative goals, visions, and high-level decisions reside, while AI takes on roles in the \textit{action space}, where artefact-level operations such as drawing, writing words, or playing notes occur.

I argue this role distribution presents challenges to maintaining human agency through what I term \textbf{severed creative agency}: a disconnect between creative intentions and action. This severing emerges from two main sources. First, a difficulty in steering generative systems through linear prompt-response interaction. Second, it emerges from a lack of involvement by the user at the action level: they become instructors and directors outsourcing creative production rather than active co-creators.

I argue that a dialogic interaction paradigm offers potential to arrive at more co-creative role distributions by enabling an iterative mutual adaptation and understanding, where humans and AI interact iteratively both through and about the creation.

To operationalise this, I combine the findings from my research studies, with emerging literature and with observations from practice, to provide a set of design principles that can inform the development of co-creative systems.

The principles are provided below for clarity, and the discussion that derives them is presented below.

\begin{tcolorbox}[colback=blue!5,colframe=blue!75!black,title=\textbf{Principle 1: Collaboration}]
\textbf{Description:} Enable collaboration both through and about the creation by providing dedicated spaces where humans and AI work together as co-creators.

\textbf{Guidelines:}
\begin{itemize}
\item Provide dedicated collaborative spaces separate from conversation spaces
\item Manage conflicts of territory through edit tracking and highlighting
\item Make clear what the AI can and cannot do by exposing creative primitives
\end{itemize}
\end{tcolorbox}

\begin{tcolorbox}[colback=green!5,colframe=green!75!black,title=\textbf{Principle 2: Iteration}]
\textbf{Description:} Support the iterative nature of creative processes through systematic exploration and preservation of creative journeys.

\textbf{Guidelines:}
\begin{itemize}
\item Support iterative workflows that allow incremental changes while maintaining control
\item Provide rich histories and stateful user journeys that preserve creative decisions
\end{itemize}
\end{tcolorbox}

\begin{tcolorbox}[colback=orange!5,colframe=orange!75!black,title=\textbf{Principle 3: Serendipity}]
\textbf{Description:} Leverage generative variability as a feature to induce surprise and unexpected creative directions.

\textbf{Guidelines:}
\begin{itemize}
\item Provide exploratory interfaces for navigating latent spaces and discovering unexpected outputs
\item Lean into the unique characteristics and "weirdness" of the generative AI medium
\end{itemize}
\end{tcolorbox}

\begin{tcolorbox}[colback=purple!5,colframe=purple!75!black,title=\textbf{Principle 4: Personalisation}]
\textbf{Description:} Enable users to personalise and own their creative style through model training and fine-tuning.

\textbf{Guidelines:}
\begin{itemize}
\item Allow users to train or fine-tune models on their own datasets
\item Support iterative model training processes for dataset curation and refinement
\end{itemize}
\end{tcolorbox}

\begin{tcolorbox}[colback=red!5,colframe=red!75!black,title=\textbf{Principle 5: Expressiveness}]
\textbf{Description:} Enable users to control generation through multiple expressive modalities beyond text.

\textbf{Guidelines:}
\begin{itemize}
\item Enable multimodal inputs for expressive control (images, audio, gestures)
\item Provide expressive interfaces such as moodboards and visual references
\end{itemize}
\end{tcolorbox}


\section{How Interaction Design Influences Roles and Agency}

At the beginning of this thesis, I introduced a fundamental distinction: interaction in co-creativity can occur both \textit{about} the creation and \textit{through} the creation. Prompt-response interaction paradigms, which are currently prevalent, primarily afford interaction \textit{about} the artifact rather than \textit{through} it. Building upon this initial distinction, I argue that we can understand creativity as a dynamic process of navigating two distinct and interconnected spaces: the \textbf{intention space} and the \textbf{action space}.

The \textbf{intention space} encompasses the acts and stances \textit{about} the artifact, such as establishing goals, expressing taste, making decisions, providing directions, and formulating the overall intention to express. Conversely, the \textbf{action space} involves potential operations \textit{on} and \textit{through} the artifact itself, like writing words, playing notes, or drawing lines. In both individual and collaborative creative processes, humans iteratively move between these two spaces.

For example, \cite{Csikszentmihalyi1997-ui} describes a self-reinforcing feedback loop between actions and evaluations. He posits that a clear feedback signal about how actions contribute to a goal is crucial for achieving \textbf{flow}, which he observes among creative professionals when their actions and awareness of those actions virtually merge. Similarly, SchÃ¶n \cite{Schon1987-fy} introduces the concept of \textbf{reflection-in-action}, where professionals, including creatives, continuously reshape their understanding of a situation (intention) and their actions within it (action) throughout the process. SchÃ¶n \cite{Schon1992-jt} further suggests that in practice, the distinction between thinking and doing collapses into an iterative, embodied dialogue, akin to a "conversation with the materials," where the artifact "talks back," and the practitioner listens and responds. The creative act is fundamentally a reciprocal shaping between action and intention.

\begin{figure}[H]
 \centering
\includegraphics[width=1\linewidth]{intention action spaces.png}
 \caption{The distinction between the intention space (goals, vision, decisions) and the action space (artefact-level operations).}
 \label{fig:intention-action-spaces}
\end{figure}

\subsection{A differential role distribution: humans in the intentional space, AI in the action space}

Throughout my research, and supported by emerging literature, I have observed a consistent pattern in human-AI interaction: humans predominantly take actions \textit{about} the artifact, while AI largely takes actions \textit{through} the artifact. This leads to a distinct \textbf{role distribution}, directly addressing my first research question (R1): humans increasingly assume roles primarily situated in the \textbf{intention space}, while AI occupies roles within the \textbf{action space}.

This separation of roles is evident in how users describe their involvement. For instance, in Chapter 4, participants articulated their experiences in ways that clearly reflect this dynamic:

\begin{quote}
"I was the curator of the storyâ€”I picked the pieces I liked and left the rest."

"I gave it the idea, and it just took it from there, writing almost everything."

"I gave it the skeleton of the story, and Vorges fleshed it out, almost like giving the recipe and having it cook the dish."

"I asked it to write a paragraph about a dystopian future, and it did everything from there."

"I started with a basic introduction, and Vorges expanded it into a complete narrative."

"Vorges wrote 90\% of the story based on my prompts. I just tweaked it a bit."
\end{quote}

These statements frame the role of the user as that of a curator, director or conceptualiser and the AI as an executor. This observation is corroborated by broader findings in the field. Palani et al. \cite{Palani2024-on}, in their comprehensive review of emerging roles in human-generative AI interaction, found that users increasingly adopt roles at the "Project" level, while AI assumes roles at the "Artifact" level. They noted, "Users saw themselves as ideators and project managers with a larger creative vision orchestrating information context and tasks across multiple GenAI models instead of traditional workers executing each task."

Similarly, in a study with musicians using generative AI tools, Suh et al. \cite{Suh2021-cj} described a shift in human roles from "composers" to "producers," "advisors," or "museum curators." One participant articulated this shift by stating, "When AI was present, our roles were more of choosing the ones that sound best and not necessarily building on top of it or creating something of ourselves," while another noted, "I felt like it was the composer and we were the listeners giving feedback and choosing."

This phenomenon is further exemplified by what AI researcher Andrej Karpathy termed \textbf{"vibe-coding"}: a practice where users prompt an AI to write code with minimal involvement in reading or understanding it.

\begin{quote}
"There's a new kind of coding I call "vibe coding", where you fully give in to the vibes, embrace exponentials, and forget that the code even exists. It's possible because the LLMs (e.g. Cursor Composer \footnote{https://cursor.sh} w Sonnet) are getting too good. Also I just talk to Composer with SuperWhisper so I barely even touch the keyboard. I ask for the dumbest things like "decrease the padding on the sidebar by half" because I'm too lazy to find it. I "Accept All" always, I don't read the diffs anymore. When I get error messages I just copy paste them in with no comment, usually that fixes it. The code grows beyond my usual comprehension, I'd have to really read through it for a while. Sometimes the LLMs can't fix a bug so I just work around it or ask for random changes until it goes away. It's not too bad for throwaway weekend projects, but still quite amusing. I'm building a project or webapp, but it's not really coding - I just see stuff, say stuff, run stuff, and copy paste stuff, and it mostly works." \cite{Karpathy2025-uu}
\end{quote}

As Weisz et al. \cite{Weisz2024-io} argue, "Generative AI technologies have introduced a new paradigm of human-computer interaction, what Nielsen refers to as 'intent-based outcome specification'. In this paradigm, users specify what they want, often using natural language, but not how it should be produced."

\subsection{The emergence of severed agency}

Agency, in its standard definition, is characterised by \textit{intentional action} \cite{Schlosser2019-jk}. It involves a dual constraint: an actor with an intention but unable to act accordingly lacks full agency. Conversely, a person is made to act in a certain way without the intention to do so also has limited agency. 

This emergent role distribution, where humans operate primarily in the intention space and AI in the action space, can lead to what I term \textbf{severed creative agency}: a disconnect between a human's creative intentions and their ability to translate them into actions. This happens for two reasons. First, the difficulty in steering generative models effectively. Second, due to reduced involvement in the action space. Below, I discuss them in detail, and their implications. 


\subsubsection{Challenge #1: Steering and Controlling Generative Outputs}

Chapter 5 argued that the main limitation we faced when employing generative AI image tools in a professional creative scenario for the production of magazine visuals was effectively controlling them. In particular, achieving a specific style needed to align with the magazine's identity, controlling the structure of images and maintaining consistency of subject/objects. 

In Chapter 6, when leveraging a large language model to drive a generative soundscape for a new media installation, I outlined how the unpredictability of outputs and the tendency for the model to unexplainably fixate on a small subset of them represented a significant challenge.

In Chapter 4, many of my participants offer an illustrative account. For example, one participant claimed (when describing his experience using ChatGPT to write):

\begin{quote}
    "I've felt frustrated because it's gone in the wrong direction and then requires a lot of input from me to put it on the track that I have in my head"
\end{quote}

Another complained that the interaction "feels somewhat random and not as iterative."

These practical challenges are identified in the literature. \cite{Palani2024-on}, in the study discussed earlier, identified "Aligning and Assessing Stochastic Model Outputs With Intent" and "Articulating creative goals" as two major limitations for the adoption of AI in creative activities. For example, one of their participants remarked:
\begin{quote}
"I was prescriptive in my prompt, and I thought I nailed it. But the model never did, and it still doesn't. That drives me crazy and keeps me surprised, delighted, and sometimes annoyed."
\end{quote}
Another user described the challenge of articulation: "at times, I didn't have the vocabulary to ask the model to help me. I think your background knowledge matters: someone with an art history background knows how to prompt a specific style, unlike someone who doesn't." This difficulty is compounded when attempting to articulate tacit knowledge, such as nuanced style and expertise, within a prompt-based paradigm.

This inherent unpredictability is a notable characteristic of generative AI systems, which \cite{Weisz2024-io} terms "generative variability." While this can, on one hand, introduce surprise and delight, it can also lead to significant annoyance and frustration. As I will discuss, balancing this variability is a core task for interaction design in co-creative systems.

Weisz argues that "With generative AI applications, users will need to develop a new set of skills to work with (not against) generative variability by learning how to create specifications that result in artifacts that match their desired intent." However, from an interaction design perspective, the burden of deducing these skills should not rest solely on the user. Instead, effective interaction design can actively help users navigate the generative variability inherent in these systems, enabling more fluid translation from intention to action.

\subsubsection{Source of Severed Creative Agency 2: A Lack of Involvement in the Creative Process}

A second factor contributing to severed creative agency emerges from the user's lack of involvement at the action level of the creative process. When human users predominantly assume directive and intentional roles, outsourcing the act-of-doing to the AI, they experience a disconnect that impacts enjoyment, ownership, and contributes to skill erosion. 

Consider the experience of a participant in my Chapter 4 study who used a chat-only interface (Vorges) for writing:

\begin{quote}
"[it] made me feel like I was cheating somehow. It does not feel like my work, even though I gave all the ideas. Also, I believe there is satisfaction in putting a lot of effort/dedication/patience into something. Vorges made everything so simple, fast, and easy that it felt artificial and no real satisfaction came as a result."
\end{quote}

Another participant, using the same interface, described their experience this way:

\begin{quote}
"I find them to be very interesting, and useful tools in getting a job done quickly, but at the cost of losing a sense of individuality."
\end{quote}

Brian Eno's reflections on using generative tools echo these sentiments:

\begin{quote}
"In my own experience as an artist, experimenting with AI has mixed results. I've used several "songwriting" AIs and similar "picture-making" AIs. I'm intrigued and bored at the same time: I find it quickly becomes quite tedious. I have a sort of inner dissatisfaction when I play with it, a little like the feeling I get from eating a lot of confectionery when I'm hungry. I suspect this is because the joy of art isn't only the pleasure of an end result but also the experience of going through the process of having made it. When you go out for a walk it isn't just (or even primarily) for the pleasure of reaching a destination, but for the process of doing the walking." \cite{Eno2024-rj}
\end{quote}

However, a lack of involvement goes beyond subjective feelings; it can lead to an erosion of skills, limiting the confidence and ability of practitioners to translate their intentions into outputs, and in turn, diminishing their creative agency. A growing body of literature indicates that over-reliance on large language models (LLMs) for writing can result in skill loss \cite{Heersmink2024-mk, Rafner2021-tm}. Gerlich et al. \cite{Gerlich2025-as} found a link between level of usage of AI for writing tasks and a loss of critical thinking skills. More recently, a study by Lee et al. \cite{Lee2025-dw} found that generative AI use among knowledge workers was associated with less cognitive effort and reduced self-confidence. This is particularly impactful for creative agency, as creative self-efficacy, defined as confidence in one's creative ability, is a crucial determinant of creative achievement \cite{Tierney2002-xp}.

In a more recent study by Kosmyna et al. \cite{Kosmyna2025-cm} conducted at MIT, researchers explored the neurological effects of engaging in a creative task using AI by measuring brain activity using Electroencephalography (EEG). They found that, compared to participants using no tools or using web search, those using ChatGPT showed significantly lower levels of brain connectivity and engagement with the task. The participants reported lower levels of ownership of the writing and struggled to quote their own work and reported lower levels of ownership of the essay.

Involvement and immersion are crucial aspects of the creative process \cite{Amabile1996-pt, Csikszentmihalyi1997-ui} and are important dimensions for analysis and design in co-creative systems \cite{Davis2016-te, Cherry2014-ty, Rezwana2022-ui, Clark2018-yf, Lawton2023-gd, Yuan2022-kb, Li2024-yh, Kantosalo2015-pk, Resnick2005-fs}. While generative AI offers new possibilities for creating more powerful and useful co-creative systems, supporting and augmenting human creativity collaboratively, paradoxically, these capabilities can provide a path of least resistance towards a type \textit{creative automation} that negatively impacts human creativity. However, as I will argue in subsequent sections, this is partly mediated by interaction design. 

Balancing this is what I suggest is the \textbf{fundamental tension in human-AI co-creativity}.

Moruzzi and Margarido \cite{Moruzzi2024-cq} have similarly highlighted this trade-off:

\begin{quote}
    "In this scenario, there is a pressing need to examine the terms of the balance between automation and agency in H-AI interaction to continue reaping the benefits of increased efficiency resulting from the automatization of repetitive and burdensome tasks, preserving at the same time the sense of agency, control, and responsibility of users."
\end{quote}

But beyond automation of repetitive tasks, generative AI can enable new creative possibilities, and synergistically support human creativity. This is arguably its most significant potential. Artists can explore new visual possibilities difficult through other means. Everyday people can have more ideas. Scientists can make new discoveries. Resource-limited creatives can produce their visions with less resources.

In the following section, I discuss how specific strategies from the perspective of interaction design can contribute to this. 

\section{Interaction Design Principles for Human-AI Co-Creativity}

\subsection{Principle of Serendipity}

While \cite{Weisz2024-io} propose that users need to develop skills to work with generative variability, they also offer interaction design guidelines to help users manage it, such as leveraging multiple outputs, visualising the user journey, enabling annotation, and drawing attention to differences between outputs. While useful, these strategies primarily focus on \textit{mitigating} generative variability, as their guidelines are aimed at general uses of generative AI across multiple fields. I argue that in the context of co-creativity, generative AI variability does not always need to be mitigated; instead, it can be strategically leveraged as a feature rather than a bug.

A crucial way generative variability can become a feature is by introducing surprise and serendipity. Multiple studies consistently show that the introduction of surprise and serendipity is often referred to as a positive attribute of co-creative interaction with generative systems \cite{Lawton2023-tb, Chiou2023-vr, Louie2020-aq, Moruzzi2022-gp, Park2024-gw, Koch2020-gx}.

This aligns with observations from my own research. For example, one participant in my study remarked:

\begin{quote}
"Vorges is like a creative collaborator or editor with ADHD - not always on point and occasionally disordered, but with no shortage of ideas."
\end{quote}

When describing the value of using the co-writing prototype in Chapter 4, multiple participants stated that its primary value resides in making them feel creative and expanding their perspectives. Many described the usefulness in shifting their perspective and generating new ideas:

\begin{quote}
"Vorges is like the smart academic friend that I go to for creative blocks - they are well versed in history and have a perfect memory from which to shower me with excellent resources and historical references for further exploration of my ideas."
\end{quote}

Sloan \cite{Sloan2016-fj} when describing his experience using an LLM-based co-author, described: "it's like writing with a deranged but very well-read parrot on your shoulder."

\subsubsection{Exploratory interfaces for discovery}

So, while the value of generative AI in inducing surprise and serendipity is well recognised, how can we design interactions that effectively leverage them? One promising alternative lies in \textbf{exploration-based interfaces}. For instance, a study by \cite{Davis2024-ml} demonstrated that a multimodal interface allowing 2D exploration of the latent space of fashion designs enabled better ideation than prompt-based text-to-image interfaces, such as the Stable Diffusion tool they tested against. They concluded that "text-only prompts in existing models restrict creative exploration, especially for novices." Their interface implemented various exploratory interactions, with central components being a latent-space exploration panel allowing users to move through designs along semantically meaningful directions (e.g., sleeve length or pattern) and a style-mixing panel for blending designs. This iterative process of exploration and remixing better afforded ideation than the request-execute interactions found in more modern text-to-image systems. 

In a study testing an ideation tool to support human-computer partnerships during a creative task, \cite{Koch2020-gx} tested an interface of cascading images that consistently showed a slow stream of images, related to the task or not. They found this interface was effective at introducing "serendipity" and perspective shifts in a creative process by providing a space for divergent exploration, compared to prompt-only text-to-image interfaces.

This aligns with broader understandings of creativity as a process of exploration \cite{Boden1998-yn, Wiggins2019-yj}. Given that the \textit{latent space} encoded in generative AI models can be understood as a space of potentiality \cite{Schaerf2024-gf}, generative AI systems may enable a more direct implementation of this process through interfaces that embody this metaphor. Therefore, \textbf{exploratory interfaces, as opposed to purely request-based interfaces}, can be highly effective in leveraging generative variability to induce shifts in perspective, particularly during ideation and divergent creative phases. 


\subsubsection{Lean into the medium}

Another way to address the challenge of generative variability, particularly in divergent creative stages, is by \textbf{leaning into the unique characteristics of the generative AI medium itself}. As Brian Eno puts it:

\begin{quote}
    Whatever you now find weird, ugly, uncomfortable and nasty about a new medium will surely become its signature. CD distortion, the jitteriness of digital video, the crap sound of 8-bit - all of these will be cherished and emulated as soon as they can be avoided \cite{Eno2007-fl}.
\end{quote}

For generative artificial intelligence, this means recognizing that its unique features, particularly its capacity for unexpected and occasionally "weird" outputs, can become valuable. My own participants offered similar perspectives:

\begin{quote}
"I also love its figurative language and descriptions because of how they kinda just don't make sense. I left that in on purpose because I love the idea of a curious nose and a perpetually second-hand jacket."
\end{quote}

This sentiment is echoed in the literature. Sloan \cite{Sloan2016-fj}, reflecting on his creative process with a generative language model, noted that: "The goal is not to make the resulting text "better"; it's to make it differentâ€”weirder, with effects maybe not available by other means." Similarly, Samuel, discussing her experience with language models and citing Du Sautoy \cite{Samuel2019-gc}, argues that art often enhances our perception by "making the familiar strange." She posits that AI can be an incredible tool for writers precisely because:

\begin{quote}
"it's great at defamiliarizing our world. The human-ish language it generates can startle us into seeing things anew, so we can in turn jolt readers awake through that sense of -ish."
\end{quote}

In my case study with the AFR magazine (Chapter 5), this was precisely our intention: to use the AI system to create "impossible photography"â€”images that were uncanny and slightly unreal, possessing the distinctive "fuzzy texture" of AI-generated visuals. As the editorial team described \cite{Drummond2023-av}:

\begin{quote}
"They are both uncanny and yet slightly unreal. All have the distinctive fuzzy texture of AI images, as if they were drawn. Our prompts were very minimal and the output hints at the way AI is learning 21st-century human culture."
\end{quote}

Akin to how photography spurred impressionism to explore what the human eye sees rather than what the lens captures, generative AI can likewise allow users to induce perspective shifts, contributing to the circularity in human-AI mutual influence. Its "weirdness" and strange artifacts offer a unique lens to understand what \textit{we are seeing} by \textit{seeing what the algorithm sees}. 

In my Chapter 6 data sonification examples leveraging an LLM, we largely engage the AI by exploiting and eliciting unique, uncanny language, offering an affective quality. The creative intention, partly, was to induce the audience to perceive the surrounding context anew through the algorithm's unique lens.

\subsection{Principle of Personalisation}

While the previous section highlighted the role of generative variability and its potential to introduce serendipity, effective co-creative systems must also provide users with a complementary degree of control. 

One strategy for enhancing user control over generative outputs involves enabling the training and fine-tuning of models. As demonstrated in Chapter 6, an iterative approach to model training was crucial for achieving desired visual outcomes in a professional creative context. By iteratively training models on curated datasets, evaluating outputs, and refining the data, we were able to steer the generative process towards specific likenesses and visual intentions. This iterative training process enhanced control, allowing for a more precise alignment with the editorial team's vision, as they noted in an article covering the process \cite{Drummond2023-bh}, "The fact that you can train Stable Diffusion â€“ by limiting or controlling the inputs it draws upon â€“ makes it better [at consistently generating what we intended]".

Furthermore, combining this training with an image-to-image workflow provided additional control over structure and composition. The distinction between a specialised, user-trained model (Stable Diffusion) and a generalist model to generate references (Midjourney) highlighted the value of tailoring models to specific creative needs.

Similar practices are observed in other creative domains. Sloan's work training LLM-based co-creators offers an illustrative example \cite{Sloan2016-fj}. 

\begin{quote}
So, a large part of the work (and fun) of applying the deep learning scenesters' hard-won technical triumphs to weird/fun objectives is tracking down non-standard, non-boring datasets. For me, decisions about the collection and processing of the text corpus have been more consequential than decisions about the RNN's design and subsequent training.
\end{quote}

Enabling users to train their own models or fine-tune existing ones is becoming a more widespread practice that is proving effective in practice. Tools like Leonardo AI's LoRA training \footnote{https://www.leonardo.ai} and Exactly.ai\footnote{https://www.exactly.ai} allow users to generate content in their unique style and have been a core feature driving their adoption. In the case of Exactly.ai, users can train models on their own work, and monetise them based on third-party usage while retaining copyright of the outputs.

From the perspective of dialogic interaction, this process can be understood as contributing to mutual understanding, by helping the user understand better how the model works. Particularly through multiple rounds of dataset curation and training, users can form a more robust mental model of the latent space of the model; its space of possibilities.

\subsection{Principle of Expressiveness}

Another way to provide controls beyond text is by allowing users to express intentions by \textit{showing, not only telling}. Earlier, I discussed how it is difficult to articulate tacit knowledge such as style and expertise in text-only interfaces. This is often recognised as a limitation of generative AI. For example, a study by Park et al. \cite{Park2024-gw} titled "We are visual thinkers, not verbal thinkers!" analysing how designers use generative AI tools found that one of their main struggles was to convey visual intentions through text.

Multimodal inputs offer a promising approach such an approach. For example, in Chapter 5 I described how we leveraged image reference to drive the outputs, as shown in Figure  \ref{fig:ai_generation_workflow}.


\begin{figure}[htbp]
    \centering

    % First subfigure - Control network workflow
    \begin{subfigure}[b]{\textwidth}
        \centering
        \includegraphics[width=0.9\textwidth]{controlnetworkflow.png}
        \caption{Workflow used to extract characteristics of an image used as reference. The reference image was generated in a software that better aligned with the aesthetic intent.}
        \label{fig:controlnetworkflow}
    \end{subfigure}


    % Second subfigure - Input/Output comparison
    \begin{subfigure}[b]{\textwidth}
        \centering
        \includegraphics[width=0.9\textwidth]{inputoutput.png}
        \caption{Using a generated image as reference allowed us to achieve the desired result.}
        \label{fig:inputoutput}
    \end{subfigure}

    \caption{AI image generation workflow showing the process of extracting visual characteristics from reference images and applying them to generate target subjects with desired aesthetic qualities.}
    \label{fig:ai_generation_workflow}
\end{figure}

However, creatives often do not work with a single specific reference; they are often targeting a more general aesthetic. For example, designers often curate moodboards that seek to capture a general intention as a starting point. Interfaces that accommodate this process can be effective. In a study by Peng et al. \cite{Peng2024-tr}, the authors described an interface that allows designers to curate mood-boards consisting of colour palettes, images, and text, and use it to drive generation. This interface, they found, allowed designers "explore and express themselves more effectively" than text-to-image tools.

\begin{figure}
    \centering
    \includegraphics[width=1\linewidth]{designprompt.png}
    \caption{DesignPrompt: a moodboard tool by \cite{Peng2024-tr} allowing designers to search images, compose multimodal prompts with images, colors, semantics, and text, and "finely tune their intentions."}
    \label{fig:enter-label}
\end{figure}

The most effective dialogic interfaces may be hybrid ones, combining text and conversation with multimodal inputs, allowing users to switch between expressing ideas through language and by showing examples. This mirrors how humans collaborate in creative tasks; for example, when musicians can't articulate an idea, they simply play it.

\subsection{Principle of Iteration}

A key component of creative processes is iteration. However, generative variability and a lack of precise control often makes this process notably difficult. In a study with creatives using generative AI tools Park et al. found one of the core limitations they highlighted was support for the iterative nature of creative processes \cite{Park2024-gw}. The same limitation was identified in my own research. 

As an illustrative example, consider Figure \ref{fig:albo_series}, from Chapter 5. We were satisfied with one of the initial outputs, shown on the left, but wished to make a minor modification: for the subject to be smiling. Despite a seemingly small change (a single word addition to the prompt with identical settings) the resulting image changed significantly. While the general scene and subject's position were retained, a suit jacket was unexpectedly added, and the overall contrast of the image shifted. 

\begin{figure}[H]
    \centering
    \includegraphics[width=1\linewidth]{alboexperiments.png}
    \caption{Screen-grab from my experiments log from the AFR case study, fixing some parameters while varying others. This example illustrates the difficulty of iterating with generative models. The intention was to change the facial expression of the subject, adding a single word to the prompt while using ControlNets to condition the generation. However, clothing was added, and the brightness and contrast of the image changed as well.}
    \label{fig:albo_series}
\end{figure}


Effective iterative refinement is partly a challenge at the model level, but interaction design can help users better understand how inputs map to outputs. Emerging communities of practice are already addressing this through the creation of guides to navigate latent spaces, primarily by systematically documenting input-output relationships in controlled experiments \cite{Smith2022-dm}. In my own research, particularly in case studies 5 and 6, I maintained detailed research journals to track how specific prompts related to their respective outputs; Chapter 6 further elaborates on these experiments.

\begin{figure}[H]
\centering
\includegraphics[width=0.8\linewidth]{linus.png}
\caption{Linus Lee's experimental interface for exploring creative possibilities.}
\label{fig:linus}
\end{figure}

This journaling practice emerged primarily due to the system's limited capability to afford this type of interaction history keeping. Several authors have argued for the need for this. Various design approaches exist to achieve this, such as tree-like visual interfaces that clearly depict branching paths of inputs and outputs, thereby preserving extensive generative histories. This approach aligns closely with Resnick et al.'s recommendations in their "Design Principles for Tools to Support Creative Thinking" \cite{Resnick2005-fs} of rich history keeping. Figure \ref{fig:linus} presents a prototype embodying this principle. Similarly, Weisz et al. propose design principles for generative AI applications, including: visualising the user's journey, supporting curation and annotation and highlighting differences or variations across outputs.

From a dialogic perspective, systematic record-keeping directly supports the development of robust mental models of the system, contributing to the user's understanding of the model's behaviour.

\begin{figure}[H]
\centering
\includegraphics[width=0.8\linewidth]{latentspacemanip.png}
\caption{Prototype by Michael Feldstein for intuitive latent space manipulation.}
\label{fig:feldstein}
\end{figure}

In the context of language generation and co-writing, chat-only interfaces can also restrict users' capacity to iterate effectively by not enabling a space to edit the text. Users frequently express frustration with linear message streams. One participant described their frustration with ChatGPT, noting the process "feels somewhat random and not as iterative." Another participant elaborated:

\begin{quote}
"ChatGPT will always rewrite the entire passage to change just one paragraph, and it is harder to work on one text as input as I often need to scroll back up to see it or continually copy and paste it."
\end{quote}

A third participant highlighted:

\begin{quote}
"I've felt frustrated because it's gone in the wrong direction and then requires a lot of input from me to put it on the track that I have in my head."
\end{quote}


In the next section, I detail how I investigated the potential of an interface that implements both a collaborative space and space for conversation to address this. 

\subsection{Principle of Collaboration}

Conversational dialogic interfaces have become the predominant form of interaction with large language models, highlighting both the value of dialogic interaction in practice and its challenges related to co-creativity. My research found that these interfaces tend to position users in a directive, requesting role, effectively outsourcing the writing process. This positioning leads to a lack of involvement, particularly when users engage with chat-only interfaces without a space for stateful collaboration through the writing itself.

Recall the participant's statement highlighted at the beginning of this conclusion:

\begin{quote}
"[it] made me feel like I was cheating somehow. It does not feel like my work, even though I gave all the ideas. Also, I believe there is satisfaction in putting a lot of effort/dedication/patience into something. Vorges made everything so simple, fast, and easy that it felt artificial and no real satisfaction came as a result."
\end{quote}

To address these challenges, this thesis found promise in separating collaborative spaces from conversational spaces, enabling users and AI to collaborate in the action space, interacting \textit{through} the creation and not only \textit{about} the creation. The interface is shown in figure \ref{fig:shared-editor}. As discussed in Chapter 4, this approach led to users reporting that the AI did most of the work less frequently. They also reported higher levels of involvement and agency:


\begin{figure}[H]
    \centering
    \includegraphics[width=1\linewidth]{sharededitor.png}
    \caption{The shared editor prototype, combining a chat with a direct manipulation space.}
    \label{fig:shared-editor}
\end{figure}

\begin{quote}
"I really-really enjoyed writing this. I even had a deep moment of reflection, my writing was nostalgic and sad, but I was able to use AI to steer it in the right direction, it gave me confidence that I was also writing with correct grammar and spelling, English is not my first language and while I am proficient, I can still use proofreading to ensure good quality, this tool helped me with it." (P4 Common AI)
\end{quote}

Others shared similar perspectives:

\begin{quote}
P9 shared: "I liked how my original ideas were still retained, and AI was used to complement my intentions. It forced me to put in some effort and do the majority of the work."

P22 emphasized: "It adds an element of working together, which I think is the moral problem with current AI toolsâ€”they often seem like they're doing all the work."
\end{quote}

Participants reported increased agency: P18 said, "It was much better than ChatGPT. I enjoyed how it gave me a lot more agency." P12 remarked, "I really enjoyed it; it still let me have autonomy."

A participant highlighted the limitations of ChatGPT, comparing it with an AI co-writer integrated within a text editor:

\begin{quote}
P5 said: "It can just be a bit clunky having a separate document to then copy, paste, and edit in [in ChatGPT]. This made it super seamless being in the one program."
\end{quote}

While participants generally reported greater involvement when using a shared collaborative space, a recurring theme was their need for improved visibility into the AI's edits and how these changes impacted their own work.

\begin{quote}
Participant 11: "When you ask the AI to check your grammar (as I did), it would be good if it told me what suggestions it had made, so I can double check its work easier."

Another participant commented: "I am unsure as what parts of the text are being edited, in the end I am not quite sure which parts were mine and which ones were edited by AI."

"Once the tool has made revisions to the original text, maybe it can highlight the key changes that have been made... otherwise I need to slowly read through and identify the changes myself."
\end{quote}
Participants also highlighted a significant limitation:
\begin{quote}
The one limitation I would say is that if you don't like what the AI has integrated you need to manually remove it from the only source of text you have (the one you are sharing with the AI). Whereas in an AI chatbox, usually you would parse through the original text copy into the chat, and the chat would then spit out a new copy, makes it a bit easier to edit/cut out any additions you don't like.
\end{quote}

These challenges in collaborative spaces are described by Buschek et al. \cite{Buschek2021-ks} as "conflicts of territory" in their "Nine Potential Pitfalls when Designing Human-AI Co-Creative Systems." These conflicts arise in co-creative spaces when the AI destructively edits user-generated content, or when the user's changes to AI-generated text are subsequently reverted by the AI. To mitigate this, Buschek et al. suggest tracking user edits to protect them and highlighting AI-introduced changes.

\subsubsection{Cursor: an example of managing contributions effectively}
An excellent example of a tool that successfully integrates a collaborative shared space with a conversational interface is Cursor \footnote{https://cursor.sh}. Cursor's value largely stems from its ability to share a coding space with the user. When the AI offers suggestions or contributions, it presents them as diffs that users can accept or reject. This also allows users to revert changes and maintain version control, much like traditional coding environments.

Naturally, incorporating such features adds complexity to the design of co-creative tools. In the second prototype developed for Chapter 4, this was precisely the focus: managing how the AI introduced edits into the text. While the prototype did not implement edit highlights, the intention was to enable the AI to make direct, single-word edits without rewriting entire sections. This approach aimed to prevent the AI from inadvertently altering text the user had already revised. To achieve this, a protocol was created, allowing the AI to target specific edits within a single text.

\subsubsection{Make clear what the collaborator can and cannot do}

When users possess a clear understanding of what the system can and cannot do (its visible creative primitives) they can engage with it more effectively and meta-cognitively discern which actions to delegate to the system and which to undertake themselves. In my literature review, I outlined how the effectiveness of human-AI interaction hinged largely on the user's ability to grasp the system's underlying mechanisms: visibility. In my Chapter 4 co-writing studies, a similar qualitative observation emerged: users expressed a benefit from having more clarity about the kinds of things they could do with chatbots for co-creation, and from having direct ways of triggering certain operations (e.g., providing feedback, generating text, providing suggestions). This points towards the need for a direct manipulation GUI that explicitly triggers creative actions, aligning with Weisz and Nielsen's call for intention-oriented, action-oriented, or outcome-oriented interfaces. In co-creative and generative systems, the 'primitives' are not static objects but dynamic processes and actions. Consequently, making these creative primitives transparent and actionable is of significant importance for fostering truly effective and deeply involved human-AI interaction.

\section{A final discussion on emerging roles: is it involvement at higher level of abstraction?}

While throughout this conclusion I characterised a lack of involvement in human-AI co-creation as inherently negative, it could be argued that users engaging in intentional roles allows them to focus on more conceptual aspects of the creative process, and with this, augment their creative agency. As one participant in my writing study described about interacting with Vorges, the AI co-writer: "I like it a lot. I think that it allowed me to focus on the ideas, the plot and the characters even more because Vorges focused on the writing."

This perspective aligns with a crucial role in co-creativity, such as that of a producer who is meaningfully and productively involved by simply providing nudges to musicians, as famed producers Brian Eno and Rick Rubin have been described doing. In fact, producer Rick Rubin explicitly argued that this is precisely the benefit of using generative AI in creative processes. In contrast, Brian Eno argues that focusing only on giving instructions to the AI system is alienating from in the process itself and the derived satisfaction. However, in his own creative practice with non-AI generative art, Eno describes himself as a gardener, who plants seeds for generative art to work \cite{Eno2007-fl}. 

A question arises: can one be considered \textbf{meaningfully involved} when acting primarily at the intentional level? I argue the answer lies in the nature and dynamic of the involvement, regardless of whether it predominantly occurs in the intentional space (planning, conceptualising) or the action space (direct execution). If the user engages in a one-off linear command-execute creation, we may consider them uninvolved. However, if they engage in an iterative cycle of mutual influence and understanding with the system (dialogic), we may consider them more involved, even if their involvement occurred primarily at the intentional level.

An illustrative example is Jason Allen's \textit{ThÃ©Ã¢tre D'opÃ©ra Spatial}, which won first place at a digital art fair but generated controversy when it was revealed to have been generated with the MidJourney software. Later on, the US Copyright Office rejected his application for copyright over the piece, arguing it was unclear how much was Allen's work and how much "was AI" \cite{US-Copyright-Office-Review-Board2023-nw}. Allen argued he was highly involved in the process, iterating hundreds of prompts over dozens of hours. For him, the image was generated by him no different from how other artists use digital software. We can argue he is merely using a different brush. In this case, prompting may be considered not only \textit{intention} but \textit{action}, simply at a higher level of abstraction.  Indeed, prompting is emerging as a creative practice in its own right, with engaged communities developing idiosyncratic approaches to it, using generative models as the creative medium \cite{Chang2023-tv, Smith2022-dm}.

It can be further argued that the process Jason Allen engaged in was to a degree, dialogic, as it involved mutual influence and understanding, engaging in a "conversation with the material" as SchÃ¶n describes. A similar thing can be said about the process of curating datasets and training and prompting generative models described in Chapter 6. In contrast, users engaging with conversational interfaces may engage in less dialogic interaction, even if it appears dialogic by virtue of involving a conversation. For example, some participants in my Chapter 4 co-writing study who engaged with a conversational AI system, described it as doing "everything", simply providing a request and having it generate the rest. Notably, little iterative interaction was reported. 

A core element for dialogic interaction, then, is the iterative building of mutual influence and understanding towards the production of something imbued with a strong intention, whatever the means. 

\subsection{Creative Primitives and Users Operating at a Higher Level of Abstraction}

The shift in role distribution described throughout can be understood as the tendency to "move up" levels of abstraction when computational primitives at lower levels are automated. Carter and Nielsen \cite{Carter2017-xj} argue that the value of generative artificial intelligence in augmenting human intellect lies in providing new cognitive primitives, much like a calculator automates the laboriousness of long division so that humans operate with "long division" as a basic unit. Extending this, I argue that generative artificial intelligence may be understood, at least partly, as providing a set of new \textit{creative primitives}.

When the user is deeply involved at this higher level of abstraction operating on these primitives, their intentional space can \textit{transform into a new action space}. My Chapter 6 example illustrates this: prompting the language model to translate incoming data into actions can be understood through the lens of operating on new creative primitives. Translating data into sound is the creative unit I operated with. I composed this unit with other units in the installation to driving visuals and generative text. This positioned me in the role of workflow orchestrator, building and connecting generative and non-generative nodes as creative primitives. As Palani described, as a finding from a systematic review, this is increasingly the role identified for creative practitioners engaging with generative models: that of orchestrator and builder of generative workflow \cite{Palani2024-on}. 

Increasingly, tools are building interactions and interfaces that specifically accommodate this type of role, moving beyond linear prompts or conversational interfaces. For example, ComfyUI \footnote{https://github.com/comfyanonymous/ComfyUI} is a popular open-source system that allows users to build complex workflows of different generative tools, with users developing personal and idiosyncratic approaches to combining the input-output of diverse generative systems across modalities as creative primitives. Tools like Flora \footnote{https://flora.ai} enable similar operations for less technically and coding-proficient advanced users, providing a comparable workflow-building interface targeted at designers and artists. Similarly, Leonardo.ai's workflow building tool and blueprints \footnote{https://www.leonardo.ai} seek to provide compositional workflow-building tools that give more control and involvement to the user beyond simpler prompt interfaces.

\subsection{Involvement and paths of least resistance}

It is important to clarify that while shared collaborative spaces might increase user involvement, this doesn't mean users are completely hands-on. In my studies, participants using either the shared space (chat + shared editor) or the chat-only interface both largely agreed that the AI did most of the work.

The key difference was the degree of agreement. Participants using the shared text editor showed less agreement with that statement compared to those using the chat-only interface. However, in both scenarios, the general sentiment was that the AI handled the bulk of the work; it was just significantly less pronounced in the shared space. As Figure \ref{fig:graphsharedspaces} illustrates, while chat-only interfaces saw higher agreement with the statement "AI did most of the work," agreement was still high across both interfaces. In essence, even with greater involvement in the collaborative editor interface, users still perceived the AI as doing most of the heavy lifting. This is an instance of what I described earlier as the fundamental tension in human-AI Co-Creativity.

\begin{figure}
\centering
\includegraphics[width=1\linewidth]{graphsharedspaces.png}
\caption{Agreement levels with the statement "AI did most of the work" across chat-only and chat + shared editor interfaces.}
\label{fig:graphsharedspaces}
\end{figure}

A similar phenomenon can be observed with tools like Cursor. Even though Cursor is integrated directly into a shared coding environment and carefully manages conflicts of territory through features like diffs, accepts, and rejects, its AI's ability to handle coding often leads users to outsource much of the work. The "vibe coding" reference I mentioned earlier, made by Andrej Karpathy, specifically referred to using Cursor. This suggests that even when using a deeply integrated tool like Cursor, users may still primarily operate at an intentional level (deciding what should be done) rather than at an action level (actively performing the coding tasks).

\section{Contribution and Future Directions}

This thesis contributes to the emerging field of human-AI co-creativity by providing a set of interaction design principles derived from empirical research and practice-based inquiry. The principles presented here stem from systematic observation of the roles emerging in human-AI creative interaction, analysed through a dialogic perspective and contextualised within my own research and creative practice. Rather than being prescriptive or absolute, these principles are descriptive of patterns observed across multiple studies and domains, aiming to inform the design of future co-creative systems by highlighting key considerations around involvement, territory, and dialogic interaction.

The primary contribution lies in identifying and addressing the challenge of severed creative agency that emerges from current interaction paradigms. By characterising the role distribution where humans operate primarily in the intention space while AI occupies the action space, this work provides a theoretical framework for understanding how interaction design influences creative agency. The five principlesâ€”Collaboration, Iteration, Serendipity, Personalisation, and Expressivenessâ€”offer practical guidance for designing systems that maintain human involvement while effectively leveraging AI's creative potential.

However, these principles should not be considered final or comprehensive. They would benefit significantly from input and validation from the broader interaction design community and practice. The principles emerged from my specific research context and creative practice, and their generalisability across different creative domains and contexts remains to be established. Future work should explore how these principles manifest across diverse creative practices, from visual arts to music composition, from writing to design.

Several key areas warrant further investigation. Longitudinal studies examining how co-creative relationships evolve over extended periods of use would provide valuable insights into the sustainability and development of human-AI creative partnerships. Research should investigate how different interface paradigms beyond current conversational and shared-editor models might support meaningful involvement. The role of AI as a creative primitiveâ€”enabling new forms of creative expression through workflow orchestration and compositionâ€”warrants deeper exploration.

Critical questions remain about balancing automation and involvement across different user skill levels and creative contexts. The fundamental tension identified in this workâ€”between leveraging AI's capabilities and maintaining human creative agencyâ€”requires nuanced approaches that may vary significantly across domains and user populations. Further work is needed on how to design for productive creative tension rather than simply optimising for ease of use.

The design community should be actively engaged in evolving and refining these principles through practice-based research. Empirical validation through controlled studies would help establish the generalisability of these principles and identify boundary conditions where they may not apply. Future systems should explore novel interaction paradigms that move beyond current conversational and shared-space models, potentially incorporating emerging technologies such as augmented reality, haptic interfaces, or brain-computer interfaces.

There is also opportunity to develop new metrics and evaluation frameworks specifically for co-creative systems. Current evaluation methods often focus on individual creativity or system performance, but co-creative systems require assessment of the collaborative relationship itself. The relationship between involvement and creative satisfaction needs deeper investigation across different contexts, as does the long-term impact of co-creative tools on skill development and creative identity.

As generative AI continues to evolve rapidly, these principles provide a foundation for thoughtful design that prioritises human agency and creative fulfilment. They represent a starting point for what should be an ongoing conversation between researchers, designers, and practitioners about how to create AI systems that enhance rather than replace human creativity. The challenge ahead lies not in perfecting these principles, but in continuously adapting them to new technological capabilities while maintaining focus on the fundamental goal of enabling meaningful human-AI creative collaboration.
