\chapter[Literature Review]{Literature Review}

The aim of this thesis is to investigate the development of effective human-AI co-creativity from the perspective of interaction design. This aim spans a multidisciplinary literature, including the psychology of human creativity, computational creativity, human-computer interaction and emerging empirical and theoretical literature on human-AI co-creativity. 

The present chapter covers this multidisciplinary literature with a primary focus on interaction design. More specifically, I use the following core question and three sub-questions as a navigational lens:

\begin{quote}
\textbf{Core Research Question:}\\
\emph{How can we design generative AI systems that act as effective co-creators, maintaining human agency while effectively leveraging the creative potential of this technology?}
\end{quote}

\begin{quote}
\textbf{Sub-Questions:}
\begin{enumerate}
    \item \textbf{R1:} \emph{How does interaction design influence the role that humans and AI play in creative production?}
    \item \textbf{R2:} \emph{What is the potential of modelling dialogue in interaction design to enable effective human–AI co-creativity?}
    \item \textbf{R3:} \emph{Which interaction design principles can guide the development of effective co-creative systems?}
\end{enumerate}
\end{quote}

This literature review is structured in two main parts. The first part establishes foundational concepts by defining human-AI co-creativity and creativity more broadly, before identifying the current gap in design principles for co-creative systems. The second part then addresses the three research questions in reverse order: beginning with design principles (R3), then exploring the potential for dialogic interaction (R2), and concluding with an analysis of roles in human-AI co-creative processes (R1). 

\section{Defining human-AI co-creativity}

In the previous chapter, I provided the working definition of co-creativity as:

\begin{quote}
\emph{A type of human-AI interaction involving creative contributions from both human and AI and where the outputs cannot be uniquely or primarily attributed to the creative behaviour of one of them.}
\end{quote}

This definition is informed by the work of \cite{Candy2002-ra} discussing human-human co-creativity as a closely woven interaction that produces outputs from symbiotic combination of actions, and from the work of Davis (2013), \cite{Davis2013-jy} who described human-computer co-creativity as an interaction where the computer is not just a rigid executor of commands but adapts dynamically, drawing on computational creativity algorithms to respond to the user. Since then, a growing literature frames human-AI co-creativity as a type of interaction that ultimately augments human creativity and can mitigate risks associated with the automation of creative work \cite{Yannakakis2014-zs, Kantosalo2020-zf, Rezwana2022-gg, Moruzzi2024-cq, Haase2024-yp, Lin2023-zq, Karimi2018-wi}. It has also been proposed as a type of interaction that can not only help humans be more creative, but computational creative algorithms be more creative \cite{Liapis2016-zt}. That is: the ultimate aim is that together, human and machine can produce more creative outputs than either could produce alone and where both are exercising creative behaviour. 

\section{Defining Creativity}

My discussion of human-AI co-creativity will benefit from establishing a working definition for creativity. However, defining creativity is not an easy task. Part of the complexity stems from the fact that when describing something as creative, we may be referring to at least one of four things: it can refer to a person (e.g., "Frida Kahlo was very creative"), a process (e.g., "my creative process"), a product (e.g., "this story is very creative"), or an environment (e.g., "a very creative city"). These four components were initially conceptualised by Rhodes \cite{Rhodes1961-od} as the 4Ps of creativity: Person, Process, Product, and Press, and today remain an influential framing for discussing creativity, and more recently, co-creativity \cite{Kantosalo2019-pz}. 

Notwithstanding the acknowledged complexity of such a wide-encompassing term, the scientific literature has largely converged to using The Standard Definition when discussing and measuring creativity. The Standard Definition provides a double constraint as a bar for creativity: something is creative if it's both considered \textbf{novel (or surprising)} and \textbf{valuable (or appropriate)} \cite{Amabile1983-lj, Sternberg1998-oz, Runco2012-mk, Boden2003-hk}. It follows from this definition that this double constraint could be applied to a Product, a Person, a Process or an Environment (Press). For example, a creative painting (Product) may be one that is both different (novel) to existing works and beautiful (if that is the value being applied). Similarly, a Person is one that produces such a work, a creative Process is one that this person employs and a creative environment in which this is produced and shared (Press). As such, a human-AI co-creative system is one that produces, as a result of meaningful contributions from human and machine, a novel and valuable output. 

A natural question emerges: can a computer by itself produce creative work, and is the Standard Definition sufficient to capture the richness of what is involved in creativity? Indeed, this has been a point of contention since the birth of computers, and it has been a more vivid debate since the inception of the field of artificial intelligence. Turing argued for the capacity of machines to produce novel things through their ability to surprise the human user when addressing the Lovelace Objection \cite{Turing1950-aq}. The Dartmouth Summer Research Project on Artificial Intelligence, where the term Artificial Intelligence was first used and which many consider as the genesis of AI research \cite{McCarthy1955-ls}, established “Randomness and Creativity” as one of the seven areas of research for the field. 

Simon and Newell, whose Logic Theorist is often cited as the first AI program \cite{Russell2016-oe}, argued that creative thinking is an extension of ordinary problem‑solving, navigating vast problem spaces through trial and error to find solutions that are both \textit{novel} and \textit{useful}\cite{Simon1967-nr}. Boden framed creativity, both human and computational, as movement within and transformation of “conceptual spaces” through combination, exploration, and transformation \cite{Boden2003-hk}. A human might move through conceptual spaces in their head based on ideas they have been exposed to. A computer may move through these spaces based on data it has been trained on, or in the possible application of rules. This framing of creativity as searching through conceptual spaces was formalised by Wiggins in his Creative Systems Framework, providing a mathematical account creativity as search within conceptual spaces  \cite{Wiggins2006-zd}.

In more recent times, Computational Creativity has grown as a robust field on its own, developing across a literature that seeks to formalise what it means for a computer to be creative, how this can be implemented in computer programs, how creative behaviour of computers can be measured \cite{Ritchie2007-jy, Colton2008-fh, Colton2011-uy, Maher2012-oj, Jordanous2012-kw}, as well as rich creative practices that employ computers both as tools, and as autonomous and collaborative creative agents \cite{Cohen1995-wt, Colton2015-qr, Perez-y-Perez1999-ma, Cope1992-pq, Reichardt1968-eo}. This interdisciplinary nature of computational creativity has been captured in the working definition for computational creativity provided by Colton and Wiggins \cite{Colton2021-bt}.

\begin{quote}
The philosophy, science and engineering of computational systems which, by taking on particular responsibilities, exhibit behaviours that unbiased observers would deem to be creative.
\end{quote}

While computational creativity was considered historically as a final frontier of artificial intelligence research \cite{Colton2021-bt}, today, empirical evidence shows that computers are increasingly showing creative behaviour according to the standard measures we use to measure human creativity. For example, computers are now able to perform at a similar or higher levels than humans in the Alternative Uses Test, which measures the ability of a person to produce a high number of novel and valuable uses for a given object \cite{Hubert2024-kv, Guzik2023-cl}. Computers have shown to be able to produce a wide variety of artefacts that human raters consider creative, and sometimes, prefer to those produced by humans, especially when they do not know it was produced by generative AI \cite{Alexander2024-pz, Wu2025-or, Kobis2021-bb}. 

This may be sufficient to acknowledge that computers are capable of producing creative outputs. However, some creativity researchers have rebuked this claim by arguing that creativity requires things other than the ability to produce novel and valuable outputs. Runco, one of the original contributors to the Standard Definition, acknowledged that “AI can be original, and its output is often useful,” but that \emph{authenticity} and \emph{intentionality} must also be present \cite{Runco2025-bu}, qualities he deems computational agents incapable of possessing. While this argument may appear as a case of merely moving the goalpost, a more benign reading may concede that Runco's argument is one of category. After all, he proposes that what we observe in computers should be better termed as \textit{artificial creativity}, and be distinguished from \textit{human creativity}. 

These arguments touch on a broader discussion on creativity, which seek to understand different forms that creativity may take across human and non-human systems. For example, a growing body of literature proposes creativity can exist in distributed complex systems such as societies and evolution. Under this view, natural selection can be considered as a creative process producing solutions to the problem of survival, even if this process is very different from that of human creativity \cite{Wagner2015-oj}. Bown proposes a distinction between \textit{adaptive creativity}, to refer to the kind that a human might engage in when trying to solve a problem with a clear defined goal and value criteria, and \textit{generative creativity}, which may refer to the kind that a non-human self-organising complex system may produce \cite{Bown2012-gg}. 

This discussion similarly extends conceptions of creativity as something that exists beyond the individual. While often, particularly popular and media descriptions of creativity view it as emanating from the genius of sole individuals, broader perceptions of creativity see it as a result of interaction between human and non-human agents. People create within contexts and environments, embedded within cultural norms. They use tools, language and musical scales created by other people. All of these elements exercise varied degrees of influence on the person, their process and their output. As such, some authors argue that creativity may be better understood as acting within \textit{networks of agency}, where agency is shared between multiple parties, rather than emanating from a sole source \cite{Brown2016-tc, Malafouris2008-xn}. 

In the case of human-machine co-creativity, the agencies between human and tool are blended and more equally shared, to a degree such that the term "tool" may not be adequate anymore \cite{Lawton2023-tb}. 

\section{The gap: a lack of principles for human-AI co-creativity}

I have established, albeit broadly, how humans and machines can be creative, and laid the ground to understand how they can be creative together. In the next sections, I will focus particularly on this issue from an interaction design lens. That is: how can we design AI systems that effectively co-create with users. 

While in other fields there are established principles and heuristics for designing effective human-computer interaction and tools that support creativity \cite{Nielsen1994-df, Amershi2019-vy, Shneiderman2020-je, Wright2020-nt, Bengler2012-jf, Resnick2005-fs}, the field of human-AI co-creativity lacks specific guidelines that capture the nuance and complexity of humans and machines blending creative agencies successfully. 

Historically, new advances in computational capabilities have required new interaction design principles. The transition from mainframes to personal computers led to the development of Apple's the Human Interface Guidelines in 1987, which have been updated with each new computational paradigm such as the internet and mobile computing. Similarly, the transition to generative AI as an underlying computational layer requires new guidelines for interacting with it. Already, the use of old interaction paradigms to interact with generative AI has led to notable limitations: what Koomen \cite{Koomen2025-eu} has termed the AI Horseless Carriage problem. Koomen draws a parallel between interacting with generative AI using old interaction paradigms with the phenomenon of early motor cars being designed simply as horseless carriages, rather than as new types of vehicles on their own. 

This does not mean, however, that existing work is not relevant: as we will see in the following sections, many of the shortcomings reported in human-AI co-creativity studies can be addressed with principles present in the existing literature. Moreover, any effort seeking to provide guidelines, principles and heuristics for human-AI co-creativity would greatly benefit from starting from this existing time tested-work on human-computer interaction. 

However, generative AI poses new specific challenges that often are at odds with previous design heuristics. An example is what Weisz et al. \cite{Weisz2024-io} terms \textit{generative variability}, where the same input may produce different results each time. In many cases, this is a feature, not a bug, of generative systems. However, it may stands at odds with design principles such as Nielsen's consistency \cite{Nielsen1994-df} of input-outputs. On the user side, advanced capabilities of new generation AI systems are beginning to lead to more over-reliance on these tools, which ultimately may hinder performance in the short term and lead to skill loss in the longer term \cite{Buschek2021-ks, Dell-Acqua2022-dy, Gerlich2025-as}. Buschek et al. \cite{Buschek2021-ks} described nine potential pitfalls when designing co-creative generative AI, including invisible boundaries of AI capabilities, lack of expressive interaction control, a false sense of proficiency, overwriting user work, agony of choice, unclear ownership of the work, and privacy risks related to training on user data. Many of these are not adequately addressed with existing principles and heuristics.

Consequently, some authors have proposed principles for interacting with generative AI. For example, \cite{Amershi2019-wu} proposed a set of Guidelines for Human-AI Interaction and Weisz et al \cite{Weisz2024-io} proposed a series of Design Principles for Generative AI systems. However, these systems focus on generative AI systems as a whole, and do not specifically deal with the intricacies of co-creativity. For example, one of Weisz et al's principles simply states: "Design for Co-Creativity", however, no specific directives are provided for enabling such co-creativity. Indeed, designing for co-creativity is a complex challenge in itself \cite{Buschek2021-ks}. 

\subsection{Frameworks and Taxonomies}

While there are no design principles for human-AI co-creativity, the literature has produced extensive work classifying and describing co-creative AI systems, in the form of taxonomies and frameworks. As early as 2019, Guzdial and Riedl provided an Interaction Framework for Studying Co-Creative AI \cite{Guzdial2019-gr} and Kantosalo's PhD dissertation provides one of the most detailed accounts for describing, evaluating and designing human-AI co-creativity in the context of poetry writing \cite{Kantosalo2019-pz}. 

More recently, Rezwana \cite{Rezwana2022-gg} proposed the Co-Creative Framework for Interaction Design (COFI), which provides an extensive account of the different possibilities for designing co-creative AI systems. Moruzzi and Margarido proposed a user-centered framework for human-AI co-creativity, which similarly describes in detail different dimensions to be considered when designing co-creative systems, which they propose should be controlled and personalised by the user \cite{Moruzzi2024-cq}. Haase and Pokutta developed a classification for different levels of creative collaboration between humans and AI, from simple task level automation to what they term full co-creation \cite{Haase2024-yp}. 

Lastly, the literature is rapidly producing empirical studies evaluating different ways in which interaction design affects aspects of human-AI co-creativity. As such, there is a ripe opportunity to critically analyse these findings and produce a theoretically grounded and empirically informed set of design principles for human-AI co-creativity. The intention of this review is to collate these findings and leverage the frameworks described above to interpret them, such that by the end of this thesis, a clearer picture of the interaction design principles that can contribute to effective human-AI co-creativity emerges. 

\subsection{The Challenge of Effective Co-Creativity}

A first challenge faced when seeking to understand what factors contribute to effective co-creativity arises in measurement. What defines effective co-creativity, in the first place? Currently, the metrics used to measure this can be broadly classified in two types. First, self-reported metrics that gather subjective user experiences, such as user satisfaction, enjoyment, creative self-efficacy, frustration and other similar evaluations. Second, observed metrics that assess task completion time, quality, creativity, and quantity of outputs, often rated by crowdsourced evaluators or experts \cite{Kim2021-fh, Kantosalo2019-pz, Rezwana2022-ui, Rezwana2023-gj, Lawton2023-tb}. Thus, effectiveness evaluations typically combine both process-oriented and outcome-oriented perspectives, encompassing both subjective and objective data.

It is worth noting that process-oriented evaluations do not always align with product-oriented evaluations. For example, a particular interface design may lead to higher third person ratings of creative writing outputs, but lower satisfaction and enjoyment of the user with the process and interaction \cite{Lee2022-rj}. 

Moreover, there remains a lack of standardised metrics or benchmarks for evaluating co-creative systems, reflecting broader methodological challenges already identified within computational creativity research \cite{Jordanous2012-kw}. Some researchers have sought to remedy this by proposing comprehensive, robust metrics and measurement frameworks across process and product \cite{Kantosalo2019-pz, Davis2016-te, Lawton2023-gd, Lee2022-rj}. 

However, my analysis of the literature revealed many of these standardised measurements are rarely used, and measurement is commonly idiosyncratic. This often leads to contradictory findings and lends itself to overly broad claims within the literature. For example, generalised assertions such as "AI enhances creativity" or "AI diminishes creativity" are common but problematic, and they are akin to claiming broadly that computers or the internet impact creativity positively or negatively. The specific nature of the interaction and targeted outcomes must be clarified to yield meaningful insights.

One illustrative example is a study titled "An empirical investigation of the impact of ChatGPT on creativity," published in Nature Human Behaviour \cite{Lee2024-vz}. The study reported that using ChatGPT during ideation tasks enhanced creative outputs compared to individual human ideation or using web search. Notably, the paper claimed human modification did not further improve the creativity of AI-generated ideas, and the authors suggested in some cases computers may act more effectively as autonomous creators. However, critical details regarding how participants interacted with ChatGPT were left unclear. On one hand, the paper states that humans only submitted one idea after selection. Arguably, this curation involves a form of modification and co-creative interaction in itself. Moreover, it is not clear how this selection was enabled. Did they use iterative ideation cycles, exploring different possibilities in a conversation, or did they simply select from a static drop-drown of options? Clarifying these interaction details is essential to make claims about the impact of human-AI interactions in creative outcomes.

Moreover, results may vary depending on the task, the expertise of the user and the stage of the creative process. For example, it has been found that one of the most common uses for generative AI is ideation and brainstorming \cite{Zao-Sanders2024-qo}. However, a study with professional writers found they regarded language models as less useful for ideation but more beneficial for feedback, translation, and rewriting tasks \cite{Chakrabarty2024-ov}.

When assessing the impact of human-AI interactions in creative contexts, it is also crucial to examine not only individual creativity but also creativity at a collective level. For example, Doshi and Hauser \cite{Doshi2023-dv} investigated the effects of using generative language models for ideation during short story writing. The study revealed that participants using AI generated more creative stories, as rated by external evaluators, compared to those who did not use AI, particularly benefiting less experienced writers. However, the study found that the stories generated with AI assistance, while rated as more creative than the non-AI assisted ones, were \textit{more similar to each other} when measured for semantic similarity, suggesting a collective homogenisation effect.

Indeed, concerns regarding such homogenisation and reduced originality has been found to be a key detractor for generative AI adoption in creative activities, with users commonly reporting concerns with the lack of originality, generic outputs, and clichéd styles \cite{Chakrabarty2024-ov, Chang2023-tv, Clark1998-yi, Ippolito2022-mf, Li2024-yh}.

So far, this section has outlined several key challenges in evaluating and designing for effective human-AI co-creativity. The following sections will examine how specific interaction design factors that can foster more effective co-creative outcomes across diverse metrics, tasks, and users. 

\section{Towards Design Principles for Human-AI Co-Creativity}

\subsection{Visibility of Creative Capabilities}

A critical factor influencing the effectiveness of human-AI interactions is users' understanding of the AI system: that is, what it can and cannot do.

A study by Dell’Acqua \cite{DellAcqua2023-og} involving consultants from a major firm undertaking complex, partly creative tasks, provides an illustrative example. Results indicated improved performance and efficiency when using an LLM for tasks within its known strengths, yet decreased performance when tasks exceeded where the capabilities of the model are less reliable, such as factual accuracy and mathematical reasoning. The authors describe this phenomenon using the concept of the "jagged technological frontier": inside the frontier, AI usage typically benefits performance; outside, it often detracts from performance. However, this frontier is usually unclear: this is what \cite{Buschek2021-ks} described as invisible boundaries, with model creators and users alike frequently uncertain of the system’s precise capabilities.

However, training and onboarding that educate users of AI's capabilities can be effective to maintain involvement and improved outcomes. For example, recent research has reported that increased reliance on language models has been associated with reduced critical thinking skills due to cognitive offloading and over-reliance \cite{Gerlich2025-as, Lee2025-dw}. However, a study by Essel et al \cite{Essel2024-qc} actually found improved critical thinking among students using LLMs after they received training about the model's appropriate use as a critical thinking tool.

These contrasting outcomes highlight that many negative effects associated with AI use stem from users’ overreliance on systems, driven by automation bias and inaccurate perceptions of AI capabilities. In a separate study, Dell’Acqua \cite{Dell-Acqua2022-dy} describes this as users "falling asleep at the wheel," overestimating AI capabilities, thus diminishing their engagement and effectiveness. Conversely, Dell’Acqua found that when users perceive the AI as less capable, they tend to rely more on their expertise, enhancing overall performance. Importantly, \textit{perceived AI capabilities} are different from \textit{actual capabilities}, and they are influenced by design decisions \cite{Moruzzi2022-tx, Lawton2023-tb}.

Consequently, effective co-creative systems must clearly communicate their capabilities and limitations to users \cite{Buschek2021-ks}. Achieving this clarity is challenging, particularly as AI models grow more complex and less interpretable. Explainable AI is an active field focused on this issue \cite{Zhu2018-zd, Llano2022-ti, Newn2020-mv, Shneiderman2020-je, Linardatos2020-uq, El-Assady2022-qc, Gomez2023-bp}. The task involves both technical challenges related to model interpretability, and aspects of interaction design. For example, El-Assady and Moruzzi \cite{El-Assady2022-qc} found that certain ways of communicating explanations may trigger biases and reasoning errors.

\subsection{Interaction Modes: Task-Divided vs. Mixed-Initiative}

Beyond visibility, the dynamic of the interaction itself significantly shapes the co-creative process. The literature often distinguishes between different modes of human-AI collaboration, broadly categorised as task-divided versus alternating or mixed-initiative approaches \cite{Kantosalo2020-nh, Kantosalo2016-nm}. In task-divided modes, human and AI perform distinct, often sequential, sub-tasks, potentially without operating on the same shared artifact simultaneously \cite{Kantosalo2016-nm}. For example, the AI might act as a 'subcontractor' generating content based on human specifications, or as a 'critic' evaluating human work \cite{Lin2023-zq}, or it may take on well defined responsibilities such as screening data before humans engage with it \cite{Jia2024-vp}. 

Conversely, alternating or mixed-initiative modes involve more dynamic, turn-taking interactions where both human and AI can contribute to and modify a shared artefact \cite{Kantosalo2020-nh, Kantosalo2016-nm, Lin2023-zq}. This may allow for more non-linear interactions, potentially fostering a stronger sense of partnership \cite{Davis2016-te, Zhou2024-vp}. Frameworks like COFI highlight dimensions within these modes, such as participation style (turn-taking vs. parallel), task distribution, timing, and mimicry \cite{Rezwana2022-gg}. Similarly, Gomez et al. identified interaction patterns ranging from simple AI-first/AI-follow assistance to more complex dialogic engagement and interactive adjustments \cite{Gomez2023-bp}.

Each of these patterns has distinct advantages and challenges. For example, a study assessing when and how AI enhances employee creativity found that task division in a context of sales calls, where AI screened clients such that human representatives only engaged with interested prospects, led to employees using more creative skills, crafting more creative pitches and reporting more job satisfaction \cite{Jia2024-vp}. However, task-divided approaches, particularly those involving delegation, can present a cognitively challenging load. Studies show that humans struggle to effectively delegate tasks to AI, often due to poor assessment of their own versus the AI's capabilities (metaknowledge), especially for difficult tasks \cite{Fugener2019-yz}. Interestingly, AI-driven delegation (where the AI delegates to the human if uncertain) can sometimes outperform human-led delegation \cite{Fugener2019-yz}. This suggests that while task division can be efficient, designing effective delegation mechanisms requires carefully ensuring the human knows exactly which tasks they are better off assigning to the AI, and similarly providing visibility of the AI's actual capabilities \cite{Dell-Acqua2022-dy, Fugener2019-yz}.

Mixed-initiative approaches, particularly those enabling bidirectional communication and AI initiative, appear to be preferred by users in creative contexts and in tasks that require higher complexity. In these contexts, they tend to lead to higher ratings of collaboration, support, and creativity \cite{Lin2023-jd}. For example, allowing the AI to critique, ask questions, or generate content proactively was valued more than simple prompt-response interactions \cite{Lin2023-jd}. A study comparing interaction models found that those involving iterative contributions from both human and AI yield higher creative performance and maintains user creative self-efficacy better than models where the human primarily edits AI output \cite{McGuire2024-im}. The authors concluded that people "must occupy the role of a co‑creator, not an editor, to reap the benefits of generative AI in the production of creative works". \cite{McGuire2024-im}.

However, mixed-initiative systems also introduce challenges. They can increase complexity and potentially lower usability if not carefully designed \cite{Lin2023-jd}. Furthermore, the dynamics of turn-taking need careful handling; explicit turn-taking in improvisational contexts requires low latency and smooth interactions \cite{Winston2017-nb}, highlighting the need for clear turn indicators and fluid transitions \cite{Shakeri2021-dx}. Designing for mixed initiative requires balancing AI agency with user control, enabling a fluid partnership where roles can shift dynamically \cite{Zhou2024-vp, Lawton2023-gd}.

Ultimately, both task-divided and mixed-initiative interactions can be considered co-creative depending on the level of AI agency and its contribution to the creative process. Task division often aligns with AI as a tool or 'subcontractor', while mixed-initiative interaction enables AI to function more like a 'teammate' \cite{Lin2023-zq}. The optimal mode depends on the specific task, user goals, expertise, and the desired balance between efficiency, control, and creative exploration \cite{Moruzzi2024-cq, Ding2024-ja, Weisz2024-io}.

\subsection{Expressive creative control}

While text-based interfaces have become dominant for interacting with LLMs like ChatGPT and text-to-image systems, research indicates that relying solely on text prompts can be limiting, especially for visually oriented creative tasks \cite{Park2024-gw, Tholander2023-rv, Verheijden2023-gn}. Designers, for instance, often think visually and struggle to translate their ideas into effective text prompts \cite{Park2024-gw, Peng2024-tr}. This highlights the need for interaction modes that offer more expressive creative control. 

Applying principles of Direct Manipulation (DM) \cite{Shneiderman1997-pu, Shneiderman1997-tv} to human-AI interaction offers a promising direction. DM emphasises continuous visual representation, physical actions (like pointing and dragging) instead of complex syntax, and rapid, reversible operations with immediate feedback. These principles aim to enhance user comprehension, predictability, and control. Masson et al. (2024) demonstrated how DM concepts can be applied to LLMs through DirectGPT, an interface for vector graphics editing \cite{Masson2024-nt}. By allowing users to select parts of the graphic to define the scope of an LLM command or drag objects to serve as arguments, DirectGPT reduces reliance on complex textual descriptions and enhances control \cite{Masson2024-nt}. 

Graphical User Interface (GUI) elements can provide more structured ways to control AI generation beyond free-form text. Examples include sliders to adjust parameters, buttons for specific actions, or templates for structuring prompts \cite{Ding2024-ta, Chang2023-tv, Moruzzi2024-cq}. Prompt templates, for instance, can encapsulate specific styles or generation strategies, making them reusable and aiding consistency \cite{Chang2023-tv}. Visual interfaces enabling direct exploration of a model's latent space, such as mapping semantic axes onto a 2D canvas, have been shown to support creative ideation (both divergent and convergent thinking) better than text-only prompts for tasks like fashion design \cite{Davis2024-ml}. 

Richer visual interfaces can also enhance visibility about the systems behaviour, helping users build more accurate mental models of what the AI can do and how to control it, potentially enhancing interaction with generative AI \cite{Weisz2024-io, Amershi2019-vy}. For example, visualising prompt token commonness can help users craft more unique prompts \cite{Chang2023-tv}, while graphical controls make the effects of parameters more tangible \cite{Davis2024-ml}. 

Multimodal interfaces which allow users to input modalities besides text can also enhance expressive creative control. For example, visual designers benefit from interfaces that accept visual inputs like sketches, reference images, or mood boards alongside text \cite{Park2024-gw, Peng2024-tr}. DesignPrompt, for example, allowed users to compose prompts using images, colour palettes, semantic tags, and text, with controls to weight each modality's influence \cite{Peng2024-tr}. This multimodal approach led to users feeling more in control, better able to express intentions, and achieving desired results more efficiently compared to text-only interaction \cite{Peng2024-tr}. Similarly, tools integrating AI image generation into online whiteboards combined with sketching capabilities provide more nuanced guidance than text alone \cite{Verheijden2023-gn}.

Tangible and embodied interfaces offer another avenue for expressive control. Mimetic Poet, a physical device using physical word magnets to construct prompts for an LLM, fostered deeper reflection and engagement through tactile interaction and a slower pace \cite{McCormack2024-gv}. Similarly, the Cobbie robot arm, which sketched physically on paper alongside a human, enhanced perceived collaboration and engagement compared to a screen-based agent, although it also increased distraction \cite{Lin2020-ji}. These examples suggest that physical embodiment and tangible interaction can make the co-creative process feel more grounded and meaningful \cite{McCormack2024-gv, Lin2020-ji}. In music, physical AI-augmented instruments fostered what the authors termed 'symbiotic virtuosity', where human and AI adapted to each other, and where the human increasingly developed skills to control the instrument \cite{Blanchard2024-jz}. Giving users the opportunity to develop virtuosity and skill is crucial for successful creative tools \cite{Lee2024-tu}, echoing Resnick's et al Principle of "high-celings" for creativity support tools \cite{Resnick2005-fs}. 

However, achieving true expressive control remains challenging at the level of models and interfaces. For example, a key limitation of current LLMs is maintaining consistent authorial voice or character style, often defaulting to generic, cliched or robotic tones \cite{Ippolito2022-mf, Yuan2022-kb, Chakrabarty2024-ov}. Professional writers, in particular, find this hinders the integration of AI outputs \cite{Ippolito2022-mf, Grigis2024-pf}. While this is largely the result of work on alignment for models to have a particular helpful personality and avoid the generation of harmful content \cite{Anthropic2024-ne, Ouyang2022-af, Bai2022-ec}, Koomen \cite{Koomen2025-eu} argues this also largely stems from the interface layer. He provided several examples of how simple interface changes, such as allowing the users to predefine a reusable voice as a custom prompt can lead to more style-aligned outputs. Regardless, providing users the ability to meaningful control tone, style, aesthetics and artistic voice remains an open research area critical for expressive co-creation.

\subsection{Bidirectional Communication}

Effective communication is fundamental to successful collaboration, both human-human and human-AI \cite{Mamykina2002-lm, Rezwana2022-gg}. In the context of co-creative AI, communication encompasses not only how humans convey intent to the AI (e.g., via prompts, GUI actions) but also how the AI communicates back to the human.

Research increasingly highlights the importance of bidirectional communication. Studies comparing AI systems that only receive input versus those that also provide feedback or explanations have found that enabling AI-to-human communication significantly enhances user engagement, perceived collaboration quality, and positive perceptions of the AI partner (making it seem more intelligent, reliable, and personal) \cite{Rezwana2023-gj, Rezwana2022-ui}. Systems lacking AI-to-human communication channels are perceived more as passive tools than active collaborators \cite{Rezwana2023-gj}. Frameworks like COFI emphasize the need to explore richer communication channels beyond simple commands, including AI providing feedback, explaining reasoning, or expressing status \cite{Rezwana2022-gg}.

Conversational interfaces (chatbots) offer a natural modality for bidirectional communication \cite{Coenen2021-ym, Zhang2021-ej}. They allow users to express intent flexibly using natural language and potentially receive clarifying questions or explanations from the AI \cite{Coenen2021-ym}. However, relying solely on conversation can be limiting \cite{Tholander2023-rv}, and challenges remain in handling ambiguity, correctly conveying the capabilities and limitations of the model (visibility) and ensuring back-end models can fulfill diverse requests \cite{Zhang2021-ej}.

Explainability and bidirectional communication intersect, since explanations can be a form of AI-to-human interaction. However, it does not only need to happen via conversation, but it can also take the form of visual examples, GUI elements and be delivered proactively or on-demand \cite{Zhu2018-zd}. Research suggests that providing explanations for AI suggestions can improve human-AI collaborative performance \cite{Vaccaro2024-ne}, and users often prefer explanations to be available on demand \cite{Oh2018-mu}.

It is worth noting that, AI to human communication may also increase anthropomorphism, potentially leading to unrealistic expectations or ethical concerns \cite{Rezwana2023-gj, Rezwana2022-ui}. Furthermore, the way AI communicates can subtly influence users; AI suggestions framed with a particular opinion can shift users' written output and underlying attitudes, often without their awareness \cite{Jakesch2023-ks}. This highlights the need for careful design of AI communication to be not only informative and engaging but also transparent and responsible \cite{Jakesch2023-ks, El-Assady2022-qc}.

\subsection{Interaction Through and About the Creation}

Effective co-creativity often involves more than just exchanging content; it requires interaction \textit{through} the creation process itself, fostering an implicit shared understanding and workspace. This aligns with theories of participatory sense-making, where meaning emerges through mutual co-regulation and interaction dynamics within a shared context \cite{Davis2016-te}.

Systems enabling interaction within a shared workspace, like collaborative mood boards \cite{Koch2020-gx} or drawing canvases \cite{Davis2016-te, Lawton2023-tb}, facilitate this process. Features like awareness mechanisms (seeing collaborator actions) \cite{Koch2020-gx} and the ability for both human and AI to modify the shared artifact support a sense of joint creation \cite{Lawton2023-tb}. Physical co-presence, such as a robot sketching on the same piece of paper, can further enhance the feeling of shared space and collaboration \cite{Lin2020-ji}.

On the other hand, and related to the previous discussion on communication, interaction \textit{about} the creation can involve meta-level communication regarding goals, evaluations, or process \cite{Rezwana2022-gg, Bown2020-oc}. AI systems capable of critiquing designs based on principles \cite{Zhou2024-vp} or providing feedback on user actions \cite{Davis2016-te} engage in this type of interaction. Tools that automatically extract semantic tags or generate reflective summaries based on the created content also support interaction about the creation, helping users articulate and synthesise ideas \cite{Koch2020-gx}.

Enabling the AI to ask clarifying questions is another form of interaction about the creation, helping to bridge the semantic gap and align human intent with AI understanding \cite{Bown2020-oc, Coenen2021-ym}. This moves beyond simple command-response towards a more dialogic process where human and AI negotiate meaning and direction \cite{Bown2020-oc, Lin2023-jd}.

Developing AI partners that can engage in both generating content (interaction through) and discussing the process, goals, and quality (interaction about) within a shared context appears important for achieving deeper levels of co-creative partnership \cite{Davis2016-te, Bown2020-oc, Zhou2024-vp}.

\subsection{Support for Different Stages within the Process}

Creative processes are typically non-linear and involve distinct stages, such as preparation, ideation, incubation, illumination, evaluation, and refinement \cite{Wallas1926-ky, Design-Council2004-fv}. Effective co-creative systems should ideally support users across multiple stages, tailoring interactions appropriately.

Current generative AI tools are often used opportunistically across different stages \cite{Li2024-yh}. Research indicates varying effectiveness depending on the stage. For instance, many studies find generative AI useful for early-stage ideation and brainstorming, helping users overcome blocks and explore possibilities \cite{Calderwood2020-gg, Clark2018-yf, Wan2023-he, Mirowski2023-oz, Doshi2023-dv}. AI can provide diverse stimuli \cite{Haase2023-mz} or act as a "second mind" offering alternative perspectives \cite{Wan2023-he}. However, some professional writers found LLMs less helpful for initial planning/ideation compared to later stages \cite{Chakrabarty2024-ov}, suggesting user expertise influences preferred stages for AI intervention.

AI assistance is also frequently applied during 'translation' or implementation stages, generating details, elaborating ideas, drafting text or code, or creating visualisations \cite{Chakrabarty2024-ov, Yuan2022-kb, Lee2024-vz, Palani2024-on}. LLMs seem particularly adept at improving the articulateness and cohesion of ideas \cite{Lee2024-vz}.

Support for evaluation and review stages is another emerging application. AI can act as a 'critic' providing feedback based on internal models or criteria \cite{Lin2023-zq, Zhou2024-vp}, or serve as a 'beta reader' \cite{Ippolito2022-mf, Chakrabarty2024-ov}. 

Designing systems that explicitly support transitions between stages, perhaps adapting the interaction mode or AI role accordingly, is a promising approach \cite{Wan2023-he, Ding2024-ta}. For example, an AI might be more proactive and generative during ideation but shift to a more critical or refining role later on. Systems like Dramatron attempt to scaffold the entire process hierarchically (log line -> outline -> dialogue) \cite{Mirowski2023-oz}, while other frameworks propose allowing users to configure AI behaviour based on their current needs \cite{Moruzzi2024-cq}. Recognising and supporting the distinct needs of different creative stages aligns with established principles of tools that support creativity \cite{Resnick2005-fs, Weisz2024-io}.

\subsection{Orchestrating Multiple Tools in Creative Workflows}

Contemporary creative workflows rarely rely on a single tool. Instead, practitioners often act as 'orchestrators', skillfully combining multiple specialized tools—including various generative AI models alongside traditional software—to achieve their creative goals \cite{Palani2024-on}. This modular approach is particularly evident in complex domains like songwriting, where teams combine different AI models for lyrics, melody, harmony, and timbre generation \cite{Huang2020-fh, Uitdenbogerd2023-no}.

This shift towards orchestration reflects both the specialized capabilities of different AI models and the need to integrate AI assistance into established practices \cite{Palani2024-on, Park2024-gw}. However, managing these multi-tool workflows presents significant challenges \cite{Huang2020-fh, Palani2024-on}. Practitioners face friction in transferring data and context between tools, lack fine-grained control across the entire pipeline, and struggle with evaluating outputs from diverse sources \cite{Palani2024-on}. The cognitive load of selecting, prompting, integrating, and curating outputs from multiple AI systems can be substantial \cite{Huang2020-fh, Uitdenbogerd2023-no}.

Therefore, a key opportunity for interaction design lies in creating systems that explicitly support this orchestration role \cite{Palani2024-on}. This could involve developing meta-platforms that integrate various AI services, designing AI agents capable of coordinating multiple backend models based on user intent \cite{Zhang2021-ej, Gottweis2025-kc}, or ensuring smoother integration of AI features into existing professional software via plugins or APIs \cite{Park2024-gw, Huang2020-fh}. Integrating AI capabilities within familiar collaborative environments, such as online whiteboards or chat platforms, can also lower adoption barriers and streamline workflows \cite{Verheijden2023-gn}.

Supporting these interconnected workflows requires designing for modularity, interoperability, and efficient management of generated assets across different tools \cite{Huang2020-fh, Palani2024-on}. Addressing the integration challenges and supporting the human role as orchestrator is crucial for enabling the effective use of generative AI within complex, real-world creative processes.

\section{The potential for dialogic interaction}

In the previous section, I reviewed the literature exploring interaction design factors that emerge as relevant for effective human-AI interaction. In this section, I turn my attention to a specific mode of human-AI interaction which I term here as dialogic interaction.

Dialogue is widely considered as a mechanism that humans use to form common meanings and align on goals, and which is crucial for effective collaboration \cite{Bohm1996-fo}. In human-machine collaboration, the need for mechanisms that enable the formation of common understandings has been recognised \cite{Dafoe2021-in}. As such, dialogue has emerged as a potential mode of interaction, and since early work on human-computer interaction, authors have proposed that human computer interaction may benefit from modelling dialogue \cite{Hayes1983-ca}, particularly in the context of mixed-initiative systems and co-creative systems \cite{Allen1999-sr, Yannakakis2014-zs, Deterding2017-wh}. However, dialogue, or dialogic interaction, is yet to be formalised as both a theoretical concept and an actionable concept for interaction design. 

In 2020, \cite{Bown2020-oc} presented a speculative exploration of dialogue in human-computer co-creation, defining it as an interaction in which both actors influence each other in an iterative process towards the creation of an output. Importantly, they defined dialogue as comprising both language-based conversation (\textit{dialogue about creative artefacts}) as well as non-linguistic dialogue that emerges through the exchange of suggestions and changes (\textit{dialogue through creative artefacts}).

More recently, a recurring theme in recent literature is the critique of simple linear interaction models with generative AI, where the human issues a command or prompt and the AI delivers an output \cite{Zhou2024-vp, Lin2023-jd, Tholander2023-rv}. On one hand, these interaction models do not capture the iterative nature of creative work. On the other hand, the variability and low-predictability of one-off generations can lead to interactions with generative systems to be described as slot-machines rather than co-creators \cite{Dylan2023-ma}. In contrast, there is growing interest in designing what can be understood as dialogic interaction sometimes referred explicitel as such, and sometimes describes merely as a back-and-forth process characterised by mutual influence, iterative refinement, and feedback loops \cite{Bown2020-oc, Gomez2023-bp, Wang2021-uy, Zhou2024-vp, Ghajargar2022-af, Feldman2017-ip}.

Empirical studies suggest that users value and benefit from these more reciprocal interactions in certain contexts. Systems enabling iterative interactions, where both human and AI can initiate diverse actions like generating, editing, critiquing, or querying, can lead to broader exploration, higher-quality results, and greater user satisfaction compared to linear, human-led prompting in certain cases \cite{Zhou2024-vp, Lin2023-jd}. Enabling bidirectional communication, where the AI provides feedback, explanations, or status updates, can enhance perceived collaboration, engagement, and the perception of the AI as an intelligent partner \cite{Rezwana2023-gj, Rezwana2022-ui}. Users offer express preference for systems offering multiple communication channels (e.g., critique, query, generation) and the ability to engage in turn-taking dialogue in complex creative activities \cite{Lin2023-jd}.

For example, Zhou et al. (2024) directly compared a linear baseline tool with a prototype supporting nonlinear, mixed-initiative interaction for poster design \cite{Zhou2024-vp}. OptiMuse allowed both human and AI to initiate actions like generation, editing, critique (with explanations), and querying, using multiple channels (text, sketch, gesture). Their comparative study found that this nonlinear, mixed-initiative approach led designers to explore more variations, achieve higher-quality results rated by experts, and report greater satisfaction and collaboration compared to the linear model.

Similar findings were provided by Lin et al. \cite{Lin2023-jd}, who used hypothetical scenarios to gauge user preferences for different co-creative story writing systems. Their findings indicated a significant preference for systems that enabled more communication channels beyond simple commands, particularly those allowing AI initiative (critique, query, generation) and supporting turn-taking dialogue. While such richer interactions were perceived as more supportive and collaborative, the study also noted a potential trade-off, as these more complex systems were sometimes rated lower on usability, suggesting a need to balance interaction richness with ease of use.

It is also worth noting that the the feedback loops inherent in dialogic interactions may also carry risks of self-reinforcing feedback loops leading to undesirable outcomes. In a series of studies with 1,401 participants, \cite{Glickman2024-zh} found that a feedback loop of human–AI interactions altered processes underlying human perceptual, emotional and social judgements, subsequently amplifying biases in humans. Another study by \cite{Jakesch2023-ks} found that co-writing with opinionated language models affected user's views on social issues \textit{after} the interaction. 

Nonetheless, the literature shows potential of dialogic interaction lies in providing a model in which human and AI are closely enagaged, which often leads to more highly rated interactions, a sense of collaboration, iterability, correction and clarification, and it may me an effective interaction model to address challenges related to users "falling asleep at the wheel".

\section{Roles in Human-AI Co-Creative Processes}

A central question in designing for human-AI co-creativity concerns the respective roles that humans and AI can effectively assume within the creative process. The literature reveals a wide spectrum of possibilities, ranging from AI acting as a simple tool under strict human command to more dynamic partnerships involving shared initiative and agency \cite{Moruzzi2022-tx, Haase2024-yp, Guzdial2019-gr, Lin2023-jd}. Understanding these roles is crucial, as the framing and functionality of the AI significantly impact user perception, interaction dynamics, creative outcomes, and even feelings of authorship and self-efficacy \cite{Guzdial2019-gr, Lawton2023-tb, McGuire2024-im, Lehmann2022-kr}.

\subsection{AI Roles}

\subsubsection{AI as Tool, Assistant, or Subcontractor}

Perhaps the most common conceptualisation positions the AI as a tool or assistant that performs specific, well-defined tasks upon human request \cite{Lubart2005-zi, Norman1994-kz}. In this model, often aligned with Human-Centred AI principles advocating for high human control \cite{Shneiderman2020-je}, the AI acts akin to Lin and Riedl's (2023) 'Computer-as-Subcontractor' \cite{Lin2023-jd} or Haase et al.'s (2024) 'AI Task Specialist' \cite{Haase2024-yp}. Examples abound: AI generating text summaries \cite{Tholander2023-rv}, creating variations on a design \cite{Kim2021-fh}, drafting content based on outlines \cite{Mirowski2023-oz, Lee2024-vz}, generating code snippets, or automating tedious parts of a workflow \cite{Li2024-yh}. Users typically initiate the interaction and provide explicit instructions \cite{Oh2018-mu}. Across the literature, users currently view AI primarily in this assistive role, particularly professionals using them in specialised activities \cite{Li2024-yh, Yuan2022-kb}. 

\subsubsection{AI as Inspiration Source or Idea Generator}
Another prevalent role sees AI functioning as a source of inspiration or a brainstorming partner, helping users overcome creative blocks or explore new possibilities \cite{Calderwood2020-gg, Wan2023-he}. This aligns with the 'Computer-as-Muse' concept \cite{Lubart2005-zi}. AI can provide unexpected stimuli, such as novel image combinations \cite{Haase2024-yp, Kim2023-zq}, alternative textual phrasings \cite{Clark2018-yf, Doshi2023-dv}, or surprising plot twists \cite{Yang2022-vs, Ghajargar2022-af}. Calderwood et al. observed novelists using AI suggestions not just for text completion but also as an 'antagonist' to clarify their own thinking or as a creative constraint \cite{Calderwood2020-gg}. Users often value the AI's ability to introduce novelty or randomness \cite{Yang2022-vs, Bougueng-Tchemeube2023-nm}. However, relying on AI for inspiration carries challenges; Wadinambiarachchi et al. (2024) found that exposure to AI-generated images during visual ideation significantly increased design fixation, leading to less novel and varied ideas compared to unassisted ideation, suggesting interaction design must carefully manage how inspirational stimuli are presented \cite{Wadinambiarachchi2024-jn}. Similarly, in a study by Chakrabarty, \cite{Chakrabarty2024-ov}, professional writers expressed less usefulness of AI as an ideation tool compared to other tasks.

\subsubsection{AI as Collaborator or Partner}
Moving towards more reciprocal interaction, AI can be framed as an active collaborator or teammate \cite{Lin2023-jd, Guzdial2019-cv}. This involves mixed-initiative interaction where the AI might suggest actions, ask clarifying questions, or build upon human contributions in a turn-taking fashion \cite{Lin2023-zq, Zhou2024-vp, Davis2016-te}. Systems enabling bidirectional communication foster this sense of partnership \cite{Rezwana2023-gj}. Users interacting with such systems may perceive the AI as having agency \cite{Lawton2023-tb, Yang2022-vs}, sometimes anthropomorphising it \cite{Oh2018-mu, Ghajargar2022-af}. Guzdial et al. (2019) found designers adopted varied stances towards their AI game level editor, perceiving it as a friend, collaborator, student, or manager depending on their style and the AI's behaviour \cite{Guzdial2019-gr}. A model of "true co-creation", as described by McGuire et al. (2024) was found to maintain creative self-efficacy and produce outputs that outperformed scenarios where humans merely edited AI output \cite{McGuire2024-im}.

\subsubsection{AI as Critic or Evaluator}
Across the literature, AI was also found to often assume the role of a critic, providing feedback on human work or intermediate results \cite{Lin2023-zq}. This might involve evaluating design drafts based on aesthetic principles \cite{Zhou2024-vp}, offering suggestions for improving text \cite{Chakrabarty2024-ov}, or acting as a beta reader for stories \cite{Ippolito2022-mf}. This role requires the AI to possess evaluative capabilities aligned with the creative domain and user goals.

Beyond a critical stance, receiving immediate feedback from AI might help maintain creative flow. In his influential theory of flow, Csikszentmihaly \cite{Csikszentmihalyi1990-hu} proposed receiving immediate feedback, particularly related to the progression towards a goal, as one of the conditions for maintaining flow. Flow involves a psychological state of full immersion that can enhance creative processes. Thus, AI-as-feedback provider, helping the user stay offers a promising, yet still relatively unexplored role. 

\subsubsection{AI as Leader, Coach or Scaffolding}

In some contexts, particularly education or structured problem-solving, AI might act as a leader or coach, proactively guiding the user through a process \cite{Zhong2024-ij}. Kim and Tan (2023) explored repurposing AI as a writing tutor using Socratic questioning to foster critical thinking \cite{Kim2023-wt}. Providing a scaffolding throughout a creative process, particularly for novices has been increasingly explored in the literature, with promising outcomes \cite{Yuan2022-kb, Fan2019-qq, Ding2024-ta, Long2019-lw, Louie2020-aq, Ippolito2022-mf, Wadinambiarachchi2024-jn}. This scaffolding can happen both in conversation, or in interactive GUI elements that guide the user through stages of the creative process, aligning with the principle of providing support through different stages identified in the previous section. 

\subsection{Human Roles in Co-Creativity}
Correspondingly, humans adopt various roles when interacting with co-creative AI. The most commonly observed role in the literature was that of Prompter or Director, setting goals and providing initial instructions \cite{Oh2018-mu, Wan2023-he}. As AI generates outputs, the human often acts as Curator, Selector, and Editor, applying judgement to evaluate, filter, modify, and integrate AI contributions \cite{Hitsuwari2023-tw, Wu2025-or, Huang2020-fh}. This curatorial role is crucial, as studies show human-AI collaboration yields superior results when it combines AI's generative capabilities with human aesthetic sense and contextual understanding \cite{Hitsuwari2023-tw, Wu2025-or}. When managing multiple AI tools, humans become Orchestrators \cite{Palani2024-on}. In more integrated systems, humans function as Collaborators, engaging in dialogue and mutual adaptation with the AI \cite{Lawton2023-tb, Wan2023-he}. In workflows emphasising verification and quality assurance, the human role has been described as a Steward \cite{Lee2025-dw}.

Across nearly all these configurations, human judgement, goal-setting, critical evaluation, and refinement remain influential in the effectiveness of co-creative systems \cite{Li2024-yh, Hitsuwari2023-tw, Sarkar2023-ee}. Even as AI capabilities advance, the human typically retains ultimate control and responsibility for the creative outcome \cite{Shneiderman2020-ue, Li2024-yh}. The effectiveness of the interaction therefore largely hinges on designing interactions that allow the human to assume these roles effectively: vetting and curating outputs, while exercising meaningful and expressive control. More broadly, clear understanding and definitions of roles can enable co-creative systems that leverage the strengths of both human and AI, supporting a interplay between them \cite{Guzdial2019-cv, Moruzzi2024-cq, Weisz2024-io}.

\section{Conclusion}

This literature review investigated interaction design factors influencing effective human-AI co-creativity, guided by questions on design principles (R3), dialogic interaction (R2), and agent roles (R1). The analysis highlights a lack of established, specific design principles for co-creative systems, although crucial factors are emerging from empirical studies and theoretical frameworks. These include the importance of AI capability visibility, expressive user control mechanisms extending beyond text prompts, the dynamics of mixed-initiative versus task-divided interaction modes, bidirectional communication strategies, support across distinct creative process stages, and facilitating the orchestration of multiple tools. The literature identifies diverse, complementary roles for both humans (e.g., prompter, curator, orchestrator) and AI (e.g., tool, muse, collaborator, critic), highlighting that human judgement, involvement and curation remain central to effective outcomes. 
