\chapter{Abstract}

Recent progress in generative artificial intelligence opens the possibility of human and machine co-creativity; however, realising this largely hinges on yet unanswered questions at the interaction layer. Crucially: how can interactions between humans and computational intelligence be designed such that their unique forms of creativity are mutually enhanced and blended, while human agency is maintained? Addressing this constitutes the core aim of my thesis.

While numerous interaction design principles exist in the field of human-computer interaction, which have emerged in response to the needs of new computational paradigms, no such principles exist yet for human-AI co-creativity. This thesis combines an analysis of emerging literature with original interaction design and creative practice-led research to fill this gap. 

Co-creativity requires mutual influence and understanding. However, current linear and request-based human-computer interaction design paradigms are limited in affording this. I argue that modeling dialogue can better support this. Consequently, I develop a theoretical framework for dialogic co-creativity where human and computer iteratively interact through and about a common creation.  I then used this framework as a navigational lens throughout three studies. 

First, in Chapter 4, I developed a co-creative writing that implements a dialogic interface supporting interaction \textit{through} and \textit{about} the writing, integrating a conversational space and a collaborative text editor. Across two user studies, I show this interface leads to greater user involvement and perceived agency, compared to chat-only interfaces. 

In Chapter 5, I describe a case study with a nationally printed magazine in Australia, where I explore the potential and challenges of image-based generative artificial intelligence to support real-world creative workflows. Although new possibilities not afforded by existing technologies were succesfully materialised into outputs, three crucial challenges are currently present: a lack of generative consistency, limited stylistic and structural control, and inadequate support for iterative creative workflows. 

Lastly, in chapter 6, I describe the creation of two generative public art installations leveraging large language models to translate real-time data feeds into a soundscape. These case studies discuss the potential and challenges for AI to assume novel roles that humans cannot assume. On one hand, the unpredictability of these systems makes them difficult to steer towards human creative intentions. On the other hand, this may the current price to pay for systems with the potential to lead works in new creative directions.  

In the final chapter, I argue that interaction with artificial intelligence is largely leading to users primarily assuming roles at the "intentional space" of goals and ideas, while the AI primarily assumes creative execution roles at the â€œaction space". This is primarily the consequence of interaction design that positions the user as a requester and the AI as an an executor. As a result, users become increasingly detached from the creative process. This leads to what I describe \textit{severed creative agency}: a disconnect between creative intention and action, which can lead to reduced user involvement, erosion of skills, and reduced intrinsic enjoyment in creative processes.

As the core contribution, I provide a set of 11 actionable design principles for creating more effective co-creative AI systems, derived from the dialogic framework established in chapter 3, informed by the literature review and subsequent original research. They are organised around the dimensions of Iteration, Communication, Collaboration, and Integration. 

This thesis contributes an understanding for how interaction designers, developers, researchers and organisations can develop co-creative systems with confidence. It is also my hope that it is useful for artists and practitioners, inspiring creative possibilities at the intersections with other intelligences.